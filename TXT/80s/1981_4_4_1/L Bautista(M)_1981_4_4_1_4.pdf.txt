MODELO II DE EISENHART
UNIVERSIDAD DE DORMUND ALEMANIA FEDERAL
Motivación.
Uno de los problemas al que con más frecuencia debe enfrentarse un estadístico que trabaje en la práctica es el recibir datos obtenidos con bastante esfuerzo y a altos costos con la misión de extraer de ellos una cierta o la mayor información estadística posible. El trabajo de encontrar "buenos" estimadores o de realizar pruebas de hipótesis "óptimas" es bastante elemental cuando estos datos provienen de un modelo de diseño de experimentos conocido y "limpiamente" realizado, pero lamentablemente no es ésta la generalidad. En la mayoría de los casos los datos provienen de modelos no conocidos, no completamente ortodoxos y el estadístico es el encargado de aplicar métodos, como el aquí expuesto, para obtener lo que de él se exige.
A nivel teórico representa este artículo un avance importante en la teoría de los modelos linea les y el diseño de experimentos, aunque lo que aquí se expone tiene una edad mayor de 20 años y científicamente tan solo un caso especial de métodos más sofisticados y modernos(1977-1978) constituye una buena manera de comenzar a familiarizarse con los modelos lineales.
Por último quiero aclarar que este no constituye un trabajo original (a nivel científico) sino un resumen sencillo y sin demostraciones del trabajo realizado en 1961 por Graybill y Hultquist. Este artículo fué el manuscrito en mi charla del 25 de Sep./80 en la U.Nal.
Supuestos
Nota: En la práctica los modelos comúnmente más utili^
zados satisfacen el modelo y las suposiciones plantea^
das, por ejemplo: los modelos de diseño de experimentos
con igual número de subclases. Modelos cruzados de tamaño n con o sin interacción. Modelos anidados de tamaño n. Modelos de parcelas divididas.
ademnás si olvidamos los supuestos. el modelo de regresión es un modelo II de Eisenhart.
Problema: El problema a resolver es encontrar estadísticos que estimen la constante; las distribuciones de estos estadísticos y c) las restricciones que se deben imponer al modelo para que los estimadores sean "óptimos" es decir insesgados y únicos de mínima varianza.
Desarrollo. Dado que existe independencia estocástica y distribución normal de los B. nuestro propósito es expresar esta forma cuadrática en forma tal que podamos distinguir la pertenencia de esta familia a la clase exponencial.
Teorema 1 . (Alg.Lin.) Sea s la cantidad de valores propios entre sí de la matriz w entonces uno mayor que k más 2.
Teorema 2. (Alg. Lin.) Si son matrices simétricas que conmutan 2 a 2 entonces existe una matriz ortogonal p tal que PA sub IP prima iguala de sub i donde d sub i es la matriz diagonal conformada por los valores propios de a sub i.
Entonces podemos diagonalizar la matriz W
Veamos ahora que según nota del supuesto 3 esta matriz tiene rango uno y por lo tanto un solo valor propio diferente de cero y este es n.
Si escogemos apropiadamente P podemos obtener que P Q sea Así obtenemos ¿ estadísticas suficientes según el criterio de Neymann 
y según teorema de Leh-mann-Scheffé podemos comprobar que éstas conforman un conjunto minimal suficiente [ 4 ] .
Teorema 3. se puede demostrar la independencia estocástica de todas estas variables aleatorias; es decir tenemos estimadores insesgados para B Q y
Ahora si se cumple que , es decir si hay completez, podemos aplicar el teorema de Lehmann-Seheffé que dice T conforma un conjunto de estadísticas suficientes y la familia de densidades Z(T) es completa entonces es el único estimador insesgado de mínima varianza para 9.

Y este era precisamente nuestro propósito, veamos ahora un ejemplo práctico.
Y aunque no podemos decir mucho acerca de la "calidad" de estos estimadores si podemos realizar pruebas de hipótesis en base a la distribución F dado que estas estadísticas tienen una distribución.
Un último ejemplo es el conocido diseño de experimentos de bloques aleatorios (b-bloques y t-trata-
mientos); el modelo es:
y en este caso  y los estimadores obtenidos son los estimadores cuadráticos únicos de mínima
varianza.
CONCLUSIONES Y RECOMENDACIONES
Enfrentados a un problema de este tipo y luego de cerciorarnos completamente de la validez de los supuestos es relativamente fácil aplicar el método para encontrar estimadores de "alta calidad" o realizar pruebas de hipótesis uniformemente más poderosas.
Cuando la completez no existe habrá que probar los estimadores a la cota de Rao-Cramer o tratar de obtener estimadores por otros métodos -Mingue ó Mivque-, y asi poder hacer comparaciones (Varianzas).
Para aquellos que se interesan desde el punto de vista teórico tendrán que recurrir al articulo original (donde se encuentran aproximadamente 10 errores tipográficos que hacen más difícil su comprensión)o al libro de Kendall y Stuart, The advanced theory of statistics, Griffin-London 1973, Vol. 2 y 3 cap. 23-36 donde el articulo ha sido trabaja do en forma amplia.Otro caso diferente desarrollado en forma similar se encuentra en el articulo:
Para finalizar quiero de nuevo señalar que toda esta teoría se convierte en casos particulares del trabajo realizado por Seely en los últimos años, por eso son recomendables los siguientes artículos:
BIBLIOGRAFÍA
Hultquist,R., Atzinger,E.The mixed effects model and simultaneous diagonalization of symmetric matrices, the annals of math. Stat. 1973 Vol.43 pag. 2024-2030.
Seely,J. Minimal sufficient statistics and completeness for multivariate normal families, Sankhyá 1977 Vol. 39 pág. 170-185.
Seely,J.A. Compl. suff. statistics for the linear model under normality and a singular covariance matriz, Communic. Statistics 1978 Vol.15 pág. 1465-1473.
Ballman.R., Introduction to matriz analysis, McGraw-Hill, N.Y. (1960).
Thrall,R., Tornheim,L., Vector spaces and matrices, John Wiley and sons, N.Y. (1957).
Witting,H., Mathematische Statistik, B.g. Teubner Stuttgart (1978) .
Lehmann,L., Scheffé.H., Completeness, similar region and unbiased estimation, part. I, Sankhyá, Vol. 10 pág. 305-340, (1950).
Gautschi.W., Some remarks on Herbach's paper, Ann. Math. Stat. Vol. 30 pág. 960-963, (1959),
Graybill, F., Marsaglia, G., Idempotent matrices and quadratic forms in the general linear hypothesis,. Ann. Math. Stat. Vol. 28 pag. 678-686, (1957).
Mood,A..Graybill,F., Boes,D., Introduction of the theory of statistics, Mc-Graw Hill, N.Y. (1950).
Rao,C.R., Minimun variance quadratic unbiases estimation of variance componets, Journal of multivariate analysis 1 N. 4, pag. 445-456, (1971).
Estimation of variance and covariance components MINQUE theory,Journal of multivariate analysis 1 N.4, pag. 257-275,(1971).
Kleffe, J. Optimal estimatioin of variance components, a survey, Ann. Math. Stat. Vol. 32 pág. 261-269, (1961) .
