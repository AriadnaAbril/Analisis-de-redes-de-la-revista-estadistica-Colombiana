SOBRE LA OPTIMIZACION DE ESTIMADORES DE MININO CUADRADO
U.Lomonósov. Moscú
Resumen
Se demuestra una variante del teorema Gauss-Markov, la cual permite estimar asintóticamente las fronteras inferiores de la función de riesgo en el caso de regresión lineal. 
Introducción
Uno de los resultados clásicos de la estadística matemática lo constituye el llamado teorema Gauss-Markov. Este teorema estipula que en la clase de estimadores lineales insesgados de las formas lineales que permiten estimación, el estimador de mínimo cuadrado tiene varianza mínima, (Scheffe (1958)). Son conocidas algunas modificaciones de este resultado (J.Dr. Hodges, Lehman E.L. (1950),Rao, C R . (1973), p.319).

      El objetivo del presente trabajo es demos-
trar una variante de este teorema, la cual permi^
te con el mínimo de alteraciones obtener el re-
sultado correspondiente para las generalizacio-
nes de los modelos de regresión no lineal y los
casos de diseño secuencial de experimentos. Este
ultimo caso no lo trataremos en esta publicación.
Anotamos sin embargo que en él, la propiedad de
optimización debe ser asintótica, local y exteii
derse a una clase más general de estimadores que
los insesgados, cuya existencia en estas condi-
ciones es dudosa.



2. Afirmación I.

      Una variante sencilla de frontera inferior
no asintótica para los estimadores lineales del
modelo lineal es la siguiente:

      Sean y • variables aleatorias (v.a.) tales
            A.-

que /- = i .Q + e ¡ ,        I    = 1,...,N, donde 9 e: n'^ es
un parámetro desconocido, i -              son vectores dados
pertenecientes a IR                  L i - i - e s una
                             tales que M =
                                    ^=1 ^ ^         j
matriz no degenerada, E C-= O y el vector E e e ,
                       T '*'
donde e = (e.,..., eji,) , tiene la matriz unita-
ria como matriz de covarianza, T denota el signo
de transposición, E - la esperanza, V - la va-
rianza. Entonces para todo a e 1R" y Í. e: IR'
            sup í í a ^ y    - L ^ e ) ^ > L^M ^L                (1)
            ecEP

        Además la igualdad sólo se alcanza para el
estimador de mínimo cuadrado

   L^e = L^M ^ r ^ y ,      donde      F = a ^ , . . . ,i¡^)^,

                                                            T
                                       y =   íy^,...,Vf^)

Demostración. utilizaremos la conocida desigual-
dad :

 EE.^ = ÍEO^+VE,,     en donde ^ - V . a . ,    EE, < ».         (2)

Bajo las condiciones             citadas

            Eía^y-L^Q)           = (Fa-D^f

De donde, sino se verifica

             Fa-L = O,                                           (3)

se cumple

                 s u p ¡ E í a ' ^ y - L ' ^ Q ) | 2 = oo
                 Q&iP
Por t a n t o de a c u e r d o con        (2)

                 sup E í a ^ y - L ^ d ) ^ = 00
                ecEP

Queda por examinar el caso en el cual (3) es ve£
dadero, o sea cuando se cumple la condición:

                        T          T
                    Ea'y       = 1 9


en cuyo caso la demostración se realiza idéntica_
mente a la demostración clásica (Scheffe (1958)).




3. Afirmación II.

        El riesgo que aparece en la parte izquier-
da de (1) no es conveniente para la generaliza-
ción de los modelos no lineales. En este caso es
más racional examinar el supremo del riesgo ele-
vado al cuadrado del estimador en un                        dominio no
muy grande.

        El significado de este tratamiento es que
se tiene información del experimento anterior
que permite hacer más pequeño el dominio donde
se busca el parámetro desconocido 9. Sin embargo
procediendo de esta manera sólo se pueden esta-
blecer asintóticamente las fronteras del riesgo
para un volumen grande de muestras.

          Supongamos que para un entero M, las medi-
ciones de las funciones F^ en el punto x c: X dan
los
J.UH   vaxuies, y
       valores  i ^^wQ'^^W»
                   ' N ^
                       - N* ^^w(^i
                              N^  1•' '•" •' •N»^iu)
                                                   ^   '     »N f^»
(l((Xj),...,(J(x^))^, (J(x) = i i ^ i x ) , . . . , i ^ í x ) ) ' ^ ,
e^ = (e^,... ,e|y), Ee^ = o, Ee^e- =                    íl,j).
Etiix) es la medida probabilística correspondien-
te a la N-ésima serie de mediciones, E^-ÍX) -
h .1 Ix('^y)' ^v(^/) = 6(x,x.), 6 - s l m b o l o de Kro-
n e k e r . El parámetro desconocido O pertenece al
conjunto abierto Qu.
                    1 ^
          Sea •'W = Ñ y l ^ ' ^ N ^ ^ ^ h    ^^   estimador esca-
                 N
         L 9 (donde L e: R*^ y ai, son función es de
lar para L O (
finidas en X)
      Las funciones definidas deben cumplir las
condiciones siguientes:

I      i i x ) es una función continua y acotada del
       espacio topológico X en n".

II     ©n^ contiene una esfera B.^ . de radio r^^,

       lím r ^ í ^ = 00.
       W-H»
III Las funciones a.|y son continuas, acotadas uni-
       formemente y convergen uniformemente a a.(x)
       en X si N tiende a o».
IV     La familia de medidas probabilísticas Ej.íX)
       converge débilmente a la medida probabilísti_
       ca E(X).

V    La matriz de información de la medida probabi
     lística límite es positiva, o sea

         m = ¡ií^)i^iX-)dEíx)              >O
                X

         Definimos el riesgo asintótico de la si-
guiente manera:

    Rl = lím lím            sup     WE (T^,-L^9) "^.
           fe->oo j r ^     B(k//n)            ^

Teorema. P a r a t o d o L e: 'B.P y p a r a t o d a           sucesión
TJ, que cumpla l a s c o n d i c i o n e s I-V


                        R^ > l ^ m ' ^ L .


Demostración.         Damos p o r c o n o c i d a l a        igualdad

RL = lím l í m      sup [||/^( ET^-L'^^S ) |I ^ + N Í ) T ^ ]            (4)
     fe^co W-,.00 B í k l / Ñ )
Si p a r a a l g u n a s u b s u c e s i ó n N - suponemos que

       lím lím          s u p _ ||/W7(ETjy . - L ^ 9 ) | | = oo,
       k ^ ÍTJ^BÍk//fr)              ^         ^
e n t o n c e s R, = «> y con e l l o        la afirmación         del te£
rema se      verifica.

         Por d e f i n i c i ó n   EXjy ^ TL ^\i ^ \ i ^ '    entonces
                                         T r
    1U'W(ET^,-1.^9)|| = \\m ( ^ Y ^ -L)e|| = YQ.

        Por definición de convergencia débil y la
condición IV obtenemos que

        lím JJ a ^ F ^ = ¡ a í x ) i í x ) d E í x ) .
        W->-oo               X

De las dos conclusiones anteriores y la condición
III se deduce que es posible encontrar una esfe-
ra 6., , /rr. de radio k/vfJ tal que


    IJm      sup Y. > fe|/(a(x)¡$(x) - L)dE(x) I
    W-^oo B(fe//íí) "    X

De esta igualdad es claro que si para todo N,
lím sup y < oo, entonces
N-x»     ^

            |/(a(x)(5(x) - L)cíE(x)l = O                             (5)
             X
Examinando el segundo sumando de R. en (4) obte-
nemos que                           '

     lím lím            NVXf. = ¡ a ^ í x ) d E í x )
     fe-^oo WH.OO B(fe//Í/)        X

Por otro lado no es difícil comprobar que

                 lím NP(L'''6) = J m ' ^ L

donde 6 es el estimador de mínimo cuadrado.

        Utilizando la igualdad                (5) concluimos que
el vector a (x)-L|5"^ (x) «: L 2 Í % , E ) ,             ÍL2(X,E)   e s el
espacio de funciones integrables al cuadro en X

con medida E) e a perpendicular al vector
 T                            a
b i í x ) G L para todo 6 e ]R' . Es efecto

\¡íaíx)-Li~^íx))b'^iíx)dEíx)\ = |/(a(x)b^iJ(x)-L6^)cíE(x)
 X                                       X
                                    = O

por lo tanto

 /a^(x)dE(x) = L^m~^L+líaíx)-Li~^íx))^dEíx) >> J m ' ^ L .
 X                      X

lo que demuestra que

                      R^ >> i ' ^ m ' ^ L .

BIBLIOGRAFÍA
Hodges J Jr,Lehamn E L.Some problems in minimax point estimation.(1950).Ann Math Statist.
Rao C R.Linear statistical inference and its applications.(1973).John Wiley and Sons.New York.
Scheffe H.The analysis of variance.(1958).John Wiley and Sons.Ney York.