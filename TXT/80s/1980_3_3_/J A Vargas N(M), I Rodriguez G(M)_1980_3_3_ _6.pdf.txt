MULTÍCOLINEALIDAD
UNIVERSIDAD NACIONAL DE COLOMBIA
Presentación del Problema.
Multicolinealidades el nombre dado al problema que aparece cuando alguna o todas las variables independientes en una relación están altamente correlacionadas una con otra. Aquí llega a ser muy difícil sino imposible, detectar sus influencias por separado y obtener estimadores razonablemente precisos de sus efectos relativos, esto es, los coeficientes de regresión parcial pueden no ser significantes aunque exista una relación estadística entre la variable dependiente y el conjunto de variables independientes.
Este fenómeno es típico en problemas económicos y de mercadeo, por ejemplo las variables independientes ingreso familiar y activos tenderán a ser altamente correlacionadas.
Cosos que se presentan.
Se pueden considerar varios casos distintos:
Caso 1: Existe una relación lineal exacta entre 2 variables (Perfecta multicolínealidad).
Supóngase que en el siguiente modelo:
Se cumple la siguiente relación exacta entre X1 y X2. La dispersión de puntos en el plano X1X2 ocurre exclusivamente sobre la línea. Las valores de Y simplemente elevan estos puntos dejándolos en un plano vertical; arriba y abajo de una línea recta en el espacio tridimensional. Al tratar de explicar el hecho de que las variables estén relacionadas literalmente hace que se pierda una dimensión, y el mejor ajuste mínimo cuadrático para Y no es un plano sino una linea, la línea AB para este caso.
Si se mantiene la misma estructura de correlación, es decir si se conserva la relación de X1 y X2 y nos limitamos a predecir sobre la línea AB de la figura no se presentan problemas especiales pero no podemos examinar como X1 y
X2 afectan a Y individualmente; cualquier intento de definir efectos margínales de X1 X2 implicaría tratar de explicar Y con un plano en lugar de con una línea y se encontraría que hay infinitos planos que pasan a través de la línea AB; cada uno de los cuales produce una suma de cuadrados de los errores igual y por lo tanto obtenemos el mismo ajuste para todos.
Caso 2. Un caso menos extremo pero mucho más probable es el caso en que los valores de las variables independientes que aparecen en nuestra muestra están altamente correlacionadas, pero no perfectamente correlacionadas. 
Lo que sucede, en otros términos, es que una o más variables tienden a ser función lineal de una u otras variables con una pequeña disturbancia.
Luego los elementos de son muy grandes y por tanto los elementos de la matriz de covarianzas de serán también muy grandes, asi como también los errores estandar de los lo cual nos da valores poblacionales muy inciertos.
Debemos observar que es posible tener una relación que se ajuste muy bien, es decir, tener un  y aún así, al aplicar pruebas t para losse puede obtener que ninguna de éstas son significativas por separado.
Un método para detectar muíticolinealidad.
Como ya se ha dicho, se puede sospechar que existe una severa muíticolinealidad cuando las variables en conjunto son significativas pero individualmente no lo son.
Prueba empírica de Klein : Para examinar la severidad de la colineatidad por pares de las variables independientes, Klein sugiere construir la matriz de correlaciones de las variables :
Eliminación de una o varias variables independientes del modelo.
Se propone esta solución para disminuir la muíticolinealidad y así reducir los errores estándar de los coeficientes de regresión estimados de las variables que restan en el modelo. Esta acción sin embargo no ayuda a evaluar los efectos de las variables independientes por 2 razones. Primero : No se obtiene información acerca de las variables dejadas. Segundo: Las magnitudes de los coeficientes de Regresión para las variables independientes ({ue quedan en el modelo son afectadas por las variables independientes no incluidas en el modelo; la influencia de las variables eliminadas pasa al término de error, de esta forma, el término de error quedará correlacionado con las otras variables y el estimador mínimo cuadrado deja de ser insesgado.
Uso de información extraña.
En algunos casos es posible obtener información adicional acerca de los parámetros del modelo; esta información puede ser conocimiento de la razón de algunos coeficientes; de los valores de algunos coeficientes, de los valores de alguna combinación de los coeficientes; o simplemente del signo de algunos coeficientes.
Este conocimiento puede provenir de investigaciones empíricas anteriores o de otras muestras.
Restricciones Lineales exactas : Mínimos cuadrados restringidos. Supongamos que la información extraña es una restricción lineal exacta sobre los coeficientes.
Casos especiales son :
Conocimiento de los valores de algunos elementos de B por ejemplo
Conocimiento de la razón de algunos elementos de B por ejemplo
Conocimiento del valor de una combinación lineal de los valores de los elementos de B por ejemplo
Para incorporar esta información se propone el método de los mínimos cuadrados restringidos.
Debe obtenerse el B que minimice la suma de cuadrados del error
Por consiguiente minimizamos
Donde  es un vector J x l de multiplicadores de Langrange. Derivando S con respecto a B e igualando a cero tenemos
Es fácil ver que hay una ganancia en eficiencia. Se sabe que V es definida positiva; puesto que es una matriz, se sigue que es definida positiva y por tanto también es definida positiva.      Además
es definida no negativa, asi cada elemento de la diagonal de es menor o igual que el correspondiente elemento de B
Concluimos que la varíanza de cada elemento B es menor o igual que la varianza del correspondiente de B
En la práctica puede ser más conveniente computar B usando las restricciones para eliminar algunos elementos de B entonces se aplican mínimos cuadrados ordinarios y finalmente imponiendo la restricción se estiman los elementos de B que restan
BIBLIOGRAFÍA
D S Johnscon.Econometric Methods.(1963).Graw Hill Book Co, Inc.New York.
Neter J,W Wassennan.Applied linear models Regression, Analysis of variance, and Experimental Designs.(1974).Inc Homewood.Illinois.
A S Goldberger.Econometríc Theory.(1964).John Willey Sons Inc.New York.
V Eduardo Aldana.Modelos Estadísticos....