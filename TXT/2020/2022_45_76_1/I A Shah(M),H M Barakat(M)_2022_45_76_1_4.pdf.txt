Some Characterizations of the Exponential Distribution by Generalized Order Statistics, with Applications to Statistical Prediction Problem. Algunas caracterizaciones de la distribución exponencial mediante estadísticas de orden generalizado, con aplicaciones al problema de predicción estadística
Sher E Kashmir Institute of Medical Sciences Srinagar, Kashmir, India. Zagazig University, Zagazig, Egypt
Abstract
Some new characterization properties of the exponential distribution based on two non-adjacent m-generalized order statistics (consequently m-dual generalized order statistics), m ̸= −1, coming from two independent exponential distributions are derived. The result of this paper provides a beneﬁcial strategy to predict the failure time of some survived components in a lifetime experiment by using the result of another independent lifetime experiment.
Key words: characterization of distributions; Exponential distribution; generalized order statistics.
Resumen
Se derivan algunas propiedades de caracterización nuevas de la distribución exponencial basadas en dos estadísticas de orden generalizado m no adyacentes (en consecuencia, estadísticas de orden generalizado m dual), m ̸= −1, procedentes de dos distribuciones exponenciales independientes. El resultado de este artículo proporciona una estrategia beneﬁciosa para predecir el tiempo de falla de algunos componentes sobrevividos en un experimento de por vida utilizando el resultado de otro experimento de por vida independiente.
Palabras clave: caracterización de distribuciones; distribución Exponencial; estadísticas de orden generalizadas.

1. Introduction
    Kamps (1995) introduced the concept of generalized order statistics (GOSs)
as a uniﬁed approach to a variety of models of ascendingly ordered random
variables (RVs). The concept of dual GOSs, denoted by DGOSs, was introduced
by Burkschat et al. (2003) as a parallel concept of GOSs to enable a common
approach to descendingly ordered RVs. Burkschat et al. (2003) has shown that
(cf. Theorem 3.3) there is a direct link between DGOSs and GOSs.
    The subclasses m−GOSs and m−DGOSs of GOSs and DGOSs, respectively,
contain many important models of ordered RVs such as ordinary order statistics
(OOSs), lower and upper record values, k−records, sequential order statistics
(SOSs) and type II censored OOSs. For any 1 ≤ r ≤ n, the marginal
probability density functions (PDFs) of the rth m-GOS X(r, n; m, k) and m-DGOS
X ∗ (r, n; m, k), based on a continuous distribution function (DF) FX (x) = P (X ≤
x) with a PDF fX (x), are given, respectively, by (cf. Kamps 1995 and Ahsanullah
2004)
                        (n)
                                        [       m+1
                                                      ]r−1
                      Cr−1 γr(n) −1       1 − F X (x)
   fX(r,n;m,k) (x) =         F      (x)                    fX (x), m ̸= −1,              (1)
                     (r − 1)! X              m+1

and
                              (n)             [              ]r−1
                            Cr−1 γr(n) −1       1 − FX
                                                     m+1
                                                         (x)
      fX ∗ (r,n;m,k) (x) =         F      (x)                     fX (x), m ̸= −1,
                           (r − 1)! X              m+1
                      (n)                                 (n)    ∏r     (n)
where F = 1 − F, γr         = k + (n − r)(m + 1) and Cr−1 =        i=1 γi ,   1 ≤ r ≤ n.
    A characterization in statistics is a speciﬁc distributional property of a statistic
that uniquely identify related parametric family of distributions. In statistical
applications, the researchers usually want to verify whether the data that they
are dealing with belong to a certain family of DFs. Therefore, the researchers
have to rely on a characterization of the assumed distribution and check if the
corresponding conditions are satisﬁed. Classical results in characterizations can
be found in El-Adll (2018), Galambos & Kotz (1978), Nagaraja (2006), and Rao
& Chanabhng (1998). Diﬀerent results of characterization and its applications in
terms of GOSs and DGOSs are derived by many authors. Among these authors
are Arnold et al. (2008), Beutner & Kamps (2008), Castaño Martínez et al. (2012),
Khan et al. (2012), Öncel et al. (2005), Samuel (2008), Shah Imtiyaz et al., (2014;
2015; 2018; 2020), Tavangar & Hashemi (2013), and Wesolowski & Ahsanullah
(2004).
    In this paper, we prove some new characteristic properties of the exponential
DF exp(α), with mean α1 , α > 0. The exponential distribution is prominent in
life testing experiments and reliability problems. The exponential distribution
is known for its memoryless property in the sense that the length of time the
component has worked in the past does not aﬀect its behavior in the future (the
components with exponentially distributed lifetime have a constant failure rate).
The result of this paper enables us to predict the time at which some survived

                 Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 149–159

Some Characterizations of the Exponential Distribution                                  151

components will have failed or to predict the mean failure time of unobserved
lifetimes in a lifetime experiment by using the result of another independent
                                                      d
lifetime experiment. Throughout this paper, “X = Y ” means that the RVs X
and Y have the same DFs and “X ∼ F ” means that the RV X has the DF F .
    The rest of this paper is organized as follows. In Section 2, we reveal some
characterization properties for the exponential distribution based on two non-
adjacent m−GOSs (consequently m−DGOSs) from two independent exponential
distributions. In Section 3, we use the results of Section 2 in an application of the
prediction problem concerning the lifetime experiments.


2. Characterization Results
   We assume that all the considered DFs are diﬀerentiable with respect to their
arguments. Moreover, all the considered RVs are non-negative.
Theorem 1. Let X(r, n; m, k), m ̸= −1, be the rth m−GOS from a sample of
size n drawn from a continuous DF FX (x) with PDF fX (x). Furthermore, let
Y (r, n; m, k), m ̸= −1, be the rth m−GOS based on a sample of size n, which is
drawn from a continuous DF FY (y) = P (Y ≤ y), where Y is independent of X.
Finally, let the relation
                                               d
                   X(n1 − n2 + r, n1 ; m, k) = X(r, n2 ; m, k) + Ỹ                     (2)
                                                           d
be satisﬁed for all 1 ≤ r < n2 < n1 . Then, Ỹ = Y (n1 − n2 , n1 ; m, k) and
Y ∼ exp(α) if and only if X ∼ exp(α), α > 0.

Proof . We ﬁrst prove the necessity part. Let the moment generating function
(MGF) of X(r, n2 ; m, k) be MX(r,n2 ;m,k) (t). Then, (2) implies that
                  MX(n1 −n2 +r,n1 ;m,k) (t) = MX(r,n2 ;m,k) (t)MỸ (t).                 (3)
Let us now derive the MGF of the rth m−GOS X(r, n; m, k) based on exp(α).
Clearly, in view of (1), we get
                              (n)      ∫ ∞                 (                )r−1
                           αCr−1             −x(αγr(n) −t)         −α(m+1)x
 MX(r,n;m,k) (t) =                         e                 1 − e               dx,
                    (m + 1)r−1 (r − 1)! 0
which by using the transformation y = e−α(m+1)x takes the form
                                (n)          ∫ 1 ( γr(n)          )
                              Cr−1                  m+1 − α(m+1) −1
                                                             t

   MX(r,n;m,k) (t) =                            y                    (1 − y)r−1 dy
                        (m + 1)r (r − 1)! 0
                                    ( (n)               )
                              (n)     γr
                            Cr−1 Γ m+1       − α(m+1)
                                                  t

                    =               ( (n)                   )
                        (m + 1)r Γ m+1γr
                                             − α(m+1)
                                                  t
                                                         +r
                                         (n)
                                                                  (            )−1
                        ∏r               γi
                                                               ∏r
                                                                           t
                    =        (n)        m+1              =         1−             , (4)
                                                                            (n)
                        i=1
                              γr
                              m+1   −      t
                                      α(m+1)    + r  −  i      i=1       αγi


                Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 149–159

152                                                                                  Imtiyaz A. Shah & Haroon M. Barakat


where Γ(.) is the usual gamma function. On the other hand, in view of (3) and by
                     (n )            (n2 ) (n1 )          (n )         (n )
using the relations Cn1 1−n2 +r−1 = Cr−1  Cn1 −n2 −1 and γn11−n2 +r = γr 2 , we get
                                                                                                            ( (n )                       )
                                                                                                              γr 2
                                                                            (n )
                                                                        Cn11−n2 −1                      Γ             − α(m+1)
                                                                                                                           t
                                                                                                                               +r
                     MX(n1 −n2 +r,n1 ;m,k) (t)                                                                m+1
MỸ (t)     =                                                   =                         ×          ( (n )                                   )
                         MX(r,n2 ;m,k) (t)                          (m + 1)n1 −n2                      γr 2
                                                                                                 Γ     m+1
                                                                                                               − α(m+1)
                                                                                                                    t
                                                                                                                        + n1 − n2 + r
                                                                ( (n )                           )
                                                                    γn 1−n
                        (n )                             Γ           m+1
                                                                        1    2
                                                                                 − α(m+1)
                                                                                      t
                      Cn11−n2 −1
            =                      ×                 ( (n )                                             )
                     (m + 1)n1 −n2                     γn 1−n
                                                 Γ       m+1
                                                            1       2
                                                                        − α(m+1)
                                                                             t
                                                                                 + n1 − n2
                                                                                         
                       −n2
                     n1∏
                                                         (n )
                                                        γi 1                                  −n2
                                                                                                            (                  )−1
                                                                                          n1∏                         t
            =                                          m+1                               =                    1−                   ,       (5)
                              γ (n1 )                                                                                 (n )
                                 n1 −n2                                                                               αγi 1
                      i=1
                                 m+1
                                                 − α(m+1)
                                                      t
                                                          + n1 − n2 − i                               i=1


                                     (n1 )
          γ (n2 )                γ
                     1 −n2
since, m+1
        r
            + r = nm+1     . On comparing (5) with (4), we deduce that MỸ (t)
is the MGF of Y (n1 − n2 , n1 ; m, k), i.e., the (n1 − n2 )th m-GOS from a sample
of size n1 drawn from the DF exp(α). This completes the proof of the necessity
part. We now turn to prove the suﬃciency part. Let the representation (2)
                                     d
be satisﬁed with Ỹ = Y (n1 − n2 , n1 ; m, k) and Y ∼ exp(α). Furthermore, let
X(n1 − n2 + r, n1 ; m, k) and X(r, n2 ; m, k) in (2) be m−GOSs, which are based on
an unknown DF FX (x) and they are independent of Y (n1 −n2 , n1 ; m, k). Therefore,
the convolution relation (2) implies that
                               ∫ x
  fX(n1 −n2 +r,n1 ;m,k) (x) =      fX(r,n2 ;m,k) (y)fY (n1 −n2 ,n1 ;m,k) (x − y) dy
                                                        0
                                                                   (n )                 ∫ x
                                                                 αCn1 1−n2 −1                      (n1 )
                                              =                                             e−αγn1 −n2 (x−y)
                                                       (n1 − n2 − 1)!(m + 1)n1 −n2 −1 0
                                                       (                    )n1 −n2 −1
                                              ×          1 − e−α(m+1)(x−y)             fX(r,n2 ;m,k) (y) dy. (6)

Diﬀerentiating both sides of (6) with respect to x, we get

                                                                             (n )
                                                                     α2 Cn11−n2 −1                       ∫ x         (             )
d fX(n1 −n2 +r,n1 ;m,k) (x)                                                                                            (n )
                                                                                                                   −α γn 1−n +(m+1) (x−y)
                                             =                                                                 e        1      2
                dx                                   (n1 − n2 − 2)!(m + 1)n1 −n2 −2 0
                                                     (                   )n1 −n2 −2
                                             ×         1 − e−α(m+1)(x−y)            fX(r,n2 ;m,k) (y) dy
                                                                     (n )
                                                             α2 γn11−n2 Cn11−n2 −1
                                                                                   (n )                  ∫ x          (n )
                                                                                                                   −αγn 1−n (x−y)
                                             −                                                                 e       1   2
                                                     (n1 − n2           − 1)!(m + 1)n1 −n2 −1
                                                                                     0
                                                     (                  )n1 −n2 −1
                                                           −α(m+1)(x−y)
                                             ×         1−e                         fX(r,n2 ;m,k) (y) dy.                                     (7)
On the other hand, by using the obvious relation
       (n )      (                           )n1 −n2 −1                             (n )         (                     )n1 −n2 −2
    −αγn 1−n z                                                                  −αγn 1−n z
e       1   2        1 − e−α(m+1)z                                  =       e        1   2           1 − e−α(m+1)z
                                                                                  (             ) (                                )n1 −n2 −2
                                                                                    (n )
                                                                                −α γn 1−n +(m+1) z
                                                                    −       e         1      2                  1 − e−α(m+1)z                   ,


                        Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 149–159

Some Characterizations of the Exponential Distribution                                                153

and by using the representation (6), we get
                                (n )                 ∫ x      (            )
                              αCn1 1−n2 −1                       (n )
                                                           −α γn 1−n +(m+1) (x−y)
                                                         e         1  2
                    (n1 − n2 − 2)!(m + 1)n1 −n2 −2 0
                    (                    )n1 −n2 −2
               ×      1 − e−α(m+1)(x−y)             fX(r,n2 ;m,k) (y) dy
                      (n )
                    Cn1 1−n2 −1
               =      (n −1)
                                  fX(n1 −n2 −1,n1 −1;m,k) (x)
                    Cn1 1−n2 −2
               −    (m + 1)(n1 −n2 −1)fX(n1 −n2 ,n1 ;m,k) (x).                                         (8)

                                         (n )                                       (n )
Thus, by using the relations γn11−n2 + (m + 1)(n1 − n2 − 1) = γ1 1 and

                                  (n )             ∏n1 −n2       (n )
                               Cn1 1−n2 −1                      γi 1       (n )
                                (n −1)
                                                = ∏ni=1−n        (n )
                                                                        = γ1 1 ,
                               Cn1 1−n2 −2             1
                                                     i=2
                                                            2
                                                                γi 1

and by combining (15) and (7), we get
 d fX(n1 −n2 +r,n1 ;m,k) (x)         (n ) [                                                            ]
                               = αγ1 1        fX(n1 −n2 +r−1,n1 −1;m,k) (x) − fX(n1 −n2 +r,n1 ;m,k) (x) ,
               dx

or equivalently, by integrating from 0 to x
                                   (n ) [                                                            ]
  fX(n1 −n2 +r,n1 ;m,k) (x) = αγ1 1         FX(n1 −n2 +r−1,n1 −1;m,k) (x) − FX(n1 −n2 +r,n1 ;m,k) (x) .
                                                                                                      (9)
Now, by using the relation (II) of Kamps (1995) on page 75, we get

                    FX(n1 −n2 +r−1,n1 −1;m,k) (x) − FX(n1 −n2 +r,n1 ;m,k) (x)

                (n −1)
               Cn1 1−n2 +r−2              (n )
                                         γn 1−n +r −1
                                                          [       m+1
                                                                          ]n1 −n2 +r−1
=                                      F   1   2
                                                      (x)   1 − F     (x)              .
  (n1 − n2 + r − 1)!(m + 1)n1 −n2 +r−1   X                        X

                                                                                   (10)
Therefore, by combining (6), (9) and (10), we get

                                                 fX (x)
                                                         = α,
                                                 F X (x)

which implies that FX (x) = 1 − e−αx , x > 0. This completes the proof of the
suﬃciency part, as well as the proof of Theorem 1.

Corollary 1. Assume that the RVs X and Y are independent, as we assumed in
Theorem 1. By replacing the additive relation (2) by the multiplicative relation
                                                           d
                       X(n1 − n2 + r, n1 ; m, k) = X(r, n2 ; m, k) × Ỹ .                            (11)
           d
Then, Ỹ = Y (n1 −n2 , n1 ; m, k) and Y ∼ P areto(α) (i.e., FY (y) = 1−y −α , y > 1)
if and only if X ∼ P areto(α), α > 0.

                    Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 149–159

154                                                      Imtiyaz A. Shah & Haroon M. Barakat


Proof . The proof immediately follows, by noting that if X ∼ P areto(α), then
log X ∼ exp(α) and

                                                 d
               log X(n1 − n2 + r, n1 ; m, k) = log X(r, n2 ; m, k) + log Ỹ ,

which implies
                                                     d
                    X(n1 − n2 + r, n1 ; m, k) = X(r, n2 ; m, k) × Ỹ .



Remark 1. In (10), the product X(r, n2 ; m, k) × Ỹ is called random dilation of
X(r, n2 ; m, k), cf. Beutner & Kamps (2008). Moreover, at n1 = n2 + 1, the
representation (11) gives

                                         d
           X(r + 1, n2 + 1; m, k) = X(r, n2 ; m, k) × Y (1, n2 + 1; m, k),              (12)

as was obtained by Beutner & Kamps (2008) for X ∼ P areto(α). Also, at
n2 = n1 − 1, the relation (11) gives

                                     d
                 X(r + 1, n1 ; 0, 1) = X(r, n1 − 1; 0, 1) × Y (1, n1 ; 0, 1)

(i.e., for the OOSs model), which was obtained by Castaño Martínez et al. (2012),
for X(1, n1 ; 0, 1) ∼ P areto(αn1 ). Finally, the representation (12) can be written
                                             d
as (for OOSs model) X(s, n1 ; 0, 1) = X(r, n2 ; 0, 1) × V, 1 ≤ r < s, n2 < n1 , which
was an unsolved problem due to Arnold et al. (2008).

Corollary 2. Assume that the RVs X and Y are independent. Let X ⋆ (r, n; m, k)
and Y ⋆ (r, n; m, k) be the rth m−DGOSs based on a sample of size n drawn from FX
and FY , respectively. By replacing the additive relation (2.1) by the multiplicative
relation
                                                d
                   X ⋆ (n1 − n2 + r, n1 ; m, k) = X ⋆ (r, n2 ; m, k) × Y ⋆ .
           d
Then, Y ⋆ = Y ⋆ (n1 − n2 , n1 ; m, k) and Y ⋆ ∼ power(α), α > 0 (i.e., FY (y) =
y α , 0 < y < 1), if and only if X ⋆ ∼ power(α).

Proof . The proof immediately follows from the simple relation between the GOSs
and DGOSs, by noting that if X ∼ power(α), then − log X ∼ exp(α), and

                                                 d
         − log X ⋆ (n1 − n2 + r, n1 ; m, k) = − log X ⋆ (r, n2 ; m, k) − log Y ⋆ ,

which implies
                                                     d
                  X ⋆ (n1 − n2 + r, n1 ; m, k) = X ⋆ (r, n2 ; m, k) × Y ⋆ .




                 Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 149–159

Some Characterizations of the Exponential Distribution                                                        155

Theorem 2. Let X(r, n; m, k), m ̸= −1, be the rth m−GOS from a sample of
size n drawn from a continuous DF FX (x) with PDF fX (x). Furthermore, let
Y (r, n; m, k), m ̸= −1, be the rth m−GOS based on a sample of size n, which is
drawn from a continuous DF FY (y), where Y is independent of X. Finally, let the
relation
                                          d
                X(n1 − n2 + r, n1 ; m, k) = X(n1 − n2 , n1 ; m, k) + Ỹ     (13)
                                                               d
be satisﬁed for all 1 ≤ r < n2 < n1 . Then, Ỹ = Y (r, n2 ; m, k) and Y ∼ exp(α) if
and only if X ∼ exp(α).

Proof . Clearly, the proof of the necessity part follows from Theorem 1, while
the proof of the suﬃciency part follows closely as the suﬃciency part of Theorem
                                                                 d
1. Namely, let the representation (13) be satisﬁed with Ỹ = Y (r; n2 , m, k) and
Y ∼ exp(α). Furthermore, let X(n1 − n2 + r, n1 ; m, k) and X(n1 − n2 , n1 ; m, k)
in (13) be m−GOSs, which are based on an unknown DF FX (x) and they are
independent of Y (r; n2 ; m, k). Therefore, the convolution relation (13) implies that
                                         ∫ x
        fX(n1 −n2 +r,n1 ;m,k) (x)   =          fX(n1 −n2 ,n1 ;m,k) (y)fY (r;n2 ,m,k) (x − y) dy
                                          0
                                                       (n )
                                                        2           ∫ x
                                                    αCr−1                          (n2 )
                                    =                                      e−αγr           (x−y)
                                         (r − 1)!(m + 1)r−1             0
                                         (                              )r−1
                                    ×        1 − e−α(m+1)(x−y)                 fX(n1 −n2 ,n1 ;m,k) (y) dy.   (14)
By diﬀerentiating both sides of (14) with respect to x, we get
                                                (n )          ∫ x         (           )
 d fX(n1 −n2 +r,n1 ;m,k) (x)              α2 Cr−1
                                                2                           (n )
                                                                        −α γr 2 +(m+1) (x−y)
                               =                                    e
            dx                      (r − 2)!(m + 1)r−2 0
                                    (                   )r−2
                               ×      1 − e−α(m+1)(x−y)      fX(n1 −n2 ,n1 ;m,k) (y) dy
                                             (n )    (n )     ∫ x
                                        α2 γr 2 Cr−1
                                                   2
                                                                           (n2 )
                               −                           e−αγr (x−y)
                                    (r − 1)!(m + 1)r−1 0
                                    (                   )r−1
                               ×      1 − e−α(m+1)(x−y)      fX(n1 −n2 ,n1 ;m,k) (y) dy.
                                        (n ) [                                                   ]
                               =    αγr 2 fX(n1 −n2 +r−1,n1 ;m,k) (x) − fX(n1 −n2 +r,n1 ;m,k) (x) ,

or equivalently, by integrating from 0 to x,
                                    [                                                       ]
fX(n1 −n2 +r,n1 ,m,k) (x) = αγr(n2 ) FX(n1 −n2 +r−1,n1 ;m,k) (x) − FX(n1 −n2 +r,n1 ;m,k) (x) .
                                                                                        (15)
Now, by using the relation of Kamps (1995) on Page 75, we get
                    FX(n1 −n2 +r−1,n1 ;m,k) (x) − FX(n1 −n2 +r,n1 ;m,k) (x)
                  (n )
                Cn1 1−n2 +r−2              (n )
                                          γn 1−n +r −1
                                                           [       m+1
                                                                           ]n1 −n2 +r−1
=                                       F   1   2
                                                       (x)   1 − F     (x)              .
   (n1 − n2 + r − 1)!(m + 1)n1 −n2 +r−1 X                          X

                                                                                    (16)
Therefore, by combining (14), (15) and (16), we get fX (x) = αF X (x), which
implies that FX (x) = 1 − e−αx , x > 0. This completes the proof of the suﬃciency
part, as well as the proof of Theorem 2.

                   Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 149–159

156                                                 Imtiyaz A. Shah & Haroon M. Barakat


Corollary 3. Assume that the RVs X and Y are independent, as we assumed in
Theorem 2. By replacing the additive relation (13) by the multiplicative relation
                                             d
                  X(n1 − n2 + r, n1 ; m, k) = X(n1 − n2 , n1 ; m, k) × Ỹ .              (17)
          d
Then, Ỹ = Y (r, n2 ; m, k) and Y ∼ P areto(α) if and only if X ∼ P areto(α).

Proof . The proof follows exactly as the proof of Corollary 1.

Remark 2. For OOSs model the relation (17) takes the form
                                       d
           X(n1 − n2 + r, n1 ; 0, 1) = X(n1 − n2 , n1 ; 0, 1) × Y (r, n2 ; 0, 1),
                                              d
which implies the relation X(s, n1 ; 0, 1) = X(r, n1 ; 0, 1) × Y (s − r, n1 − r; 0, 1) that
is belonging to Castaño Martínez et al. (2012).

Corollary 4. Assume that the RVs X and Y are independent. Let X ⋆ (r, n; m, k)
and Y ⋆ (r, n; m, k) be the rth m-DGOSs based on a sample of size n drawn from FX
and FY , respectively. By replacing the additive relation (13) by the multiplicative
relation
                                            d
               X ⋆ (n1 − n2 + r, n1 ; m, k) = X ⋆ (n1 − n2 , n1 ; m, k) × Y ⋆ .
              d
Then, Y ⋆ = Y ⋆ (r, n2 ; m, k) and Y ⋆ ∼ power(α) if and only if X ⋆ ∼ power(α).

Proof . The proof follows as the proof of Corollary 2.


3. Applications to the Prediction Problem
    Prediction problem usually arises in life-testing experiments of medical and
industrial applications. Often, in the life-testing experiments, the observations
arrive in ascending order of magnitude. Consequently, in reliability theory,
especially for OOSs and SOSs, X(r, n; m, k) represents the life length of a n−r +1-
out-of-n system made up of n independent life lengths (these components are
identical for OOSs and non identical for SOSs). Motivation for the prediction
problems arises when the experiment is terminated before its conclusion by
stopping after a given time (Type I censoring) or after a given number of failures
(Type II censoring). Several authors have considered prediction problems involving
GOSs, see for example Aitcheson & Dunsmore (1975), Barakat et al., (2011; 2018;
2021a; 2021b; 2021c), Lawless (1971), Nagaraja (1986), Raqab (2001), and Raqab
& Barakat (2018).
    Theorems 1 and 2 suggest a new method for treating two prediction problems of
diﬀerent types. Namely, Theorem 2 treats a classical prediction problem, denoted
by Problem-1, that predicting X(s, n; m, k), 1 ≤ r < s ≤ n, based on the observed
m−GOSs X(1, n; m, k) ≤ X(2, n; m, k) ≤ · · · ≤ X(r, n; m, k). On the other hand,
Theorem 2.1 considers the prediction problem of X(r, n; m, k), when the sample
size of the test is enlarged from n to N, by adding some extra items Xn+1 , . . . , XN

                  Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 149–159

Some Characterizations of the Exponential Distribution                                    157

after observing X(r, n; m, k). This problem will be noted by Problem-2. Clearly,
the sequence {X(r, n; m, k)} is non-increasing in n. For example, if FX (x) is
continuous and for any ﬁxed value r < n, the observed value of X(r, n; 0, 1),
denoted by x(r, n; 0, 1), did not change if min(xn+1 , . . . , xN ) > x(r, n; 0, 1),
otherwise we get x(r, n; 0, 1) < x(r, N ; 0, 1). In the preceding two prediction
problems, the failure times of the un-observed lifetimes in a lifetime experiment are
predicted by using the result of another independent lifetime experiment. Below,
more details are given.

Problem-1: Let us assume that there are two independent lifetime experiments.
     The ﬁrst one contains n1 items, which follow X ∼ exp(α). Furthermore, let us
     assume that s items were observed until they failed. The second experiment
     contains n2 = n1 − s items, which follow Y ∼ exp(α). Furthermore, in the
     second experiment let us assume that r failure times were observed. Theorem
     2.2 enables us to predict

             X(s + 1, n1 ; m.k), X(s + 2, n1 ; m.k), . . . , and X(s + r, n1 ; m.k)

      by X(s, n1 ; m.k) + Y (1, n2 ; m.k), X(s, n1 ; m.k) + Y (2, n2 ; m.k), . . . , and
      X(s, n1 ; m.k) + Y (r, n2 ; m.k), respectively.
Problem-2: Let us assume that there are two independent lifetime experiments.
     The ﬁrst one contains n2 items, which follow X ∼ exp(α). Furthermore, let us
     assume that r items were observed until they failed. The second experiment
     contains n1 items, which follow Y ∼ exp(α), where n1 > n2 . Furthermore,
     in the second experiment let us assume that s = n1 − n2 failure times were
     observed. If we decided to enlarge the number of installed items in the ﬁrst
     experiment to n1 , Theorem 1 would enable us to predict

             X(s + 1, n1 ; m.k), X(s + 2, n1 ; m.k), . . . , and X(s + r, n1 ; m.k)

      by X(1, n2 ; m.k) + Y (s, n1 ; m.k), X(2, , n2 ; m.k) + Y (s, n1 ; m.k), . . ., and
      X(r, n2 ; m.k) + Y (s, n1 ; m.k), respectively.


Acknowledgements
   The authors are grateful to the editorial board and the referees for suggestions
that improved the presentation substantially.
             [                                                                ]
                 Received: December 2020 — Accepted: November 2021


References
Ahsanullah, M. (2004), ‘A characterization of the Uniform Distribution by Dual Generalized Order Statistics’, Communications in Statistics - Theory and Methods 33(12), 2921–2928.
Aitcheson, J. & Dunsmore, I. (1975), Statistical Prediction Analysis, Cambridge University Press, Cambridge, U. K.
Arnold, B. C., Castillo, E. & Sarabia, J. (2008), ‘Some Characterizations Involving Uniform and Powers of Uniform Random Variables’, Statistics 42(6), 527–534.
Barakat, H. M., El-Adll, M. E. & Aly, A. E. (2011), ‘A characterization of the Uniform Distribution by Dual Generalized Order Statistics’, Computers & Mathematics with Applications 61(5), 1366–1378.
Barakat, H. M., El-Adll, M. E. & Aly, A. E. (2021a), ‘Two-Sample Nonparametric Prediction Intervals Based on Random Number of Generalized Order Statistics’, Communications in Statistics - Theory and Methods 50(19), 4571–4586.
Barakat, H. M., Khaled, O. M. & Ghonem, H. A. (2021b), ‘New Method for Prediction of Future Order Statistics’, Quality Technology & Quantitative Management 18(1), 101–116.
Barakat, H. M., Khaled, O. M. & Ghonem, H. A. (2021c), ‘Predicting Future Order Statistics with Random Sample Size’, AIMS Mathematics 6(5), 5133–5147.
Barakat, H. M., Nigm, E. M., El-Adll, M. E. & Yusuf, M. (2018), ‘Prediction for future exponential Lifetime Based on Random Number of Generalized Order Statistics Under a General Set-Up’, Statistical Papers 59(2), 605–631.
Beutner, E. & Kamps, U. (2008), ‘Random Contraction & Random Dilation of Generalized Order Statistics’, Communications in Statistics - Theory and Methods 37(14), 2185–2201.
Burkschat, M., Cramer, E. & Kamps, U. (2003), ‘Dual Generalized Order Statistics’, Metron LXI(I), 13–26.
Castaño Martínez, A., López-Blázquez, F. & Salamanca-Miño, B. (2012), ‘Random Translations, Contractions and Dilations of Order Statistics and Records’, Statistics 46(1), 57–67.
El-Adll, M. E. (2018), ‘Characterization of Distributions by Equalities of Two Generalized or Dual Generalized Order Statistics’, Communications in Statistics - Theory and Methods 26(3), 522–528.
Galambos, J. & Kotz, S. (1978), Characterizations of Probability Distributions, Cambridge University Press, Berlin Heidelberg, New York.
Kamps, U. (1995), A Concept of Generalized Order Statistics, B. G. Teubner, Stuttgart.
Khan, A. H., Shah Imtiyaz, A. & Ahsanullah, M. (2012), ‘Characterization Through Distributional Properties of Order Statistics’, Journal of the Egyptian Mathematical Society 20(3), 211–214.
Lawless, J. F. (1971), ‘A Prediction Problem Concerning Samples from the Exponential Distribution with Applications in Life Testing’, Technometrics 13(4), 725–730.
Nagaraja, H. N. (1986), ‘Comparison of Estimators and Predictors from Two-Parameter Exponential Distribution’, Sankhya, Series B 48(1), 10–18.
Nagaraja, H. N. (2006), Characterizations of Probability Distributions -Handbook of Engineering Statistics, 79-87(In Book Chapter), Springer, Editor: Hoang Pham, Uk.
Öncel, S. Y., Ahsanullah, M., Aliev, F. A. & Aygun, F. (2005), ‘Switching Record and Order Statistics via Random Contraction’, Statistical Probability Letters 73(3), 207–217.
Rao, C. R. & Chanabhng, D. N. (1998), Recent Approaches to Characterizations Based on Order Statistics and Record Values (Handbook of Statistics, 16, 231-256), Elsevier.
Raqab, M. Z. & Barakat, H. M. (2018), ‘Prediction Intervals for Future Observations Based on Samples of Random Sizes’, Journal of Mathematics and Statistics 14(1), 16–28.
Raqab, Z. M. (2001), ‘Optimal Prediction-Intervals for the Exponential Distribution Based on Generalized Order Statistics’, IEEE Transactions on Reliability 50(1), 112–115.
Samuel, P. (2008), ‘Characterization of Distributions by Conditional Expectation of Generalized Order Statistics’, Statistical. Papers 49, 101–108.
Shah Imtiyaz, A., Barakat, H. M. & Khan, A. H. (2018), ‘Characterization of Pareto and Power Function Distributions by Conditional Variance of Order Statistics’, Proceedings of the Bulgarian Academy of Sciences 71(3), 313–316.
Shah Imtiyaz, A., Barakat, H. M. & Khan, A. H. (2020), ‘Characterizations Through Generalized and Dual Generalized Order Statistics with an Application to Statistical Prediction Problem’, Statistics & Probability Letters 163, 1–7.
Shah Imtiyaz, A., Khan, A. H. & Barakat, H. M. (2014), ‘Random Translation, Dilation and Contraction of Order Statistics’, Statistics & Probability Letters 92, 209–214.
Shah Imtiyaz, A., Khan, A. H. & Barakat, H. M. (2015), ‘Translation, Contraction and Dilation of Dual Generalized Order Statistics’, Statistics & Probability Letters 107, 131–135.
Tavangar, M. & Hashemi, M. (2013), ‘On Characterizations of the Generalized Pareto Distributions Based on Progressively Censored Order Statistics’, Statistical Papers 54, 381–390.
Wesolowski, J. & Ahsanullah, M. (2004), ‘Switching Order Statistics Through Random Power Contractions’, Australian & New Zealand Journal of Statistics 46(2), 297–303.
