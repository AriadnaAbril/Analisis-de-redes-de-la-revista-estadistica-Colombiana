Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation Study. Datos atípicos aditivos en modelos autorregresivos de umbrales: un estudio de simulación
Universidad Nacional de Colombia, Bogotá D.C., Colombia
Abstract
The eﬀect of additive outlier observations is investigated in adapting a non-linearity test and a robust estimation method for the autoregressive coeﬃcients from SETAR(self-exciting threshold autoregressive) models to open-loop models. TAR (threshold autoregressive). Through a Monte Carlo experiment, the power and size of the non-linearity test are studied. Regarding the estimation, the bias and the mean square error ratio between the robust estimator and the least-squares estimator are compared. Additionally, the approximation of the GM estimators’ empirical distribution to the univariate normal distribution is evaluated together with the coverage levels of the asymptotic conﬁdence intervals. The results indicate that the adapted non-linearity test has higher power than that based on least squares and does not present distortions in size under the presence of additive outliers. On the other hand, the robust estimation method for autoregressive coeﬃcients exceeds the least-squares one in terms of the mean square error in the presence of this type of observations. These results were analogous to those obtained for SETAR models. Finally, the use of the non-linearity test and the estimation method are illustrated through two real examples.
Key words: additive outliers; open-loop TAR models; generalized method (GM) estimator; nonlinear time series.
Resumen
Se investiga el efecto de observaciones atípicas aditivas en la adaptación de una prueba de no linealidad y un método de estimación robusto para los coeﬁcientes autorregresivos de modelos SETAR(self-exciting threshold autoregressive) a modelos open-loop TAR(threshold autoregressive). A través de un experimento Monte Carlo se estudia la potencia y el tamaño de la prueba de no linealidad. Respecto a la estimación, se compara el sesgo y la razón de error cuadrático medio entre el estimador robusto y el de mínimos cuadrados. Adicionalmente, se evalúa la aproximación de la distribución empírica de los estimadores GM de los coeﬁcientes a la distribución normal univariada junto a los niveles de cobertura de los intervalos de conﬁanza asintóticos. Los resultados indican que la prueba de no linealidad adaptada presenta una potencia superior a la basada en mínimos cuadrados y no presenta distorsiones en el tamaño bajo la presencia de datos atípicos aditivos. Por otro lado, el método de estimación robusto para los coeﬁcientes autorregresivos supera al de mínimos cuadrados en términos de error cuadrático medio bajo la presencia de este tipo de observaciones. Estos resultados fueron análogos a los obtenidos para modelos SETAR. Finalmente, se ilustra a través de dos ejemplos reales el uso de la prueba de no linealidad y el método de estimación.
Palabras clave: datos atípicos aditivos; modelos open-loop TAR; estimadores GM ; series de tiempo no lineales.



1. Introduction
    Since their appearance in the literature in Tong (1978) and Tong (1990), TAR
(threshold autoregressive) models have been widely used to explain phenomena
observed in empirical time series and are still very popular. An excellent review
was carried out in Hansen (2011), who references more than seventy articles in
economics that range from applications of the model to contributions to the theory
of estimation and inference. In Chan & Ng (2004), other articles outside this ﬁeld
in which this type of model had been used. The great popularity of TAR models
lies in their ease of estimation (which is, in general, the estimation method is
conditional least squares) and their ability to capture non-linear behaviors such as
asymmetries, limit cycles, and jump phenomena (many of these referenced in the
literature, see for instance Franses et al. 2000, Granger & Teräsvirta 1993).
    Despite its wide use, one of the topics little studied in the literature is related to
outliers data in TAR models; this fact contrasts with the situation in linear models
for which the topic has been studied in greater depth (see, for instance, Chen & Liu
1993, Tsay 1988). The few articles on the subject have focused mainly on the case
of SETAR(Self Exciting Threshold Autoregressive) models, a particular case of the
open-loop TAR model, more speciﬁcally the SETAR model is the one obtained by
making the time series that determines the change between regimes(the threshold
variable) is equal to the same observed time series. This fact can be a limitation in
real data analysis because another variable can drive the dynamic of the variable of
interest. Then, open-loop TAR models can be used for modeling in that real data
applications, see Knotters & De Gooijer (1999), Zhang & Nieto (2015), Gonzalez
& Nieto (2020) for examples in univariate open-loop TAR model, and Tsay (1998),
Calderón & Nieto (2017), Romero & Calderón (2021) for examples in Multivariate
TAR models. The literature of outliers in non-linear time series models has focused

                    Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...           3

mainly on three research lines; the ﬁrst refers to the detection of non-linearity, the
second to robust estimation methods in the presence of outlier data, and the third
to methods of detection and modeling of the outlier observations.
    In the ﬁrst place, regarding the detection of non-linearity, Chan & Ng (2004)
carried out a simulation study to evaluate some classical tests’ properties for
the detection of SETAR-type non-linearity existing in the literature; the tests
considered are those mentioned in Chan & Tong (1990), Luukkonen et al. (1988),
Petruccelli & Davies (1986), Petruccelli (1990), Tsay (1989). In the presence of
outlier observations, the results suggest that none of the tests considered is robust
since, for these, the empirical sizes generally exceed the nominal size. Based on
this, in Hung et al. (2009) is proposed a robust extension to outlier observations
of the non-linearity test introduced by Tsay (1989) for the case of SETAR models
and show through simulations that the empirical size and power of this new test
are adequate. Second, as far as robust estimation methods are concerned, Chan &
Cheung (1994) proposed the use of GM (generalized-M) estimators for this type
of model; The authors conclude that under the presence of outlier observations,
the GM method has a better performance in terms of mean square error than that
of conditional least squares. This result was questioned in Giordani (2006), who
exempliﬁes some situations in which the estimators obtained through this method
can become inconsistent and ineﬃcient if it is used to estimate the thresholds
that determine the model regimes. A few years later, in Zhang et al. (2009) is
given conditions under which the estimators obtained through the GM method
for the model parameters are consistent. Finally, regarding the third line of
research, Battaglia & Orfei (2005) propose a general framework under which outlier
observations can be detected and modeled in non-linear time series through the
conditional maximum likelihood method; using Monte Carlo exercises, the authors
illustrate the performance of this methodology for the case of diﬀerent non-linear
models including the SETAR model.
    One of the problems that arise when carrying out traditional estimation
procedures for non-linear time series models in the presence of outlier observations
is that, as mentioned by Tiao & Tsay (1994), there is always the possibility of
confusing eﬀects of this type of observations with non-linear dynamics typical of
the time series. Hence, a process that follows a linear model with these types of
observations can appear non-linear, and likewise, a linear time series with some
outliers could be non-linear. Being able to distinguish these cases is essential
since improperly identifying the model can lead to misinference. Therefore,
this document seeks to evaluate through simulations the size and power of the
non-linearity test in Hung et al. (2009) adapted to the open-loop TAR model.
The experimentation is carried out using an autoregressive process as the data-
generating process(GDP) for the threshold variable. Additionally, we compare
through the mean square error and the bias(that was not studied before) the
proposed estimation method of Chan & Cheung (1994) against the classical
estimation method (conditional least squares(LS)) for the case of open-loop TAR
models (adapting the methodology beyond SETAR models). We also study for
ﬁnite samples the empirical normal distribution of the GM estimators for the
so-called autoregressive parameters in each regime and how it is the empirical

                   Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

4                                             Sergio Calderon & Daniel Ordoñez Callamad


coverage of the conﬁdence intervals for the autoregressive parameters with the
adapted estimation methods for open-loop TAR models. We carried out those
studies because in Sorour & Tong (1993), it is suggested that the direct extensions
from the SETAR model to the open-loop TAR model should be studied. Then
the paper proceeds as follows. In the second session, an adaptation of the robust
estimation procedure is presented. In the third Section, a non-linearity test of
TAR type is implemented to take into account outlier observations. In section 4,
a Monte Carlo simulation study is carried out. Finally, a real data application to
ﬁnancial time series showed to illustrate the methodology.


2. Adaptation of the Estimation Procedure and
   the Non-Linearity Test to the Open-Loop TAR
   Model
   This section presents the adaptation of the estimation procedure of Chan &
Cheung (1994) and the non-linearity test of Hung et al. (2009) from the SETAR
models to the open-loop TAR models. We ﬁrst introduce the Open-loop TAR
model and how this model can be written as a linear regression model by regimes.
Next, it is presented how to take into account the additive outliers in this context.
    In Tong (1990, p. 101), we can ﬁnd the deﬁnition of an Open-loop TAR model;
however we use a simpliﬁcation of that model. A time series {Yt }t∈Z is said to
follow a open-loop TAR model, denoted TAR(Z, k, p1 , . . . , pk , d) if

                      (j)
                             ∑
                             pj
                                    (j)
               Yt = ϕ 0 +          ϕi Yt−i + σj ϵt     si rj−1 ≤ Zt−d < rj ,               (1)
                             i=1

                                                 iid
where j = 1, . . . , k, it is assumed that {ϵt } ∼ (0, 1), {Zt }t∈Z is a known stationary
time series, we have r0 = −∞ < r1 < · · · < rk = ∞. The parameter pj is the
                                                                     (j)
order of the autoregressive model in the j-th regime and the ϕi           i = 0, . . . , pj the
                                                 (j)
autoregressive coeﬃcients in this regime(ϕ0 is the intercept). d is known as the
delay parameter, k is the number of regimes and the rj is known as the thresholds.
σj represents the scale of ϵt at the j-th regime. A particular case of the open-loop
TAR model, widely used in practice, is the SETAR model. In this model, the
time series that characterizes the regime change {Zt }t∈Z is the same time series
under analysis {Yt }t∈Z . As it was mentioned in Tsay (1998), the behavior of the
threshold variable has a profound impact on the dynamic of the interest variable;
therefore, the data-generating process(DGP) for threshold variable can aﬀect the
results over the non-linearity test and the estimation procedure in open-loop TAR
models in the presence of outliers.
   The expressions used in this paper correspond to an open-loop TAR model
with two regimes, that is, when k = 2 in (1); however, this methodology can be
extended to models with more regimes. We ﬁrst can observe that a 2-regime TAR
model

                     Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...            5
                             ∑p1 (1)
                      ϕ(1)
                        0 +    i=1 ϕi Yt−i + σ1 ϵt                    if      Zt ≤ r
                 Yt =                                                                    (2)
                      ϕ(2) + ∑p2 ϕ(2) Y + σ ϵ                        if      Zt > r,
                        0      i=1 i    t−i   2 t


can be written as a linear regression model by regimes, that is, for j = 1, 2, and
assuming that p1 = p2 = p, then

                                         y j = Xj ϕ j + ϵj ,                             (3)




                                    ϵj = (ϵji1 , . . . , ϵjiTj )′ ,

                                              (j)          ′
                                   ϕj = (ϕ0 , . . . , ϕ(j)
                                                       p ) ,

                               xjil −1 = (1, Yjil −1 , . . . , Yjil −p )′ ,

                                   Xj = [xji1 −1 , . . . , xjiTj −1 ]′ ,


where observations {Yp+1 , . . . , YT } can be split in two groups according to the
following rule:

                       
                       Yt ∈ 1st group                 if    Zt−d0 ≤ r1
                                                                                         (4)
                       Y ∈ 2nd group                   if    Zt−d0 > r1 ,
                           t


with l = 1, . . . , Tj , and d0 is a proposed positive integer value for the delay value. It
is necessary to know the threshold value r1 . Therefore y1 = (Y1i1 , . . . , Y1iT1 )′ , y2 =
(Y2i1 , . . . , Y2iT2 )′ are the observations in the ﬁrst and second regime respectively
(T1 + T2 = T − p, each one represents the number of observations in each regime).
With these, we complete the speciﬁcation of the linear regression model by
regimes (3).
    We consider in this paper outlier observations of an additive nature(which are
the most studied). Chan & Ng (2004) extended what is suggested by Denby
& Martin (1979) and propose to deﬁne them as follows: The observed time
series is {Yt∗ }t∈Z (time series with outlier eﬀect), and the time series of interest
is {Yt }t∈Z (time series without outlier eﬀect),

                                           Yt∗ = Yt + κt ,                               (5)

where κt is an identically distributed independent random variable that follows a
mixed distribution with density (1 − β)δ0 (·) + βϕω (·) with ϕω (·) representing the
normal distribution of mean 0 and variance ω 2 , δ0 (·) representing a degenerate
distribution at 0, β (0 ≤ β ≤ 1) is the percentage of contamination in the time
series and ω its magnitude.

                    Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

6                                                Sergio Calderon & Daniel Ordoñez Callamad


2.1. Robust Estimation of the Open-Loop Threshold
     Autoregressive Models
    In this section, we propose an adaptation of the robust methodology proposed
in Chan & Cheung (1994) for SETAR to the case of the open-loop TAR model
based on a linear regression model by regimes in 3. Note that parameters of the
TAR model in (3) can be estimated using least squares estimation in each regime.
If the time series is aﬀected by an additive outlier, the estimator is no eﬃcient, and
then a robust estimator can be better. The class of estimators GM is an extension
of the class of M -robust estimators proposed in classical regression problems (see,
for example, Maronna et al. (2019)). It is necessary to take into account two cases
when threshold r1 is known and unknown.
Case threshold r1 is known.
If r1 is known, then the GM-estimator ϕ̃j of ϕj is deﬁned implicitly for the
condition for j = 1, 2
                          (                                     )
                   ∑
                   Tj
                                         Yjil − xjil −1 ′ ϕ̃j
                              2
                         η d (xjil −1 ),                            xjil −1 = 0,                     (6)
                                                σ̂j
                   l=1

where d2 (x) is used to denote the squared Mahalanobis distance, that is, d2 (x) =
(x − m)′ V−1 (x − m) with m and V robust location and dispersion estimators(it is
generally suggested to calculate m through the median and V using the estimator
proposed by Rousseeuw & Van Zomeren (1990)). σ̂j is obtained with a robust
scale estimator (for example a M -estimator). The conditions that the function
η(·, ·) must fulﬁll to have optimal asymptotic properties can be found in (Hampel
et al., 1986, p. 315). We propose to use Schweppe-type parametrization of the
function η(·, ·), that is, for j = 1, 2

          (                                 )                         (                          )
              2      Yjil − xjil −1 ′ ϕ̃j             2                   Yjil − xjil −1 ′ ϕ̃j
     η d (xjil −1 ),                            = w(d (xjil −1 ))ψ
                            σ̂j                                           σ̂j w(d2 (xjil −1 ))

where the function ψ(·) belongs to the group of functions used in the construction
of the class of M-robust estimators (in Table 1 we present some of the functions
ψ(·) most used in practice, see Maronna et al. (2019) for plots of that functions).
The function w(·) is a function that assigns weights, with rank at [0, 1], and is
deﬁned as w(u) = ψ(u)
                    u if u ̸= 0 and w(0) = 1.

    Where ρ(u) is a function such that ∂ρ(u)    ∂u    = ψ(u).     With Schweppe
parametrization and with ﬁxed functions ρ(·) and ϕ(·), the equation (6) is non-
linear in ϕ̃j , therefore, to ﬁnd the solution, numerical methods must be used.
In general, it is suggested to take a robust initial estimator for ϕj as the LAD
(least absolute deviations) estimator proposed in Rousseeuw (1984). From this
               (0)
estimator (ϕ̃j ) we can obtain the residuals for all time jil in the regime j
as, ϵ̂jil = Yjil − xjil −1 ′ ϕ̃j , where the value of σ̂ (0) can be obtained using the
    (0)                       (0)

estimator MAD (median absolute deviation) over the residuals. Once you have

                    Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...                           7
                                                                     (         (0)
                                                                                          )
                                                                              ϵ̂ji
this information, you can calculate the weights: w                        (0)
                                                                               l
                                                                                              in the case of
                                                                         σj w(d2 (xt ))
the Schweppe. Taking these weights as if they were ﬁxed, the equation (6) can
                                                                    (1)
be solved. Weighted least squares are used to obtain the value of ϕ̃j . With this
                                                     (1)
last value, you can ﬁnd the value of σ̂j                   and calculate the weights again to ﬁnd
               (2)
the value of ϕ̃j ; this procedure is carried out successively until some previously
imposed convergence condition is met (for example, that the diﬀerence between
two successive estimates is small enough). Ultimately, this solution method is
known as IWLS (iterative weighted least squares). It is important to point out
that weighted least squares can be used because ψ(u) = w(u)×u, which is replaced
in η(·, ·) and equation (6).

              Table 1: Some functions ψ and their respective functions ρ
          Type                   Function-ρ ρ(u)                Function-ψ ψ(u)      Rank of u
                                           u2
          Least Squares                     2
                                                                       u             (−∞, ∞)


                                           u2
          Huber(k)                          2
                                                                       u              |u| ≤ k
                                                2
                                       k|u| − k2                   ksgn(u)            |u| > k

                                 (      (            )
                            c2
                                            ( ) 2 )3             (   ( ) 2 )2
          Tukey(c)           6
                                     1 − 1 − uc                 u 1 − uc              |u| ≤ c
                                             2
                                           c
                                            6
                                                                       0              |u| > c


    Following to Maronna et al. (2019, p. 173), we can see that the estimator ϕ̃j
for j = 1, 2 obtained trough GM method is asymptotically normal

                                 √
                                  Tj (ϕ̃j − ϕj ) ∼ N (0, Σϕ ).                                           (7)

   For this case, the asymptotic covariance matrix of ϕ̃j can be obtained as:

                                                            ′
                                       Σ̂ϕj = σj2 B−1 CB−1                                               (8)

      [ (                         )         ]
                     y j − Xj ϕ j                                                         ∂η(d2 (Xj ), Rt )
B = −E η ∗ d2 (Xj ),                Xj ′ Xj                      η ∗ (d2 (Xj ), Rt ) =
                          σj                                                                   ∂Rt
        [ (                             )2            ]
              2  y j − Xj ϕj                     ′
C = E η d (Xj ),                             Xj Xj .
                      σj

   Case threshold r1 is unknown.
   It can be considered that the estimator GM with the Schweppe type
parametrization in each of the regimes, it is, in fact, the solution to the
optimization problem (9). A global objective function can be deﬁned as:

                     Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

8                                                 Sergio Calderon & Daniel Ordoñez Callamad



                                                        ∑
                                                        2
                         Γ(ϕ1 , ϕ2 , σ1 , σ2 , r1 ) =           γj (ϕj , σj ),                 (9)
                                                        j=1

where γj (ϕj , σj ) is the function deﬁned as

                                  ∑
                                  Tj                        (                         )
                                            2         2         Yjil − xjil −1 ′ ϕj
                γj (ϕj , σj ) =         w(d (xjil −1 )) ρ                                 .
                                                                σj w(d2 (xjil −1 ))
                                  l=1

  A robust estimator of r1 (r̂1 ) can be found by searching through the set
{Xpα% , . . . , Xp(1−α)% } where Xpα% denotes the α-th percentile of the variable Zt .
That is, the value of r̂1 is the solution to:

                               Argmin              Γ(ϕ1 , ϕ2 , σ1 , σ2 , r1 ).                (10)
                      r1 ∈{Ypα% ,...,Yp(1−α)% }


   Note that once the value of r1 is set, the estimators ϕ̂1 , ϕ̂2 , σ̂1 , σ̂2 can be easily
found according to discussed above. In practice it is suggested to take a value
α = 0.25 so that there are enough observations in each of the regimes.
    Giordani (2006) exempliﬁed some problems where the threshold value
estimated using the above procedure may be incorrect. To ensure the consistency
of the threshold estimator, the function ψ used must meet certain conditions that
can be found in Zhang et al. (2009). In fact, one of the conditions is that the
function used is convex, the Tukey function (originally used in the article by Chan
& Cheung 1994) of the Table 1 does not fulﬁll this property while the of Huber
does.


3. Non-linearity Test of open-loop TAR Type
   The importance of carrying out the non-linearity test allows identifying better
a model that best ﬁts the data; this translates into both better forecasts and more
accurate inference. Tsay & Chen (2019) mentions several examples of observed
time series that seem to be better represented through non-linear models and
emphasizes the improvement obtained in forecasting.
    The idea behind the non-linearity test for SETAR models proposed by Hung
et al. (2009) (in fact, it is a generalization of the Tsay (1989) test) is to carry out an
autoregression ordered using a GM estimator with a function ψ with the Schweppe
to obtain predictive residuals that will later be used in the non-linearity test.
The adaptation proposed for Open-Loop TAR in this paper consist of arranged
autoregression is according to threshold variable Zt−d instead of Yt−d .
    The proposed FGM statistic is

                           y
                           t−1          M SS(T − p − m − (p + 1))
                         FGM   =                                  ,                           (11)
                                              RSS(p + 1)


                    Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...           9

where

                 M SS = Ψ̂′ WX(X′ WWX)−1 X′ WΨ̂

                  RSS = Ψ̂′ Ψ̂ − M SS

                            ϵ̂πj
                   R̂πi =        for i = m + 1, . . . , T − p
                             σ̂ϵ

                     Ψ̂ = (ψ(R̂πm+1 ), . . . , ψ(R̂πT −p ))′

                     X = [xπm , . . . , xπT−p −1 ]′

                    W = diag(w(d2 (xπm ))), . . . , w(d2 (xπT−p −1 )),

and ϵ̂πj is the one-step-ahead prediction residual based on the GM estimator,
and vectors xπl for l = m, . . . , T − p, where deﬁned in (3), σ̂ϵ is the robust
variance error estimator, and the matrix X is obtained from the regressors of the
arranged autoregression. Note that p is the order of the AR model proposed for
null hypothesis H0 . Under the null hypothesis of an autoregressive linear model,
the test statistic in (11) has asymptotically a distribution F (see Hung et al.,
2009) with p + 1 and (T − p − m − (p + 1)) degrees of freedom. In Tsay (1989) and
                                                                       T
Hung et al. (2009) proposed to use in practice a value of m equal to 10  + p. Note
that m is the number of observations that it is used to start the estimation of the
parameters in the ordered autoregression. Note that asymptotic convergence of
the statistic FGM is not aﬀected by the change of the threshold variable. Finally,
in the case where we want to consider another value of delay d on the time series
Yt−d , the estimator of this parameter can be selected in such a way that:
                                                   y
                                                  t−v
                                   Argmax       FGM   ,                                (12)
                                      v inS

where S is a previously selected set of values. The value of p used in the
construction of the test can be obtained through a preliminary analysis of the
PACF (partial autocorrelation function) and carrying out the identiﬁcation of the
autoregressive process as if the model out linear.


4. Monte Carlo Results
    In order to verify the suitability of the proposed methodology, the results of
the simulation exercises related to the adaptation of the non-linearity test of Hung
et al. (2009) and the estimation method of Chan & Cheung (1994) are presented
applied to the case of TAR models in the presence of additive outlier observations.
Also, the eﬀects that additive outlier observations have on this test and the
estimation method are evaluated in the following ways: (1) diﬀerent percentages
of contamination of this type of observations, (2) diﬀerent proportion of outlier
observations in each of the model regimes, and (3) coverage levels of the asymptotic
conﬁdence intervals constructed under the traditional GM methodology.

                   Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

10                                              Sergio Calderon & Daniel Ordoñez Callamad


    Following the simulation exercises’ design in Chan & Cheung (1994), Hung
et al. (2009), a model with two regimes TAR(Z, 2,1,1,0) is considered. This model
is also chosen based on the ease with which its estimation process can be carried
out and because in practical applications, two or three regimes are generally used
(see Hansen, 2011). The transition variable {Zt }t∈Z follows an AR (1) model. The
GDP is then:
                              
                              ϕ(1)  (1)
                                0 + ϕ1 Yt−1 + ϵt            si Zt ≤ r
                       Yt =                                                                   (13)
                              ϕ(2) + ϕ(2) Y
                                  0       1    t−1 + ϵt     si Zt > r

                                  Zt = νZt−1 + ηt         |ν| < 1                             (14)


                                         Yt∗ = Yt + κt                                        (15)
                                                                          iid
where {ϵt }t∈Z and {ηt }t∈Z , are sequences of random variables ∼ N (0, 1). {Yt∗ }t∈Z
represents the observed time series (contaminated with additive outliers), κt is
an independent and identically distributed random variable that follows a mixed
distribution with density (1−β)δ0 (·)+βϕω (·), where ϕω (·) representing the normal
distribution mean 0 and variance ω 2 . δ0 (·) represents a degenerate distribution at
0, β (0 ≤ β ≤ 1) is the time percentage of contamination in the time series and ω
its magnitude. Finally, {Yt }t∈Z represents the underlying (uncontaminated) time
series. For each replication, a sample {Y1 , . . . , YT } is generated according to the
equation (13). Sample sizes T = 100, T = 200 are considered. The initial value
X0 is taken equal to zero. The ﬁrst 1000 observations are discarded in each of the
replications,to eliminate possible eﬀects of this initial value on the time series.
    Regarding the non-linearity test, the results of the power and size of the test
                                   zt
are presented based on the value FGM    with diﬀerent choices for the function ψ(·).
The function of Huber with values of k = 1.345 and k = 3.291and that of Tukey
with values of c = 4.685 y c = 15. All these choices are based on those selected by
Hung et al. (2009)1 . In both the non-linearity test and the estimation procedure,
the Least Squares ( LS) function is considered to facilitate comparison.
    Finally, as regards the values of the model parameters TAR, we consider
ν = ±0.5, ±0.8, ω = 0, 3, 6, 10, and r = 0. The contamination percentage
β = 5% (in exercises presented later we consider β = 10% and β = 1%). The
                                                  T               (1) (1)  (2)  (2)
initial value for arranged autoregression is m = 10 + 1 and for ϕ0 , ϕ1 , ϕ0 , ϕ1
following the results of Hung et al. (2009), seven combinations of parameters are
                      (1)        (2)          (1)             (2)
considered where ϕ0 = 0.5, ϕ0 = 0.5, ϕ1 = 0.5 and ϕ1 varies from −0.8
                          (1)
to 0.8. The coeﬃcient ϕ1 remains ﬁxed as in the previously mentioned article2 .
                                                                      (2)
It is important to mention that in the case in which the coeﬃcient ϕ1 takes the
   1 In general these values are selected so that estimator obtained with them has a relative

asymptotic eﬃciency in the Gaussian case of 95% y 99.5% respectively.
   2 Hung et al. (2009) suggests that the results of the simulations for the non-linearity test (in

the case SETAR) are not very sensitive to the choice of the autoregressive coeﬃcient in the ﬁrst
regime.


                      Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...          11

value of 0.5 the model is reduced to a ﬁrst-order autoregressive linear model. In
Hung et al. (2009) was speciﬁed that some of the parameter combinations for the
simulation experiment were taken from Tsay (1989). Other combinations were
chosen such that there are adequate observations in both regimes for eﬃcient
parameter estimation and non-linearity testing.


4.1. Main Results of Non-linearity Test
    Table 2 (T = 100) and Table 3 (T = 200) show the relative empirical
frequencies of rejection of the null hypothesis of linearity at signiﬁcance levels
of 10%, 5%, and 1% based on 1000 replications with a contamination percentage
of outliers β = 5%.
    The row in bold shows the empirical size of the test when there are no outliers
(ω = 0); this is because when all coeﬃcients are equal, the model is, in fact,
linear. We can observe the following: for the function ψ : LS (least squares), the
empirical size is 0.011 at a signiﬁcance level of 1%, 0.054 at a level of 5%, and
0.110 to 10% (as expected). The following three columns show the empirical size
for the function ψ : Huber at the same three levels of signiﬁcance with parameter
k = 1.345. The following columns show the respective results for diﬀerent choices
of function ψ. In all cases, the empirical sizes coincide with the nominal ones.
When all the coeﬃcients are equal, but the parameter ω is diﬀerent from 0, the
results of Table 2 are the empirical size of the test in the presence of outliers. In
this case, when the magnitude of the outliers is greater (ω = 10), the empirical
size of the test obtained using the least-squares function (the original proposal
of Tsay (1989)) is 0.127, 0.236, and 0.298, that is, it becomes higher than the
corresponding nominal levels (10%, 5%, and 1%). On the other hand, when the
function ψ(·) used corresponds to the Huber (or Tukey), the empirical sizes always
remain close to the nominal, regardless of the presence of outlier observations (ω =
3,6,10). As can be seen in Tables 2 and 3, this result is maintained when increasing
the sample size from T = 100 to T = 200.
                                                   (2)
     On the other hand, when the parameter ϕ1 takes values other than 0.5, the
Table 2 presents the power of the non-linearity test. As this coeﬃcient varies
and the value of ω is ﬁxed at 0, the power of the test is obtained when there
are no outliers, for example, for the least squares function the empirical power
at a signiﬁcance level of 1% is 0.978, 0.808, 0.450, 0.213 in the parameter values
  (2)
ϕ1 = −0. 8, −0.5, −0.2 and 0 respectively. Now, if ω is set to a value other than
                        (2)
0 and the parameter ϕ1 is varied, the power of the non-linearity test is obtained
under the presence of outlier observations (remember that ω is related to the
magnitude of these, a greater value of ω generates outliers of greater magnitude);
by way of illustration, it can be seen in the table that the power of the test with
choice of function ψ : Huber and parameter k = 1, 345 at a signiﬁcance level
of 1% and ω = 10 is 0.840, 0.506, 0.215, and 0.101 for the values of parameters
  (2)
ϕ1 = −0.8, −0.5, −0.2, and 0 respectively. The following columns show the power
for diﬀerent choices of function ψ.



                   Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Sergio Calderon & Daniel Ordoñez Callamad




                                                                                                                                                                                                                     Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40
                                            Table 2: Empirical relative frequencies of rejection of the linearity hypothesis based on 1000 replications with a model T AR(Z, 2, 1, 1, 0),
                                                     sample size equal to 100.
                                                                                                  LS               Huber k = 1.345         Huber k = 3.291          Tukey c = 4.685           Tukey c = 15
                                                (1)     (1)    (2)       (2)
                                               ϕ0     ϕ1      ϕ0     ϕ1         ω   α=   1%      5%      10%      1%     5%    10%        1%     5%    10%         1%     5%    10%        1%     5%    10%
                                               0.5    0.5     0.5    -0.8      0         0.978   0.996   0.999    0.903 0.970 0.988       0.970 0.998 0.999        0.817 0.918 0.955       0.964 0.996 0.999
                                                                               3         0.864   0.938   0.965    0.862 0.939 0.973       0.900 0.962 0.982        0.757 0.888 0.930       0.891 0.962 0.982
                                                                               6         0.595   0.753   0.811    0.833 0.931 0.970       0.817 0.923 0.958        0.750 0.895 0.943       0.770 0.901 0.942
                                                                               10        0.395   0.551   0.644    0.840 0.940 0.965       0.757 0.895 0.938        0.758 0.899 0.937       0.727 0.884 0.926
                                               0.5    0.5     0.5    -0.5      0         0.808   0.932   0.954    0.655 0.837 0.899       0.799 0.911 0.949        0.528 0.743 0.826       0.791 0.912 0.949
                                                                               3         0.602   0.768   0.848    0.574 0.766 0.854       0.598 0.794 0.862        0.462 0.678 0.778       0.597 0.786 0.859
                                                                               6         0.370   0.574   0.668    0.509 0.756 0.834       0.478 0.710 0.787        0.438 0.674 0.777       0.439 0.689 0.773
                                                                               10        0.280   0.447   0.525    0.506 0.750 0.829       0.403 0.675 0.784        0.464 0.675 0.778       0.384 0.642 0.776
                                               0.5    0.5     0.5    -0.2      0         0.450   0.695   0.798    0.325 0.566 0.681       0.416 0.666 0.785        0.262 0.484 0.603       0.418 0.665 0.780
                                                                               3         0.296   0.522   0.647    0.256 0.485 0.623       0.255 0.498 0.629        0.218 0.424 0.547       0.264 0.511 0.631
                                                                               6         0.246   0.416   0.513    0.241 0.475 0.602       0.193 0.420 0.553        0.225 0.449 0.560       0.167 0.385 0.521
                                                                               10        0.208   0.366   0.450    0.215 0.446 0.578       0.163 0.360 0.481        0.214 0.436 0.549       0.152 0.343 0.463
                                               0.5    0.5     0.5    0         0         0.213   0.408   0.544    0.150 0.343 0.492       0.183 0.406 0.533        0.131 0.309 0.431       0.188 0.405 0.529
                                                                               3         0.170   0.344   0.467    0.116 0.298 0.451       0.119 0.299 0.429        0.109 0.262 0.387       0.126 0.306 0.432
                                                                               6         0.155   0.304   0.419    0.105 0.280 0.400       0.088 0.245 0.345        0.106 0.257 0.382       0.078 0.233 0.334
                                                                               10        0.172   0.295   0.385    0.101 0.276 0.406       0.067 0.215 0.307        0.115 0.273 0.375       0.065 0.185 0.297
                                               0.5    0.5     0.5    0.2       0         0.070   0.201   0.313    0.053 0.169 0.251       0.062 0.186 0.292        0.060 0.173 0.255       0.066 0.190 0.295
                                                                               3         0.080   0.208   0.301    0.048 0.147 0.232       0.046 0.143 0.225        0.048 0.156 0.240       0.049 0.139 0.246
                                                                               6         0.120   0.246   0.341    0.044 0.138 0.218       0.033 0.120 0.201        0.049 0.146 0.211       0.041 0.113 0.189
                                                                               10        0.148   0.266   0.357    0.046 0.130 0.218       0.028 0.106 0.176        0.047 0.161 0.224       0.030 0.097 0.165
                                               0.5    0.5     0.5    0.5       0         0.011   0.054   0.110    0.011 0.054 0.100       0.013 0.048 0.098        0.010 0.067 0.125       0.014 0.049 0.103
                                                                               3         0.039   0.100   0.158    0.012 0.054 0.100       0.014 0.053 0.098        0.015 0.054 0.119       0.011 0.052 0.097
                                                                               6         0.057   0.155   0.231    0.009 0.048 0.089       0.010 0.059 0.108        0.013 0.060 0.111       0.014 0.049 0.088
                                                                               10        0.127   0.236   0.298    0.010 0.046 0.083       0.014 0.056 0.091        0.013 0.060 0.100       0.018 0.047 0.074
                                               0.5    0.5     0.5    0.8       0         0.236   0.457   0.591    0.170 0.366 0.501       0.206 0.424 0.563        0.146 0.325 0.436       0.204 0.431 0.560
                                                                               3         0.148   0.340   0.465    0.138 0.336 0.461       0.164 0.368 0.480        0.113 0.288 0.411       0.148 0.345 0.467
                                                                               6         0.144   0.268   0.372    0.127 0.292 0.403       0.129 0.268 0.379        0.119 0.287 0.389       0.100 0.233 0.337
                                                                               10        0.157   0.263   0.346    0.108 0.272 0.389       0.086 0.231 0.336        0.125 0.277 0.388       0.065 0.194 0.297
                                            This table presents the percentages of rejection of the non-linearity hypothesis when using the Hung et al. (2009) test adapted to the case of a TAR model. In
                                            the equation (13) the model is presented, the value of ω is related to the magnitude of the outliers, and its deﬁnition is presented in the lower part of the equation
                                            (5). The value of the ν parameter is equal to 0.5 and the sample size is T = 100.
12

                                                                            Table 3: Empirical relative frequencies of rejection of the linearity hypothesis based on 1000 replications with a model T AR(z, 2, 1, 1, 0),
                                                                                     sample size equals to 200.
                                                                                                                                 LS              Huber k = 1.345     Huber k = 3.291       Tukey c = 4.685          Tukey c = 15
                                                                                (1)    (1)    (2)       (2)
                                                                              ϕ0      ϕ1     ϕ0     ϕ1         ω   α=   1%      5%      10%     1%     5%    10%    1%     5%    10%      1%     5%    10%       1%     5%    10%
                                                                              0.5     0.5    0.5    -0.8      0         1.000   1.000   1.000   0.999 1.000 1.000   1.000 1.000 1.000     0.992 0.998 0.999      1.000 1.000 1.000
                                                                                                              3         0.994   0.998   0.999   0.995 0.999 1.000   0.999 1.000 1.000     0.978 0.995 0.997      0.997 0.999 1.000
                                                                                                              6         0.847   0.924   0.952   0.996 0.998 0.999   0.993 0.999 1.000     0.981 0.995 0.998      0.986 1.000 1.000
                                                                                                              10        0.488   0.660   0.748   0.994 1.000 1.000   0.985 0.997 1.000     0.985 0.996 0.998      0.974 0.996 0.998
                                                                              0.5     0.5    0.5    -0.5      0         0.994   0.999   1.000   0.965 0.996 0.998   0.995 0.999 0.999     0.896 0.969 0.983      0.995 0.998 0.999
                                                                                                              3         0.906   0.964   0.977   0.928 0.980 0.994   0.943 0.979 0.991     0.844 0.946 0.978      0.932 0.984 0.991
                                                                                                              6         0.593   0.772   0.837   0.919 0.984 0.992   0.878 0.956 0.982     0.849 0.951 0.973      0.862 0.955 0.976
                                                                                                              10        0.334   0.493   0.592   0.906 0.971 0.991   0.828 0.926 0.961     0.864 0.956 0.978      0.805 0.922 0.956
                                                                              0.5     0.5    0.5    -0.2      0         0.861   0.949   0.971   0.702 0.879 0.939   0.832 0.940 0.973     0.584 0.778 0.857      0.838 0.944 0.975
                                                                                                              3         0.634   0.807   0.867   0.606 0.830 0.906   0.628 0.819 0.895     0.499 0.736 0.837      0.633 0.832 0.896
                                                                                                              6         0.376   0.590   0.691   0.578 0.813 0.881   0.510 0.744 0.831     0.501 0.712 0.825      0.491 0.728 0.832
                                                                                                              10        0.217   0.382   0.463   0.559 0.762 0.854   0.434 0.670 0.767     0.518 0.740 0.825      0.409 0.665 0.778
                                                                              0.5     0.5    0.5    0         0         0.532   0.754   0.850   0.392 0.620 0.745   0.518 0.736 0.836     0.316 0.532 0.644      0.503 0.733 0.839
                                                                                                              3         0.380   0.599   0.703   0.334 0.556 0.675   0.339 0.551 0.677     0.274 0.474 0.594      0.356 0.577 0.691
                                                                                                              6         0.254   0.421   0.521   0.312 0.519 0.643   0.234 0.445 0.570     0.266 0.471 0.598      0.215 0.430 0.549
                                                                                                              10        0.174   0.311   0.408   0.285 0.522 0.661   0.201 0.403 0.547     0.289 0.482 0.608      0.177 0.380 0.501
                                                                              0.5     0.5    0.5    0.2       0         0.199   0.378   0.522   0.147 0.319 0.428   0.184 0.370 0.494     0.132 0.294 0.396      0.179 0.374 0.505
                                                                                                              3         0.160   0.328   0.455   0.110 0.273 0.373   0.090 0.251 0.373     0.107 0.250 0.355      0.095 0.259 0.383
                                                                                                              6         0.161   0.298   0.406   0.111 0.256 0.369   0.082 0.200 0.299     0.114 0.254 0.356      0.066 0.211 0.301
                                                                                                              10        0.152   0.267   0.334   0.107 0.269 0.364   0.051 0.184 0.271     0.129 0.269 0.374      0.050 0.167 0.268
                                                                              0.5     0.5    0.5    0.5       0         0.010   0.059   0.109   0.012 0.061 0.115   0.014 0.051 0.103     0.017 0.078 0.135      0.012 0.056 0.101
                                                                                                              3         0.027   0.096   0.154   0.006 0.051 0.112   0.013 0.058 0.122     0.013 0.064 0.121      0.011 0.059 0.116
                                                                                                              6         0.076   0.187   0.264   0.011 0.053 0.113   0.015 0.052 0.102     0.014 0.079 0.124      0.012 0.041 0.087
                                                                                                              10        0.091   0.179   0.249   0.009 0.053 0.094   0.012 0.050 0.097     0.015 0.067 0.123      0.011 0.033 0.072
                                                                              0.5     0.5    0.5    0.8       0         0.573   0.774   0.847   0.434 0.656 0.755   0.540 0.752 0.832     0.348 0.557 0.680      0.542 0.749 0.834
                                                                                                              3         0.380   0.595   0.700   0.357 0.606 0.716   0.418 0.666 0.773     0.293 0.516 0.636      0.397 0.629 0.759
                                                                                                              6         0.215   0.382   0.501   0.325 0.553 0.667   0.310 0.548 0.660     0.296 0.507 0.646      0.261 0.475 0.594
                                                                                                              10        0.167   0.305   0.403   0.319 0.559 0.689   0.246 0.478 0.611     0.294 0.542 0.648      0.195 0.421 0.562

                                                                            This table presents the percentages of rejection of the non-linearity hypothesis when using the Hung et al. (2009) test adapted to the case of a TAR
                                                                            model. In the equation (13) the model is presented, the value of ω is related to the magnitude of the outliers and its deﬁnition is presented in the lower
                                                                                                                                                                                                                                         Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...




                                                                            part of the equation (5). The value of the ν parameter is equal to 0.5 and the sample size is T = 200.




Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40
                                                                                                                                                                                                                                         13

14                                             Sergio Calderon & Daniel Ordoñez Callamad


    It is worth highlighting some results obtained, for example, in Table 3 for a
sample size T = 200 and in the case ω = 3. It is observed that the empirical
levels for the test (corresponding to the nominals of 1%, 5%, and 10%) using
the LS function are (0.076, 0.0187, 0.264), while those of the Huber function with
parameter k = 1.345 are (0.011, 0.053, 0.113). This result shows the size problems
that additive outlier observations can cause when the least-squares function is used
and shows that this problem does not disappear with the increase in the sample
size (see Table 2). What we found goes in hand with that pointed out by Hung
et al. (2009) for the case of SETAR models and veriﬁes the advantages of the test
in the presence of outlier observations.
    It is observed that the introduction of outlier data (ω ̸= 0) slightly decreases the
power of the test; however, this eﬀect can be controlled by taking a larger sample
                                                                             (2)
size. For example, for the function Tukey with parameter c = 4.685, ϕ1 = −0.5,
a nominal size of 5% and a sample T = 100 the power is (0.743, 0.678, 0.674,
0.675) (see Table 2) for the values of ω = 0, 3,6,10 respectively. On the other
hand, when taking a sample of size T = 200, the power increases to (0.969, 0.946,
0.951, 0.956).
    Regarding the choice of the ψ(·) function and its respective parameters, the
results of the simulations in Tables 2 and 3 show that the Huber function with
parameter k = 1.345 generally achieves higher power levels than the Tukey function
with c = 4.6853 . Similarly, when this function is compared with k = 3.291 and that
of Tukey with c = 15 the former seems to give slightly better results. Additionally,
unlike what Hung et al. (2009) found, there does not seem to be strong evidence
to prefer the use of the Huber (k = 3.291) and Tukey (c = 15) to those that use
smaller values of to those that k and c parameters.


Additional Monte Carlo Simulation About Non-Linearity
Test
    In Appendix A, we can ﬁnd complementary simulation results about the non-
linearity test. We consider three scenarios: (1) diﬀerent values of autoregressive
coeﬃcient for the threshold variable ν = −0.54 ; (2) diﬀerent percentages of outlier
observations β = 10%5 , and (3) diﬀerent percentage of observation in each regime,
the threshold value controls this. Each scenario is evaluated for sample size
T = 2006 . Scenarios (2) and (3)were not taking into account in Hung et al.
(2009). For the scenario (1), we can observe in Table A1 similar results to that
obtained when the autoregressive parameter is ν = 0.5 for the non-linearity test,
that is, it seems the autoregressive parameter does not aﬀect the results for the
   3 This comparison is valid as long as these parameters guarantee a relative asymptotic eﬃciency

of the estimator in the Gaussian case of 95%.
   4 Results for coeﬃcients ν = ±0.8 were not reported in the appendix for the Journal guidelines,

however they are available for the authors.
   5 Results for β = 1% were not reported in the appendix for the Journal guidelines, however

they are available for the authors.
   6 Results for sample size T = 100 were not reported in the appendix for the Journal guidelines,

however they are available for the authors.


                     Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...           15

non-linearity test. For scenario (2), the results of the non-linearity test simulations
for diﬀerent percentages of contamination of outliers based on Table A2 show that
if these types of observations are present, the Huber and Tukey functions are better
than least-squares since they do not suﬀer from size problems. If the percentage of
contamination is high, then the power is decreased, and it is suggested to use these
same functions with low k and c values, while if the percentage is low, the power is
kept, and the values of k and c should be high. Huber’s function appears to perform
better on average than Tukey’s. For scenario (3), the main conclusion derived
from the results obtained is that the diﬀerence in the percentages of observations
in each regime generates a signiﬁcant decrease in the power of the non-linearity
test. However, this problem improves with an increase in the sample size see Table
A3. In general, we can observe similar results to those obtained in Hung et al.
(2009) for SETAR models. However, we can observe a slight increase in the power
of robust non-linearity test for the open-loop TAR models compared with the test
                                              (2)
for SETAR models, when the parameter ϕ1 moves from 0.5 to positive or zero
values, even when ω is increased.


4.2. Main Results about Estimation of the Autoregressive
     coeﬃcients
   The relative performance of the proposed Robust estimator with respect to
the least-squares one is evaluated. First, the mean square error ratio between
the estimator GM with function choices ψ : Huber, Tukey is reported (parameters
k = 1.345, c = 4.685) against the least squares estimator (that is ψ : LS)7 . Second,
we obtain the absolute average bias for the estimations is studied. We initially
consider a contamination percentage of outlier data of β = 5%.
    Table 4 presents the mean square error ratios between the GM estimator and
the least-squares estimator.On the other hand, Table 5 shows the average biases
in absolute value. All results are based on 1000 simulations and for samples of size
T = 100. Tables 6 and 7 show comparable results for samples of size T = 200.
    In the case that ω = 0 (that is, when there are no outliers), the estimators
obtained through least-squares are better (in terms of mean square error) than
those of the GM method for both a sample size T = 100 as in the case T = 200.
                                   (1)
For example, for the parameter ϕ1 , the root of the mean square error ratio almost
always exceeds the value of 1.2. On the other hand, under outlier observations,
the estimator based on the GM method has a better performance than the least-
squares one. In fact, in most cases where outliers exist, the root of the mean square
error ratios choosing the function ψ : Huber is less than 1. For example, the ratios
                 (2)
for the model ϕ1 = −0.8 with the highest magnitude outliers (ω = 10), and a
sample size of T = 200 (see Table 6), they become as low as 0.095 and 0.037 for
the autoregressive coeﬃcients of each regimen. As the contamination parameter
ω increases, the results further favor the estimator based on the GM method.

  7 That is, the root mean square error based on the estimator GM is located in the numerator

while the least squares in the denominator.


                    Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

16                                                   Sergio Calderon & Daniel Ordoñez Callamad

Table 4: Mean square error ratio between the GM and the classical estimator based on
         1000 replications with a TAR model (Z, 2, 1, 1, 0), sample size equal to 100,
         ν = 0.5.
                                           Huber k = 1.345                     Tukey c = 4.685
  (1)    (1)    (2)    (2)           (1)       (1)       (2)     (2)     (1)      (1)    (2)      (2)
 ϕ0     ϕ1     ϕ0     ϕ1     ω     ϕ̂0       ϕ̂1       ϕ̂0     ϕ̂1     ϕ̂0       ϕ̂1    ϕ̂0      ϕ̂1
  0.5    0.5    0.5   -0.8    0   1.297     1.554      1.176   1.410   1.877    3.071   1.464    2.558
                             3    0.917     0.793      0.719   0.485   1.227    1.430   0.870    0.796
                             6    0.434     0.283      0.326   0.140   0.563    0.485   0.367    0.207
                             10   0.269     0.208      0.195   0.080   0.327    0.311   0.223    0.118
  0.5    0.5    0.5   -0.5    0   1.274     1.504      1.179   1.420   1.823    2.782   1.463    2.501
                             3    0.877     0.703      0.801   0.772   1.182    1.210   0.963    1.313
                             6    0.449     0.335      0.409   0.310   0.608    0.537   0.476    0.479
                             10   0.286     0.232      0.222   0.221   0.337    0.351   0.248    0.350
  0.5    0.5    0.5   -0.2    0   1.231     1.386      1.154   1.384   1.698    2.580   1.486    2.574
                             3    0.806     0.658      0.948   1.119   1.044    1.072   1.236    2.109
                             6    0.365     0.298      0.502   0.851   0.463    0.478   0.632    1.523
                             10   0.254     0.215      0.309   0.653   0.309    0.340   0.380    1.213
  0.5    0.5    0.5     0    0    1.215     1.369      1.245   1.484   1.716    2.546   1.689    2.794
                             3    0.799     0.676      1.055   1.377   1.076    1.102   1.469    2.785
                             6    0.381     0.313      0.620   1.432   0.462    0.505   0.811    2.761
                             10   0.241     0.212      0.340   1.124   0.294    0.327   0.434    2.087
  0.5    0.5    0.5    0.2   0    1.231     1.391      1.201   1.416   1.821    2.505   1.747    2.727
                             3    0.809     0.723      0.922   1.050   1.090    1.151   1.281    2.011
                             6    0.410     0.321      0.540   0.761   0.530    0.500   0.716    1.362
                             10   0.255     0.229      0.347   0.684   0.317    0.345   0.468    1.236
  0.5    0.5    0.5    0.5   0    1.259     1.427      1.276   1.435   1.886    2.649   2.050    2.830
                             3    0.767     0.697      0.804   0.664   1.141    1.179   1.208    1.189
                             6    0.423     0.344      0.374   0.342   0.529    0.511   0.508    0.545
                             10   0.252     0.241      0.238   0.208   0.328    0.358   0.318    0.327
  0.5    0.5    0.5    0.8   0    1.248     1.456      1.288   1.392   1.829    2.633   2.110    2.691
                             3    0.745     0.716      0.511   0.433   0.989    1.145   0.701    0.674
                             6    0.376     0.311      0.180   0.143   0.493    0.499   0.238    0.217
                             10   0.225     0.204      0.104   0.086   0.271    0.299   0.145    0.132

This table presents the mean square error ratio obtained through simulations between the GM
estimator and the least-squares estimator. In equation (13) the model is presented, the value of
ω is related to the outliers’ magnitude, and its deﬁnition is presented in the lower part of the
equation (5). The value of the parameter ν is equal to 0.5, and the sample size is T = 100.




                      Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...                                      17

Table 5: The GM and classical estimators’ absolute average bias based on 1000
         replications with a TAR model(Z, 2, 1, 1, 0), sample size equal to 100, ν = 0.5.
     Huber k = 1.345                  Tukey c = 4.685                      LS
  (1)    (1)    (2)       (2)            (1)    (1)    (2)    (2)    (1)    (1)    (2)    (2)    (1)    (1)    (2)    (2)
ϕ0      ϕ1     ϕ0     ϕ1          ω     ϕ̂0    ϕ̂1    ϕ̂0    ϕ̂1    ϕ̂0    ϕ̂1    ϕ̂0    ϕ̂1    ϕ̂0    ϕ̂1    ϕ̂0    ϕ̂1
0.5     0.5    0.5    -0.8       0      0.01 0.02 0.00 0.00         0.01 0.03 0.00 0.00         0.00 0.02 0.01 0.01
                                 3      0.02 0.05 0.01 0.03         0.02 0.04 0.00 0.01         0.05 0.10 0.05 0.13
                                 6      0.02 0.05 0.02 0.04         0.02 0.04 0.00 0.01         0.12 0.21 0.12 0.29
                                 10     0.02 0.05 0.02 0.03         0.02 0.04 0.00 0.00         0.14 0.28 0.16 0.41
0.5     0.5    0.5    -0.5       0      0.02 0.03 0.00 0.01         0.03 0.03 0.01 0.01         0.01 0.02 0.00 0.00
                                 3      0.04 0.05 0.01 0.02         0.03 0.04 0.00 0.01         0.08 0.13 0.05 0.09
                                 6      0.04 0.05 0.01 0.02         0.03 0.04 0.00 0.00         0.14 0.23 0.10 0.20
                                 10     0.04 0.05 0.01 0.02         0.03 0.03 0.00 0.00         0.19 0.30 0.13 0.28
0.5     0.5    0.5    -0.2       0      0.01 0.02 0.01 0.01         0.01 0.02 0.01 0.01         0.01 0.02 0.00 0.01
                                 3      0.02 0.05 0.00 0.01         0.02 0.03 0.00 0.00         0.08 0.13 0.03 0.04
                                 6      0.03 0.05 0.00 0.00         0.01 0.02 0.01 0.01         0.17 0.24 0.04 0.07
                                 10     0.03 0.05 0.00 0.00         0.01 0.03 0.01 0.01         0.21 0.31 0.07 0.11
0.5     0.5    0.5    0          0      0.02 0.03 0.01 0.02         0.02 0.03 0.00 0.01         0.02 0.03 0.01 0.02
                                 3      0.04 0.05 0.00 0.02         0.02 0.03 0.01 0.02         0.10 0.14 0.01 0.01
                                 6      0.04 0.05 0.00 0.02         0.03 0.03 0.00 0.01         0.18 0.24 0.00 0.02
                                 10     0.03 0.05 0.01 0.02         0.02 0.03 0.01 0.02         0.23 0.31 0.00 0.02
0.5     0.5    0.5    0.2        0      0.03 0.03 0.02 0.02         0.03 0.03 0.01 0.02         0.03 0.03 0.02 0.02
                                 3      0.05 0.06 0.03 0.04         0.04 0.05 0.02 0.02         0.11 0.13 0.05 0.07
                                 6      0.05 0.06 0.03 0.04         0.04 0.04 0.02 0.02         0.21 0.25 0.09 0.11
                                 10     0.05 0.05 0.03 0.04         0.04 0.04 0.02 0.03         0.26 0.31 0.11 0.14
0.5     0.5    0.5    0.5        0      0.03 0.03 0.02 0.03         0.04 0.04 0.02 0.02         0.03 0.03 0.03 0.03
                                 3      0.06 0.06 0.05 0.06         0.05 0.05 0.04 0.04         0.13 0.13 0.13 0.13
                                 6      0.06 0.06 0.06 0.06         0.05 0.04 0.03 0.03         0.23 0.24 0.24 0.23
                                 10     0.07 0.07 0.05 0.05         0.05 0.05 0.03 0.04         0.31 0.32 0.30 0.31
0.5     0.5    0.5    0.8        0      0.05 0.03 0.06 0.03         0.05 0.03 0.06 0.04         0.05 0.03 0.06 0.03
                                 3      0.09 0.06 0.10 0.06         0.07 0.05 0.08 0.05         0.17 0.12 0.25 0.16
                                 6      0.08 0.06 0.10 0.06         0.06 0.04 0.08 0.05         0.29 0.21 0.51 0.32
                                 10     0.08 0.06 0.10 0.06         0.06 0.04 0.07 0.04         0.41 0.29 0.70 0.43

This table presents the absolute average biases for each of the parameters obtained using the GM
estimator and the least-squares estimator. In equation (13), the model is presented, the value of
ω is related to the magnitude of the outliers, and its deﬁnition is presented in the lower part of
the equation (5). The value of the parameter ν is equal to 0.5, and the sample size is T = 100.




                                Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

18                                                   Sergio Calderon & Daniel Ordoñez Callamad

Table 6: Mean square error ratio between the GM and the classical estimator based on
         1000 replications with a TAR model (Z, 2, 1, 1, 0), sample size equal to 200,
         ν = 0.5.
                                           Huber k = 1.345                     Tukey c = 4.685
  (1)    (1)    (2)    (2)           (1)       (1)       (2)     (2)     (1)      (1)    (2)      (2)
 ϕ0     ϕ1     ϕ0     ϕ1     ω     ϕ̂0       ϕ̂1       ϕ̂0     ϕ̂1     ϕ̂0       ϕ̂1    ϕ̂0      ϕ̂1
  0.5    0.5    0.5   -0.8    0   1.201     1.432      1.142   1.328   1.553    2.562   1.357    2.298
                             3    0.795     0.539      0.643   0.285   0.956    0.798   0.735    0.401
                             6    0.344     0.157      0.271   0.070   0.383    0.218   0.300    0.089
                             10   0.211     0.095      0.141   0.037   0.231    0.137   0.152    0.048
  0.5    0.5    0.5   -0.5    0   1.163     1.352      1.187   1.357   1.583    2.393   1.453    2.362
                             3    0.695     0.479      0.745   0.449   0.879    0.732   0.884    0.699
                             6    0.319     0.171      0.350   0.158   0.371    0.243   0.395    0.234
                             10   0.191     0.111      0.216   0.099   0.234    0.157   0.234    0.146
  0.5    0.5    0.5   -0.2    0   1.228     1.335      1.202   1.405   1.650    2.372   1.536    2.503
                             3    0.721     0.492      0.853   1.023   0.887    0.738   1.068    1.900
                             6    0.296     0.170      0.520   0.655   0.350    0.248   0.635    1.127
                             10   0.194     0.112      0.300   0.459   0.221    0.154   0.363    0.789
  0.5    0.5    0.5     0    0    1.198     1.332      1.154   1.379   1.614    2.257   1.479    2.510
                             3    0.658     0.476      0.940   1.284   0.811    0.753   1.210    2.429
                             6    0.285     0.178      0.588   1.384   0.333    0.247   0.706    2.450
                             10   0.175     0.111      0.304   1.065   0.206    0.160   0.371    1.951
  0.5    0.5    0.5    0.2   0    1.268     1.464      1.211   1.403   1.796    2.629   1.654    2.569
                             3    0.615     0.484      0.879   0.935   0.780    0.750   1.182    1.682
                             6    0.274     0.185      0.516   0.582   0.314    0.260   0.677    1.021
                             10   0.170     0.116      0.286   0.413   0.196    0.165   0.356    0.677
  0.5    0.5    0.5    0.5   0    1.252     1.405      1.290   1.384   1.782    2.328   1.918    2.430
                             3    0.611     0.488      0.600   0.466   0.800    0.713   0.784    0.720
                             6    0.245     0.173      0.247   0.163   0.304    0.240   0.324    0.236
                             10   0.142     0.115      0.151   0.107   0.169    0.150   0.195    0.157
  0.5    0.5    0.5    0.8   0    1.253     1.447      1.302   1.463   1.844    2.660   1.950    2.583
                             3    0.615     0.525      0.396   0.318   0.848    0.848   0.495    0.435
                             6    0.219     0.173      0.116   0.083   0.280    0.255   0.135    0.109
                             10   0.126     0.096      0.064   0.045   0.156    0.143   0.077    0.061

This table presents the mean square error ratio obtained through simulations between the GM
estimator and the least-squares estimator. In equation (13) the model is presented, the value of
ω is related to the outliers’ magnitude, and its deﬁnition is presented in the lower part of the
equation (5). The value of the parameter ν is equal to 0.5, and the sample size is T = 200.




                      Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...                                             19

Table 7: The GM and classical estimators’ absolute average bias based on 1000
         replications with a TAR model(Z, 2, 1, 1, 0), sample size equal to 200, ν = 0.5.
                                              Huber k = 1.345               Tukey c = 4.685                      LS
  (1)    (1)    (2)       (2)            (1)      (1)    (2)    (2)    (1)      (1)    (2)    (2)    (1)    (1)       (2)    (2)
ϕ0      ϕ1     ϕ0     ϕ1          ω     ϕ̂0      ϕ̂1    ϕ̂0    ϕ̂1    ϕ̂0     ϕ̂1     ϕ̂0    ϕ̂1    ϕ̂0    ϕ̂1    ϕ̂0       ϕ̂1

0.5     0.5    0.5    -0.8       0      0.01 0.01 0.00 0.01           0.01 0.00 0.00 0.01           0.01 0.01 0.01 0.01
                                 3      0.03 0.03 0.02 0.03           0.02 0.02 0.01 0.02           0.06 0.10 0.06 0.13
                                 6      0.03 0.03 0.02 0.04           0.02 0.01 0.01 0.02           0.14 0.22 0.13 0.32
                                 10     0.03 0.03 0.01 0.03           0.02 0.01 0.01 0.01           0.19 0.30 0.18 0.46
0.5     0.5    0.5    -0.5       0      0.01 0.02 0.00 0.00           0.01 0.02 0.00 0.01           0.01 0.02 0.00 0.00
                                 3      0.03 0.05 0.01 0.03           0.02 0.03 0.00 0.00           0.08 0.13 0.05 0.11
                                 6      0.03 0.04 0.01 0.02           0.02 0.02 0.00 0.00           0.16 0.25 0.10 0.24
                                 10     0.03 0.04 0.02 0.02           0.02 0.02 0.00 0.00           0.21 0.33 0.14 0.32
0.5     0.5    0.5    -0.2       0      0.01 0.02 0.00 0.01           0.02 0.02 0.01 0.01           0.01 0.02 0.00 0.00
                                 3      0.03 0.05 0.00 0.01           0.02 0.03 0.00 0.00           0.09 0.13 0.02 0.05
                                 6      0.04 0.05 0.01 0.01           0.02 0.03 0.00 0.01           0.19 0.27 0.06 0.10
                                 10     0.03 0.05 0.01 0.01           0.02 0.03 0.00 0.01           0.23 0.35 0.06 0.13
0.5     0.5    0.5    0          0      0.01 0.02 0.00 0.00           0.01 0.02 0.00 0.00           0.01 0.02 0.00 0.00
                                 3      0.03 0.05 0.00 0.00           0.02 0.03 0.00 0.00           0.10 0.14 0.00 0.00
                                 6      0.04 0.04 0.00 0.00           0.02 0.02 0.00 0.00           0.20 0.27 0.00 0.00
                                 10     0.03 0.04 0.00 0.01           0.02 0.02 0.00 0.00           0.26 0.34 0.02 0.01
0.5     0.5    0.5    0.2        0      0.02 0.02 0.00 0.01           0.02 0.02 0.00 0.01           0.02 0.02 0.01 0.01
                                 3      0.04 0.05 0.01 0.02           0.03 0.03 0.01 0.02           0.12 0.14 0.04 0.06
                                 6      0.04 0.05 0.02 0.03           0.02 0.03 0.01 0.01           0.22 0.26 0.08 0.11
                                 10     0.04 0.04 0.01 0.03           0.03 0.02 0.00 0.01           0.29 0.35 0.10 0.15
0.5     0.5    0.5    0.5        0      0.01 0.02 0.02 0.02           0.00 0.02 0.02 0.02           0.01 0.02 0.02 0.01
                                 3      0.04 0.05 0.05 0.05           0.02 0.03 0.04 0.03           0.12 0.13 0.14 0.13
                                 6      0.03 0.05 0.05 0.05           0.01 0.02 0.03 0.03           0.25 0.26 0.27 0.27
                                 10     0.03 0.04 0.05 0.04           0.01 0.02 0.03 0.02           0.34 0.34 0.35 0.34
0.5     0.5    0.5    0.8        0      0.00 0.01 0.04 0.02           0.00 0.01 0.05 0.02           0.01 0.01 0.04 0.02
                                 3      0.04 0.03 0.09 0.05           0.02 0.02 0.07 0.04           0.13 0.10 0.25 0.16
                                 6      0.04 0.04 0.09 0.05           0.02 0.02 0.06 0.03           0.30 0.23 0.54 0.34
                                 10     0.04 0.04 0.08 0.05           0.01 0.02 0.05 0.03           0.41 0.31 0.74 0.47

This table presents the absolute average biases for each of the parameters obtained using the GM
estimator and the least-squares estimator. In equation (13), the model is presented, the value of
ω is related to the magnitude of the outliers, and its deﬁnition is presented in the lower part of
the equation (5). The value of the parameter ν is equal to 0.5, and the sample size is T = 200.



    A comparison of the ratios obtained using the function ψ : Huber and
that of Tukey shows that the ﬁrst choice (Huber) seems to perform better for
estimating the models’ of the autoregressive coeﬃcients. This observation is
particularly relevant for the case where there are no outliers. For example,
                                                                 (2)
the ratios for a sample size T = 100 (see Table 4), the model ϕ1 = −0.5

                                Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

20                                             Sergio Calderon & Daniel Ordoñez Callamad


are 1.274, 1.504, 1.179, 1.420 for the Huber function while with Tukey it is
1.823, 2.782, 1.463, 2.501.
    Regarding the absolute average bias presented in Tables 5 and 7, both
estimators (GM and LS) have a bias very small in the case that there are no
outliers. As the magnitude of these observations increases, the bias of the least
squares estimator also increases. A case that draws attention is presented in Table
                   (2)
5 for the model ϕ1 = 0.8 and ω = 10, where absolute average bias of the least-
squares estimator reaches 0.7 for the intercept of the second regime and 0.43 for
its respective autoregressive coeﬃcient.
    The GM estimators obtained for the two functions ψ(·) considered have
relatively small absolute average bias magnitudes, and in general, these seem to
improve with increasing sample size (see Table 7). Unlike the results obtained
for the root mean square error ratios, Tables 5 and 7 show that, in general, the
magnitude of the bias of the estimator GM used by the Huber function is greater
than the one based on Tukey. This suggests that the estimator based on the ﬁrst
has a lower variance in the simulations (so that its mean square error may be
smaller as seen in Tables 4 and 6).


Additional Monte Carlo Simulation for the Estimation of the
Autoregressive Coeﬃcients
    In Appendix B, we can ﬁnd any other results about parameter estimation.
We consider ﬁve scenarios: (1) diﬀerent value of the autoregressive coeﬃcient
for the threshold variable ν 8 ; (2) diﬀerent percentage of outlier observations9 ,
(3) diﬀerent percentage of observations in each regime, (4) empirical distribution
of the GM estimator of the autoregressive coeﬃcients for ﬁnite samples, and
(5) Percentage of empirical coverage of the ﬁnite sample conﬁdence intervals
for the autoregressive coeﬃcients. Each scenario is evaluated for sample size
T = 20010 . For scenario (1), we can observe in Table B1, similar results to
that obtained when the autoregressive parameter is ν = −0.5, ±0.8 for the ratio
between the mean square error of the GM and least-squares estimators, that is, it
seems the autoregressive parameter does not aﬀect the results for the estimation
performance. For scenario (2), based on Table B2, we can observe similar results
to that obtained for the contamination percentage of 5%. In the case of scenario
(3), based on Table B3 we can see similar results to those obtained previously
when the number of observations in each regime is approximately the same. This
corroborates the evidence regarding the improvement obtained (in terms of mean
square error) when using the GM estimator instead of the least-squares in the
presence of outlier observations, especially when the magnitude of these is large
ω = 10. Additionally, the decrease in the number of observations in the second
   8 Results for coeﬃcients ν = ±0.8 were not reported in the appendix for Journal guidelines,

however they are available for the authors.
   9 Results for β = 1% were not reported in the appendix for the Journal guidelines, however

they are available for the authors.
  10 Results for sample size T = 100 were not reported in the appendix for the Journal guidelines,

however they are available for the authors.


                     Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...          21

                                                                                         (2)
regime worsens the relative performance of the estimator of the coeﬃcients ϕ0
       (2)
and ϕ1 . In scenario (4), we used Tables B4 and B5 to explore the estimator
GM ’s distribution because the asymptotic normal distribution is guaranteed by
Theorem 1 in Hung et al. (2009) for open-loop TAR models. These tables give
us the p-value for the univariate Shapiro-Wilk normality test for the distribution
of individual GM estimator when the sample size is T = 100 and T = 1000,
based on 1000 replications. We can observe that by increasing the sample size, it
is possible to approximate the distribution of the GM estimator by a normal
distribution, in special if the magnitude of the additive outliers is not large.
Finally, in scenario (5), we evaluate the coverage percentage of the 95% conﬁdence
intervals for the autoregressive parameters of the open-loop TAR model based
on the normal distribution, see Table B6. The results show that the empirical
coverage percentages are relatively close to the nominal 95%; however, in the vast
majority of cases, the empirical levels are lower than the nominal for both functions
ψ : Huber and Tukey. This problem seems to improve with increasing sample size.
All results about empirical coverage of conﬁdence intervals were possible using the
covariance matrix estimator in (8).
    Comparisons with the work of Chan & Cheung (1994) are not straightforward;
however, the results are analogous because the performance of the GM estimator
is better in the presence of outliers. That is, the mean square error ratio
between the estimator GM and the LS tends to decrease in the presence of
outliers, and the size of the outlier ω is large, while the ratio tends to decrease
when the size of outlier is small or zero. It is important to point out that in
Chan & Cheung (1994) is not studied the empirical distributions of the GM
estimators for the autoregressive parameters in ﬁnite samples, neither the empirical
coverage of the conﬁdence intervals.


5. Real Data Application
    This section presents two real data applications of the non-linearity test and
the estimation procedure proposed to study the behavior of the returns of the
nominal exchange rate COP/USD. The sample under study is relevant to the
extent that the world economic crisis of 2009 generated extreme depreciation of
the peso against the dollar Vargas (2011). These movements were widely reﬂected
in the returns; therefore, it could be thought that there are outliers in the observed
time series. The weekly returns of the nominal exchange rate are calculated based
on daily information taken directly from the Banco de la República website. The
sample begins in the ﬁrst week of 2009 and ends in the last week of 2018; there
are 520 observations weekly.
    In the ﬁrst example, we can observe the impact of the outlier in the non-
linearity test. The second example is comparable with the real data example
BLOWFLY in Hung et al. (2009); the classical non-robust and robust tests gave
same results, that is, reject the null hypothesis.




                   Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

22                                             Sergio Calderon & Daniel Ordoñez Callamad


First Example
    Analogously to what was proposed in Franses et al. (2000, p. 88) for the use of
the TAR model, it is considered that the variable determining the regime change
is a measure of volatility similar to that proposed by LeBaron (1992) calculated
as the median of the absolute value of returns in the last four weeks(previous
month)11 . This measure has been widely used in ﬁnance as an approximation to
the volatility of exchange rate returns.
     Th interest variable Rett is:
                                               F X7t
                                     Rett =          − 1,                                    (16)
                                               F X1t
where F X7t y F X1t represent the nominal exchange rate of the last/ﬁrst day of
the t-th week.
    On the other hand, the determining variable of the thresholds is (note that in
this case, the value of delay d is equal to 0):

                    Zt = med(|Rett−1 |, |Rett−2 |, |Rett−3 |, |Rett−4 |).                    (17)

     We can observe the plot of two-time series in 1.

Table 8: P -values of the non-linearity test for diﬀerent orders p of the autoregressive
         process using volatility measure as a transition variable.
 p       LS     Huber k = 1.345       Huber k = 3.291       Tukey c = 4.685      Tukey c = 15
 1      0.05           0.11                  0.03                 0.27                0.02
 2      0.09           0.11                  0.07                 0.31                0.08

This table presents the p-values of the non-linearity test proposed by Hung et al. (2009) adapted
to the case of open-loop TAR models for diﬀerent values of autoregressive orders. The time
series considered is the series of weekly exchange rate returns COP/USD in 2009-2019. The
variable used to determine the thresholds is the median of the absolute values of the returns in
the last four weeks.




  11 The measure proposed by LeBaron (1992) is the average in the last j weeks, with j a known

number.


                     Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...               23

Figure 1: The behavior of the weekly returns of the COP/USD exchange rate and the
          volatility measure used as a determinant of the regime change.
                                                   Retornos




                 0.04




                 0.00




                −0.04




                         2010         2012           2014         2016       2018
        Valor




                                                Variable Umbral




                 0.04




                 0.03




                 0.02




                 0.01




                 0.00

                         2010         2012           2014         2016       2018
                                                   Fecha

The upper panel presents the weekly returns of the COP/USD exchange rate from the ﬁrst week
of 2009 to the last week of 2018. The lower panel presents the median of the absolute value of
the returns in the four weeks before each week.


    The results of the non-linearity test are presented in Table 8. As it can be seen
for values of the autoregressive order p = 1, 2 when using the LS function(that is,
when the test is not robust to outliers), the null hypothesis of linearity is rejected
in favor of the non-linearity type open-loop TAR at the level of signiﬁcance of
10%. However, when testing with functions ψ : Huber, Tukey with parameters
k = 1.345, c = 4.685, the null hypothesis is not rejected at this level signiﬁcance.
Therefore, we decide not to reject the null hypothesis of linearity.




                        Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

24                                              Sergio Calderon & Daniel Ordoñez Callamad


Second Example

   In a relatively recent study, Mohammadi & Jahan-Parvar (2012) ﬁnd that there
may be a relationship between real oil prices and real exchange rates for countries
where there is a high production of this product. Since Colombia is a country
where this condition is met, the non-linearity test is carried out, but considering
that the threshold variable is the change in the actual weekly price of a barrel of
Brent oil. The two-time series are shown in Figure 2.


Figure 2: Behavior of the weekly returns of the COP/U SD exchange rate and the
          change in the real price of a barrel of Brent oil measured in USD
                                                   Retornos




                 0.04




                 0.00




                −0.04




                         2010         2012           2014         2016       2018
        Valor




                                                Variable Umbral

                  10




                   5




                   0




                  −5




                 −10

                         2010         2012           2014         2016       2018
                                                   Fecha

The upper panel presents the weekly returns of the COP/U SD exchange rate from the ﬁrst week
of 2009 to the last week of 2018. The lower panel shows the change in the price of a barrel of
Brent oil measured in dollars.


                        Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...                   25

    The non-linearity test results for diﬀerent values of the autoregressive order
are presented in Table 9. As it can be seen, it is found that for all lags and using
all the ψ(·) functions, there is statistical evidence to reject the null hypothesis of
linearity in favor of the TAR-type non-linearity hypothesis. Based on this result,
we proceed to estimate the TAR model parameters with two regimes using the
function ψ(·): Huber with parameter k equal to 1.3454. In order to identify the
autoregressive orders, the estimation procedure is carried out for all the possible
combinations p1 = 1, . . . , 5, and p2 = 1, . . . , 5. The best model is chosen through
the criterion of Akaike information
            AIC(p1 , p2 ) = n1 ln(σ̂12 ) + n2 ln(σ̂22 ) + 2(p1 + 1) + 2(p2 + 1).             (18)
The optimal value of the threshold r is obtained by carrying out a procedure similar
to that speciﬁed in (10) once the values of p1 and p2 are known. It is assumed that
the number of regimens is 2; in empirical applications, it is suggested to carry out
this process for a diﬀerent number of regimens and compare the results obtained.
Table 9: P -values of the non-linearity test for diﬀerent orders p of the autoregressive
         process using as threshold variable the changes in the Brent oil price.
 p        LS         Huber k = 1.345        Huber k = 3.291   Tukey c = 4.685      Tukey c = 15
 1    6.7×10−16         8.0×10−11              3.9×10−13          1.2×10−7            5.1×10−13
 2    1.1×10−15         1.7×10−8               1.7×10−11          6.3×10−5            4.2×10−11
 3    3.8×10−15         3.2×10−6               3.3×10−9           3.8×10−5            8.4×10−9
 4    2.8×10−14         3.5×10−4               2.2×10−6           2.2×10−2            1.8×10−6
 5    2.2×10−14         7.3×10−4               5.2×10−6           6.5×10−3            4.0×10−6

This table represent the p-values of the non-linearity test proposed by Hung et al. (2009) adapted
to the case of the open-loop TAR models for diﬀerent values of the autoregressive order. The
time series considered is the weekly exchange rate return COP/USD in the period 2009-2019.
The variable used to determinate the thresholds is the change in the weekly real price of the
barrel of Brent oil.


Table 10: Values of the Akaike information criterion for diﬀerent combination of p1 y
          p2 used by obtaining GM estimator with function ψ : Huber k = 1.345.
           p1 /p2         1             2             3             4             5
               1      -2260.20      -2347.18       -2357.90     -2356.50      -2355.73
               2      -2268.12      -2267.31       -2346.77     -2356.56      -2350.59
               3      -2276.35      -2262.60       -2253.61     -2274.53      -2347.00
               4      -2271.96      -2267.79       -2255.57     -2261.20      -2344.17
               5      -2284.75      -2288.07       -2274.72     -2277.78      -2267.48

         This table presents the values of the information criterion AIC deﬁned in the
         equation (18) for the diﬀerent combinations of p1 and p2 selected to carry
         out the estimation of the open-loop TAR model using the estimator GM with
         function ψ : Huber k = 1.345.

    The results in Table 10 show that the model selected through Akaike’s
information criterion is p1 = 1 and p2 = 3. For this model, the estimated threshold

                     Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

26                                                Sergio Calderon & Daniel Ordoñez Callamad


value is r̂ = −1.482. When carrying out the estimation procedure, it is found that
the last coeﬃcient in the second regime is not signiﬁcant; therefore the estimation
is carried out for the model p1 = 1 and p2 = 2 and the following results are
obtained.

Table 11: Estimation results of the GM method for the model T AR(k = 2, p1 = 1, p2 =
          2, d = 0), r = −1.482 with function ψ : Huber k = 1.345.
                                          ϕ0              ϕ1           ϕ2                 σ
     Primer régimen        ϕ̂(1)       0.007∗∗∗        0.398∗∗∗         -               0.013
                           σ̂ϕ(1)      0.001           0.126            -                 -
     Segundo régimen       ϕ̂(2)      -0.0007          0.005        0.135∗∗             0.011
                           σ̂ϕ(2)     0.0006           0.061        0.064                 -

This table presents the estimation results of the open-loop TAR model with two regimes,
p1 = 1, p2 = 2, r = −1.482 using GM method with function ψ : Huber k = 1.345. The
results are presented for each of the regimens. ϕ̂(j) y σ̂ϕ(j) denote the estimates and their
respective standard errors for the j-th regime. The latter are calculated using the expression
in the equation (8). Signiﬁcance is evaluated through Z statistics based on the assumption of
asymptotic normality.


    The results of the proposed model suggest that eﬀectively the behavior of the
nominal COP/U SD exchange rate changes in response to changes in the real price
of Brent oil. When there is a drop during the week above 1,482 dollars (in real
terms) in the price of a barrel of Brent oil, the nominal exchange rate COP/U SD
has a behavior with more remarkable persistence concerning the previous week’s
value (regime 1). On the other hand, when this price decreases less than this value
(or increases), it is observed that this variable has a lower persistence; in fact, its
values are determined partly by the value of two weeks ago. The variance in each
of these regimes is quite close.
     The model can be written as:
            {
              0.007 + 0.398Rett−1 + 0.013ϵt , si Zt < −1.482
     Rett =
              −0.0007 + 0.005Rett−1 + 0.135Rett−2 + 0.011ϵt − 1.482 ≤ Zt


6. Conclusions
    In this investigation, an adaptation of the non-linearity test proposed by Hung
et al. (2009) and of the estimation method proposed by Chan & Cheung (1994) for
the autoregressive coeﬃcients of the regimes was carried out in the case of open-
loop TAR models. Monte Carlo experiments were used to compare the power
and size of the non-linearity test with the classical test (which is not robust to
outliers) in the presence of additive outliers. The robust estimation method was
contrasted with that of least-squares through the mean square error ratios and
bias in the presence of these observations. Additionally, diﬀerent percentages of
contamination and the proportion of observations in each regime of the model
was studied. The approximation of the empirical distribution of the coeﬃcient

                       Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...            27

estimators was evaluated through the univariate normal distribution and also
the empirical coverage levels of the conﬁdence intervals in ﬁnite samples for the
parameters autoregressive in each regime.
    The non-linearity test results show that the classical test (based on least-
squares) presents discrepancies in its empirical and nominal size in the presence
of additive outlier observations, while the robust test does not. It was observed
that the Huber type’s robust function has slightly better power than the Tukey
type. The results are similar for diﬀerent percentages of contamination. The non-
linearity test’s power is susceptible concerning the proportion of observations in
each regime; however, this problem is solved with the increase in the sample size.
    On the other hand, for the estimation method of the autoregressive coeﬃcients,
the simulation exercises show that the robust estimator based on the GM
methodology has a better performance in terms of mean square error than that of
least-squares that when indeed there are additive outliers in the data. These results
are maintained by changing the percentages of contamination and the proportion
of observations in each regime.
    Although the marginal empirical distribution of each of the estimators by the
GM method is similar to a univariate normal distribution, the results of the
Shapiro-Wilk suggest that this approximation is only correct when the sample
size is large enough (T = 1000). In any case, the coverage percentages of the
asymptotic conﬁdence intervals based on assumption of normality are encouraging
even for small sample sizes such as T = 100 and T = 200, so their use in practical
situations seems to be justiﬁed.
    In the empirical application, the non-linearity test and the adapted estimation
procedure were used for the returns of the nominal exchange rate COP/USD time
series that can be considered contaminated with outlier observations. The robust
non-linearity test results were consistent with diﬀerent choices of function ψ and
the results of the estimation procedure were adequate.
                 [                                                       ]
                     Received: January 2021 — Accepted: July 2021



Appendix A. Additional Monte Carlo Simulation
            about Non-Linearity Test
    Diﬀerent value of autoregressive coeﬃcient ν for threshold variable. In this
section the percentage of contamination is 5% (Table A1). Diﬀerent contamination
percentage β (Table A2). Diﬀerent Percentage of observations in each regime. In
this section the global percentage of contamination is 5% (Table A3).


Appendix B. Additional Monte Carlo Simulation
            about Estimation of Autoregressive
            Coeﬃcients
    Diﬀerent value of autoregressive coeﬃcient ν for threshold variable. Diﬀerent
contamination percentage β of outliers (Tables B1, B2). Diﬀerent percentage
of observations in each regime (Table B3). Empirical distribution of the GM
estimator of the autoregressive coeﬃcients for ﬁnite samples (Tables B4, B5).
Percentage of the empirical coverage of the ﬁnite sample conﬁdence intervals for
the autoregressive coeﬃcients (Table B6).




                  Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

                                                                            Table A1: Empirical relative frequencies of rejection of the linearity hypothesis based on 1000 replications with a model T AR(Z, 2, 1, 1, 0),
                                                                                      sample size equal to 200 and parameter ν = −0.5.
                                                                                                                                 LS              Huber k = 1.345     Huber k = 3.291        Tukey c = 4.685          Tukey c = 15
                                                                                (1)    (1)    (2)       (2)
                                                                               ϕ0     ϕ1     ϕ0     ϕ1         ω   α=   1%      5%      10%     1%     5%    10%    1%     5%    10%       1%     5%    10%       1%     5%    10%
                                                                               0.5    0.5    0.5    -0.8      0         1.000   1.000   1.000   1.000 1.000 1.000   1.000 1.000 1.000      0.993 0.999 0.999      1.000 1.000 1.000
                                                                                                              3         0.994   1.000   1.000   0.998 1.000 1.000   1.000 1.000 1.000      0.988 0.997 0.999      0.999 1.000 1.000
                                                                                                              6         0.826   0.911   0.936   0.999 1.000 1.000   0.996 0.999 1.000      0.980 0.996 0.998      0.992 0.998 1.000
                                                                                                              10        0.463   0.650   0.730   0.994 0.998 0.999   0.985 0.996 0.997      0.979 0.998 1.000      0.985 0.995 0.997
                                                                               0.5    0.5    0.5    -0.5      0         0.999   1.000   1.000   0.984 0.998 1.000   0.996 1.000 1.000      0.922 0.976 0.992      0.996 1.000 1.000
                                                                                                              3         0.903   0.972   0.986   0.951 0.986 0.998   0.946 0.990 0.996      0.859 0.953 0.970      0.957 0.993 0.996
                                                                                                              6         0.610   0.770   0.840   0.944 0.986 0.998   0.895 0.969 0.985      0.880 0.956 0.981      0.892 0.973 0.986
                                                                                                              10        0.329   0.500   0.594   0.933 0.981 0.995   0.845 0.950 0.975      0.890 0.973 0.985      0.844 0.949 0.975
                                                                               0.5    0.5    0.5    -0.2      0         0.902   0.975   0.983   0.743 0.894 0.938   0.874 0.960 0.977      0.617 0.797 0.860      0.875 0.958 0.980
                                                                                                              3         0.628   0.797   0.869   0.643 0.836 0.900   0.655 0.834 0.905      0.535 0.745 0.833      0.660 0.850 0.910
                                                                                                              6         0.355   0.538   0.646   0.616 0.812 0.884   0.518 0.744 0.829      0.525 0.732 0.817      0.529 0.765 0.846
                                                                                                              10        0.223   0.341   0.438   0.577 0.813 0.885   0.427 0.679 0.793      0.534 0.746 0.837      0.437 0.698 0.824
                                                                               0.5    0.5    0.5    0         0         0.582   0.794   0.873   0.413 0.642 0.750   0.547 0.765 0.849      0.312 0.534 0.658      0.541 0.768 0.848
                                                                                                              3         0.359   0.579   0.678   0.316 0.569 0.691   0.323 0.547 0.672      0.257 0.493 0.605      0.338 0.573 0.700
                                                                                                              6         0.217   0.385   0.472   0.285 0.541 0.655   0.223 0.439 0.569      0.269 0.498 0.602      0.225 0.436 0.581
                                                                                                              10        0.181   0.308   0.396   0.299 0.530 0.672   0.196 0.400 0.530      0.272 0.514 0.628      0.184 0.410 0.557
                                                                               0.5    0.5    0.5    0.2       0         0.213   0.416   0.549   0.148 0.333 0.441   0.174 0.380 0.519      0.134 0.285 0.408      0.189 0.387 0.519
                                                                                                              3         0.141   0.308   0.413   0.106 0.266 0.386   0.098 0.258 0.359      0.107 0.249 0.369      0.112 0.273 0.377
                                                                                                              6         0.139   0.271   0.362   0.108 0.247 0.379   0.072 0.196 0.309      0.102 0.258 0.366      0.072 0.197 0.322
                                                                                                              10        0.143   0.240   0.315   0.106 0.232 0.336   0.056 0.165 0.247      0.102 0.267 0.364      0.056 0.169 0.254
                                                                               0.5    0.5    0.5    0.5       0         0.013   0.069   0.121   0.010 0.057 0.108   0.012 0.068 0.117      0.016 0.085 0.135      0.013 0.069 0.114
                                                                                                              3         0.031   0.094   0.166   0.013 0.047 0.092   0.014 0.054 0.099      0.017 0.075 0.123      0.012 0.057 0.090
                                                                                                              6         0.078   0.182   0.253   0.008 0.052 0.103   0.010 0.055 0.102      0.014 0.070 0.131      0.011 0.041 0.088
                                                                                                              10        0.105   0.193   0.260   0.008 0.046 0.099   0.007 0.038 0.080      0.016 0.069 0.124      0.006 0.028 0.067
                                                                               0.5    0.5    0.5    0.8       0         0.453   0.696   0.797   0.378 0.589 0.719   0.450 0.675 0.783      0.297 0.536 0.644      0.445 0.675 0.785
                                                                                                              3         0.265   0.459   0.555   0.282 0.518 0.630   0.298 0.529 0.657      0.243 0.479 0.594      0.291 0.511 0.649
                                                                                                              6         0.144   0.290   0.376   0.231 0.474 0.609   0.205 0.412 0.550      0.241 0.459 0.585      0.169 0.380 0.509
                                                                                                              10        0.121   0.225   0.294   0.235 0.452 0.591   0.157 0.341 0.463      0.255 0.477 0.597      0.150 0.318 0.441

                                                                            This table presents the percentages of rejection of the non-linearity hypothesis when using the Hung et al. (2009) test adapted to the case of a TAR
                                                                            model. In the equation (13) the model is presented, the value of ω is related to the magnitude of the outliers, and its deﬁnition is presented in the lower
                                                                                                                                                                                                                                          Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...




                                                                            part of the equation (5). The value of the ν parameter is equal to −0.5 and the sample size is T = 200.




Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40
                                                                                                                                                                                                                                          31

Sergio Calderon & Daniel Ordoñez Callamad




                                                                                                                                                                                                        Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40
                                            Table A2: Empirical relative frequencies of rejection of the linearity hypothesis based on 1000 replications with a model T AR(Z, 2, 1, 1, 0),
                                                      sample size equal to 200 and contamination percentage 10% ν = 0.5.
                                                                                                 LS              Huber k = 1.345     Huber k = 3.291      Tukey c = 4.685          Tukey c = 15
                                                (1)    (1)    (2)       (2)
                                               ϕ0     ϕ1     ϕ0     ϕ1         ω   α=   1%      5%      10%     1%     5%    10%    1%     5%    10%     1%     5%    10%       1%     5%    10%
                                               0.5    0.5    0.5    -0.8      0         1.000   1.000   1.000   0.999 1.000 1.000   1.000 1.000 1.000    0.992 0.998 0.999      1.000 1.000 1.000
                                                                              3         0.959   0.988   0.992   0.984 0.997 0.998   0.987 0.995 0.996    0.962 0.985 0.995      0.986 0.997 0.997
                                                                              6         0.546   0.733   0.819   0.981 0.996 0.998   0.913 0.975 0.989    0.960 0.989 0.997      0.897 0.968 0.989
                                                                              10        0.178   0.334   0.444   0.974 0.994 0.997   0.848 0.958 0.975    0.956 0.996 0.997      0.805 0.933 0.963
                                               0.5    0.5    0.5    -0.5      0         0.994   0.999   1.000   0.965 0.996 0.998   0.995 0.999 0.999    0.896 0.969 0.983      0.995 0.998 0.999
                                                                              3         0.743   0.893   0.942   0.856 0.959 0.980   0.806 0.936 0.964    0.775 0.917 0.952      0.823 0.936 0.973
                                                                              6         0.309   0.495   0.595   0.824 0.939 0.976   0.618 0.798 0.891    0.774 0.908 0.950      0.590 0.800 0.882
                                                                              10        0.120   0.242   0.327   0.805 0.922 0.955   0.523 0.737 0.832    0.812 0.927 0.959      0.470 0.711 0.807
                                               0.5    0.5    0.5    -0.2      0         0.861   0.949   0.971   0.702 0.879 0.939   0.832 0.940 0.973    0.584 0.778 0.857      0.838 0.944 0.975
                                                                              3         0.427   0.669   0.764   0.499 0.741 0.841   0.418 0.677 0.775    0.421 0.636 0.768      0.433 0.694 0.790
                                                                              6         0.158   0.328   0.445   0.464 0.697 0.798   0.271 0.502 0.628    0.420 0.652 0.752      0.236 0.497 0.632
                                                                              10        0.080   0.174   0.262   0.428 0.662 0.770   0.208 0.417 0.546    0.435 0.649 0.762      0.169 0.389 0.530
                                               0.5    0.5    0.5    0         0         0.532   0.754   0.850   0.392 0.620 0.745   0.518 0.736 0.836    0.316 0.532 0.644      0.503 0.733 0.839
                                                                              3         0.281   0.464   0.591   0.266 0.512 0.634   0.214 0.430 0.540    0.228 0.436 0.565      0.228 0.457 0.570
                                                                              6         0.112   0.242   0.339   0.234 0.444 0.552   0.101 0.274 0.399    0.218 0.430 0.542      0.098 0.258 0.382
                                                                              10        0.076   0.139   0.200   0.192 0.396 0.528   0.076 0.220 0.311    0.224 0.421 0.536      0.057 0.180 0.288
                                               0.5    0.5    0.5    0.2       0         0.199   0.378   0.522   0.147 0.319 0.428   0.184 0.370 0.494    0.132 0.294 0.396      0.179 0.374 0.505
                                                                              3         0.119   0.272   0.371   0.110 0.239 0.341   0.078 0.199 0.287    0.099 0.234 0.328      0.076 0.193 0.309
                                                                              6         0.077   0.175   0.270   0.087 0.212 0.308   0.039 0.128 0.207    0.090 0.212 0.308      0.036 0.129 0.208
                                                                              10        0.066   0.138   0.201   0.078 0.205 0.298   0.028 0.107 0.166    0.099 0.230 0.331      0.030 0.091 0.155
                                               0.5    0.5    0.5    0.5       0         0.010   0.059   0.109   0.012 0.061 0.115   0.014 0.051 0.103    0.017 0.078 0.135      0.012 0.056 0.101
                                                                              3         0.029   0.091   0.155   0.009 0.054 0.109   0.014 0.068 0.128    0.018 0.065 0.109      0.010 0.069 0.128
                                                                              6         0.044   0.122   0.199   0.009 0.044 0.083   0.018 0.069 0.134    0.006 0.048 0.094      0.011 0.044 0.098
                                                                              10        0.044   0.091   0.153   0.011 0.054 0.090   0.012 0.048 0.097    0.014 0.058 0.120      0.010 0.035 0.068
                                               0.5    0.5    0.5    0.8       0         0.573   0.774   0.847   0.434 0.656 0.755   0.540 0.752 0.832    0.348 0.557 0.680      0.542 0.749 0.834
                                                                              3         0.289   0.488   0.614   0.313 0.539 0.667   0.361 0.602 0.714    0.259 0.470 0.591      0.306 0.555 0.655
                                                                              6         0.132   0.243   0.359   0.229 0.454 0.573   0.205 0.417 0.547    0.233 0.431 0.557      0.130 0.318 0.441
                                                                              10        0.081   0.179   0.268   0.217 0.431 0.553   0.156 0.327 0.446    0.253 0.469 0.579      0.089 0.238 0.346
                                            This table presents the percentages of rejection of the non-linearity hypothesis when using the Hung et al. (2009) test adapted to the case of a TAR
                                            model with a percentage of contamination of 10%. In the equation (13) the model is presented, the value of ω is related to the magnitude of the outliers,
                                            and its deﬁnition is presented in the lower part of the equation (5). The value of the ν parameter is equal to 0.5 and the sample size is T = 200.
32

                                                                            Table A3: Empirical relative frequencies of rejection of the linearity hypothesis based on 1000 replications with a model T AR(Z, 2, 1, 1, 0),
                                                                                      sample size equal to 200, threshold value r = 0.6 and ν = 0.5.
                                                                                                                                 LS              Huber k = 1.345     Huber k = 3.291     Tukey c = 4.685        Tukey c = 15
                                                                                (1)    (1)    (2)       (2)
                                                                               ϕ0     ϕ1     ϕ0     ϕ1         ω   α=   1%      5%      10%     1%     5%    10%    1%     5%    10%    1%     5%    10%     1%     5%    10%
                                                                               0.5    0.5    0.5    -0.8      0         0.969   0.990   0.998   0.859 0.955 0.976   0.968 0.989 0.997   0.765 0.880 0.935    0.965 0.988 0.995
                                                                                                              3         0.890   0.944   0.968   0.810 0.924 0.951   0.884 0.958 0.976   0.722 0.872 0.922    0.880 0.957 0.975
                                                                                                              6         0.619   0.768   0.831   0.801 0.921 0.952   0.824 0.923 0.961   0.729 0.866 0.922    0.807 0.913 0.952
                                                                                                              10        0.365   0.558   0.643   0.775 0.907 0.943   0.764 0.900 0.941   0.712 0.872 0.923    0.736 0.883 0.939
                                                                               0.5    0.5    0.5    -0.5      0         0.850   0.942   0.970   0.670 0.842 0.906   0.823 0.936 0.965   0.574 0.776 0.853    0.821 0.928 0.961
                                                                                                              3         0.640   0.807   0.871   0.576 0.781 0.864   0.617 0.803 0.889   0.485 0.722 0.814    0.618 0.820 0.895
                                                                                                              6         0.410   0.587   0.702   0.549 0.771 0.851   0.516 0.733 0.826   0.509 0.714 0.814    0.491 0.703 0.818
                                                                                                              10        0.254   0.413   0.512   0.571 0.760 0.837   0.465 0.698 0.792   0.518 0.744 0.831    0.433 0.682 0.770
                                                                               0.5    0.5    0.5    -0.2      0         0.494   0.731   0.827   0.333 0.584 0.709   0.464 0.701 0.811   0.283 0.495 0.632    0.471 0.706 0.807
                                                                                                              3         0.327   0.577   0.694   0.265 0.523 0.655   0.286 0.531 0.652   0.228 0.460 0.583    0.276 0.536 0.665
                                                                                                              6         0.243   0.444   0.560   0.247 0.487 0.638   0.200 0.441 0.562   0.236 0.448 0.576    0.187 0.415 0.544
                                                                                                              10        0.185   0.326   0.406   0.255 0.484 0.607   0.161 0.378 0.497   0.263 0.472 0.575    0.150 0.348 0.475
                                                                               0.5    0.5    0.5    0         0         0.252   0.466   0.596   0.188 0.377 0.493   0.243 0.445 0.588   0.170 0.333 0.455    0.240 0.456 0.581
                                                                                                              3         0.196   0.380   0.506   0.156 0.340 0.445   0.154 0.324 0.435   0.154 0.302 0.422    0.157 0.335 0.450
                                                                                                              6         0.182   0.331   0.438   0.148 0.313 0.412   0.095 0.240 0.359   0.137 0.301 0.406    0.078 0.219 0.350
                                                                                                              10        0.146   0.269   0.364   0.131 0.291 0.403   0.072 0.213 0.322   0.151 0.291 0.408    0.057 0.190 0.288
                                                                               0.5    0.5    0.5    0.2       0         0.084   0.224   0.325   0.073 0.208 0.294   0.074 0.220 0.323   0.085 0.207 0.293    0.075 0.221 0.324
                                                                                                              3         0.089   0.221   0.329   0.065 0.177 0.255   0.045 0.147 0.239   0.067 0.178 0.259    0.047 0.147 0.252
                                                                                                              6         0.125   0.253   0.352   0.057 0.165 0.264   0.035 0.128 0.205   0.075 0.183 0.260    0.034 0.123 0.206
                                                                                                              10        0.139   0.248   0.322   0.057 0.164 0.259   0.029 0.107 0.190   0.074 0.189 0.286    0.019 0.097 0.169
                                                                               0.5    0.5    0.5    0.5       0         0.010   0.059   0.109   0.012 0.061 0.115   0.014 0.051 0.103   0.017 0.078 0.135    0.012 0.056 0.101
                                                                                                              3         0.027   0.096   0.154   0.006 0.051 0.112   0.013 0.058 0.122   0.013 0.064 0.121    0.011 0.059 0.116
                                                                                                              6         0.076   0.187   0.264   0.011 0.053 0.113   0.015 0.052 0.102   0.014 0.079 0.124    0.012 0.041 0.087
                                                                                                              10        0.091   0.179   0.249   0.009 0.053 0.094   0.012 0.050 0.097   0.015 0.067 0.123    0.011 0.033 0.072
                                                                               0.5    0.5    0.5    0.8       0         0.262   0.452   0.585   0.160 0.335 0.461   0.223 0.421 0.555   0.139 0.294 0.403    0.213 0.419 0.550
                                                                                                              3         0.180   0.365   0.465   0.142 0.306 0.427   0.183 0.394 0.512   0.113 0.258 0.379    0.162 0.352 0.481
                                                                                                              6         0.133   0.239   0.349   0.117 0.282 0.403   0.127 0.317 0.423   0.112 0.280 0.377    0.095 0.237 0.377
                                                                                                              10        0.136   0.242   0.324   0.109 0.262 0.388   0.099 0.254 0.358   0.115 0.263 0.379    0.077 0.205 0.314

                                                                            This table presents the percentages of rejection of the non-linearity hypothesis when using the Hung et al. (2009) test adapted to the case of a TAR
                                                                            model. In the equation (13) the model is presented, the value of ω is related to the magnitude of the outliers, and its deﬁnition is presented in the
                                                                                                                                                                                                                                    Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...




                                                                            lower part of the equation (5). The value of the ν parameter is equal to 0.5 and the sample size is T = 200 and the threshold value r is 0.6 so that
                                                                            approximately 30% of the observations remain in the second regime.




Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40
                                                                                                                                                                                                                                    33

34                                                   Sergio Calderon & Daniel Ordoñez Callamad




Table B1: Mean square error ratio between the GM and the classical estimator based
          on 1000 replications with a TAR model (Z, 2, 1, 1, 0), sample size equal to
          200, ν = −0.5.
                                           Huber k = 1.345                     Tukey c = 4.685
  (1)    (1)    (2)    (2)           (1)       (1)       (2)     (2)     (1)      (1)    (2)      (2)
 ϕ0     ϕ1     ϕ0     ϕ1     ω     ϕ̂0       ϕ̂1       ϕ̂0     ϕ̂1     ϕ̂0       ϕ̂1    ϕ̂0      ϕ̂1
  0.5    0.5    0.5   -0.8    0   1.165     1.354      1.185   1.375   1.400    2.419   1.465    2.378
                             3    0.870     0.499      0.638   0.275   1.011    0.812   0.749    0.384
                             6    0.438     0.141      0.237   0.070   0.474    0.214   0.264    0.096
                             10   0.251     0.079      0.145   0.043   0.271    0.118   0.162    0.059
  0.5    0.5    0.5   -0.5    0   1.176     1.323      1.188   1.380   1.438    2.383   1.522    2.496
                             3    0.831     0.461      0.721   0.488   0.995    0.717   0.866    0.779
                             6    0.408     0.154      0.346   0.165   0.447    0.230   0.392    0.259
                             10   0.209     0.096      0.200   0.102   0.213    0.134   0.220    0.151
  0.5    0.5    0.5   -0.2    0   1.226     1.395      1.191   1.307   1.575    2.450   1.546    2.204
                             3    0.763     0.486      0.908   0.948   0.933    0.772   1.153    1.637
                             6    0.337     0.175      0.484   0.555   0.389    0.250   0.602    0.933
                             10   0.199     0.108      0.284   0.410   0.223    0.158   0.338    0.654
  0.5    0.5    0.5     0    0    1.180     1.346      1.218   1.419   1.540    2.407   1.656    2.560
                             3    0.652     0.464      0.983   1.348   0.792    0.724   1.331    2.469
                             6    0.295     0.159      0.627   1.173   0.342    0.245   0.825    2.195
                             10   0.179     0.117      0.314   1.019   0.196    0.180   0.406    1.990
  0.5    0.5    0.5    0.2   0    1.288     1.537      1.206   1.427   1.793    2.810   1.656    2.471
                             3    0.644     0.489      0.880   0.980   0.818    0.769   1.174    1.709
                             6    0.274     0.174      0.466   0.565   0.340    0.264   0.588    0.922
                             10   0.174     0.118      0.342   0.429   0.209    0.173   0.416    0.686
  0.5    0.5    0.5    0.5   0    1.274     1.390      1.261   1.416   1.835    2.432   1.815    2.579
                             3    0.587     0.454      0.637   0.474   0.768    0.691   0.848    0.753
                             6    0.228     0.153      0.246   0.161   0.298    0.231   0.303    0.235
                             10   0.145     0.098      0.160   0.103   0.182    0.145   0.194    0.152
  0.5    0.5    0.5    0.8   0    1.274     1.415      1.333   1.454   1.969    2.635   2.003    2.531
                             3    0.591     0.530      0.386   0.294   0.821    0.861   0.503    0.414
                             6    0.212     0.157      0.111   0.077   0.270    0.223   0.128    0.099
                             10   0.120     0.091      0.069   0.046   0.153    0.131   0.084    0.061

This table presents the mean square error ratio obtained through simulations between the GM
estimator and the least-squares estimator. In equation (13) the model is presented, the value of
ω is related to the outliers’ magnitude, and its deﬁnition is presented in the lower part of the
equation (5). The value of the parameter ν is equal to −0.5, and the sample size is T = 200.




                      Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...                       35


Table B2: Mean square error ratio between the GM and the classical estimator based
          on 1000 replications with a TAR model (Z, 2, 1, 1, 0), sample size equal to
          200, ν = 0.5 and percentage of contamination 10%.
                                            Huber k = 1.345                   Tukey c = 4.685
  (1)    (1)    (2)    (2)           (1)       (1)    (2)      (2)     (1)       (1)    (2)      (2)
 ϕ0     ϕ1     ϕ0     ϕ1       ω    ϕ̂0       ϕ̂1    ϕ̂0      ϕ̂1     ϕ̂0       ϕ̂1    ϕ̂0      ϕ̂1
  0.5   0.5    0.5    -0.8      0   1.201    1.432   1.142    1.328   1.553    2.562   1.357    2.298
                               3    0.633    0.373   0.504    0.202   0.708    0.448   0.532    0.214
                               6    0.271    0.133   0.210    0.065   0.269    0.139   0.212    0.056
                               10   0.165    0.089   0.117    0.037   0.161    0.096   0.108    0.033
  0.5   0.5    0.5    -0.5      0   1.163    1.352   1.187    1.357   1.583    2.393   1.453    2.362
                               3    0.528    0.358   0.586    0.321   0.622    0.452   0.675    0.410
                               6    0.250    0.149   0.274    0.137   0.262    0.160   0.297    0.165
                               10   0.161    0.109   0.161    0.095   0.165    0.120   0.159    0.107
  0.5   0.5    0.5    -0.2      0   1.228    1.335   1.202    1.405   1.650    2.372   1.536    2.503
                               3    0.548    0.355   0.714    0.785   0.617    0.454   0.886    1.425
                               6    0.239    0.152   0.374    0.518   0.233    0.166   0.424    0.858
                               10   0.163    0.110   0.211    0.384   0.163    0.118   0.239    0.642
  0.5   0.5    0.5         0   0    1.198    1.332   1.154    1.379   1.614    2.257   1.479    2.510
                               3    0.509    0.344   0.825    1.246   0.564    0.428   1.077    2.585
                               6    0.225    0.156   0.425    1.297   0.220    0.175   0.500    2.339
                               10   0.147    0.110   0.224    1.069   0.143    0.121   0.258    2.012
  0.5   0.5    0.5    0.2      0    1.268    1.464   1.211    1.403   1.796    2.629   1.654    2.569
                               3    0.484    0.359   0.744    0.740   0.545    0.455   0.984    1.291
                               6    0.222    0.161   0.378    0.466   0.225    0.188   0.450    0.764
                               10   0.139    0.108   0.204    0.387   0.134    0.117   0.233    0.576
  0.5   0.5    0.5    0.5      0    1.252    1.405   1.290    1.384   1.782    2.328   1.918    2.430
                               3    0.460    0.351   0.451    0.342   0.522    0.417   0.520    0.423
                               6    0.199    0.155   0.203    0.146   0.211    0.170   0.219    0.165
                               10   0.129    0.115   0.135    0.109   0.129    0.119   0.143    0.121
  0.5   0.5    0.5    0.8      0    1.253    1.447   1.302    1.463   1.844    2.660   1.950    2.583
                               3    0.446    0.363   0.287    0.234   0.545    0.485   0.296    0.252
                               6    0.164    0.139   0.097    0.073   0.176    0.154   0.090    0.070
                               10   0.112    0.093   0.059    0.044   0.107    0.102   0.052    0.041

This table presents the mean square error ratio obtained through simulations between the GM
estimator and the least-squares estimator. In equation (13) the model is presented, the value of
ω is related to the outliers’ magnitude, and its deﬁnition is presented in the lower part of the
equation (5). The value of the parameter ν is equal to 0.5, and the sample size is T = 200 with
a percentage of contamination of 10%.



                      Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

36                                                   Sergio Calderon & Daniel Ordoñez Callamad



Table B3: Mean square error ratio between the GM and the classical estimator based
          on 1000 replications with a TAR model (Z, 2, 1, 1, 0), sample size equal to
          200, ν = 0.5 and threshold value r = 0.6.
                                            Huber k = 1.345                    Tukey c = 4.685
  (1)    (1)    (2)    (2)           (1)       (1)      (2)     (2)     (1)       (1)    (2)      (2)
 ϕ0     ϕ1     ϕ0     ϕ1       ω    ϕ̂0       ϕ̂1      ϕ̂0     ϕ̂1     ϕ̂0       ϕ̂1    ϕ̂0      ϕ̂1
  0.5   0.5    0.5    -0.8      0   1.186    1.397     1.150   1.380   1.615    2.574   1.461    2.534
                               3    0.683    0.418     0.650   0.387   0.827    0.625   0.765    0.620
                               6    0.244    0.126     0.330   0.119   0.294    0.181   0.374    0.175
                               10   0.148    0.073     0.183   0.070   0.171    0.101   0.207    0.104
  0.5   0.5    0.5    -0.5      0   1.266    1.375     1.172   1.398   1.781    2.402   1.493    2.422
                               3    0.622    0.402     0.779   0.651   0.786    0.570   0.949    1.060
                               6    0.237    0.125     0.387   0.234   0.279    0.173   0.456    0.363
                               10   0.140    0.076     0.233   0.162   0.159    0.102   0.270    0.243
  0.5   0.5    0.5    -0.2      0   1.170    1.324     1.205   1.305   1.529    2.305   1.559    2.292
                               3    0.579    0.381     0.922   1.109   0.687    0.545   1.201    2.058
                               6    0.216    0.120     0.499   0.737   0.242    0.165   0.621    1.309
                               10   0.133    0.074     0.283   0.586   0.148    0.100   0.322    0.957
  0.5   0.5    0.5         0   0    1.231    1.421     1.204   1.452   1.676    2.512   1.681    2.776
                               3    0.561    0.375     1.003   1.434   0.692    0.553   1.432    2.863
                               6    0.209    0.121     0.580   1.064   0.238    0.168   0.802    2.096
                               10   0.128    0.075     0.356   1.104   0.146    0.105   0.472    2.091
  0.5   0.5    0.5    0.2      0    1.202    1.318     1.274   1.437   1.659    2.181   1.883    2.706
                               3    0.511    0.382     0.973   1.161   0.627    0.540   1.363    2.150
                               6    0.212    0.130     0.572   0.680   0.247    0.169   0.761    1.193
                               10   0.139    0.080     0.328   0.547   0.165    0.110   0.444    0.974
  0.5   0.5    0.5    0.5      0    1.219    1.425     1.286   1.405   1.787    2.497   1.966    2.478
                               3    0.505    0.385     0.745   0.648   0.638    0.556   1.043    1.049
                               6    0.180    0.126     0.337   0.279   0.212    0.164   0.431    0.417
                               10   0.104    0.076     0.235   0.197   0.122    0.103   0.310    0.277
  0.5   0.5    0.5    0.8      0    1.211    1.426     1.234   1.352   1.806    2.577   1.800    2.547
                               3    0.499    0.403     0.495   0.398   0.638    0.595   0.664    0.637
                               6    0.174    0.124     0.166   0.120   0.200    0.160   0.206    0.174
                               10   0.095    0.072     0.106   0.077   0.113    0.096   0.120    0.111

This table presents the mean square error ratio obtained through simulations between the GM
estimator and the least-squares estimator. In equation (13) the model is presented, the value of
ω is related to the outliers’ magnitude, and its deﬁnition is presented in the lower part of the
equation (5). The value of the parameter ν is equal to 0.5, and the sample size is T = 200 and
threshold value r = 0.6 so that approximately 30% of the observations remain in the second
regime.




                      Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...                        37

Table B4: P -values of the Shapiro-Wilk test of normality for the empirical distributions
          of the GM estimators based on 1000 replications of the estimation process
          with a TAR model(Z, 2, 1, 1, 0), sample size equal to 100.

                                               Huber k = 1.345                Tukey c = 4.685
    (1)    (1)    (2)      (2)           (1)      (1)    (2)     (2)    (1)      (1)    (2)      (2)
   ϕ0     ϕ1     ϕ0       ϕ1       ω    ϕ̂0      ϕ̂1    ϕ̂0    ϕ̂1     ϕ̂0      ϕ̂1    ϕ̂0      ϕ̂1
    0.5    0.5   0.5      -0.8      0   0.00     0.00   0.95   0.00    0.00     0.00   0.19     0.00
                                   3    0.00     0.00   0.58   0.00    0.00     0.00   0.01     0.00
                                   6    0.00     0.00   0.88   0.00    0.00     0.00   0.18     0.00
                                   10   0.00     0.00   0.32   0.00    0.00     0.00   0.02     0.00
    0.5    0.5   0.5      -0.5      0   0.00     0.25   0.04   0.01    0.00     0.02   0.00     0.00
                                   3    0.00     0.02   0.37   0.03    0.00     0.00   0.01     0.00
                                   6    0.00     0.01   0.01   0.00    0.00     0.02   0.00     0.00
                                   10   0.00     0.12   0.08   0.01    0.00     0.00   0.04     0.00
    0.5    0.5   0.5      -0.2      0   0.00     0.02   0.13   0.04    0.00     0.24   0.00     0.01
                                   3    0.00     0.00   0.31   0.40    0.00     0.02   0.00     0.00
                                   6    0.01     0.55   0.09   0.33    0.00     0.03   0.02     0.04
                                   10   0.02     0.03   0.12   0.54    0.00     0.03   0.00     0.16
    0.5    0.5   0.5           0   0    0.00     0.14   0.04   0.03    0.00     0.00   0.00     0.00
                                   3    0.00     0.01   0.00   0.03    0.00     0.00   0.00     0.00
                                   6    0.00     0.00   0.03   0.07    0.00     0.00   0.00     0.27
                                   10   0.00     0.01   0.09   0.00    0.00     0.00   0.00     0.00
    0.5    0.5   0.5       0.2     0    0.00     0.00   0.02   0.22    0.00     0.00   0.04     0.03
                                   3    0.00     0.00   0.20   0.25    0.00     0.00   0.09     0.20
                                   6    0.00     0.01   0.02   0.24    0.00     0.00   0.00     0.01
                                   10   0.00     0.00   0.07   0.37    0.00     0.00   0.00     0.01
    0.5    0.5   0.5       0.5     0    0.00     0.01   0.00   0.00    0.00     0.00   0.00     0.00
                                   3    0.00     0.00   0.00   0.00    0.00     0.00   0.00     0.00
                                   6    0.00     0.00   0.00   0.06    0.00     0.00   0.00     0.00
                                   10   0.00     0.07   0.00   0.00    0.00     0.00   0.00     0.00
    0.5    0.5   0.5       0.8     0    0.00     0.00   0.00   0.00    0.00     0.00   0.00     0.00
                                   3    0.00     0.00   0.00   0.00    0.00     0.00   0.00     0.00
                                   6    0.00     0.00   0.00   0.00    0.00     0.00   0.00     0.00
                                   10   0.00     0.14   0.00   0.00    0.00     0.08   0.00     0.00

This table present the p-values obtained when carrying out the Shapiro-Wilk normality test
on the empirical distribution of the coeﬃcients estimated through the GM method obtained
through simulations. In equation (13) the model is presented, the value of ω is related to the
magnitude of the outliers and its deﬁnition is presented in the lower part of equation (5). The
value of the parameter ν is equal to 0.5, the sample size is T = 100, and the threshold value r
is 0.



                        Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

38                                                  Sergio Calderon & Daniel Ordoñez Callamad


Table B5: P -values of the Shapiro-Wilk test of normality for the empirical distributions
          of the GM estimators based on 1000 replications of the estimation process
          with a TAR model(Z, 2, 1, 1, 0), sample size equal to 1000.

                                                Huber k = 1.345                 Tukey c = 4.685
     (1)    (1)    (2)     (2)            (1)      (1)    (2)      (2)    (1)      (1)    (2)      (2)
 ϕ0        ϕ1     ϕ0      ϕ1       ω     ϕ̂0      ϕ̂1    ϕ̂0      ϕ̂1    ϕ̂0      ϕ̂1    ϕ̂0      ϕ̂1
     0.5   0.5    0.5     -0.8      0    0.74     0.08   0.87     0.05   0.10     0.28   0.72     0.04
                                   3     0.03     0.29   0.83     0.46   0.01     0.21   0.36     0.04
                                   6     0.84     0.14   0.36     0.02   0.28     0.08   0.36     0.03
                                   10    0.52     0.00   0.48     0.03   0.36     0.05   0.13     0.12
     0.5   0.5    0.5     -0.5      0    0.99     0.50   0.37     0.00   0.66     0.73   0.04     0.00
                                   3     0.76     0.08   0.59     0.08   0.69     0.12   0.11     0.04
                                   6     0.96     0.43   0.58     0.01   0.82     0.59   0.56     0.04
                                   10    0.86     0.48   0.80     0.05   0.73     0.04   0.12     0.01
     0.5   0.5    0.5     -0.2      0    0.23     0.83   0.28     0.01   0.17     0.92   0.78     0.06
                                   3     0.11     0.95   0.27     0.04   0.40     0.82   0.42     0.35
                                   6     0.41     0.73   0.33     0.30   0.11     0.65   0.99     0.36
                                   10    0.21     0.85   0.36     0.61   0.09     0.37   0.70     0.11
     0.5   0.5    0.5          0   0     0.95     0.70   0.14     0.48   0.73     0.57   0.08     0.37
                                   3     0.20     0.86   0.57     0.66   0.58     0.94   0.07     0.20
                                   6     0.28     0.17   0.14     0.02   0.12     0.46   0.29     0.04
                                   10    0.52     0.06   0.55     0.51   0.29     0.02   0.18     0.83
     0.5   0.5    0.5      0.2     0     0.56     0.53   0.00     0.75   0.41     0.74   0.00     0.20
                                   3     0.67     0.64   0.01     0.51   0.92     0.55   0.00     0.02
                                   6     0.44     0.29   0.04     0.79   0.19     0.54   0.02     0.08
                                   10    0.02     0.52   0.08     0.57   0.05     0.85   0.00     0.46
     0.5   0.5    0.5      0.5     0     0.04     0.03   0.14     0.40   0.01     0.00   0.56     0.24
                                   3     0.15     0.08   0.28     0.38   0.01     0.00   0.24     0.10
                                   6     0.12     0.01   0.14     0.22   0.01     0.01   0.04     0.52
                                   10    0.54     0.18   0.64     0.07   0.23     0.05   0.80     0.17
     0.5   0.5    0.5      0.8     0     0.85     0.35   0.07     0.74   0.24     0.86   0.01     0.70
                                   3     0.75     0.78   0.02     0.19   0.06     0.67   0.00     0.63
                                   6     0.53     0.22   0.06     0.58   0.36     0.54   0.05     0.76
                                   10    0.04     0.04   0.11     0.26   0.16     0.05   0.02     0.51

This table present the p-values obtained when carrying out the Shapiro-Wilk normality test
on the empirical distribution of the coeﬃcients estimated through the GM method obtained
through simulations. In equation (13) the model is presented, the value of omega is related to
the magnitude of the outliers and its deﬁnition is presented in the lower part of equation (5).
The value of the parameter ν is equal to 0.5, the sample size is T = 1000, and the threshold
value r is 0.



                         Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

Additive Outliers in Open-Loop Threshold Autoregressive Models: A Simulation...                       39


Table B6: Empirical coverage of the 95% conﬁdence intervals constructed from the GM
          estimator based on 1000 replications with a TAR model(Z, 2, 1, 1, 0), sample
          size equal to 200.
                                              Huber k = 1.345                 Tukey c = 4.685
  (1)    (1)     (2)     (2)            (1)      (1)    (2)      (2)    (1)      (1)    (2)      (2)
 ϕ0     ϕ1     ϕ0       ϕ1       ω     ϕ̂0      ϕ̂1    ϕ̂0      ϕ̂1    ϕ̂0      ϕ̂1    ϕ̂0      ϕ̂1
  0.5    0.5    0.5     -0.8      0    0.94     0.95   0.95     0.94   0.94     0.93   0.95     0.94
                                 3     0.92     0.91   0.94     0.92   0.93     0.93   0.94     0.93
                                 6     0.93     0.91   0.95     0.92   0.93     0.92   0.95     0.94
                                 10    0.93     0.91   0.94     0.93   0.93     0.94   0.94     0.94
  0.5    0.5    0.5     -0.5      0    0.95     0.94   0.95     0.93   0.94     0.93   0.96     0.93
                                 3     0.93     0.91   0.95     0.94   0.94     0.93   0.95     0.94
                                 6     0.93     0.92   0.95     0.94   0.94     0.92   0.97     0.94
                                 10    0.93     0.92   0.95     0.95   0.94     0.93   0.95     0.94
  0.5    0.5    0.5     -0.2      0    0.94     0.93   0.94     0.93   0.95     0.93   0.94     0.93
                                 3     0.95     0.91   0.94     0.94   0.95     0.93   0.94     0.95
                                 6     0.93     0.92   0.95     0.93   0.94     0.93   0.94     0.93
                                 10    0.95     0.92   0.94     0.93   0.95     0.93   0.94     0.95
  0.5    0.5    0.5          0   0     0.95     0.96   0.94     0.94   0.95     0.95   0.93     0.95
                                 3     0.95     0.93   0.95     0.94   0.94     0.94   0.93     0.94
                                 6     0.95     0.93   0.94     0.94   0.95     0.94   0.94     0.94
                                 10    0.94     0.93   0.94     0.95   0.94     0.93   0.93     0.94
  0.5    0.5    0.5      0.2     0     0.95     0.94   0.93     0.94   0.95     0.94   0.94     0.94
                                 3     0.94     0.93   0.93     0.94   0.95     0.94   0.93     0.95
                                 6     0.94     0.93   0.95     0.93   0.94     0.94   0.94     0.93
                                 10    0.94     0.93   0.93     0.92   0.95     0.95   0.93     0.93
  0.5    0.5    0.5      0.5     0     0.94     0.93   0.94     0.93   0.95     0.94   0.93     0.93
                                 3     0.92     0.91   0.93     0.92   0.94     0.94   0.93     0.93
                                 6     0.92     0.92   0.93     0.91   0.93     0.93   0.94     0.93
                                 10    0.94     0.93   0.94     0.91   0.94     0.94   0.94     0.93
  0.5    0.5    0.5      0.8     0     0.95     0.93   0.93     0.93   0.95     0.93   0.93     0.94
                                 3     0.94     0.92   0.92     0.92   0.94     0.93   0.92     0.93
                                 6     0.93     0.91   0.92     0.91   0.95     0.93   0.92     0.92
                                 10    0.94     0.91   0.93     0.92   0.95     0.93   0.94     0.93

This table presents the empirical coverage of the conﬁdence intervals obtained through
simulations based on the GM estimator and following those proposed in subsection 2.1. In
equation (13) the model is presented, the value of ω is related to the magnitude of the outliers
and its deﬁnition is presented in the lower part of equation (5). The value of the parameter ν is
equal to 0.5, the sample size is T = 200, and the threshold value r is 0.



                       Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

           Revista Colombiana de Estadística - Theoretical Statistics 45 (2022) 1–40

References
Battaglia F,  Orfei L. Outlier detection and estimation in nonlinear time series.(2005). Journal of Time Series Analysis.
Calderón S, Nieto F. Bayesian analysis of Multivariate Threshold Autoregressive Models with Missing Data.(2017). Communications in Statistics: Theory and Methods.
Chan K, Tong H. On likelihood ratio tests for threshold autoregression.(1990). Journal of the Royal Statistical Society - Series B: Statistical Methodology.
Chan W S, Cheung S H. On robust estimation of threshold autoregressions.(1994). Journal of Forecasting.
Chan W S, Ng M W. Robustness of alternative non-linearity tests for setar models.(2004). Journal of Forecasting.
Chen C, Liu L M. Joint estimation of model parameters and outlier eﬀects in time series.(1993). Journal of the American Statistical Association.
Denby L, Martin R D. Robust estimation of the ﬁrst-order autoregressive parameter.(1979). Journal of the American Statistical Association.
Franses P H, Van Dijk D. Non-linear time series models in empirical ﬁnance.(2000).Cambridge University Press.
Giordani P. A cautionary note on outlier robust estimation of threshold models.(2006). Journal of Forecasting.
Gonzalez J, Nieto F. Bayesian analysis of multiplicative seasonal threshold autoregressive processes.(2020). Revista Colombiana de Estadística.
Granger C, Teräsvirta T. Modelling Non-Linear Economic Relationships.(1993). Oxford University Press.
Hampel F R, Ronchetti E M, Rousseeuw P J, Stahel W A. Robust statistics: the approach based on inﬂuence functions.(1986).John Wiley and Sons.
Hansen B E. Threshold autoregression in economics.(2011). Statistics and its Interface.
Hung K C, Cheung S H, Chan W S, Zhang L X. On a robust test for setar-type nonlinearity in time series analysis.(2009). Journal of forecasting.
Knotters M, De Gooijer J. Tarso modeling of water table depths.(1999). Water Resources Research.
LeBaron B. Some relations between volatility and serial correlations in stock market returns.(1992). Journal of Business.
Luukkonen R, Saikkonen P, Teräsvirta T. Testing linearity against smooth transition autoregressive models.(1988). Biometrika.
Maronna R, Martin R, Yohai V, Salibián Barrera M. Robust Statistics Theory and Methods (with R).(2019). John Wiley and Sons.
Mohammadi H, Jahan Parvar M R. Oil prices and exchange rates in oil-exporting countries: evidence from tar and m-tar models.(2012). Journal of Economics and Finance.
Petruccelli J. A comparison of tests for setar-type non-linearity in time series.(1990). Journal of Forecasting.
Petruccelli J, Davies N. A portmanteau test for self-exciting threshold autoregressive-type nonlinearity in time series.(1986). Biometrika.
Romero L, Calderón S. Bayesian estimation of a multivariate TAR model when the noise process follows a Student-t distribution.(2021). Communications in Statistics: Theory and Methods.
Rousseeuw P J. Least median of squares regression.(1984). Journal of the American statistical association.
Rousseeuw P J, Van Zomeren B C. Unmasking multivariate outliers and leverage points.(1990). Journal of the American Statistical association.
Sorour A, Tong H. A note on tests for threshold-type non-linearity in open loop systems).(1993). Journal of the Royal Statistical Society.
Tiao G C, Tsay R S. Some advances in non-linear and adaptive modelling in time-series.(1994). Journal of Forecasting.
Tong H. On a threshold model.(1978). Pattern Recognition and Signal Processing.(1978).
Tong H. Non-linear Time Series: A Dynamical System Approach - Dynamical System Approach.(1990). Clarendon Press.
Tsay R, Chen R. Nonlinear Time Series Analysis.(2019). Wiley Interscience.
Tsay R S. Outliers level shifts and variance changes in time series.(1988). Journal of forecasting.
Tsay R S. Testing and modeling threshold autoregressive processes.(1989). Journal of the American statistical association.
Tsay R S. Testing and Modeling Multivariate Threshold Models.(1998). Journal of the American Statistical Association.
Vargas H. Monetary policy and the exchange rate in Colombia.(2011).Bank for International Settlements.
Zhang H, Nieto F. Tar modeling with missing data when the white noise process follows a students t-distribution.(2015). Revista Colombiana de Estadística.
Zhang L X, Chan W S, Cheung S H, Hung K C. A note on the consistency of a robust estimator for threshold autoregressive processes.(2009). Statistics and Probability Letters.