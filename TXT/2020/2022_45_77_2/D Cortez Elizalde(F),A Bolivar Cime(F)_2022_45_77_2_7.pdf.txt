Behavior of Some Hypothesis Tests for the Covariance Matrix of High Dimensional Data. Comportamiento de algunas pruebas de hip√≥tesis para la matriz de covarianza de datos de dimensi√≥n alta
Universidad Ju√°rez Aut√≥noma de Tabasco, Cunduac√°n, M√©xico
Abstract
The study of the structure of the covariance matrix when the dimension of the data is much greater than the sample size (high dimensional data) is a complicated problem, since we have many unknown parameters and few data. Several hypothesis tests for the covariance matrix, in the high dimensional context and in the classical case (where the dimension of the data is less than the sample size), can be found in the literature. It has been of interest to test the null hypothesis that either the covariance matrix of Gaussian data is equal to the identity matrix or proportional to it, considering the classical case as well as the high dimensional context. Since it is important to have a wide comparison between these tests found in the literature, and for some of them it is dicult to have theoretical results about their powers, in this work we compare several tests by simulations, in terms of the size and power of the test. We also present some examples of application with real high dimensional data found in the literature.
Key words   : Covariance matrix; High dimensional data; Hypothesis test; Multivariate Gaussian data; Tracy-Widom law.
Resumen
El estudio de la matriz de covarianza cuando la dimensi√≥n de los datos es mucho m√°s grande que el tama√±o de la muestra (datos de dimensi√≥n alta) es un problema complicado, ya que se tiene una gran cantidad de par√°metros desconocidos y pocos datos. Se pueden encontrar en la literatura varias pruebas de hip√≥tesis para la matriz de covarianza, en el contexto de datos de dimensi√≥n alta y en el caso cl√°sico (donde la dimensi√≥n de los datos es menor que el tama√±o de la muestra). Ha sido de inter√©s probar la hip√≥tesis nula de que la matriz de covarianza de datos Gaussianos es igual a la matriz identidad o proporcional a ella, considerando el contexto cl√°sico as√≠ como el de dimensi√≥n alta. Ya que es importante tener una amplia comparaci√≥n entre estas pruebas encontradas en la literatura, y para algunas de ellas es dif√≠cil tener resultados te√≥ricos acerca de sus potencias, en este trabajo comparamos varias pruebas mediante simulaciones, en t√©rminos del tama√±o y la potencia de la prueba. Tambi√©n presentamos algunos ejemplos de aplicaci√≥n con datos de dimensi√≥n alta reales encontrados en la literatura.
Palabras clave : Datos de dimensi√≥n alta; Datos Gaussianos multivariados; Ley Tracy-Widom; Matriz de covarianza; Prueba de hip√≥tesis.


1. Introduction

    Data with dimension much greater than the sample size (high dimensional
data) arise in many elds, such as genomics, document classication, climatology,
nance, functional data analysis, among others (see, Hastie et al., 2009; Johnstone,
2001). In the context of high dimensional data, the estimation of the covariance
matrix is a dicult problem because we need to estimate many parameters with
few data, for that reason the estimation of the covariance matrix and hypothesis
tests about it sometimes require statistical techniques dierent from those of the
classical case, where the sample size is greater than the dimension of the data.
    It is worth mentioning that hypothesis tests for the covariance matrix are
of interest because several multivariate statistical methodologies strongly depend
on the structure of the covariance matrix of the data, for example, principal
component analysis, classication, comparison of means, etc. Therefore, it is
important to check the structure of the covariance matrix by appropriate statistical
tests.
    Let X1 , X2 , . . . , XN be independent random vectors of the multivariate normal
distribution Np (¬µ, Œ£), where the mean ¬µ and the covariance matrix Œ£ are unknown,
and suppose that we are interested in testing
                           H0 : Œ£ = Ip     vs H1 : Œ£ Ã∏= Ip ,                           (1)
or
                          H0 : Œ£ = ŒªIp     vs H1 : Œ£ Ã∏= ŒªIp ,                          (2)
where Œª is unknown and Ip denotes the identity matrix of size p √ó p. The null
                                                                  PN
hypothesis H0 in (2) is called hypothesis of sphericity. Let Sn =    i=1 (Xi ‚àí
X)(Xi ‚àí X)‚Ä≤ /n, with n = N ‚àí 1, be the sample covariance matrix of the data,
           PN
where X = i=1 Xi /N is the sample mean.
    In Anderson (1984) and Muirhead (2005) it is showed that the likelihood ratio
test for (1) is based on the statistic
                              e pN/2
                        Œõ=             etr(‚àíA/2)(detA)N/2 ,
                               N

                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data              375

with A = nSn , where etr(A) := exp(tr(A)) (the exponential of the trace of the
matrix A); and the likelihood ratio test for (2) is based on the ellipticity statistic
given by

                                          det(Sn )
                                  V =                .
                                        [tr(Sn )/p]p

For the case p ‚â• N , with probability one, Sn is not of full rank, therefore
det(Sn ) = 0. Thus, the likelihood ratio tests for (1) and (2) only exist for the
case p < N . Hence, it has been of interest to propose and analyze tests for (1)
and (2) in the context of high dimensional Gaussian data.
    Some tests for (1) were proposed by Johnstone (2001), based on the Tracy-
Widom distribution; Ledoit & Wolf (2002); Srivastava (2005); Bai et al. (2009);
Cai & Ma (2013) and Srivastava et al. (2014). These tests can be applied in the
high dimensional and classical contexts, except the test of Bai et al. (2009) which
is only for the classical case. Whereas, for (2) some tests were proposed by John
(1971); Srivastava (2005); Zou et al. (2014); Srivastava et al. (2014) and Li &
Yao (2016). The last tests can be applied in the high dimensional and classical
contexts, except the tests of Li & Yao (2016) which is only for the high dimensional
case. In the references provided above there are some comparisons by simulations
of some tests, however a broader comparison considering those tests is needed.
Furthermore, there is very little about the comparison of the power of the tests.
    This work is the result of the master's thesis Cortez-Elizalde (2020). In the
present manuscript, we describe briey several tests found in the literature for (1)
and (2) considering Gaussian data, in the high dimensional and classical contexts,
being the rst one our greatest interest. The tests are compared by simulations in
terms of the size and power of the test. The purpose of this analysis is to provide
a wide comparison between several tests found in the literature for the covariance
matrix of Gaussian data. For many tests it is dicult to provide theoretical results
about the power of the test, therefore it is important to carry out simulation studies
to compare simultaneously the power of several tests, at least in some cases.
    This manuscript is divided as follows, in sections 2 and 3 we present some
tests found in the literature for (1) and (2), respectively; in section 4 we present
a simulation study for the comparison of the tests; in section 5 we show examples
of applications with real high dimensional data found in the literature; in section
6 we provide some conclusions. We also include an appendix with some technical
results and details of the simulations.
     It is well known, that if we have a random sample X1 , X2 , . . . , XN from the
Np (¬µ, Œ£), we can obtain from it a random sample Z1 , Z2 , . . . , Zn , with n = N ‚àí 1,
from the Np (0, Œ£)P     . Furthermore, the sample covariance matrix of the Xi 's, Sn ,
                         n
satises, nSn = i=1 Zi Zi‚Ä≤ ; see Appendix A for details. For this reason, some
authors of the tests for (1) and (2) give their results considering a random sample
                                                           Pn
Z1 , Z2 , . . . , Zn from the Np (0, Œ£), and taking Sen = i=1 Zi Zi‚Ä≤ /n as the sample
covariance matrix. In the tests presented in this work we consider a random sample
X1 , X2 , . . . , XN from the Np (¬µ, Œ£), unless otherwise specied, and X and Sn , with
n = N ‚àí 1, are its sample mean and sample covariance matrix, respectively. We

                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

376                                          Didier Cortez-Elizalde & Addy Bolivar-Cime

try to respect, as much as possible, the notation of the original sources to avoid
confusion in the description of their results.



2. Tests for        H0 : Œ£ = Ip
    Suppose that we are interested in testing (1). Note that if we want to test H0 :
Œ£ = Œ£0 vs H1 : Œ£ Ã∏= Œ£0 , where Œ£0 is a specic known positive denite covariance
matrix, this is equivalent to testing (1), since we can transform Xi to Yi =
  ‚àí1/2
Œ£0 Xi , i = 1, 2, . . . , N , which are independent random vectors with distribution
      ‚àí1/2    ‚àí1/2      ‚àí1/2
Np (Œ£0 ¬µ, Œ£0 Œ£Œ£0 ), and we observe that under the null hypothesis the Yi 's
                                                          ‚àí1/2
are independent random vectors with distribution Np (Œ£0 ¬µ, Ip ). Thus, we can
test (1) based on the transformed data.


2.1. Likelihood ratio test (           LRT1 )
      Here we suppose N > p. As we can see in Muirhead (2005), the level Œ±
likelihood ratio test for (1) rejects H0 if Œõ ‚©Ω cŒ± , where

                              e pN/2
                        Œõ=                 etr(‚àíA/2)(detA)N/2 ,
                               N

A = nSn , n = N ‚àí 1 and cŒ± is the lower Œ± √ó 100% point of the distribution
of Œõ. This test is biased, however, doing the following slight modication to the
likelihood ratio statistic we obtain an unbiased test
                                e pn/2
                        Œõ‚àó =               etr(‚àíA/2)(detA)n/2 .
                                n
Observe that this statistic is obtained from Œõ by replacing the sample size N by
the degrees of freedom n. Therefore, the likelihood ratio test rejects H0 : Œ£ = Ip
for small enough values of Œõ‚àó , or equivalently, of

                             V ‚àó = etr(‚àíA/2)(detA)n/2 .

    When the hypothesis H0 : Œ£ = Ip is true and n is large, the distribution of
‚àí2œÅlogŒõ‚àó , where œÅ = 1 ‚àí (2p2 + 3p ‚àí 1)/(6n(p + 1)), follows approximately a
chi-square distribution with f = p(p + 1)/2 degrees of freedom, that is,

                     P(‚àí2œÅlogŒõ‚àó ‚â§ x) ‚âà P(œá2f ‚©Ω x),         ‚àÄx ‚àà R.                     (3)

Using this approximation, a level Œ± test for (1) rejects H0 if ‚àí2œÅ log Œõ‚àó > œá2f (Œ±),
where œá2f (Œ±) is the upper Œ± √ó 100% point of the chi-square distribution with f
degrees of freedom. This test will be called the level Œ± likelihood ratio test (LRT1 )
for (1).


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data              377

2.2. Corrected Likelihood Ratio Test (CLRT)

    As it is observed in Bai et al. (2009), the likelihood ratio test has a size much
higher than the nominal level in the case when the dimension of the data is very
large. For that reason Bai et al. (2009) proposed a correction to the likelihood
ratio test statistic using some results of Random Matrix Theory.
   Suppose n > p. Let

                            L‚àó = trSn ‚àí log(detSn ) ‚àí p.                                (4)

From (3) we have that
                               Tn = nL‚àó = ‚àí2 log Œõ‚àó ,
converges to the chi-square distribution with p(p + 1)/2 degrees of freedom under
H0 : Œ£ = Ip , when p is xed and n ‚Üí ‚àû. In Bai et al. (2009) it is proved the
following result.
                                                                               ‚àó
Theorem 1. Suppose yn := p/n ‚Üí y ‚àà (0, 1) when n, p ‚Üí ‚àû. Let L                     be as in
equation (4) and g(x) = x ‚àí logx ‚àí 1. Then, under H0 and when n ‚Üí ‚àû

                                                           d
                Ten = v(g)‚àí1/2 [L‚àó ‚àí p ¬∑ F yn (g) ‚àí m(g)] ‚àí‚Üí N (0, 1),                  (5)

where

                                     log(1 ‚àí y)
                          m(g) = ‚àí              ,
                                         2
                          v(g) = ‚àí2log(1 ‚àí y) ‚àí 2y,
                                         yn ‚àí 1
                          F yn (g) = 1 ‚àí         log(1 ‚àí yn ),
                                           yn
       d
and  ‚àí‚Üí denotes convergence in distribution. The expressions m(g) and v(g) are
                                                             ‚àó       y
the asymptotic mean and variance, respectively, of Gn (g) = L ‚àí p ¬∑ F n (g) when
n ‚Üí ‚àû. The statistic Ten will be called the corrected likelihood ratio statistic.

    A level Œ± test for (1) based on the statistic (5) rejects H0 if Ten > zŒ± , where
zŒ± is the upper Œ± √ó 100% point of the standard normal distribution N (0, 1). This
test will be called the level Œ± corrected likelihood ratio test (CLRT) for (1).


2.3. Ledoit and Wolf (LW) Test

    For the testing problem (1) the likelihood ratio test statistic is degenerate when
p is greater than n. Nagao (1973) proposed the test statistic V = tr[(Sn ‚àí Ip )2 ]/p,
which does not degenerate in that case. This test statistic for the testing problem
(1) is the equivalent of the test statistic U proposed by John (1971) for the testing
problem (2) (see section 3.2). In Ledoit & Wolf (2002) it is shown that the power
and size of the sphericity test based on U is robust against p large, and even
large than n. However, the test of (1) based on V is not consistent against every
alternative when p goes to innity with n. For that reason in Ledoit & Wolf (2002)


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

378                                        Didier Cortez-Elizalde & Addy Bolivar-Cime

it is proposed the following test statistic for (1)
                                                       -2
                           1                   p 1         p
                     W = tr[(Sn ‚àí Ip )2 ] ‚àí         trSn + ,
                           p                   n p         n
which will be called the Ledoit & Wolf statistic. Contrary to V , the power and the
size of the test based on W are robust against p large, and even larger than n.
    In Ledoit & Wolf (2002) is proved that under H0 : Œ£ = Ip , when n ‚Üí ‚àû and
p is xed,
                                       d   2 2
                            nW ‚àí p ‚àí‚Üí       œá         ‚àí p.
                                           p p(p+1)/2
They also proved the following result.
Theorem 2. Suppose that p/n ‚Üí y ‚àà (0, ‚àû) as n, p ‚Üí ‚àû, then under H0

                                            d
                                 nW ‚àí p ‚àí‚Üí N (1, 4).

    By the last theorem, a level Œ± test for (1) based on the Ledoit & Wolf statistic,
rejects H0 if (nW ‚àí p ‚àí 1)/2 > zŒ± , where zŒ± is the upper Œ± √ó 100% point of the
standard normal distribution. We called this test the level Œ± Ledoit and Wolf (LW)
test for (1).



2.4. Tracy-Widom (TW) Test

    In Johnstone (2001) the case when n and p are large, with n = n(p) and
n/p ‚Üí Œ≥ > 0 as p ‚Üí ‚àû, is considered. Based on Random Matrix Theory, in
that work it is obtained the asymptotic distribution of the largest eigenvalue of
the sample covariance matrix of Gaussian data, which can be used to give a test
for (1).
   We denote by Wp (n, Œ£) the Wishart distribution with n degrees of freedom
and covariance matrix Œ£ of size p √ó p. The next theorem proposed by Johnstone
(2001), gives the asymptotic distribution of the largest eigenvalue of a random
matrix with Wishart distribution.
Theorem 3. Let A with distribution Wp (n, Ip ) and let l1 be the largest eigenvalue
of A. If n/p ‚Üí Œ≥ ‚â• 1 as p ‚Üí ‚àû, then

                                  l1 ‚àí ¬µnp d
                                          ‚àí‚Üí F1 ,
                                     œÉnp
where the center and scaling constants are
                            ‚àö  ‚àö 2
                   ¬µnp =        n‚àí1+
                                p ,                                                    (6)
                                              1/3
                         ‚àö
                                   
                               ‚àö     1    1
                   œÉnp =   n‚àí1+ p ‚àö      +‚àö        ,                                   (7)
                                     n‚àí1    p
and F1 is the distribution function of the Tracy-Widom law of order 1.



                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data              379

    The last theorem is stated for the case when n ‚â• p. However, as mentioned
in Johnstone (2001), it applies equally well if n < p are both large, simply by
reversing the roles of n and p in (6) and (7). Therefore, if we have a random
sample of size N from the multivariate normal distribution Np (¬µ, Œ£) and l1 is the
largest eigenvalue of the sample covariance matrix Sn , with distribution Wp (n, Œ£),
a level Œ± test for (1) rejects H0 if
                                       nl1 ‚àí ¬µnp
                                          œÉnp
is greater than the upper Œ± √ó 100% point of the Tracy-Widom distribution F1 ,
denoted by F1 (Œ±), where ¬µnp and œÉnp are the center and scaling constants of
Theorem 3. We called this test the level Œ± Tracy-Widom (TW) test for (1).


2.5. Cai and Ma (CM) Test

    Motivated by a test of Chen et al. (2010), Cai & Ma (2013) proposed a test for
(1). The original proposal in Chen et al. (2010) involves higher order symmetric
functions of the Xi 's than the proposal of Cai & Ma (2013). The test is established
in the setting where the dimension p = pn ‚Üí ‚àû as the sample size n ‚Üí ‚àû,
and there is no restriction on the limit of p/n. Cai & Ma (2013) proved that
the asymptotic power of their proposed test, in a subset of covariance matrices,
uniformly dominates that of the CLRT given in section 2.2, when p < n and
p/n ‚Üí y ‚àà (0, 1).
    Let X1 , . . . , Xn be independent random vectors from the normal distribution
Np (0, Œ£). Cai & Ma (2013) consider to test the hypothesis H0 : Œ£ = Ip versus the
alternative hypothesis
                     H1 : Œ£ ‚àà Œò,     Œò = {Œ£ :‚à• Œ£ ‚àí Ip ‚à•F ‚©æ œµn },                       (8)
where œµn > 0 and                vÔ£´
                                u        Ô£∂
                                u X         q
                       ‚à• A ‚à•F = tÔ£≠  a2ij Ô£∏ = tr(AAH ),
                                u
                                       i,j

is the Frobenius norm of the matrix A = (aij ), where AH is the conjugate transpose
of A. The diculty of testing between H0 and H1 depends on the value of œµn ; the
smaller œµn is, the harder it is to distinguish between the two hypotheses.
   Dene the statistic
                                   2           X
                         Tn =                          h(Xi , Xj ),
                                n(n ‚àí 1)
                                             1‚©Ωi<j‚©Ωn

where
                   h(Xi , Xj ) = (Xi‚Ä≤ Xj )2 ‚àí (Xi‚Ä≤ Xi + Xj‚Ä≤ Xj ) + p.

     It is important to mention that Tn is an estimator of ‚à• Œ£‚àíIp ‚à•2F = tr[(Œ£‚àíIp )2 ].
The next result given in Cai & Ma (2013) provides the asymptotic distribution of
Tn .


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

380                                             Didier Cortez-Elizalde & Addy Bolivar-Cime

Theorem 4. Suppose that p ‚Üí ‚àû as n ‚Üí ‚àû.                       If the succession of covariance
matrices satises

                      tr(Œ£2 ) ‚àí‚Üí ‚àû       and     tr(Œ£4 )/tr2 (Œ£2 ) ‚àí‚Üí 0

as n ‚Üí ‚àû, then


                                Tn ‚àí ¬µn (Œ£) d
                                           ‚àí‚Üí N (0, 1),
                                  œÉn (Œ£)
where

        ¬µn (Œ£) = EŒ£ (Tn ) = tr(Œ£ ‚àí Ip )2 ,
                                  4                            8
        œÉn2 (Œ£) = varŒ£ (Tn ) =          (tr2 (Œ£2 ) + tr(Œ£4 )) + tr(Œ£2 (Œ£ ‚àí Ip )2 ).
                               n(n ‚àí 1)                        n

                                                       p=1 satises the assumptions
    Note that the succession of identity matrices {Ip }‚àû
of the last theorem, furthermore ¬µn (Ip ) = 0 and œÉn2 (Ip ) = 4p(p + 1)/n(n ‚àí 1).
Theorem 4 provides the asymptotic behavior of Tn under   qH0 . Thus, a level Œ± test
                                                          p(p+1)
for (1) based on the statistic Tn rejects H0 if Tn > zŒ± 2 n(n‚àí1) , where zŒ± is the
upper Œ± √ó 100% point of the standard normal distribution. We called this test the
level Œ± Cai and Ma (CM) test for (1).


2.6. Srivastava's Tests ( 2s ,      T      T2 )
    The tests for (1) presented in this section were proposed by Srivastava (2005)
and Srivastava et al. (2014). They considered a distance function between the null
hypothesis and the alternative hypothesis, and proposed tests based on consistent
estimators of this parametric function of the covariance matrix Œ£ for testing (1).
Specically, they considered estimators of the squared Frobenius norm (divided
by p)
               1                  1
                 tr[(Œ£ ‚àí Ip )2 ] = [tr(Œ£2 ) ‚àí 2tr(Œ£) + p] = a2 ‚àí 2a1 + 1,                 (9)
               p                  p
where
                                       trŒ£i
                                ai =        ,    i = 1, 2, . . . .                       (10)
                                         p
Observe that under the null hypothesis H0 : Œ£ = Ip we have that (9) is equal to
zero. Therefore, a test for (1) can be based on an estimator of (9), where the null
hypothesis should be rejected if the observed value of the estimator is greater than
some specic amount.
      Consider the following assumptions

               a) If p ‚Üí ‚àû, then ai ‚Üí a0i , 0 < a0i < ‚àû,             i = 1, . . . , 8.
                           Œ¥
                                                                                         (11)
               b) n = O(p ),     0 < Œ¥ ‚©Ω 1,


                     Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data                381

where n = O(pŒ¥ ) denotes that n/pŒ¥ remains bounded as n and p go to innity,
this includes the case when (n/p) ‚Üí 0. The following results can be found in
Srivastava (2005).

Lemma 1. Under assumption             a), and when n ‚Üí ‚àû, unbiased and consistent
estimators of a1 and a2 are given, respectively, by

                                            n2
                                                                      -
                     trSn                                     1
              a1 =        ,   a2s =                    trSn2 ‚àí (trSn )2 .
                                      (n ‚àí 1)(n + 2)p
              b               b
                       p                                      n

Theorem 5. Consider the assumptions (11). Under H0 : Œ£ = Ip , when n, p ‚Üí ‚àû,
we have

                                 n                  d
                         T2s =             a1 + 1) ‚àí‚Üí N (0, 1).
                                    a2s ‚àí 2b
                                   (b
                                 2

    Thus, a level Œ± test for (1) based on T2s rejects H0 if T2s > zŒ± , where zŒ± is the
upper Œ± √ó 100% point of the normal standard distribution. We called this test the
level Œ± Srivastava's test T2s for (1).
   Srivastava et al. (2014) proposed a dierent test, but now based on a new
unbiased estimator of a2 , given by
                         1
                           (N ‚àí 2)ntr(M 2 ) ‚àí N ntr(D2 ) + (trD)2 ,                     (12)
                                                                 
                  a2 =
                  b
                         f

where f = pN (N ‚àí 1)(N ‚àí 2)(N ‚àí 3), M = Y‚Ä≤ Y, Y = (Y1 , . . . , YN ), D =
diag(Y1‚Ä≤ Y1 , . . . , YN‚Ä≤ YN ), with Yi = Xi ‚àí X . In Srivastava et al. (2014) it is proved
the following result.

Theorem 6. Consider the assumption              N = O(pŒ¥ ), 1/2 < Œ¥ < 1.             Under
H0 : Œ£ = Ip , when n, p ‚Üí ‚àû, we have
                                 n                 d
                          T2 =            a1 + 1) ‚àí‚Üí N (0, 1).
                                    a2 ‚àí 2b
                                   (b
                                 2

   Therefore, a level Œ± test for (1) based on T2 rejects H0 if T2 > zŒ± , where zŒ± is
the upper Œ± √ó 100% point of the standard normal distribution. We called this test
the level Œ± Srivastava's test T2 for (1).


3. Tests for          H0 : Œ£ = ŒªIp
    In this section we describe briey some tests for sphericity, that is, tests for
(2), where the null hypothesis arms that the covariance matrix is proportional
to the identity matrix.
    Note that if we want to test H0 : Œ£ = ŒªŒ£0 vs H1 : Œ£ Ã∏= ŒªŒ£0 , where Œ£0
is a specic known positive denite covariance matrix and Œª is unknown, this is
                                                          ‚àí1/2
equivalent to test (2), by transforming the data to Yi = Œ£0 Xi , i = 1, 2, . . . , N ,
and testing (2) based on the transformed data.


                     Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

382                                        Didier Cortez-Elizalde & Addy Bolivar-Cime

3.1. Likelihood Ratio Test (              LRT2 )
    In Muirhead (2005) it is shown that the level Œ± likelihood ratio test for (2)
rejects H0 if
                                detA          detSn
                       V ‚â°             p =            p ‚©Ω kŒ± ,                        (13)
                             (tr(A)/p)     (tr(Sn )/p)

where A = nSn and kŒ± is the lower Œ± √ó 100% point of the distribution of V . The
statistic V is called ellipticity statistic.
   When the hypothesis H0 : Œ£ = ŒªIp is true, the distribution of ‚àínœÅlogV ,
where œÅ = 1 ‚àí (2p2 + p + 2)/6np, has approximately a chi-square distribution with
f = (p + 2)(p ‚àí 1)/2 degrees of freedom when n is large, that is,

                     P(‚àínœÅlogV ‚©Ω x) ‚âà P(œá2f ‚©Ω x),          ‚àÄx ‚àà R.                    (14)

By this approximation, a level Œ± test for (2) rejects H0 if ‚àínœÅ log V > œá2f (Œ±),
where œá2f (Œ±) is the upper Œ± √ó 100% point of the chi-square distribution with f
degrees of freedom. We called this test the level Œ± likelihood ratio test (LRT2 ) for
(2).


3.2. John's (J) Test

   For the testing problem (2) the likelihood ratio test is degenerate when p is
greater than n. John (1971) proposed to test (2) using the following test statistic,
which does not degenerate,
                      "                   2 #
                  1          Sn                     (1/p)tr(Sn2 )
             U = tr                   ‚àí Ip      =                 ‚àí 1.         (15)
                  p      (1/p)tr(Sn )             [(1/p)tr(Sn )]2

We called this statistic the John's statistic. John (1972) proved that, when n ‚Üí ‚àû
and p is xed, under H0
                                      d   2 2
                           nU ‚àí p ‚àí‚Üí       œá           ‚àí p.
                                          p p(p+1)/2‚àí1

    In Ledoit & Wolf (2002) it is shown that the power and size of the sphericity
test based on U is robust against p large, and even larger than n. They proved
the following result.
Theorem     7.   Suppose that   p/n ‚Üí y ‚àà (0, ‚àû) as n, p ‚Üí ‚àû, then under
H0 : Œ£ = ŒªIp
                                           d
                                 nU ‚àí p ‚àí‚Üí N (1, 4).

   Then, a level Œ± test for (2) based on the John's statistic rejects H0 if
(nU ‚àí p ‚àí 1)/2 > zŒ± , where zŒ± is the upper Œ± √ó 100% point of the standard
normal distribution. This test will be called the level Œ± John's (J) test for (2).


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data              383

3.3. Quasi-Likelihood Ratio Test (QLRT)

    Let X1 , X2 , . . . , Xn be independent random vectors of the multivariate normal
distribution Np (0, Œ£), and let X = (X1 , . . . , Xn ) be the matrix of size p √ó n whose
columns are the vectors Xi , i = 1, 2, . . . , n. The likelihood ratio test for (2),
denoted by LRT2 and described in section 3.1, requires p ‚©Ω n because when
p > n, p ‚àí n eigenvalues of the sample covariance matrix Sn are zero and therefore
V in (13) is equal to zero. Li & Yao (2016) proposed an extension of the LRT2 for
the case when p > n, by considering the matrix X‚Ä≤ X/p which has exactly the same
n non-zero eigenvalues with the matrix Sn = XX‚Ä≤ /n (up to some scaling). Their
results are in the ultra-dimensional asymptotic setting p ‚â´ n, where p/n ‚Üí ‚àû
and n ‚Üí ‚àû.
   The quantity ‚àín log V that appears in the left side of (14) can be expressed as
                                 Ô£Æ            p Ô£π
                                    1 Pp
                                 Ô£Ø p i=1 i Ô£∫ ‚Ñì
                           n log Ô£Ø   Qp           Ô£∫,
                                        i=1 ‚Ñìi
                                 Ô£∞                Ô£ª


where ‚Ñìi , i = 1, 2, . . . , p, are the eigenvalues of the matrix Sn . Based on the last
expression, Li & Yao (2016) proposed the quasi-likelihood ratio statistic given by
                                            Ô£Æ             n Ô£π
                                               1 Pn
                                      p     Ô£Ø n i=1 ŒªÃÉi Ô£∫
                                Ln = log Ô£Ø       Qn           Ô£∫,
                                      n     Ô£∞
                                                   i=1 ŒªÃÉi
                                                              Ô£ª


where ŒªÃÉi , i = 1, 2, . . . , n, are the eigenvalues of the matrix X‚Ä≤ X/p. They presented
the next theorem.

Theorem 8. Suppose that p/n ‚Üí ‚àû and n ‚Üí ‚àû, then under H0


                                n n2     v4 ‚àí 2 d
                         Ln ‚àí     ‚àí    ‚àí       ‚àí‚Üí N (0, 1),
                                2   6p      2
where v4 is the fourth moment of the standard normal distribution.

                                                                                      n
   Thus, a level Œ± test for (2) based on the statistic Ln rejects H0 if Ln ‚àí            ‚àí
                                                                                      2
n2     v4 ‚àí 2
    ‚àí         > zŒ± , where zŒ± is the upper Œ± √ó 100% point of the standard normal
6p        2
distribution. We called this test the level Œ± quasi-likelihood ratio test (QLRT) for
(2).


3.4. Srivastava's Tests ( 1s ,     T    T1 )
   The next tests for (2) were proposed by Srivastava (2005) and Srivastava et al.
(2014). Let ai , for i = 1, 2, . . . , given by (10). Srivastava (2005) showed, using the


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

384                                            Didier Cortez-Elizalde & Addy Bolivar-Cime

Cauchy-Schwarz inequality, that
                                       Pp     2
                                 a2      i=1 Œªi /p
                                  2 =  Pp           ‚â• 1,
                                 a1   ( i=1 Œªi /p)2

with equality holding if and only if Œªi = Œª, for i = 1, 2, . . . , p and some constant
Œª; where the Œªi 's are the eigenvalues of Œ£. Thus, a measure of sphericity is given
by
                                          a2
                                              ‚àí 1,                                      (16)
                                          a21

which is equal to zero if and only if Œªi = Œª, for i = 1, 2, . . . , p. Therefore, a test
for (2) can be based on an estimator of (16), where the null hypothesis should
be rejected if the observed value of the estimator is greater than some specic
amount.
      Consider the unbiased estimators of a1 and a2 of lemma 1. Dene
                                                  
                                      n b  a2s
                                T1s =          ‚àí 1   .
                                      2 b  a21

      We have the following result given by Srivastava (2005).

Theorem 9. Consider the assumptions (11).                     Under   H0 : Œ£ = ŒªIp , when
n, p ‚Üí ‚àû, we have

                                           d
                                     T1s ‚àí‚Üí N (0, 1).

   Thus, a level Œ± test for (2) based on T1s rejects H0 if T1s > zŒ± , where zŒ± the
upper Œ± √ó 100% point of the standard normal distribution. This test will be called
the level Œ± Srivastava's test T1s for (2).
               a2 given by (12). Substituting b
      Consider b                                    a2s in T1s we get
                                              a2 by b
                                                        
                                        n          a2
                                                       ‚àí1 .
                                                   b
                                   T1 =
                                        2          a21
                                                   b

      The next result is provided by Srivastava et al. (2014).

Theorem 10. Consider N          = O(pŒ¥ ), 1/2 < Œ¥ < 1. Under H0 : Œ£ = ŒªIp , when
n, p ‚Üí ‚àû, we have

                                          d
                                     T1 ‚àí‚Üí N (0, 1).

   Therefore, a level Œ± test for (2) based on T1 rejects H0 if T1 > zŒ± , where zŒ± is
the upper Œ± √ó 100% point of the standard normal distribution. We called this test
the level Œ± Srivastava's test T1 for (2).


                     Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data                385

3.5. Zou's (Z) Test

    The next test was proposed by Zou et al. (2014). They proposed a test for (2)
considering a random sample from a p-variate elliptical distribution, in the high
dimensional context. Their proposal is a modication of the sign test statistic
(Hallin & Paindaveine (2006)), which is dened by mimicking John's test statistic
given by (15), considering the multivariate sign function.
   Let X1 , . . . , Xn be random vectors from a p-variate elliptical distribution with
density function of the form
                           det(Œ£p )‚àí1/2 gp (‚à•Œ£‚àí1/2
                                              p    (X ‚àí Œ∏p )‚à•),

where ‚à•X‚à• = (X ‚Ä≤ X)1/2 is the Euclidean norm of the vector X , Œ∏p is the symmetry
centre, Œ£p is a positive-denite symmetric p √ó p scatter matrix, and gp is a non-
negative function of a real variable. The matrix Œ£p that describes the covariances
between the p variables can be expressed as Œ£p = œÉp Œõp , where œÉp = œÉ(Œ£p ) is a scale
parameter and Œõp = œÉp‚àí1 Œ£p is a shape matrix. The scale parameter is assumed to
satisfy œÉ(Ip ) = 1 and œÉ(aŒ£p ) = aœÉ(Œ£p ) for all a > 0. We are interested in testing
H0 : Œ£p = ŒªIp , which is equivalent to Œõp = Ip .
   The multivariate sign function is dened as
                          U (X) = ‚à•X‚à•‚àí1 X,           for all X Ã∏= 0.
The observed signs for Xi , i = 1, 2, . . . , n, are
                                    Ui = U (Xi ‚àí Œ∏p ).

    Let X1 , . . . , Xn be random vectors from the multivariate normal distribution
Np (¬µ, Œ£). The multivariate normal distribution is an elliptical distribution, for
which Œ∏p = ¬µ and its estimator is given by Œ∏bn,p = X . Consider the statistic
                                      p     X
                                                   bj‚Ä≤ )2 ‚àí 1,
                                               bi‚Ä≤ U
                              QÃÉ =            (U
                                   n(n ‚àí 1)
                                              iÃ∏=j

where U bi = U (Xi ‚àí X). This statistic is a modied version of the sign test
statistic given in Hallin & Paindaveine (2006). Let Ri =‚à• Xi ‚àí ¬µ ‚à• and consider
the following assumption.
                                   ‚àík
Assumption 1. The moments E(Ri ) for k = 1, 2, . . . , 4 exist for large enough p;
          ‚àík       ‚àí1 k
and E(Ri )/E(Ri ) ‚Üí dk ‚àà [1, ‚àû) as p ‚Üí ‚àû, where the dk are constants, for
k = 2, 3, 4.
    In the supplementary material of Zou et al. (2014) is veried Assumption 1 for
the multivariate normal distribution, the multivariate t distribution, and mixtures
of multivariate normal distributions. The following result of Zou et al. (2014) gives
the asymptotic distribution of QÃÉ.
                                                                           2
Theorem 11. Under H0 : Œ£ = ŒªIp and Assumption 1, if p = O(n                    ), then
                                  QÃÉ ‚àí pŒ¥n,p d
                                            ‚àí‚Üí N (0, 1)
                                      œÉÃÉ0


                    Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

386                                        Didier Cortez-Elizalde & Addy Bolivar-Cime

                   e02 = 4(p ‚àí 1)/[n(n ‚àí 1)(p + 2)] and
as n, p ‚Üí ‚àû, where œÉ

                                      -2 !
              2E(Ri‚àí2 )     E(Ri‚àí2 )
                          
        1
 Œ¥n,p = 2  2‚àí           +
       n      E(Ri‚àí1 )2     E(Ri‚àí1 )2
            "                         2                                 # (17)
          1 8E(Ri‚àí2 )        E(Ri‚àí2 )       2E(Ri‚àí2 )E(Ri‚àí3 ) E(2Ri‚àí3 )
                          
        + 3           ‚àí6                  +                  ‚àí            .
         n E(Ri‚àí1 )2        E(Ri‚àí1 )2          E(Ri‚àí1 )5       E(Ri‚àí1 )3

   The unknown quantities in Œ¥n,p are E(Ri‚àí2 )/E(Ri‚àí1 )2 and E(Ri‚àí3 )/E(Ri‚àí1 )3 ,
which can be estimated as follows. Let
                                         bi + Œ∏b‚Ä≤ U      ‚àí1 b ‚àí1 b
             bi = ‚à•Xi ‚àí Œ∏bn,p ‚à•,
             R                     R
                                   bi‚àó = R
                                                n,p i ‚àí 2
                                                   b       Ri ‚à•Œ∏n,p ‚à•2 .

Thus, substituting
                                   E(Ri‚àík )/E(Ri‚àí1 )k
by
                                        Pn b‚àík
                                    nk‚àí1 i=1 R  i‚àó
                                      Pn b‚àí1 k
                                     ( i=1 Ri‚àó )

in (17) we obtain an estimator of Œ¥n,p , denoted by Œ¥ÃÇn,p .
    Therefore, a level Œ± test for (2) based on the statistic QÃÉ rejects H0 if
(QÃÉ ‚àí pŒ¥ÃÇn,p )/œÉÃÉ0 > zŒ± , where zŒ± is the upper Œ± √ó 100% point of the standard
normal distribution. We called this test the level Œ± Zou's (Z) test for (2).


4. Simulation Study

    In this section we present a simulation study to compare the tests presented
before, in terms of the size and power of the test. For both hypothesis testing
problems (1) and (2), we considered M = 10, 000 random samples of size N = n+1
from the p-variate standard normal distribution. We considered several values of
n and p. For the case n > p, we xed n = 500 and took ve values of p less than
n; and for the case p ‚©æ n, we xed p = 500 and took ve values of n less than p.
We considered the signicance level Œ± = 0.05 for all the tests, and we calculated
the empirical size of each test, given by the proportion of rejections of H0 with
the test. If a test is good in terms of the size of the test, its empirical size should
be very close to the signicance level.
    To evaluate the power of the tests, for some values of p and n, we compute
the empirical power of each test, given by the proportion of rejections of H0
under H1 with the test, considering random samples from the multivariate normal
distribution with zero mean and covariance matrix in a subset of matrices satisfying
the alternative hypothesis H1 . The covariance matrices of this subset have the form

                                    Œ£ = Ip + hvv ‚Ä≤ ,

where h is a positive scalar and v is a unit vector. Observe that this covariance
matrix is a slightly deviation from the identity matrix when h is very small, and


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data             387

it becomes very dierent from the identity when h increases. The vector v was
randomly generated in the following way: we rst generated a random vector from
the p-variate standard normal distribution, then we divided each entry by the
norm of the random vector in order to obtain a unit vector. The scalar h varied
in a range of adequate values. This range is chosen in such a way that we can
observe how the values of the empirical powers are close to one when h increases.
Since the empirical powers may change for dierent values of p and n, the range
of values of h may also vary.
    For the tests that consider a random sample from the Np (¬µ, Œ£), we compute the
test statistics with the original data. For the tests that consider a random sample
from the Np (0, Œ£), which are the CM test and the QLRT, we rst transform
the data to a random sample of size n = N ‚àí 1 from the Np (0, Œ£), using the
transformation of multivariate normal data given in the Appendix A. We also
present in Appendix A the general ideas of the algorithms used in the simulations
to compute the empirical sizes and empirical powers of the tests. We used the
software R (https://www.r-project.org) to perform the simulation study.


4.1. Simulations for        H0 : Œ£ = Ip
    The considered tests for (1) are: LRT1 , TW, LW, CLRT, CM, T2s , T2 . For the
classical case (p < n) all the tests can be applied, and for the high dimensional
case (p ‚â• n) all the tests, except LRT1 and CLRT, can be applied.


4.1.1. Empirical Sizes of the Tests


   The results of the empirical sizes of the tests are shown in tables 1 and 2. In
these tables we observe the following:

  1. The empirical sizes of TW, LW, CM, T2s and T2 are very close to the
     signicance level, for the cases p < n and p ‚â• n, this means that these
     tests are good in terms of the size of the test.

  2. On the other hand, LRT1 is not good, since its empirical sizes are far from
     the considered signicance level. When p approaches to n the empirical size
     approaches to 1, however this test can be good if n is large enough with
     respect to p.

  3. CLRT corrects the problem of LRT1 , since its empirical sizes are very close
     to the considered signicance level, actually when p approaches to n the
     behavior of the empirical size of CLRT is better.


4.1.2. Empirical powers of the tests


   The results of the empirical powers of the tests by varying h, are presented in
the tables 3 and 4. The gures 1 and 2 illustrate the behavior of the empirical


                  Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

388                                           Didier Cortez-Elizalde & Addy Bolivar-Cime

          Table 1: Empirical sizes of the tests for H0 : Œ£ = Ip , case p < n.
          n, p     LRT1      TW      CLRT        LW       CM       T2s      T2
        500,25     0.0740   0.0498   0.0555     0.0541   0.0526   0.0546   0.0552
        500,50     0.2240   0.0480   0.0526     0.0538   0.0519   0.0541   0.0535
        500,100    0.9753   0.0520   0.0526     0.0539   0.0527   0.0525   0.0531
        500,200       1     0.0517   0.0513     0.0493   0.0500   0.0491   0.0500
        500,400       1     0.0536   0.0509     0.0492   0.0487   0.0495   0.0503

          Table 2: Empirical sizes of the tests for H0 : Œ£ = Ip , case p ‚©æ n.
                   n, p      TW       LW         CM       T2s      T2
                   25,500   0.0503    0.055     0.0537   0.0541   0.0591
                   50,500   0.0494   0.0504     0.0509   0.0491   0.0514
                  100,500   0.0526   0.0527     0.0483   0.0485   0.0491
                  200,500   0.051    0.0549     0.0547   0.0546   0.0546
                  400,500   0.0528   0.0501     0.0516   0.0498   0.0508



powers of the tests for the classical case (p < n) and the high dimensional case
(p ‚©æ n), respectively. We observe the following:

  1. For p < n and p ‚â• n, the empirical powers of the tests are good when h
     increases, since they are equal to or approximately one.

  2. For p < n the empirical power of the TW test is bigger than the
     corresponding to the rest of the tests, except LRT1 . For p ‚â• n the empirical
     power of the TW test has the best behavior.

  3. Despite that the empirical power of LRT1 is one for all values of h when
     n = 500 and p = 200, this test is bad in terms of the size (see Table 1),
     therefore it is not recommended in this case.

  4. Even when the empirical power of CLRT is the smallest, it has an acceptable
     behavior.

  5. The empirical powers of LW, CM, T2s and T2 are very close between them
     that their graphs are almost indistinguishable for both cases, p < n and
     p ‚â• n. This may be due to the fact that the test statistics of these tests are
     based on estimators of the squared Frobenius norm ‚à• Œ£‚àíIp ‚à•2F = tr[(Œ£‚àíIp )2 ].




4.2. Simulations for         H0 : Œ£ = ŒªIp
   The considered tests for (2) are: LRT2 , J, QLRT, T1s , T1 and Z. For the case
n > p all the tests, except QLRT, can be applied; whereas for the case p ‚â• n all
the test, except LRT2 , can be applied.


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data              389

         Table 3: Empirical powers of the tests for H0 : Œ£ = Ip , case p < n.
                                     n = 500, p = 50

           h     LRT1       TW      CLRT      LW         CM       T2s      T2
           0.3   0.3494    0.1884    0.104   0.1266     0.1215   0.1255   0.1263
           0.6   0.6777    0.9047   0.3514   0.5456     0.5373   0.5413   0.5425
           0.9   0.9405    0.9997   0.7731   0.9543     0.9514   0.9524   0.9526
           1.2   0.9964       1     0.9729   0.9994     0.9992   0.9993   0.9993
           1.5      1         1     0.9986      1          1        1        1
                                     n = 500, p = 200

           h     LRT1       TW      CLRT      LW         CM       T2s      T2
           0.5     1       0.1172   0.0751    0.095     0.0948   0.0945   0.0955
            1      1       0.8746   0.1596   0.3575     0.3535   0.3538   0.3554
           1.5     1       0.9998   0.3455   0.8389     0.8363   0.8361   0.8371
            2      1          1     0.6014   0.9945     0.9943   0.9944   0.9943
           2.5     1          1     0.8295   0.9999     0.9999   0.9999   0.9999

         Table 4: Empirical powers of the tests for H0 : Œ£ = Ip , case p ‚©æ n.
                                     p = 500, n = 50

                       h    TW       LW       CM         T2s      T2
                    1.9    0.0911   0.077    0.0739     0.0732   0.0763
                    3.8    0.3753   0.196    0.1881     0.1877   0.1935
                    5.7    0.7866   0.4707   0.4638     0.4686   0.4716
                    7.6    0.9577   0.7576   0.745      0.7551    .7514
                    9.5    0.9932   0.9139   0.9096      0.916   0.9148
                                     p = 500, n = 200

                       h    TW       LW       CM         T2s      T2
                    1.2    0.1086   0.0943   0.0935     0.0945   0.0945
                    2.4     0.796   0.3261   0.3241      0.322   0.3211
                    3.6    0.9985   0.7751   0.7703     0.7735   0.7726
                    4.8       1     0.9788   0.9771      0.979   0.9784
                     6        1     0.9994   0.9993     0.9994   0.9994



4.2.1. Empirical Sizes of the Tests


   The results of the empirical sizes of the tests are in the tables 5 and 6. We
observe the following:

  1. The empirical sizes of J, T1s , T1 y Z are very close to the signicance level,
     for p < n and p ‚©æ n, therefore they have a good behavior in terms of the
     size of the test.

  2. On the other hand, for p < n, LRT2 has empirical size close to the
     signicance level when n is large enough with respect to p, but it has a
     bad behavior when p is close to n.


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

390                                         Didier Cortez-Elizalde & Addy Bolivar-Cime




          (a) p = 50, n = 500                             (b) p = 200, n = 500
       Figure 1: Empirical powers of the tests for H0 : Œ£ = Ip , case p < n.




          (a) p = 500, n = 50                             (b) p = 500, n = 200
       Figure 2: Empirical powers of the tests for H0 : Œ£ = Ip , case p ‚©æ n.


  3. For p ‚©æ n, QLRT has good behavior of the empirical size only when p is
     large enough with respect to n. When n approaches to p the empirical size
     approaches to one.

        Table 5: Empirical sizes of the tests for H0 : Œ£ = ŒªIp , case p < n.
                  n, p    LRT2       J         T1s      T1        Z
                 500,25   0.0475   0.0493     0.0492   0.0497    0.052
                 500,50   0.0505   0.0515      0.052   0.0519   0.0534
                500,100   0.0676   0.0526     0.0515   0.0522   0.0501
                500,200   0.3673   0.0488     0.0493    0.049   0.0491
                500,400      1     0.0497     0.0491   0.0496   0.0502


                 Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data              391

          Table 6: Empirical sizes of the tests for H0 : Œ£ = ŒªIp , case p ‚©æ n.
                    n, p      J      QLRT       T1s      T1        Z
                   25,500    0.054   0.0615   0.0537   0.0586    0.0604
                   50,500   0.0498   0.0629    0.049    0.051    0.0519
                  100,500   0.0519   0.1313   0.0481   0.0489    0.0511
                  200,500   0.0545   0.9593   0.0546   0.0543    0.0536
                  400,500   0.0499      1     0.0497   0.0504    0.052



4.2.2. Empirical Powers of the Tests


   The results of the empirical powers of the tests by varying h, are presented in
the tables 7 and 8. The gures 3 and 4 illustrate the behavior of the empirical
powers of the tests for the cases p < n and p ‚©æ n. We observe the following:

  1. For p < n and p ‚â• n, the empirical powers of the tests are good when h
     increases, since they are equal or approximately one.
  2. For the cases p < n and p ‚â• n, the empirical powers of J, T1s , T1 and Z
     are very close between them that their graphs are almost indistinguishable.
     This may be due to the fact that the test statistics of J, T1s and T1 are
     based on estimators of the measure of sphericity a2 /a21 ‚àí 1, with ai given by
     expression (10), and the test statistic of the Z test is similar to the statistic
     of the J test.
  3. For the case n = 500 and p = 50, the empirical powers of J, T1s , T1 and Z
     are bigger than the corresponding to LRT2 , however the empirical power of
     the last one is good when h increases.
  4. When n = 500, p = 200 and h = 0.5, 1, LRT2 has bigger empirical power
     than J, T1s , T2 and Z, however LRT2 has a bad behavior in terms of the size
     of the test (see Table 5), hence it is not recommendable in this case.
  5. When p = 500, n = 50 and h ‚â• 3.8, the empirical powers of J, T1s , T1 and
     Z are bigger than the corresponding to QLRT.
  6. When p = 500 and n = 200, for all the considered values of h, QLRT has
     the biggest empirical power, however the size of this test is bad (see Table
     6), therefore this test is not recommendable in this case.



5. Examples of Application

    In this section we apply the tests for (1) and (2) in the high dimensional context
(p ‚©æ n) to two sets of DNA microarray data found in the literature. It is worth to
mention that, in real applications with DNA microarray data, where there is an
expert of the dataset that can suggest a form for the covariance matrix, frequently
it is of interest to test H0 : Œ£ = Œ£0 vs H1 : Œ£ Ã∏= Œ£0 , for some specic covariance


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

392                                        Didier Cortez-Elizalde & Addy Bolivar-Cime

        Table 7: Empirical powers of the tests for H0 : Œ£ = ŒªId , case p < n.
                                   n = 500, p = 50

                    h    LRT2       J       T1s        T1        Z
                   0.3   0.0987   0.1161   0.1159     0.1158   0.1108
                   0.6   0.3323   0.5133   0.5133     0.5115   0.4691
                   0.9   0.7453   0.9423   0.9427     0.9423   0.9139
                   1.2   0.9649   0.9989   0.999      0.9989   0.9978
                   1.5    0.998      1        1          1        1
                                   n = 500, p = 200

                    h    LRT2       J       T1s        T1        Z
                   0.5   0.4466   0.0921   0.0927     0.0931   0.0924
                    1    0.6174   0.3445   0.3441     0.3443   0.3309
                   1.5   0.8065   0.8287   0.8286     0.8287   0.8052
                    2    0.9349   0.9935   0.9934     0.9936   0.9905
                   2.5   0.9849   0.9999   0.9999     0.9999   0.9999

        Table 8: Empirical powers of the tests for H0 : Œ£ = ŒªIp , case p ‚©æ n.
                                   p = 500, n = 50

                    h      J      QLRT      T1s        T1        Z
                   1.9   0.0745   0.0841   0.0699     0.0744   0.0722
                   3.8   0.1865   0.1672   0.1813     0.1863   0.1716
                   5.7   0.4546   0.3466   0.4573     0.4582   0.4249
                   7.6   0.7424   0.5834   0.7436     0.7401   0.7031
                   9.5    0.908    0.782   0.9106      0.91    0.8834
                                   p = 500, n = 200

                    h      J      QLRT      T1s        T1        Z
                   1.2   0.0929   0.9714    0.092     0.0925   0.0923
                   2.4    0.319   0.9902   0.3151     0.3156   0.3083
                   3.6   0.7653   0.9979   0.7656     0.7653   0.7434
                   4.8   0.9768   0.9995    .9775     0.9767   0.9695
                    6    0.9992      1     0.9993     0.9994    0.999



matrix Œ£0 xed by the expert. As mentioned in previous sections, to test the last
null hypothesis we can transform the data and test (1) based on the transformed
dataset. Since the objective of this work is not the study of some specic datasets,
and we do not have an expert of the considered data found in the literature, we
only consider the null hypotheses in (1) and (2) to illustrate the implementation
of the tests and to observe their behavior.
  For the high dimensional context we considered the following tests: TW, J,
LW, QLRT, CM, T1s , T2s , T1 , T2 and Z. The p-value of each test was calculated.
We took the signicance level Œ± = 0.05.
    Since all of the considered tests for the high dimensional context take a random
sample from the Np (¬µ, Œ£), except QLRT that consider a random sample from the
Np (0, Œ£), for the last test we applied the transformation of multivariate normal

                  Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data             393




           (a) p = 50, n = 500                          (b) p = 200, n = 500
        Figure 3: Empirical powers of the tests for H0 : Œ£ = ŒªIp , case p < n.




           (c) p = 500, n = 50                         (d) p = 500, n = 200
        Figure 4: Empirical powers of the tests for H0 : Œ£ = ŒªIp , case p ‚©æ n.


data given in Appendix A before the application of this test. Because the real
datasets might not be scaled to have covariance matrix equal to the identity matrix,
the datasets are scaled by Œª               b = tr(Sn )/p, before the application of
                             b‚àí1/2 , where Œª
the tests for (1), as suggested in Ma (2012).


5.1. DLBCL Data


   We consider the DNA microarray data of Rosenwald et al. (2002), which
correspond to patients with diuse large B-cell lymphoma (DLBCL). This dataset
considers 7399 genes and 240 patients. The values of the test statistics for
the hypothesis testing problems (1) and (2) are shown in the tables 9 and 10,
respectively.


                  Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

394                                       Didier Cortez-Elizalde & Addy Bolivar-Cime

    For each test in the tables 9 and 10 the value of the statistic was very large,
and then the p-value was approximately zero. Due to the p-values of all the tests
are approximately zero, we are strongly rejecting both null hypotheses. Therefore,
considering, say, the signicance level Œ± = 0.05, we have statistical evidence to
reject H0 : Œ£ = Ip and H0 : Œ£ = ŒªIp with all the considered tests.
    Since the hypotheses H0 : Œ£ = Ip and H0 : Œ£ = ŒªIp were rejected, we conclude
that the population covariance matrix of the data has not these structures. This
was expected, because it is known that there exists correlation between the genes
of the same individual.

 Table 9: Values of the test statistics for H0 : Œ£ = Ip considering the DLBCL data.
                           Test   Value of the test statistic
                           LW              80.19308
                           TW              2035.514
                            T2s            5859.268
                            T2             5820.955
                           CM              361737.7



Table 10: Values of the test statistics for H0 : Œ£ = ŒªIp considering the DLBCL data.
                           Test    Value of the test statistic
                            J              231.2596
                          QLRT             5263.1241
                            T1s            23836.63
                            T1             23679.95
                             Z             181.0721




5.2. NCI60 Data


    We now consider the NCI microarray data of Ross et al. (2000). The data
contains expression levels on 6830 genes from 64 cancer cell lines. The values
of the tests statistics for testing (1) and (2) are shown in the tables 11 and 12,
respectively.
    For each test in the tables 11 and 12 the value of the statistic was very large,
and then the p-value was approximately zero. Due to the p-values of all the tests
are approximately zero, we are strongly rejecting both null hypotheses. Therefore,
considering, say, the signicance level Œ± = 0.05, we have statistical evidence to
reject H0 : Œ£ = Ip and H0 : Œ£ = ŒªIp with all the considered tests.
     Therefore, we conclude that the population covariance matrix of the data has
not these structures. As in the last example, this conclusion was expected, because
it is known that there exists correlation between the genes of the same individual.


                  Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data              395

  Table 11: Values of the test statistics for H0 : Œ£ = Ip considering the NCI60 data.
                            Test   Value of the test statistic
                            LW              188.7283
                            TW              676.3819
                             T2s            2491.531
                             T2             2459.416
                            CM              514277.4

 Table 12: Values of the test statistics for H0 : Œ£ = ŒªIp considering the NCI60 data.
                            Test    Value of the test statistic
                             J               315.2971
                           QLRT              2988.593
                             T1s             6417.741
                             T1              6334.869
                              Z              176.9723



6. Conclusions


    In this work we studied tests for the covariance matrix of multivariate Gaussian
data. Our main interest was the case when the dimension of the data is greater
than or equal to the sample size (high dimensional case), however we also studied
tests for the case when the sample size is greater than the dimension of the data
(classical case). We considered the null hypotheses H0 : Œ£ = Ip and H0 : Œ£ = ŒªIp .
    The simulation study of this work to analyze the behavior of the tests for
H0 : Œ£ = Ip , indicates that in the considered settings, for the classical case (p < n)
and the high dimensional case (p ‚â• n), the tests TW, CLRT, LW, CM, T2s and
T2 have a good behavior in terms of the size of the test, since the empirical sizes
were very close to the considered signicance level. For the case p < n, LRT1
had empirical sizes far away from the considered signicance level when p was
close to n, and the empirical sizes of CLRT have a better behavior than those
of LRT1 . In terms of the power of the test, the TW test was superior to the
other considered tests. Despite the empirical powers of the tests CLRT, LW, CM,
T2s and T2 are smaller than that of TW, these tests are good alternatives for the
considered settings. It is important to mention that although in some cases LRT1
had empirical power bigger than the corresponding to the TW test, this test is
not recommendable in those cases, since it has a bad behavior in terms of the size
of the test. Therefore, for the considered settings, the TW test is a very good
alternative for testing H0 : Œ£ = Ip , in both cases, p < n and p ‚â• n, since it had
good results in terms of size and power of the test.
    The simulations to evaluate the tests for H0 : Œ£ = ŒªIp , indicated that in
the considered settings, for the classical and the high dimensional cases, the tests
J, T1s , T1 and Z have a good behavior in terms of the size of the test, since
the empirical sizes were very close to the considered signicance level. Whereas,
LRT2 and QLRT in some cases had empirical sizes far away from the considered
signicance level. LRT2 had a good behavior only when n is large enough with


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

396                                        Didier Cortez-Elizalde & Addy Bolivar-Cime

respect to p, and QLRT had a good behavior only when p is large enough with
respect to n. The empirical powers of the tests J, T1s , T1 and Z had a good
behavior for both cases, p < n and p ‚â• n. The empirical powers of LRT1 and
QLRT in some cases were bigger than the corresponding to the other considered
tests, however they had a bad behavior in terms of the size of the test, thus they
are not recommendable in those cases. Therefore, for the considered settings, the
tests J, T1s , T1 and Z are very good alternatives for testing H0 : Œ£ = ŒªIp in both
cases, p < n and p ‚â• n, since they had good results in terms of size and power of
the test.
    The results obtained in this work are useful to have a better knowledge of the
behavior of several tests of the literature for the covariance matrix of multivariate
Gaussian data, by comparing the tests simultaneously in terms of size and power
of the test.
   On the other hand, we applied the tests to real data found in the literature.
For the examples of application we considered two sets of DNA microarray data,
and with all the tests we rejected the two null hypotheses H0 : Œ£ = Ip and
H0 : Œ£ = ŒªIp , considering the signicance level Œ± = 0.05. Therefore, we concluded
that the covariance matrices of these datasets are not equal nor proportional to
the identity matrix. This conclusion was expected, since it is well known that
there exist high correlations between the genes of the same individual. These
examples show the usefulness of the considered tests to analyze the structure of
the covariance matrix of DNA microarray data.


Acknowledgments

   The authors thank the Editor and the anonymous reviewers for their comments
and valuable suggestions, which helped greatly to improve this manuscript.
               
                Received: September 2021  Accepted: May 2022
References

Anderson, T. W. (1984), An Introduction to Multivariate Statistical Analysis, John Wiley & Sons, Inc.
Bai, Z., Jiang, D., Yao, J. F. & Zheng, S. (2009), `Corrections to LRT on large-dimensional covariance matrix by RMT', The Annals of Statistics 37(6B), 3822- 3840.
Cai, T. T. & Ma, Z. (2013), `Optimal hypothesis testing for high dimensional covariance matrices', Bernoulli 19(5B), 2359-2388.
Chen, S. X., Zhang, L.-X. & Zhong, P.-S. (2010), `Tests for high-dimensional covariance matrices', Journal of the American Statistical Association 105(490), 810-819.
Cortez-Elizalde, D. (2020), Pruebas de hip√≥tesis para la matriz de covarianza poblacional de datos de dimensi√≥n alta, Tesis de Maestr√≠a, Universidad Ju√°rez Aut√≥noma de Tabasco, Divisi√≥n Acad√©mica de Ciencias B√°sicas, Cunduac√°n, M√©xico.
Hallin, M. & Paindaveine, D. (2006), `Semiparametrically ecient rank-based inference for shape. i. optimal rank-based tests for sphericity', The annals of statistics 34(6), 2707-2756.
Hastie, T., Tibshirani, R. & Friedman, J. H. (2009), Elements of statistical learning: data mining, inference, and prediction, Springer.
John, S. (1971), `Some optimal multivariate tests', Biometrika 58(1), 123-127.
John, S. (1972), `The distribution of a statistic used for testing sphericity of normal distributions', Biometrika 59(1), 169-173.
Johnstone, I. M. (2001), `On the Distribution of the Largest Eigenvalue in Principal Components Analysis', The Annals of Statistics 29(2), 295-327.
Ledoit, O. & Wolf, M. (2002), `Some hypothesis tests for the covariance matrix when the dimension is large compared to the sample size', The Annals of Statistics 30(4), 1081-1102.
Li, Z. & Yao, J. (2016), `Testing the sphericity of a covariance matrix when the dimension is much larger than the sample size', Electronic Journal of Statistics 10(2), 2973-3010.
Ma, Z. (2012), `Accuracy of the tracy-widom limits for the extreme eigenvalues in white wishart matrices', Bernoulli 18(1), 322-359.
Muirhead, R. J. (2005), Aspects of Multivariate Statistical Theory, John Wiley & Sons, Inc.
Nagao, H. (1973), `On some test criteria for covariance matrix', The Annals of Statistics (1), 700-709.
Rosenwald, A., Wright, G., Chan, W. C., Connors, J. M., Campo, E., Fisher, R. I. & et al. (2002), `The use of molecular proling to predict survival after chemotherapy for diuse large-B-cell lymphoma', New England Journal of Medicine 346(25), 1937-1947.
Ross, D. T., Scherf, U., Eisen, M. B., Perou, C. M., Rees, C., Spellman, P. & et al. (2000), `Systematic variation in gene expression patterns in human cancer cell lines', Nature genetics 24(3), 227-235.
Srivastava, M. S. (2005), `Some tests concerning the covariance matrix in high dimensional data', Journal of the Japan Statistical Society 35(2), 251-272.
Srivastava, M. S., Yanagihara, H. & Kubokawa, T. (2014), `Tests for covariance matrices in high dimension with less sample size', Journal of Multivariate Analysis 130, 289-309.
Zou, C., Peng, L., Feng, L. & Wang, Z. (2014), `Multivariate sign-based high- dimensional tests for sphericity', Biometrika 101(1), 229-236.



Appendix A. Details of the Simulations


Transformation of Multivariate Normal Data

    By Anderson (1984, pp. 76), if X1 , X2 , . . . , XN is a random sample from the
Np (¬µ, Œ£), we can obtain from it a random sample Z1 , Z2 , . . . , Zn , with n = N ‚àí 1,
         Np (0, Œ£), such that the sample covariance matrix of the Xi 's, Sn , satises
from the P
            n
            i=1 Zi Zi . The procedure to obtain the new random sample is the
                    ‚Ä≤
nSn =
following:

  1. Take an N ‚àö√ó N ‚àö  orthogonal ‚àömatrix B = (bi,j ) with the last row equal to
     A = (1/ N , 1/ N , . . . , 1/ N )‚Ä≤ . To do this, let C = [e1 e2 ¬∑ ¬∑ ¬∑ eN ‚àí1 ]
      ‚Ä≤

     be the matrix whose j -th column is the p-dimensional unit vector ej , with
     one in the j -th entry and zeros in the rest, for j = 1, 2, . . . , N ‚àí 1. Dene
     D = C ‚àíAA‚Ä≤ C and E = OŒõ‚àí1/2 , where O is an (N ‚àí1)√ó(N ‚àí1) orthogonal
     matrix and Œõ is a (N ‚àí 1) √ó (N ‚àí 1) diagonal matrix such that D‚Ä≤ D = OŒõO‚Ä≤ .
     Dene B e = DE . Then the matrix
                                           " #
                                             e‚Ä≤
                                             B
                                      B=
                                             A‚Ä≤

     is an N √ó N orthogonal matrix with the last row equal to A‚Ä≤ .
                      PN
  2. Dene Zi =        j=1 bi,j Xj , for j = 1, 2, . . . , N .  Then the Zi 's are
     independent, Z1‚àö, Z1 , . . . , ZN ‚àí1 have distribution Np (0, Œ£) and ZN has
                                                        Pn
     distribution Np ( N ¬µ, Œ£). Furthermore, nSn = i=1 Zi Zi‚Ä≤ .


Algorithms for the Simulations

   Now we present the general ideas of the algorithms used on the simulations to
compute the empirical sizes and empirical powers of the tests.
    Consider the tests for the hypothesis testing problem (1) (or (2)). For specic
values of n and p, the following algorithm was used to compute the empirical sizes
of the tests.
Algorithm 1. (Empirical sizes of the tests)


  1. Generate a random sample of size N = n + 1 from the p-variate standard
     normal distribution.

  2. For the tests that consider random samples from the Np (¬µ, Œ£), compute the
     test statistics with the original data. For the tests that consider random


                   Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

Behavior of Some Tests for the Covariance Matrix of High Dimensional Data                 399

      samples from the Np (0, Œ£), transform the original data to a random sample
      of size n = N ‚àí 1 from the Np (0, Œ£), as described in the previous section,
      then compute the test statistics with the new random sample.

   3. Taking the signicance level Œ± = 0.05, record for each test whether the null
      hypothesis was rejected.

   4. Repeat the last steps M = 10, 000 times, and take the proportion of times
      that each test was rejected. These proportions are the empirical sizes of the
      tests.

   As mentioned before, to evaluate the power of the tests we considered
covariance matrices of the form

                                         Œ£ = Ip + hvv ‚Ä≤ ,                                (18)

where h is a positive scalar and v is a unit vector. The vector v is randomly
generated and the scalar h varies in a range of values, say, in the interval [0, r], for
some r > 0. For specic values of n, p and r, the following algorithm was used to
compute the empirical powers of the tests.
Algorithm 2. (Empirical powers of the tests)


   1. Generate a random vector from the p-variate standard normal distribution,
      then compute its norm and divide by it each entry of the vector. Call the
      resulting unit vector ve.

   2. Let h = (h1 , h2 , . . . , h5 )‚Ä≤ , where hi = i ‚àó r/5, for i = 1, 2, . . . , 5.

   3. For i = 1, generate a random sample of size N = n + 1 from the p-variate
      normal distribution with zero mean and covariance matrix (18), with v = ve
      and h = hi .

   4. For the tests that consider random samples from the Np (¬µ, Œ£), compute the
      test statistics with the original data. For the tests that consider random
      samples from the Np (0, Œ£), transform the original data to a random sample
      of size n = N ‚àí 1 from the Np (0, Œ£), as described in the previous section,
      then compute the test statistics with the new random sample.

   5. Taking the signicance level Œ± = 0.05, record for each test whether the null
      hypothesis was rejected.

   6. Repeat M = 10, 000 times the steps 3-5, and take the proportion of times
      that each test was rejected. These proportions are the empirical powers of
      the tests for the covariance matrix (18), with v = ve and h = hi .

   7. For i = 2, 3, 4, 5, repeat the steps 3-6 to obtain the empirical powers of the
      tests for the covariance matrix (18), with v = ve and h = hi , for i = 2, 3, 4, 5.




                      Revista Colombiana de Estad√≠stica - Applied Statistics 45 (2022) 373-399

