Nonparametric Prediction for Spatial Dependent Functional Data Under Fixed Sampling Design. Predicci√≥n no param√©trica para datos funcionales dependientes del espacio bajo un dise√±o de muestreo jo
Cheikh Anta Diop University (UCAD), Dakar, Senegal. University of Lille, Villeneuve d'ascq, France. Cheikh Anta Diop University, Dakar, Senegal
Abstract
In this work, we consider a nonparametric prediction of a spatio-functional process observed under a non-random sampling design. The proposed predictor is based on functional regression and depends on two kernels, one of which controls the spatial structure and the other measures the proximity between the functional observations. It can be considered, in particular, as a supervised classication method when the variable of interest belongs to a predened discrete nite set. The mean square error and almost complete (or sure) convergence are obtained when the sample considered is a locally stationary Œ±-mixture sequence. Numerical studies were performed to illustrate the behavior of the proposed predictor. The nite sample properties based on simulated data show that the proposed prediction method outperforms the classical predictor which not taking into account the spatial structure.
Key words : Functional dependent data; Fixed design; Non-parametric prediction; Supervised classication.
Resumen
En este trabajo consideramos una predicci√≥n no param√©trica de un proceso espacial y funcional observado bajo un dise√±o de muestreo no aleatorio. El predictor propuesto se basa en la regresi√≥n funcional y depende de dos n√∫cleos, uno de los cuales controla la estructura espacial y el otro mide la proximidad entre las observaciones funcionales. Esta metodolog√≠a puede considerarse, en particular, como una nueva herramienta de clasicaci√≥n supervisada cuando la variable de inter√©s pertenece a un conjunto nito discreto predenido. El error cuadr√°tico medio y la convergencia casi completa (o certera) se obtienen cuando la muestra considerada es una secuencia Œ±-mixta localmente estacionaria. Adem√°s, en este estudio se han realizado estudios num√©ricos para ilustrar el comportamiento de nuestro predictor. Esta aplicaci√≥n mediante simulaci√≥n de un modelo num√©rico muestra que el m√©todo de predicci√≥n propuesto supera al predictor cl√°sico que no tiene en cuenta la estructura espacial.
Palabras clave : Clasicaci√≥n supervisada; Datos funcionales dependientes; Dise√±o jo; Predicci√≥n no param√©trica.



1. Introduction
      Functional data analysis (FDA) deals with the analysis and theory of data that
are in the form of functions, curves, images and shapes, or more general complex
objects (Wang et al., 2016).

      In the last decade, FDA has undergone a large development in a wide variety
of elds such as ecology, Embling et al. (2012),Yen et al. (2014),Yan et al.
(2015),Yates et al. (2021);       medicine, S√∏rensen et al. (2013), Oshinubi et al.
(2022), Wu & Li (2022) or environmental sciences, Giraldo et al. (2011), Torres
et al. (2011), Dabo-Niang et al. (2010); monitoring networks of the weather and
pollutants see Escabias et al. (2005), Ignaccolo et al. (2013), among others. It has
been applied, for modeling purposes, in many areas that require spatial statistics;
a branch of mathematics that studies spatially dependent processes.

      Functional data can be recored both in temporal and in spatial setting. The
analysis of processing of spatially distributed information that is measured, in
continuously way, in time or in space/space-time uses functional modeling.                  It
have contributed to the development of new mathematical theories in functional
statistics; with the emergence of continuous and spatially dependent data.                  It
gave birth to a branch of mathematics which is a combination of spatial statistics
and functional statistics.     Indeed, Ruiz-Medina (2011) recognizes the necessity
of new developments in spatial correlated functional data and extends the real-
valued spatial autoregressive model and the spatial moving average model to
stochastic processes taking values in Hilbert spaces.           The dimension reduction
methodology based on eigenfunctions basis of the auto-covariance operator has
been used in Ruiz-Medina M (2012) and Ruiz-Medina et al. (2015). FDA applies
tools on multivariate spatial statistics to address questions about prediction at
un-sampled locations, classifying spatial curves with unsupervised classication
methods or/and discrimination rules, estimating relationships between a primary
variable and independent variables.

      They are many situations in which one may wish to study the link between
two variables, with the main goal is to able to predict new values of one of them,
or classify it in   k -given homogenous groups inside of each one.            For example,



                    Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                        393



in marine biology, it is interesting to see the eect of the environment or other
ecology parameter to the variability of biomass and spatial distribution of one
specie or a group of species in marine wildlife fauna. In many ecological studies,
counts or biomass of interacting species are collected from several sites. Such data
are often very sparse, high-dimensional and include highly correlated responses,
and the main aim of the statistical analysis is to understand relationships among
such multiple, correlated responses Niku et al. (2019), Niku et al. (2021).               In
Environmental & socio-economic studies,           some aquatic species are useful as
indicators to study ecosystem health and habitat quality.              Amphibian species
have been considered as useful ecological indicators.         Soltysiak et al. (2016) use
a Machine-learning methods in the classication of water bodies. The later use
Amphibian species as indicators of environmental contamination. In ecosystemic
approach, better understanding interaction between species and environment helps
to monitoring sheries in the context of climate change.

   In oil research, we can be interested in the prediction of the physical parameters
of oil layers by taking into account other parameters available in oil elds Baouche
(2015).   The explanatory relationship between variables (response variable and
co-variables) is widely studied, in prediction and classication problems, using
classical FDA methods.       Functional analysis in spatial statistics thus makes it
possible to build, among other things, regression, prediction and classication
methods, see Ferraty & Vieu (2006), Mateu & Romano (2017), Cuesta-Albertos
et al. (2017), Li et al. (2018), Ballari et al. (2018), Chen et al. (2019), among others.
However, this study is relatively limited from a theoretical and practical point of
view.   In addition, it relates, in large part, to parametric/and semi-parametric
models Menafoglio et al. (2013), Zhang (2019), Menafoglio (2021), Menafoglio
et al. (2022). The high intrinsic dimensionality of these data poses challenges both
for theory and computation, that vary with how the functional data were sampled.
This means that parametric/and semi-parametric models are not suitable in this
new spatio-functional context. Therefore, the modeling of these complex problems
uses non-parametric regression models as alternative methods especially when the
relationship between the two variables of interest is not linear.

   Nonparametric prediction problem, in the spatial setting, has been widely
studied in the literature when variables are of nite dimension Dabo-Niang et al.
(2016).

   During the rst half of the 20th century, spatial prediction was widely studied
in the scope of geostatistics, commonly known as Kriging. The latter is a spatial
linear interpolation method Cressie (1993). Krigging has been applied to a various
number of areas including marine biology to evaluate sh abundances Rivoirard
et al. (2000).   Other methods have also been applied such as K-function Ripley
(1987), Heppell et al. (1999), Gardner et al. (2008), Lefort et al. (2011), SDMs
model using conventional statistical methods as Generalized linear models and
Generalized additive models Young & Carr (2015), Luan et al. (2018), Pollock
et al. (2014).

   Nowadays there is a dynamic on the development of non-parametric methods
for spatial prediction and classication.       The rst results in this direction are



                   Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

394                                       Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

those of Biau and Cadre Biau & Cadre (2004), on kernel prediction of a strictly
                                               ‚àó N
stationary random eld indexed in (N )               . Later, Dabo-Niang & Yao (2007) have
contributed to Biau and Cadre's              Biau & Cadre (2004) investigation since they
were interested in kernel regression estimation and prediction for continuously
indexed strictly stationary random elds.               In Dabo-Niang et al. (2016), non-
parametric prediction for spatial multivariate setting is considered.                   The latter
deals with xed design and controls the geographic proximity of the spatial
sites.   In Menezes et al. (2010), non-parametric kernel prediction is considered
for spatial stochastic processes when a stochastic sampling design is assumed for
the sample locations. In Rachdi et al. (2021) two main aspects of the statistical
analysis, namely the parametric and nonparametric approaches are considered to
construct and compare four estimators of the regression quantile. Precisely, using
a parametric approach, they construct two estimators that are based respectively
on the B-spline smoothing and the PCA regression. The other two estimators are
constructed using a non-parametric approach, namely the local constants method
and the local linear method.             Then, they establish the asymptotic properties of
the four constructed estimators. Ternynck (2014) considered a functional spatial
regression model estimated for strict stationary processes using a kernel method
accounting the spatial proximity of locations.

      Discrimination kernel rule has been investigated extensively in the literature
particularly for independent or time-series data Paredes & Vidal (2006), Devroye
et al. (1994), Devroye & Wagner (1982), Hastie & Tibshirani (1996) among
others, see the monograph of Biau & Devroye (2015) for more details. Recently,
Younso (2017) has addressed a discrimination kernel rule for multivariate strictly
stationary spatial processes         (Xi ‚àà Rd )i‚ààNN       and binary spatial classes        (Yi ‚àà
{0, 1})i‚ààNN .     Ahmed       et   al.   (2019)   proposed   a   spatial   k -nearest   neighbors
classication rule for multivariate data.

      In the functional context, Ferraty & Vieu (2006) investigated a non-parametric
prediction and a discrimination kernel rule for independent data and dependent
non-spatial data.       In Cuevas et al. (2007) and Cuesta-Albertos et al. (2017) a
DDG -classication and a Depth classication rules are proposed.                    In Xiaoying
et al. (2021), a classication of functional data is discussed. Firstly, it preprocesses
the abnormal curve based on the centrality and externality of the functional data
depth; then combines the functional data non-parametric classication method
to calculate the posterior probability value of the given curve belonging to each
category, and classify the unknown curve according to the principle of maximum
posterior probability, see Xiaoying et al. (2021).
                  1
      In this work , we extend the regression estimate of Ternynck (2014) to a non-
strictly stationary sequences and establish the uniform convergence, in addition
we investigate a kernel classication rule.            Namely, our aim is to propose both
kernel method spatial prediction and, in particular, a supervised classication
approach in a spatio-functional setting.               The propoed model is based on the
fact that the response variable of interest is real-valued while the covariate is
functional nature. The sample used comes from to a spatial sequence locally and

   1 this come from chapter 4 of this thesis Ndiaye et al. (2020)



                      Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                        395



identically distributed, contrary to that used in the work of Ternynck (2014). The
originality of the suggested method takes advantages of that previously considered
by Ternynck (2014), Dabo-Niang et al. (2014), in a more general context. In fact,
the present contribution goes along the direction of spatial proximity structure
into a kernel predictor and takes advantages of these previous works Francisco-
Fernandez & Opsomer (2005), Francisco-Fern√°ndez et al. (2012), Dabo-Niang et al.
(2014), Ternynck (2014).




2. Regression Model and Predictor
                                                                               N
   Denote the integer lattice points in the N -dimensional Euclidean space by Z ,
N ‚â• 1. We consider a spatial process {Zi = (Xi , Yi ), i ‚àà ZN } dened over some
probability space (‚Ñ¶, F, P).

   A point in bold i    = (i1 , . . . , iN ) ‚àà ZN will be referred as a site. Suppose
Xi takes values in a separable semi-metric space (E, d(¬∑, ¬∑)) (of eventually innite
dimension) (i.e. Xi is a functional random variable and d(., .) a semi-metric) and
Yi takes values in R. In the following, ‚à•¬∑‚à• will denote any norm in Rd or RN (there
                                                 N                       ‚Ä≤
will be no ambiguity since the vectors of R        are in bold), C and C will indicate
some arbitrary positive constants that may vary from line to line, for each real u,
‚åäu‚åã will indicate the integer part of u. Moreover, we write un = O(vn ) means that
‚àÉ C such that |un /vn | ‚â§ C as vn ‚Üí ‚àû and un = o(vn ) means that |un /vn | ‚Üí 0 as
vn ‚Üí ‚àû, where n ‚àà RN .
   As it is classically assumed in the literature, the process under study {Zi } is ob-
servable over the rectangular domain In = {i = (i1 , . . . , iN ), 1 ‚â§ ik ‚â§ nk , k = 1, . . . , N },
where a point    i ‚àà ZN refers to a site. Let n = (n1 , . . . , nN ) and pose
b = n1 √ó ¬∑ ¬∑ ¬∑ √ó nN , the sample size. From now on, we assume, for seek of
n
simplicity, that n1 = n2 = . . . = nN = n El Machkouri (2007), El Machkouri
& Stoica (2010), El Machkouri (2011), but the following results can be extended
to a more general framework. We write n ‚Üí ‚àû if n ‚Üí ‚àû. For each site i0 , let
             P
kn = kn,i0 = 1[‚à•i‚àíi ‚â§d ‚à•] denote the number of neighbors i for which the distance
                     0 n
between i0 is less than or equal to distance dn > 0 such that dn ‚Üí ‚àû as n ‚Üí ‚àû.
This last assumes the proximity between locations (eventually) increases as the
sample size increases.

   We do not suppose strict stationarity.           We will assume that the variables
(Xi , Yi )i‚ààIn are locally identically distributed (see for instance Klemel√§ (2008) who
considered density estimation for locally identically time-series data): a sucient
number of (Xi , Yi ) has a distribution close to that of a couple (X, Y ).

                                                                   N
   The main goal is to predict the spatial process {Yi , i ‚àà Z         } in some unobserved
locations, particularly at an unobserved site i0 ‚àà In under the information that
can be drawn on Xi0 and observations (Xi , Yi )i‚ààOn , where On is the observed
spatial set of nite cardinality tending to ‚àû as n ‚Üí +‚àû and contained in In ,
        / On . Let (Xi0 , Yi0 ) be of same distribution as (X, Y )).
with i0 ‚àà



                   Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

396                                      Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

    One may imagine that when i is close to some i0 , and if there is enough sites
               / In , then sequence (Xi , Yi )i‚ààOn may be used to predict Yi0 , under
i closed to i0 ‚àà
the condition Xi0 = xi0 , denoted x in the following with abuse of notation.

      We suppose that the spatial process satises the following non-parametric
regression model:
                                          Yi := r(Xi ) + Œµi                               (1)

where r(.)   = E(Yi |Xi = .), is assumed to be independent of i, the noise Œµi is
centered, Œ±-mixing and independent of Xi . Let E|Yi | < ‚àû.
Let the following regression estimator where we assume that the observed region
On is the rectangular domain In :

                                           gn (x)
                                         Ô£±
                                         Ô£¥
                                         Ô£¥        , if fn (x) Ã∏= 0,
                                         Ô£≤ fn (x)
                                         Ô£¥
                                         Ô£¥
                           rn (x) =                                                       (2)
                                         Ô£¥ 1 X
                                               Yi otherwise,
                                         Ô£¥
                                         Ô£¥
                                         Ô£¥
                                         Ô£≥ n
                                           b
                                               i‚ààOn

where the functions fn and gn are dened, respectively, by

                                                             
                               1 X                d(x, Xi )
                   fn (x) =        K1                             K2,œÅn (‚à•i0 ‚àí i‚à•) ,
                              an                     bn
                                   i‚ààOn

and                                                           
                             1 X                   d(x, Xi )
                   gn (x) =      Yi K1                             K2,œÅn (‚à•i0 ‚àí i‚à•) ,
                            an                        bn
                                  i‚ààOn
                                                  -
             X                            d(x, Xi )
with an =      K2,œÅn (‚à•i0 ‚àí i‚à•) E K1                   ,
                                             bn
          i‚ààOn                                              
                               ‚à•(i0 ‚àíi)/n‚à•
                                             = K2 ‚à•inœÅ   0 ‚àíi‚à•   i     i1 i2      iN
                                                                                      
where K2,œÅn (‚à•i0 ‚àí i‚à•) = K2
                                    œÅn                      n    n = ( n , n , ... n ) , bn
and œÅn are bandwidths tending to zero; K1 and K2 are kernels, dened in
hypothesis   H1.
                                                        N
      Hereinafter, we assume that kn = CN dn                + O(dŒ≤n ) as dn ‚Üí +‚àû, 0 < Œ≤ < N
and CN is a constant that depends on N .

    Taking the Euclidean distance and if N = 2 (square grid), we have kn ‚â§
                                               nœÅ2n ).
4d2n ‚àí 4dn + 4 which leads to kn = O(d2n ) = O(b
      Recall that the main application of the above regression estimate is the
prediction of the unobserved value Yi0 at a location i0 using a sucient number of
observations (Xi , Yi ) available at neighbor locations. For that, let the sample set
                                                                         ‚ôØ        ‚ôØ
of sites be On = In \ {i0 }, with optimal bandwidths bn and œÅn (detailed in the
prediction procedure of Section 5). The predictor is dened as:

                                                    
                              P             d(x,Xi )
                              i‚ààOn Yi K 1        ‚ôØ     K2,œÅ‚ôØn (‚à•i0 ‚àí i‚à•)
                     Ybi‚ôØ0 = P           bn                            ,                (3)
                                          d(x,Xi )
                                    K 1        ‚ôØ      K    ‚ôØ (‚à•i0 ‚àí i‚à•)
                               i‚ààOn          b      n
                                                        2,œÅn



                    Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                           397



if the denominator is not null otherwise the predictor is equal to the empirical
mean. The accuracy of (3) will be compared with the following one that does not
take into account the spatial structure:
                                                                    
                                      P                   d(x,Xi )
                                         i‚ààOn Yi K1         b‚ãÜ
                               Ybi‚ãÜ0 = P                    n
                                                                    ,                      (4)
                                                        d(x,Xi )
                                          i‚ààOn K1         b‚ãÜ
                                                           n

       ‚ãÜ
with bn an optimal bandwidth detailed in Section 5.1.
Remark that equation (4) is based on the classical non-parametric regression
estimator Dabo-Niang et al. (2011) without the second kernel on the locations.
                                                                
                                        P               d(x,Xi )
                                          i‚ààOn Yi K 1     bn
                              rncl (x) = P                     .                          (5)
                                                      d(x,Xi )
                                           i‚ààOn K 1      bn



3. Large Sample Properties and Assumptions
     We rst introduce some mixing assumptions. In fact, to take into account the
                                                                                N
spatial dependency, we assume that the process {Zi = (Xi , Yi ), i ‚àà Z              } satises a
mixing condition dened in Carbon et al. (1997) as follows: there exists a function
œá(t) ‚Üò 0 as t ‚Üí ‚àû, such that
      Œ±(œÉ(S), œÉ(S ‚Ä≤ ))    =   sup{|P(A ‚à© B) ‚àí P(A)P(B)|, A ‚àà œÉ(S), B ‚àà œÉ(S ‚Ä≤ )},
                          ‚â§ œà(Card(S), Card(S ‚Ä≤ ))œá(dist(S, S ‚Ä≤ )),
                 ‚Ä≤
where dist(S, S ) is the Euclidean distance between the two nite sets of sites S
       ‚Ä≤
and S , Card(S) denotes the cardinality of the set S , œÉ(S) (resp.             œÉ(S ‚Ä≤ )) denotes
the œÉ -elds generated by {Zi , i ‚àà S} (resp.           {Zi , i ‚àà S ‚Ä≤ }) and œà(¬∑) is a positive
symmetric function nondecreasing in each variable. We recall that the process is
said to be strongly mixing if œà ‚â° 1. As usual, we will assume that one of both
following conditions on œá(i) is veried. These conditions are dened by

                              œá(i) ‚â§      Ci‚àíŒ∏ , for some Œ∏ > 0,                            (6)

i.e. that œá(i) tends to zero at a polynomial rate, or

                          œá(i) ‚â§ C exp(‚àísi), for some s > 0,                                (7)

i.e. that œá(i) tends to zero at an exponential rate. Concerning the function œá(¬∑),
for the sake of simplicity, we will only study the case where œá(¬∑) tends to zero
at a polynomial rate. However, similar asymptotic results may be obtained with
œá(¬∑) tending to zero at an exponential rate (which implies the polynomial case).
Throughout the paper, it will be assumed that œà satises either

                         ‚àÄn, m ‚àà N,    œà(n, m) ‚â§ C min(n, m),                               (8)

or

                              œà(n, m) ‚â§ C(n + m + 1)Œ∫                                       (9)



                     Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

398                                            Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

for some C               > 0, and some Œ∫ ‚â• 1.             Such functions œà(n, m) can be found, for
instance, in Tran (1990), Carbon et al. (1997), Hallin et al. (2004), Biau & Cadre
(2004), Dabo-Niang & Yao (2013).
                         QN                             1+Œµ
                                                                                P
      Let un =             i=1 (log ni )(log log ni )         for Œµ > 0, then     n‚ààN 1/nÃÇun < ‚àû.
      We will denote by pi the probability distribution of Xi and by pi,j the joint
probability distribution of (Xi , Xj ), for all i and j.                   The small ball probabilities
are denoted by œÜi,x (bn ) = P[Xi ‚àà B(x, bn )], with œÜi,x (bn ) tending to zero when bn
goes to zero (see e.g. Ferraty & Vieu (2006) for more details).

      For any real-valued random variable                       Z and integer p ‚àà N‚àó , let ‚à•Z‚à•p =
        p      1/p
(E [|Z| ])           .

The mean square consistency result of                            rn   is obtained under the following
assumptions on r , the kernel, the bandwidth and local dependence condition.


H1:         ¬à K1 is dened from R+ to R+ , and we assume that there exist two
              constants C11 and C12 with 0 < C11 < C12 < ‚àû, such that

                                         C11 I[0,1] (t) ‚â§ K1 (t) ‚â§ C12 I[0,1] (t).

            ¬à K2 is a bounded nonnegative function dened from R+ to R+ , and we
              assume that there exist constants C21 , C22 and œÅ such that


                         C21 I{‚à•s‚à•‚â§œÅ} ‚â§ K2 (‚à• s ‚à•) ‚â§ C22 I{‚à•s‚à•‚â§œÅ} , ‚àÄ s ‚àà RN ,
                                                                      0 < C21 ‚â§ C22 < ‚àû, œÅ > 0.      (10)


H2: r is a Lipschitz function, that is r ‚àà LipE where
                                              ‚Ä≤                     ‚Ä≤              ‚Ä≤
        LipE = {f : E ‚Üí R, ‚àÉ C3 ‚àà R+                2
                                   ‚àó , ‚àÄ (x, x ) ‚àà E , |f (x) ‚àí f (x )| < C3 d(x, x )}.

H3: (i) Local dependence condition: For all i Ã∏= j ‚àà NN , i, j ‚àà Vi the joint                    0
        probability distribution pi,j of Xi and Xj satises

                                                                                               1+Œµ
                ‚àÉ Œµ ‚àà (0, 1], pi,j (B(x, bn ) √ó B(x, bn )) ‚â§ C4 (œÜi,x (bn )œÜj,x (bn )) 2 ,
                                                                                i‚àíi0
        for some constant C4 > 0, where Vi0 = {i ‚àà On , ‚à•
                                                                                 n ‚à• < œÅn }.
        (ii) Small ball probabilities: For all i and x, there exist a function
        œÜx (h) > 0 tending to zero as h goes to zero such that
                                            sup |œÜi,x (h) ‚àí œÜx (h)| = o(1).
                                           i‚ààVi0

Remark         1.        These assumptions are standard in the context of spatial non-
parametric modeling.                  Indeed, Assumptions       H1 and H2 allow to control the
bias of the estimator.                  Assumption        H1 is satised, for instance, by several
kernels with compact support such as triangular (Bartlett), biweight, triweight,
Epanechnikov, Parzen kernels. The Lipschitz condition                       H2 allows to obtain rate of
convergence whereas a continuity-type model would give only convergence results.
Local dependence condition                 H3(i) is a classical condition in kernel estimation of
dependent sequences non-necessarily strictly stationary (Bosq, 1998; Carbon et al.,
1997; Masry, 2005).



                              Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                                      399



In order to control the constraints on the bandwidth sequence due to the mixing
coecients with polynomial decreasing rate (6), we dene

                                     2N ‚àí Œ∏      ‚àó       N ‚àíŒ∏
                            Œ≥1 =            and Œ≥1 =                .
                                     4N ‚àí Œ∏          N (3 + 2Œ∫) ‚àí Œ∏
The following result gives a bound of the mean squared error of rn

Theorem 1. Assume that assumptions H1-H3 hold with |Yi | ‚â§ M .
  1. If (8) is satised and

                       b œÅN
                       n            Œ≥1 N Œ≥ 1
                          n œÜx (bn ) œÅn           b )‚àíŒ≥1 ‚Üí ‚àû with Œ∏ > 4N,
                                             (log n

      or
  2. if (9) is satised and
                                 ‚àó    N Œ≥‚àó           ‚àó
                  b œÅN
                  n            Œ≥1
                     n œÜx (bn ) œÅn
                                   1
                                          b )‚àíŒ≥1 ‚Üí ‚àû with Œ∏ > (3 + 2Œ∫)N,
                                     (log n

      then
                                                               s                    !
                                                                         1
                           ‚à•rn (x) ‚àí r(x)‚à•2        = O bn +            N
                                                                                        .
                                                                    b œÅn œÜx (bn )
                                                                    n

Precisely, we have

   ‚à•rn (x) ‚àí r(x)‚à•2                                        =
                                                      ‚àö     q
                C 3 √ó bn    + 2C(2M C22 + 2M C4 + C0 ) + 4M √ó nbœÅN œÜ1x (bn ) ,
                                                                                            n


where C depends on N whereas C0 is a constant depending on the constant
appearing in Lemma 1.
Remark     2.    The    conditions      on   the   bandwidth   in    Theorem        1       are   technical
assumptions, which appear (in the proofs when studying the asymptotic behavior
of the estimator) in the particular case where the mixing coecient is such that œá
tends to zero at a polynomial rate, for some examples, see Neaderhouser (1980),
Rosenblatt (1985). Each of these conditions is related to a specic case of mixing in
the spatial context and are used respectively in Neaderhouser (1980) and Takahata
(1983).



3.1. Uniform Almost Complete Convergence
                                                   Svn
   We consider a set D such that D ‚äÇ                 k=1 Bk where Bk = B(xk , ‚Ñìn ) (note that
such set can always be built), vn > 0 is some integer, xk ‚àà E, k = 1, . . . , vn , and
‚Ñìn > 0. We assume that:

 H4 there exist Œìi (bn ) = supx‚ààD œÜi,x (bn ), Œì(bn ) = supx‚ààD œÜx (bn ) non increasing
      positive functions such that:



                       Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

400                                              Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

           (i)    limn‚Üí‚àû Œìi (bn ) = limn‚Üí‚àû Œì(bn ) = 0, and

                                                 sup |Œìi (bn ) ‚àí Œì(bn )| = o(1),
                                                 i‚ààVi0


                                b œÅN
                                n  n Œì(bn )
           (ii)   limn‚Üí‚àû           log n
                                       b    ‚Üí ‚àû,
        (iii)          b Œ≤ for some Œ≤ > 0.
                  vn = n

 H5 Local dependence condition: For and i Ã∏= j ‚àà NN , i, j ‚àà Vi , the joint                  0
        probability distribution pi,j of Xi and Xj satises


                  ‚àÉ Œµ ‚àà (0, 1], pi,j (B(x, bn ) √ó B(x, bn )) ‚â§ C3‚Ä≤‚Ä≤ (Œì(bn ))1+Œµ , for all x ‚àà D.

 H6 There exists s > 2 and C > 0 such that for i, j ‚àà Vi ,                   0

                                  s
           (i)    supi E (|Yi | | Xi ) < C ,
           (ii)   supi,j E (|Yi Yj | |Xi , Xj ) < C for some constant C > 0.

Let us introduce the following functions of the mixing coecient which is related
to the conditions on the bandwidth and the moment of the functional covariate:

                   2s(N ‚àí Œ∏)                        (Œ∏ ‚àí 2N )s
Œ∏1     =                            , Œ∏2 =                          ,
             2N s(Œ≤ + 2) + Œ∏(2 ‚àí s)          2N s(Œ≤ + 2) + Œ∏(2 ‚àí s)
                   2(N s + Œ∏)                           s(‚àíN ‚àí Œ∏)
Œ∏3     =                              Œ∏1‚àó =                                  ,
             2N s(Œ≤ + 2) + Œ∏(2 ‚àí s)         N (2sŒ≤ + 2sŒ∫ + s + 2) + Œ∏(2 ‚àí s)
                         s(Œ∏ ‚àí N )                                2(N + Œ∏)
Œ∏2‚àó    =                                         Œ∏3‚àó =                                  .
             N (2sŒ≤ + 2sŒ∫ + s + 2) + Œ∏(2 ‚àí s)          N (2sŒ≤ + 2sŒ∫ + s + 2) + Œ∏(2 ‚àí s)

      The following theorem gives an uniform almost sure convergence of the
regression estimate.


Theorem 2. Assume that assumptions H1-H6 hold.
  (i) If (8) is satised and

                  b Œì(bn )Œ∏1 œÅN
                  n           n
                                Œ∏1
                                        b )Œ∏2 uŒ∏n3 ‚Üí ‚àû with Œ∏ > 2N s(Œ≤ + 2)/ (s ‚àí 2) ,
                                   (log n                                                          (11)



 (ii) or if (9) is satised and
                     ‚àó   N Œ∏‚àó           ‚àó
                                            Œ∏‚àó
                             b )Œ∏2 un3 ‚Üí ‚àû with Œ∏ > N (2sŒ≤ + 2sŒ∫ + s + 2)/ (s ‚àí 2) , (12)
        b Œì(bn )Œ∏1 œÅn 1 (log n
        n

then
                                                                s                 !
                                                                       log n
                         sup |rn (x) ‚àí r(x)| = O bn +                                 a.s.
                                                                           b
                         x‚ààD                                        b œÅN
                                                                    n  n Œì(b n)



                          Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                       401



   Recall that Dabo-Niang et al. (2011) gave an uniform almost sure bound
                                                                        q        
                                                                           log n
of their regression estimate on a specic set           C that is O b‚ãÜn + Œì(b  b
                                                                             ‚ãÜ )b
                                                                                n   with
                                                                                n
Œì(b‚ãÜn ) = supœÜx (b‚ãÜn ) when the considered process is strictly stationary.
         x‚ààC

Corollary 1. Under the conditions of Theorem 2, one can derive an almost sure
consistency of the predictor,

                           Ybi0 ‚àí Yi0 ‚àí‚Üí 0         almost surely,                      (13)
                                      n‚Üí‚àû

where                                             
                           P              d(x,Xi )
                            i‚ààOn Yi K 1     bn       K2,œÅn (‚à•i0 ‚àí i‚à•)
                    Ybi0 = P                                        ,                (14)
                                        d(x,Xi )
                             i‚ààOn K1       bn       K2,œÅn (‚à•i0 ‚àí i‚à•)

is the predictor of Yi0 at a location i0 .


4. Application to Supervised Classication Issue
   The goal of supervised classication or discrimination is to predict a feature
Y lying in a discrete nite set {1, . . . , M }, with the help of a variable of interest
X . When M = 2, the problem becomes a binary classication. That may occur
when one want to model absence or presence of some phenomena, abundance or
not, specie overshing or not.     When M         > 2, we have categorical classication
problem. In a context of supervised classication, we aim to predict at a given
location, an unknown discrete variable Y given a functional observed variable X .
The unknown nature Y    is called a class, the functional variable X belongs to
(E, d(¬∑, ¬∑)).
Let i0 ‚àà In be the location where we want to predict the class using a sample
of spatial dependent observations (Xi , Yi )i‚ààOn , On ‚äÇ In \i0 . In the following,
we describe a non-parametric spatial functional classication rule.          This is done
through a kernel estimator derived from the regression estimate (2).

    General classication rule (Bayes rule): Given a function x at some station
i0 ‚àà In , namely x = Xi0 the purpose is to estimate the |M | posterior probabilities,

                       pj (x) = P (Y = j/X = x), j = 1, . . . , M.

Once that the |M | probabilities are estimated (b
                                                p1 (x), . . . , pbM (x)), the classication
rule consists of assigning an incoming functional observation x to the class with
highest estimated posterior probability:


                               yb(x) = arg      max         pbj (x).                   (15)
                                             j‚àà{1,...,M }


Remark that

                               pj (x) = E(1[Y =j] |X = x),                             (16)



                  Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

402                                  Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

with    1[Y =j] equals to 1, if Y = j and 0 elsewhere.                 Then, estimations of the
posterior probabilities can be expressed as:
                                                      X       ‚ôØ
                     pbn,j (x) = pbbn ,œÅn ,j (x) =           Wn,i0
                                                                   (x)1[Yi =j] ,            (17)
                                                     i‚ààOn

where                                                   
                                              d(x,Xi )
                                     K1         bn       K2,œÅn (‚à•i0 ‚àí i‚à•)
                   ‚ôØ
                  Wn,i0
                        (x) = P                                               .           (18)
                                                    d(x,Xi )
                                    i‚ààOn K1           bn       K2,œÅn (‚à•i0 ‚àí i‚à•)

      As explained in Ferraty & Vieu (2006),                  the discrimination problem can
be viewed as a prediction one since it is related to estimation of conditional
expectation of indicator variable (class). So, the asymptotic results stated in the
prediction setting remain valid in the discrimination context. Then we state the
following theorems; the rst gives the point-wise almost complete convergence of
the estimator of posterior probabilities whereas the second one gives the uniform
almost complete convergence.

Theorem 3. Under conditions of Theorem 1 and assumption on the continuity
on the model (i.e pj ‚àà LipE : see Ferraty & Vieu (2006) for this assumption), we
have, for j = 1, . . . , M ,
                                                   s               !
                                                          1
                   ‚à•b pn,j (x) ‚àí pj (x)‚à•2 = O bn +                   .      (19)
                                                     b œÅN
                                                     n  n œÜx (bn )

Theorem 4. Under assumptions of Theorem 2 and pj ‚àà LipE , see Ferraty &
Vieu (2006) for this assumption, we have, for j = 1, . . . , M ,
                                         s              !
                                              log n
        sup |b
             pn,j (x) ‚àí pj (x)| = O bn +                    , almost surely.
                                                  b
        x‚ààD                                b œÅN
                                           n  n Œì(bn )



5. Finite Sample Properties With Simulated Data
      In this section, we study the performance of the proposed predictor towards
some numerical experiment which highlight its importance.                           The proposed
predictor is compared with the classical kernel method which does not take into
account the spatial dependency (proximity between locations) proposed in the
strict stationary case Biau & Cadre (2004), Dabo-Niang & Yao (2007).                      Let us
rst describe the prediction procedure. It allows to compute optimal bandwidths
using leave one cross-validation approach based on the regression model ( 1 ).



5.1. Procedure of Prediction

      The choice of bandwidth (even in nite or innite dimensional setting) is a
crucial question in non-parametric estimation. We propose to choose the optimal
bandwidths using leave one cross-validation approach.



                  Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                            403



Step 1
Specify sets bandwidths S1 and S2 for respectively K1 and K2 .

Step 2
For each bn ‚àà S1 , œÅn ‚àà S2 and i0 ‚àà In , compute equation (2).

Step 3
                                       ‚ôØ        ‚ôØ
Compute optimal bandwidths bn and œÅn by applying a cross-validation procedure
over S1 and S2 . More precisely, consider the following minimization problem i.e
determine bn and œÅn that minimizing the mean squared error over the nÃÇ sites

                                           1 X b
                                    min       (Yi0 ‚àí Yi0 )2                                  (20)
                            bn ‚ààS1 ,œÅn ‚ààS2 nÃÇ
                                                 i0 ‚ààIn

                    ‚ôØ          ‚ôØ
and denote them bn and œÅn .
                                                                             ‚ãÜ
   The same procedure is applied to equation (5) for computing bn by replacing
rn (.) by rncl (.) in equation (20) minimizing with respect to S1 .
Step 4

   For each site i0 , predict Yi0 by:


   ¬à computing the proposed predictor Ybi‚ôØ0 using b‚ôØn and œÅ‚ôØn , see equation (3)

   ¬à computing Ybi‚ãÜ0 , the one that does not takes into account the spatial proximity,
            ‚ãÜ
     using bn , see equation (4)


   ¬à comparing Ybi‚ôØ0 and Ybi‚ãÜ0 , through their prediction errors respectively, using
      equation (25).



5.2. Simulations Studies

   In the following, we let N = 2, to illustrate our results, we have done some of
simulations based on observations (X(i,j) , Y(i,j) ), 0 ‚â§ i, j ‚â§ 25 such that ‚àÄ i, j,


                                    Y(i,j) = r(X(i,j) ) + Œµ(i,j)                             (21)

                                           = 4A2(i,j) + Œµ(i,j) ,                             (22)


and for t ‚àà [0, 1], X(i,j) (t) is dened according to the following model:


                                   Xi,j (t) = A2i,j ‚àó (t ‚àí 0.5)2 .                           (23)


Where A     = (Ai,j ) and Œµ = (Œµi,j ) are random variables which will be specied
later on.   Several curves examples of X(i,j) (t), are drawn on Figure           1(left down
                                                                     ‚Ä≤‚Ä≤              ‚Ä≤‚Ä≤
panel). An example of the function r(.) could be r(X) = 2X                (where f        denotes
the second derivatives of a function f ).

   The model (21) is simulated with spatial dependency structure.                Thereafter,
                           2
we denote by GRF (m, œÉ   , s) a stationary Gaussian random eld with mean m
                                             2        ‚à•h‚à•         2
and covariance function dened by C(h) = œÉ exp(‚àí(
                                                       s )), h ‚àà R and s > 0.


                  Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

404                                                        Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

1.0




                                                                                 0.015
                                                                  0.4
0.8




                                                                                 0.010
                                                                  0.2
0.6




                                                                          X(t)

                                                                                 0.005
0.4                                                               0.0




0.2
                                                                  ‚àí0.2




                                                                                 0.000
0.0                                                                                      0.0        0.2         0.4         0.6             0.8     1.0

      0.0   0.2        0.4      0.6      0.8       1.0                                                                 t


Figure 1: Some of simulation when a = 5; right panel: eld Y ; left panel: simulated
                  curves for model 23.


We simulate the model 21 based on A = (Ai,j ).                                                     Then, we dene the following
                                                                                               2
version for A. Ai,j = Di,j (sin(2Gi,j )+2 exp(‚àí16Gi,j )); Œµi,j = GRF (0, .1, 5), Gi,j =
                                                           
GRF (0, 5, 3) and Di = nb1          ‚àí ‚à•i‚àíj‚à•
                                           P
                                        a     .j exp
                                                     
                  1
                      P                 ‚à•(i,j)‚àí(m,t)‚à•
      (D(i,j) = 25√ó25   1‚â§m,t‚â§25 exp ‚àí          a       ).                                            The function D is here to

ensure and control the spatial mixing condition (even if using the Gaussian
Random Fields also brings some spatial dependency).                                                            Indeed, our model can
be seen verifying a mixing condition with Œ±(h) ‚Üí 0 at exponential rate. Then,
the greater is a, the weaker is the spatial dependency. Furthermore, if a ‚Üí ‚àû,
Di ‚Üí 1. Simulations have done with dierent values of a which are a = 5, 10, 20
              b = 35 √ó 30 = 1050).
and grid size(n

      Along this part, the spatial prediction is computed based several kernels K1 (for
observations) and K2 (for sites) respectively. The choice of the semi-metric d(., .)
is important and depends on the information one gets on the data. We consider
a semi-metric between curves(observations) based on their rst q = 2 derivatives.
This latter is presented in Ferraty & Vieu (2006).

      The construction of the proposed predictor                                               Ybi0 is based on the regression
estimator         rn (.).      We study its performance and compare it with the one that
                                                                                                                                                     cl
does not directly take into account the distance between locations noted by rn (.);
                                                                                                           ‚ôØ                      ‚ãÜ
each studied model is replicated 50 times. Remind that Y                                                       (.) and Y (.) are dened
by:


                                       d(X ,X )                                                                            d(X ,X ) 
                  P                        j  i                                                      P                                 j        i
                      i‚ààIn
                              Yi K1       b ‚ôØ          K      ‚ôØ                                           i‚ààIn
                                                                                                                  Yi K1               b‚ãÜ
                                           n               2,œÅn (‚à•j‚àíi‚à•)                                                                 n
                                                                                                                                                     (24)
    ‚ôØ                  iÃ∏=j                                                    ‚ãÜ                           iÃ∏=j
  Yj (Xj ) =                                                            and Yn (Xj ) =                                    d(X ,X )  .
                                      d(Xj ,Xi )
                                                                                                          P                        j        i
                   P                                                                                                  K1
                       i‚ààIn K1            ‚ôØ
                                         bn
                                                       K    ‚ôØ
                                                         2,œÅn (‚à•j‚àíi‚à•)
                                                                                                              i‚ààIn                b‚ãÜn
                        iÃ∏=j                                                                                   iÃ∏=j




      At each replication k , we compute the mean squared error over the n
                                                                         b sites.
The bandwidths used at each replication are those obtained using the previous



                              Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                           405



procedure 5.1.       For the     k th replication, we dene the mean squared error of
                  (+)
predictions (M SE
                 (k) ) by:
                    (+)     1 X +                          +
             M SE(k) =         (Yn,opt (Xj ) ‚àí Yj )2 with Yn,opt = Yn‚ôØ or Yn‚ãÜ .             (25)
                            n
                            b
                                j‚ààIn

      The obtained results are summarized in following Tables 1, 2, 3 which give the
average mean squared errors (AMSE), standard deviation, the average coecients
                            ‚ãÜ
of determination (AR ).           The last column gives the p-value of a paired t-test
                                                   ‚ôØ                                    ‚ãÜ
performing in order to determine if M SE               is signicantly less than M SE       (the
                                               ‚ôØ               ‚ãÜ
alternative hypothesis is then H1: M SE < M SE ). The quality of estimation is
                                                                   2
measured by coecient of determination. We recall that a value of R close to 1
means that the quality of estimation is reliable.

      In regardless of any considered cases of the spatial dependency, measured
                                                           ‚ôØ
by parameter a, for all kernels, the estimator rn (.) leads to better results since
              ‚ôØ
the   AM SE       is signicantly lower than       AM SE ‚ãÜ .       In the other hand we note
                                               ‚ôØ
that the standard deviation of         AM SE       is smaller than     AM SE ‚ãÜ 's one, for all
considered cases.         In addition, even if the spatial dependency becomes low,
AM SE ‚ãÜ stills higher and relatively constant, while AM SE ‚ôØ varies constantly.
                       ‚ôØ
That highlight, that rn (.) method is more adapted to a local data structure and
                                                         2‚ôØ                   2‚ãÜ
local stationarity(local dependency). Finally we note AR , is higher than AR
for all considered cases, but the dierence between them decreases as the value of
a increases(less spatial dependency).


6. Conclusion
      In this work, we propose a new non-parametric spatial predictor for a local
strictly stationary spatial process in a functional setting. The proposed predictor
becomes a new method of supervised classication when response variable Y belong
to a discret set. The originality of the proposed method is to take into account
both the distance between sites and that between functional observations. In the
setting of prediction, we give an extension of the recent work of Dabo-Niang et al.
(2016) on spatial kernel predictor of a local stationary multivariate process. In the
context of Supervised Classication, we contribute rst to the kernel discrimination
rule of Younso (2017) for multivariate strictly stationary spatial processes and
on the other hand the kernel discrimination rule of Ferraty & Vieu (2006) for
functional observations.         We provide asymptotic results on the predictor.            The
numerical results show that proposed predictor method outperforms the classical
kernel predictor.




                    Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

406                                 Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

      Table 1: Simulation results according several kernels, with a = 5, nxy = 1050
 Kernel1          Kernel2    AM SE ‚ôØ Var(AM SE ‚ôØ ) AM SE ‚ãÜ Var(AM SE ‚ãÜ ) AR2‚ôØ            AR2‚ãÜ P-value
                Triangular   0,00018   1, 1 10   ‚àí09
                                                       0,0080   2, 2 10   ‚àí06
                                                                                0, 9998 0, 9905   ****
                  Biweight   0,00017   1, 3 10‚àí09      0,0081   2, 9 10‚àí06      0, 9998 0, 9902   ****
                 Triweight   0,00011   3, 7 10‚àí10      0,0079   2, 5 10‚àí06      0, 9999 0, 9903   ****
 Trianglaire
                   Parzen    0,00006   1, 0 10‚àí10      0,0081   3, 2 10‚àí06      0, 9999 0, 9906   ****
                Epanechnikov 0,00032   2, 9 10‚àí09      0,0077   1, 8 10‚àí06      0, 9996 0, 9907   ****
                                               ‚àí09
                   Gauss     0,00195   9, 8 10         0,0079   2, 2 10‚àí06      0, 9976 0, 9904   ****
                Triangular   0,00037    4 10‚àí09        0,0080   2, 4 10‚àí06      0, 9996 0, 9907   ****
                                               ‚àí09
                  Biweight   0,00020   1, 2 10         0,0083   2, 3 10‚àí06      0, 9998 0, 9902   ****
                 Triweight   0,00019   9, 1 10‚àí10      0,0078   1, 8 10‚àí06      0, 9998 0, 9910   ****
 Biweight
                   Parzen    0,00012   4, 8 10‚àí10      0,0081   2, 4 10‚àí06      0, 9999 0, 9903   ****
                Epanechnikov 0,00218   1, 6 10‚àí07      0,0083   2, 6 10‚àí06      0, 9975 0, 9904   ****
                                               ‚àí10
                   Gauss     0,00007   2, 0 10         0,0084   3, 5 10‚àí06      0, 9999 0,9898    ****
                Triangular   0,00032   3, 6 10‚àí09      0,0081   2, 4 10‚àí06      0, 9996 0, 9903   ****
                  Biweight   0,00018   9, 8 10‚àí10      0,0077    2 10‚àí06        0, 9998 0, 9911   ****
                 Triweight   0,00017   9, 7 10‚àí10      0,0080   2, 9 10‚àí06      0, 9998 0, 9908   ****
 Triweight
                                            ‚àí10
                   Parzen    0,00010    4 10           0,0082   2, 2 10‚àí06      0, 9999 0, 9903   ****
                Epanechnikov 0,00183   9, 6 10‚àí09      0,0079   2, 1 10‚àí06      0, 9979 0, 9910   ****
                                               ‚àí10
                   Gauss     0,00006   2, 1 10         0,0081    2 10‚àí06        0, 9999 0, 9902   ****
                Triangular   0,00027   3, 3 10‚àí09      0,0077    2 10‚àí06        0, 9997 0, 9908   ****
                  Biweight   0,00015   1, 3 10‚àí09      0,0080    5 10‚àí06        0, 9998 0, 9908   ****
                 Triweight   0,00014   5, 5 10‚àí10      0,0078    3 10‚àí06        0, 9998 0, 9909   ****
 Parzen
                                            ‚àí10
                   Parzen    0,00009    3 10           0,0083    2 10‚àí06        0, 9999 0, 9904   ****
                Epanechnikov 0,00162   1, 1 10‚àí07      0,0078    2 10‚àí06        0, 9980 0, 9903   ****
                   Gauss     0,00005    1 10‚àí10        0,0081   2, 9 10‚àí06      0, 9999 0, 9905   ****
                Triangular   0,00044   6, 3 10‚àí09      0,0083   3, 2 10‚àí06      0, 9995 0,9895    ****
                  Biweight   0,00025   2, 4 10‚àí09      0,0086   3, 5 10‚àí06      0, 9997 0, 9900   ****
                 Triweight   0,00024   1, 8 10‚àí09      0,0084   2, 7 10‚àí06      0, 9997 0, 9901   ****
 Epanechnikov
                   Parzen    0,00015    6 10‚àí10        0,0083    2 10‚àí06        0, 9998 0, 9903   ****
                Epanechnikov 0,00247    1 10‚àí07        0,0083    1 10‚àí06        0, 9971 0, 9903   ****
                   Gauss     0,00008   2, 8 10‚àí10      0,0083    2 10‚àí06        0, 999 0, 9905    ****
                Triangular   0,00067   6, 6 10   ‚àí09
                                                       0,0091    2 10‚àí06        0, 9992 0,9887    ****
                  Biweight   0,00041   3, 8 10‚àí09      0,0086    3 10‚àí06        0, 9995 0,9896    ****
                                               ‚àí09
                 Triweight   0,00040   3, 5 10         0,0090    3 10‚àí06        0, 9995 0,9892    ****
 Gauss
                   Parzen    0,00026   1, 1 10‚àí09      0,0089    3 10‚àí06        0, 9997 0,9896    ****
                Epanechnikov 0,00319    4 10‚àí07        0,0085    3 10‚àí06        0, 996   0, 990   ****
                   Gauss     0,00015   5, 9 10‚àí10      0,0088   2, 8 10‚àí06      0, 9998 0, 9895   ****




                   Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                             407




   Table 2: Simulation results according several kernels, with a = 10, nxy = 1050
 Kernel1          Kernel2      AM SE ‚ôØ Var(AM SE ‚ôØ ) AM SE ‚ãÜ Var(AM SE ‚ãÜ ) AR2‚ôØ AR2‚ãÜ P-value
                Triangular     0,0005    6, 4 10‚àí09      0,0085   2, 2 10‚àí06   0, 990 0,840   ****
                                               ‚àí09
                  Biweight     0,0005    3, 8 10         0,0087   1, 5 10‚àí06   0, 991 0,837   ****
                 Triweight     0,0003    2, 0 10‚àí09      0,0085   1, 3 10‚àí06   0, 994 0,845   ****
 Triangular
                Epanechnikov   0,0009    1, 5 10‚àí08      0,0085   1, 5 10‚àí06   0,983 0,839    ****
                  Gaussian     0,0035    2, 6 10‚àí07      0,0086   2, 2 10‚àí06   0,936 0,842    ****
                   Parzen      0,0002    7, 0 10‚àí10      0,0085   1, 5 10‚àí06   0, 997 0,839   ****
                Triangular     0,0006    9, 0 10‚àí09      0,0086   2, 9 10‚àí06   0,989 0,841    ****
                   Parzen      0,0002    9, 9 10‚àí10      0,0088   1, 9 10‚àí06   0, 996 0,841   ****
                                               ‚àí09
                  Biweight     0,0006    6, 5 10         0,0089   1, 7 10‚àí06   0,989 0,829    ****
 Biweight
                 Triweight     0,0004    2, 1 10‚àí09      0,0088   1, 7 10‚àí06   0, 993 0,836   ****
                Epanechnikov   0,0010    1, 6 10‚àí08      0,0086   1, 5 10‚àí06   0,981 0,838    ****
                  Gaussian     0,0037    2, 3 10‚àí07      0,0088   1, 8 10‚àí06   0,932 0,838    ****
                Triangular     0,0005    7, 1 10   ‚àí09
                                                         0,0085   2, 8 10‚àí06   0, 990 0,842   ****
                   Parzen      0,0002    5, 0 10‚àí10      0,0085   1, 5 10‚àí06   0, 997 0,839   ****
                  Biweight     0,0005    5, 4 10‚àí09      0,0088   1, 6 10‚àí06   0, 991 0,831   ****
 Triweight
                   Parzen      0,0002    5, 0 10‚àí10      0,0085   1, 5 10‚àí06   0, 997 0,839   ****
                  Gaussian     0,0034    4, 4 10‚àí07      0,0085   2, 8 10‚àí06   0,937 0,842    ****
                                               ‚àí09
                 Triweight     0,0003    1, 6 10         0,0085   1, 5 10‚àí06   0, 994 0,839   ****
                Triangular     0,0007    1, 2 10‚àí08      0,0087   2, 9 10‚àí06   0,987 0,838    ****
                  Biweight     0,0007    8, 5 10‚àí09      0,0091   1, 7 10‚àí06   0,987 0,827    ****
                 Triweight     0,0004    3, 5 10‚àí09      0,0089   1, 7 10‚àí06   0, 992 0,833   ****
 Epanechnikov
                   Parzen      0,0002    1, 4 10‚àí09      0,0089   1, 9 10‚àí06   0, 996 0,838   ****
                Epanechnikov   0,0012    2, 2 10‚àí08      0,0087   1, 6 10‚àí06   0,978 0,835    ****
                                               ‚àí07
                  Gaussian     0,0040    2, 9 10         0,0089   1, 8 10‚àí06   0,925 0,835    ****
                Triangular     0,0004    5, 1 10‚àí09      0,0083   2, 7 10‚àí06   0, 992 0,845   ****
                  Biweight     0,0004    4, 1 10‚àí09      0,0087   1, 6 10‚àí06   0, 992 0,834   ****
                 Triweight     0,0003    1, 1 10‚àí09      0,0085   1, 6 10‚àí06   0, 995 0,841   ****
 Parzen
                                               ‚àí10
                   Parzen      0,0001    5, 7 10         0,0085   1, 8 10‚àí06   0, 997 0,845   ****
                Epanechnikov   0,0008    1, 0 10‚àí08      0,0083   1, 4 10‚àí06   0,986 0,842    ****
                  Gaussian     0,0030    1, 6 10‚àí07      0,0085   1, 7 10‚àí06   0,944 0,842    ****
                Triangular     0,0010    2, 4 10‚àí08      0,0090   3, 1 10‚àí06   0,981 0,833    ****
                  Biweight     0,0009    1, 4 10‚àí08      0,0093   1, 8 10‚àí06   0,982 0,822    ****
                 Triweight     0,0006    5, 7 10‚àí09      0,0092   1, 8 10‚àí06   0,988 0,829    ****
 Gaussian
                                               ‚àí09
                   Parzen      0,0004    2, 6 10         0,0091   2, 0 10‚àí06   0, 993 0,834   ****
                Epanechnikov   0,0016    3, 9 10‚àí08      0,0090   1, 7 10‚àí06   0,970 0,831    ****
                  Gaussian     0,0048    3, 8 10‚àí07      0,0091   1, 9 10‚àí06   0,910 0,831    ****




                   Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

408                                     Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom




      Table 3: Simulation results according several kernels, with a = 20, nxy = 1050
 Kernel1           Kernel2     AM SE ‚ôØ Var(AM SE 2‚ôØ ) AM SE ‚ãÜ Var(AM SE ‚ãÜ ) AR2‚ôØ AR2‚ãÜ P-value
                 Triangular    0,0007     1, 39 10‚àí08   0,0087   3, 00 10‚àí06   0, 998 0,981   ****
                                                 ‚àí09
                  Biweight     0,0007     8, 58 10      0,0091   1, 69 10‚àí06   0, 999 0,980   ****
                  Triweight    0,0004     2, 71 10‚àí09   0,0089   1, 80 10‚àí06   0, 999 0,980   ****
 Epanechnikov
                   Parzen      0,0002     1, 36 10‚àí09   0,0089   2, 01 10‚àí06   0, 997 0,981   ****
                Epanechnikov   0,0012     2, 05 10‚àí08   0,0087   1, 64 10‚àí06   0, 991 0,981   ****
                   Gauss       0,0041     2, 98 10‚àí07   0,0089   1, 94 10‚àí06   0, 997 0,981   ****
                 Triangular    0,0005     7, 90 10‚àí09   0,0085   2, 86 10‚àí06   0, 991 0,981   ****
                                                 ‚àí09
                  Biweight     0,0005     5, 31 10      0,0089   1, 62 10‚àí06   0, 998 0,980   ****
                  Triweight    0,0003     1, 54 10‚àí09   0,0087   1, 72 10‚àí06   0, 998 0,981   ****
 Triangular
                   Parzen      0,0002     7, 90 10‚àí10   0,0085   2, 86 10‚àí06   0, 999 0,981   ****
                   Gauss       0,0036     2, 26 10‚àí07   0,0085   1, 55 10‚àí06   0, 992 0,981   ****
                                                 ‚àí08
                Epanechnikov   0,0009     1, 27 10      0,0085   1, 55 10‚àí06   0, 998 0,981   ****
                 Triangular    0,0006     9, 71 10‚àí09   0,0086   2, 90 10‚àí06   0, 999 0,981   ****
                                                 ‚àí09
                  Biweight     0,0006     6, 45 10      0,0089   1, 64 10‚àí06   0, 999 0,981   ****
                  Triweight    0,0004     1, 90 10‚àí09   0,0088   1, 74 10‚àí06   0, 997 0,980   ****
 Biweight
                   Parzen      0,0002     9, 46 10‚àí10   0,0088   1, 94 10‚àí06   0, 992 0,981   ****
                Epanechnikov   0,0010     1, 51 10‚àí08   0,0086   1, 57 10‚àí06   0, 998 0,981   ****
                                                 ‚àí07
                   Gauss       0,0037     2, 48 10      0,0088   1, 89 10‚àí06   0, 997 0,981   ****
                 Triangular    0,0005     7, 94 10‚àí09   0,0085   2, 24 10‚àí06   0, 992 0,981   ****
                  Biweight     0,0005     3, 62 10‚àí09   0,0088   1, 52 10‚àí06   0, 998 0,981   ****
                  Triweight    0,0003     2, 02 10‚àí09   0,0086   1, 39 10‚àí06   0, 999 0,981   ****
 Triweight
                                                 ‚àí10
                   Parzen      0,0002     6, 66 10      0,0082   1, 62 10‚àí06   0, 999 0,982   ****
                Epanechnikov   0,0009     1, 55 10‚àí08   0,0085   1, 56 10‚àí06   0, 998 0,982   ****
                                                 ‚àí07
                   Gauss       0,0034     2, 54 10      0,0086   2, 29 10‚àí06   0, 992 0,981   ****
                 Triangular    0,0004     4, 24 10‚àí09   0,0085   1, 81 10‚àí06   0, 998 0,981   ****
                  Biweight     0,0004     4, 00 10‚àí09   0,0084   1, 50 10‚àí06   0, 999 0,982   ****
                  Triweight    0,0003     1, 95 10‚àí09   0,0084   2, 17 10‚àí06   0, 999 0,982   ****
 Parzen
                                                 ‚àí10
                   Parzen      0,0001     4, 89 10      0,0084   1, 35 10‚àí06   0, 999 0,982   ****
                Epanechnikov   0,0008     9, 41 10‚àí09   0,0084   1, 46 10‚àí06   0, 998 0,981   ****
                   Gauss       0,0032     2, 21 10‚àí07   0,0086   1, 48 10‚àí06   0, 993 0,981   ****
                 Triangular    0,0011     1, 50 10‚àí08   0,0090   1, 69 10‚àí06   0, 997 0,980   ****
                  Biweight     0,0010     1, 96 10‚àí08   0,0090   3, 14 10‚àí06   0, 997 0,980   ****
                  Triweight    0,0007     6, 94 10‚àí09   0,0093   1, 79 10‚àí06   0, 998 0,989   ****
 Gauss
                                                 ‚àí09
                   Parzen      0,0004     1, 34 10      0,0092   2, 05 10‚àí06   0, 999 0,980   ****
                Epanechnikov   0,0016     3, 57 10‚àí08   0,0090   1, 69 10‚àí06   0, 996 0,980   ****
                   Gauss       0,0050     4, 67 10‚àí07   0,0092   1, 86 10‚àí06   0,989 0,980    ****




                    Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                           409



Acknowledgements
   This paper originates from chapter 4 of the Ph.D. thesis entitled Contribution
to spatial and functional statistics:          Modeling spatio-temporal of the shery
resources of Senegal deal with spatial and functional statistics Ndiaye et al. (2020).

                  
                   Received: November 2021  Accepted: May 2022
References
Ahmed, M. S., Ndiaye, M., Attouch, M. & Dabo-Niang, S. (2019), `k-nearest neighbors prediction and classication for spatial data', preprinted .
Ballari, D., Giraldo, R., Campozano, L. & Samaniego, E. (2018), `Spatial functional data analysis for regionalizing precipitation seasonality and intensity in a sparsely monitored region: Unveiling the spatio-temporal dependencies of precipitation in ecuador', International Journal of Climatology 38(8), 3337-3354.
Baouche, R. (2015), Pr√©diction des Param√®tres Physiques des Couches P√©trolif√®res par Analyse des R√©seaux de Neurones et Analyse Faciologique., PhD thesis, universit√© M'hamed Bougara. Boumerd√®s.
Biau, G. & Cadre, B. (2004), `Nonparametric spatial prediction', Statistical Inference for Stochastic Processes 7(3), 327-349.
Biau, G. & Devroye, L. (2015), Lectures on the nearest neighbor method, Springer.
Bosq, D. (1998),  Nonparametric Statistics for Stochastic Processes: Estimation and prediction, Vol. 110 of Lecture Notes in Statist., 2nd edn, Springer-Verlag, New York.
Carbon, M., Tran, L. T. & Wu, B. (1997), `Kernel density estimation for random elds', Statistics & Probability Letters       36(2), 115-125.
Chen, W., Pourghasemi, H. R., Zhang, S. & Wang, J. (2019), A comparative study of functional data analysis and generalized linear model data-mining techniques for landslide spatial modeling, in `Spatial Modeling in GIS and R for Earth and Environmental Sciences', Elsevier, pp. 467-484.
Cressie, N. A. C. (1993), Statistics for Spatial Data, Vol. 110 of Wiley Series in Probability and Statistics, revised edn, Wiley-Interscience.
Cuesta-Albertos, J. A., Febrero-Bande, M. & de la Fuente, M. O. (2017), `The ddG -classier in the functional setting', Test 26(1), 119-142.
Cuevas, A., Febrero, M. & Fraiman, R. (2007), `Robust estimation and classication for functional data via projection-based depth notions', Computational Statistics 22(3), 481-496.
Dabo-Niang, S., Hamdad, L.,Ternynck, C. & Yao, A.-F. c. c. (2014), `A kernel spatial density estimation allowing for the analysis of spatial clustering: application to Monsoon Asia Drought Atlas data', Stoch. Environ. Res. Risk Assess 28(8), 2075-2099.
Dabo-Niang, S., Rachdi, M. & Yao, A.-F. (2011), `Kernel regression estimation for spatial functional random variables', Far East Journal of Theoretical Statistics 37(2), 77-113.
Dabo-Niang, S., Ternynck, C. & Yao, A.-F. (2016), `Nonparametric prediction of spatial multivariate data', Journal of Nonparametric Statistics                      28(2), 428-458.
Dabo-Niang, S. & Yao, A.-F. (2007), `Kernel regression estimation for continuous spatial processes', Mathematical Methods of Statistics 16(4), 298-317.
Dabo-Niang, S. & Yao, A.-F. (2013), `Kernel spatial density estimation in innite dimension space', Metrika 76(1), 19-52.
Dabo-Niang, S., Yao, A.-F., Pischedda, L., Cuny, P. & Gilbert, F. (2010), `Spatial mode estimation for functional random elds with application to bioturbation problem', Stochastic Environmental Research and Risk Assessment 24(4), 487-497.
Devroye, L., Gyor, L., Krzyzak, A. & Lugosi, G. (1994), `On the strong universal consistency of nearest neighbor regression function estimates', The Annals of Statistics .
Devroye, L. & Wagner, T. J. (1982), `8 nearest neighbor methods in discrimination', Handbook of Statistics .
El Machkouri, M. (2007), `Nonparametric regression estimation for random elds in a xed-design', Stat. Inference Stoch. Process. 10(1), 29-47.
El Machkouri, M. (2011), `Asymptotic normality of the Parzen-Rosenblatt density estimator for strongly mixing random elds', Statistical Inference for Stochastic Processes 14(1), 73-84.
El Machkouri, M. & Stoica, R. (2010), `Asymptotic normality of kernel estimates in a regression model for random elds', J. Nonparametr. Stat. 22(8), 955-971.
Embling, C. B., Illian, J., Armstrong, E., van der Kooij, J., Sharples, J., Camphuysen, K. C. J. & Scott, B. E. (2012), `Investigating ne-scale spatio-temporal predator-prey patterns in dynamic marine ecosystems: a functional data analysis approach', Journal of Applied Ecology 49(2), 481-492.
Escabias, M., Aguilera, A. & Valderrama, M. (2005), `Modeling environmental data by functional principal component logistic regression', Environmetrics: The ocial journal of the International Environmetrics Society 16(1), 95-107.
Ferraty, F. & Vieu, P. (2006), Nonparametric Functional Data Analysis: Theory and Practice, Springer Series in Statistics, Springer.
Francisco-Fernandez, M. & Opsomer, J. D. (2005), `Smoothing parameter selection methods for nonparametric regression with spatially correlated errors', Canadian Journal of Statistics 33(2), 279-295.
Francisco-Fern√°ndez, M., Quintela-del R√≠o, A. & Fern√°ndez-Casal, R. (2012), `Nonparametric methods for spatial regression. an application to seismic events', Environmetrics 23(1), 85-93.
Gardner, B., Sullivan, P. J., Morreale, S. J. & Epperly, S. P. (2008), `Spatial and temporal statistical analysis of bycatch data: patterns of sea turtle bycatch in the North Atlantic', Canadian Journal of Fisheries and Aquatic Sciences 65(11), 2461-2470.
Giraldo, R., Delicado, P. & Mateu, J. (2011), `Ordinary kriging for function-valued spatial data', Environmental and Ecological Statistics 18(3), 411-426.
Hallin, M., Lu, Z. & Tran, L. T. (2004), `Local linear spatial regression', The Annals of Statistics 32(6), 2469-2500.
Hastie, T. & Tibshirani, R. (1996), `Discriminant adaptive nearest neighbor classication and regression', Advances in Neural Information Processing Systems .
Heppell, S. S., Crowder, L. B. & Menzel, T. R. (1999), Life table analysis of long-lived marine species with implications for conservation and management, in `American Fisheries Society Symposium', Vol. 23, pp. 137-148.
Ignaccolo, R., Ghigo, S. & Bande, S. (2013), `Functional zoning for air quality', Environmental and ecological statistics 20(1), 109-127.
Klemel√§, J. (2008), `Density estimation with locally identically distributed data and with locally stationary data', J. Time Ser. Anal. 29(1), 125-141. http://dx.doi.org/10.1111/j.1467-9892.2007.00547.x
Lefort, R., Fablet, R., Berger, L. & Boucher, J.-M. (2011), `Spatial statistics of objects in 3-d sonar images: application to sheries acoustics', IEEE Geoscience and Remote Sensing Letters 9(1), 56-59.
Li, X., Ghosal, S. et al. (2018), `Bayesian classication of multiclass functional data', Electronic Journal of Statistics 12(2), 4669-4696.
Luan, J., Zhang, C., Xu, B., Xue, Y. & Ren, Y. (2018), `Modelling the spatial distribution of three portunidae crabs in haizhou bay, China', PloS one 13(11), e0207457.
Masry, E. (2005), `Nonparametric regression estimation for dependent functional data: asymptotic normality', Stochastic Process. Appl.115(1), 155-177.
Mateu, J. & Romano, E. (2017), `Advances in spatial functional statistics'.
Menafoglio, A. (2021), Spatial statistics for distributional data in bayes spaces: From object-oriented kriging to the analysis of warping functions, in `Advances in Compositional Data Analysis', Springer International Publishing, pp. 207-224.
Menafoglio, A., Pigoli, D. & Secchi, P. (2022), `Mathematical foundations of functional kriging in Hilbert spaces and riemannian manifolds', Geostatistical Functional Data Analysis pp. 27-54.
Menafoglio, A., Secchi, P. & Rosa, M. D. (2013), `A universal kriging predictor for spatially dependent functional data of a Hilbert space', Electronic Journal of Statistics 7(none).
Menezes, R., Garc√≠a-Soid√°n, P. & Ferreira, C. (2010), `Nonparametric spatial prediction under stochastic sampling design', Journal of Nonparametric Statistics 22(3), 363-377.
Ndiaye, M., Dabo-Niang, S., Ngom, P., Cir√© Elimane, S. & Fall, M. (2020), Contribution to spatial and functional statistics : Modelingspatio-temporal of the shery resources of Senegal, PhD thesis, Ecole Doctorale Math√©matiques et Informatique de l'Universit√© Cheikh Anta Diop de Dakar.
Neaderhouser, C. C. (1980), `Convergence of block spins dened by a random eld', J. Statist. Phys. 22(6), 673-684.
Niku, J., Hui, F. K., Taskinen, S. & Warton, D. I. (2019), `gllvm: Fast analysis of multivariate abundance data with generalized linear latent variable models in r', Methods in Ecology and Evolution 10(12), 2173-2182.
Niku, J., Hui, F. K., Taskinen, S. & Warton, D. I. (2021), `Analyzing environmental-trait interactions in ecological communities with fourth-corner latent variable models', Environmetrics 32(6), e2683.
Oshinubi, K., , Ibrahim, F., Rachdi, M. & Demongeot, J. (2022), `Functional data analysis: Application to daily observation of COVID-19 prevalence in france', AIMS Mathematics 7(4), 5347-5385.
Paredes, R. & Vidal, E. (2006), `Learning weighted metrics to minimize nearest-neighbor classication error', IEEE Transactions on Pattern Analysis and Machine Intelligence .
Pollock, L. J., Tingley, R., Morris, W. K., Golding, N., O'Hara, R. B., Parris, K. M., Vesk, P. A. & McCarthy, M. A. (2014), `Understanding co-occurrence by modelling species simultaneously with a joint species distribution model (jsdm)', Methods in Ecology and Evolution 5(5), 397-406.
Rachdi, M., Laksaci, A. & Al-Awadhi, F. A. (2021), `Parametric and nonparametric conditional quantile regression modeling for dependent spatial functional data', Spatial Statistics 43, 100498.
Ripley, B. (1987), Spatial point pattern analysis in ecology, in `Develoments in Numerical Ecology', Springer, pp. 407-429.
Rivoirard, J., Simmonds, J., Foote, K., Fernandes, P. & Bez, N. (2000), Geostatistics for estimating sh abundance, Wiley Online Library.
Rosenblatt, M. (1985), Stationary sequences and random elds, Birkhauser, Boston.
Ruiz-Medina, M. (2011), `Spatial autoregressive and moving average Hilbertian processes', Journal of Multivariate Analysis 102(2), 292-305.
Ruiz-Medina, M. D., Anh, V. V., Espejo, R. M., Angulo, J. M. & Frias, M. P. (2015), `Least-squares estimation of multifractional random elds in a Hilbert-valued context', Journal of Optimization Theory and Applications 167(3), 888-911.
Ruiz-Medina M, E. R. (2012), `Spatial autoregressive functional plug-in prediction of ocean surface temperature', Stoch Environ Res Risk Assess 26(3):335-344 .
Soltysiak, M., Blachnik, M. & Dabrowska, D. (2016), `Machine-learning methods in the classication of water bodies', Environmental & Socio-economic Studies 4(2), 34-42.
S√∏rensen, H., Goldsmith, J. & Sangalli, L. M. (2013), `An introduction with medical applications to functional data analysis', Statistics in medicine 32(30), 5222-5240.
Takahata, H. (1983), `On the rates in the central limit theorem for weakly dependent  random elds', Zeitschrift f√ºr Wahrscheinlichkeitstheorie und verwandte Gebiete 64(4), 445-456.
Ternynck, C. (2014), `Spatial regression estimation for functional data with spatial dependency', SFDS,155, 2 .
Torres, J. M., Nieto, P. G., Alejano, L. & Reyes, A. (2011), `Detection of outliers in gas emissions from urban areas using functional data analysis', Journal of hazardous materials 186(1), 144-149.
Tran, L. T. (1990), `Kernel density estimation on random elds',Journal of Multivariate Analysis 34(1), 37-53.
Wang, J.-L., Chiou, J.-M. & M√ºller, H.-G. (2016), `Functional data analysis', Annual Review of Statistics and Its Application 3, 257-295.
Wu, H. & Li, Y.-F. (2022), `Clustering spatially correlated functional data with multiple scalar covariates', IEEE Transactions on Neural Networks and Learning Systems pp. 1-15.
Xiaoying, W., Qian, S. & Jialiang, G. (2021), Research on nonparametric classication method of functional data, in `2021 2nd International on Education, Knowledge and Information Management (ICEKIM)', IEEE.
Yan, F., Liu, L., Li, Y., Zhang, Y., Chen, M. & Xing, X. (2015), `A dynamic water quality index model based on functional data analysis', Ecological Indicators 57, 249-258.
Yates, M. C., Derry, A. M. & Cristescu, M. E. (2021), `Environmental RNA: A revolution in ecological resolution?', Trends in Ecology & Evolution 36(7), 601-609.
Yen, J. D. L., Thomson, J. R., Paganin, D. M., Keith, J. M. & Nally, R. M. (2014), `Function regression in ecology and evolution: FREE', Methods in Ecology and Evolution 6(1), 17-26.
Young, M. & Carr, M. H. (2015), `Application of species distribution models to explain and predict the distribution, abundance and assemblage structure of nearshore temperate reef shes', Diversity and Distributions 21(12), 1428-1440.
Younso, A. (2017), `On the consistency of a new kernel rule for spatially dependent data', Statistics & Probability Letters .
Zhang,   H. (2019),     Topics in functional data analysis and machine learning predictive inference, PhD thesis, Iowa State University.




Appendix A. Proofs of Theorems 1, 2, 3 and 4
Appendix A.1. Some Preliminary Results for the Proofs

Lemma 1. Carbon et al. (1997) Let the sets S1 , S2 , . . . , Sk containing each m
sites and such that, for all i Ã∏= j , and for 1 ‚â§ i, j ‚â§ k , dist(Si , Sj ) ‚â• Œ¥0 . Let
W1 , W2 , . . . , Wk a sequence of random variables with real values and measurable
respectively with respect to B(S1 ), . . . , B(Sk ). Let be Wl with values in [a, b]. There
exists a sequence of independent random variables W1‚àó , W2‚àó , . . . , Wk‚àó such that Wl‚àó
has the same distribution as Wl and satises:
               k
               X
                     E|Wl ‚àí Wl‚àó | ‚â§ 2k(b ‚àí a)œà((k ‚àí 1)m, m)œá(Œ¥0 ).
               l=1

Lemma 2. Tran (1990) Denote by Lr (F) the class of F -measurable random
variables X which satisfy: ‚à•X‚à•r = (E|X|r )1/r < ‚àû. Suppose that X ‚àà Lr (B(E)),
Y ‚àà Lr (B(E ‚Ä≤ )), 1 ‚â§ r, s, t < ‚àû and 1r + 1s + 1t = 1. Then,

  |EXY ‚àí EXEY |         ‚â§   C‚à•X‚à•r ‚à•Y ‚à•s {œà(Card(E), Card(E ‚Ä≤ ))œá(dist(E, E ‚Ä≤ ))}1/t .

For bounded random variables with probability 1, we have:

         |EXY ‚àí EXEY |        ‚â§    C{œà(Card(E), Card(E ‚Ä≤ ))œá(dist(E, E ‚Ä≤ ))}.

                  Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                                           415



   In the following,   we will often use the notation Ki (x) = K1i K2i and
             Ki (x)                    
                                         d(x,Xi )
                                                  
Wni (x) = P             with K1i = K1               and K2i = K2,œÅn (‚à•i0 ‚àí i‚à•). By
                                           bn
            j‚ààIn Kj (x)          P
convention, we set 0/0 = 0, then   i‚ààIn Wni (x) = 0 or 1. Thus, we have

                            P                                     P
                               i‚ààIn Wni (x)Yi                 if        i‚ààIn Wni (x) = 1;
             rn (x)      =   1
                               P
                             n
                             b   i‚ààIn Yi                      otherwise.


Let us use the following decomposition:


                                    1
          rn (x) ‚àí r(x) =                [(gn (x) ‚àí E(gn (x))) ‚àí (r(x) ‚àí E(gn (x)))]                        (26)
                                  fn (x)

                                                r(x)
                                           ‚àí          [fn (x) ‚àí 1]
                                               fn (x)
Lemma 3. Under hypotheses H1-H3, we have
                            Ô£Æ                                          Ô£π2
                                X
                    E1/2 Ô£∞            Wni (x)E(Yi |Xi ) ‚àí r(x)Ô£ª             =      O(bn ).
                              i‚ààVi0


Lemma 4. Under the conditions of Theorem 1, we have
                Ô£Æ                                        Ô£π2
                                                                                                1/2
           1/2 Ô£∞
                    X                                                                1
         E               Wni (x)(Yi ‚àí E(Yi |Xi ))Ô£ª                 =    O                               .
                                                                                b œÅN
                                                                                n    œÜ
                                                                                   n x (bn )
                 i‚ààVi0


Lemma 5. Under the conditions of Theorem 1, we have
                        Ô£Æ                          Ô£π2
                                                                                         1/2
                    1/2 Ô£∞ 1                                                 1
                                 X
                E                       Yi ‚àí r(x)Ô£ª      = O                                      .
                            n
                            b                                          b œÅN
                                                                       n    œÜ
                                                                          n x (bn )
                                i‚ààVi0


   Dene

                                            1
                                Œõi (x) =      [Ki (x) ‚àí E(Ki (x))] ,
                                           an

                X       h          i           X X
                                 2
     In (x) =          E (Œõi (x)) and Rn (x) =     |E [Œõi (x)Œõk (x)]| .
                i‚ààOn                                          i,k‚ààOn iÃ∏=k


Lemma 6. Under the conditions of Theorem 1, we have
                                                                                 
                                                                    1
                            In (x) + Rn (x)         = O                               .
                                                               b œÅN
                                                               n    œÜ
                                                                  n x (bn )


                     Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

416                                                  Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

Appendix A.2. Proofs


Appendix A.2.1. Proof of Theorem 1

      Because    of     the        local         stationarity            dened      in      assumption     (   H3),    the
decomposition of rn (x) ‚àí r(x) makes sense over Vi0 . Thus we have


                                  Ô£´                                                 Ô£∂
                                        X
  rn (x) ‚àí r(x)         =         Ô£≠              Wni (x)E(Yi |Xi ) ‚àí r(x)Ô£∏ 1P                                  
                                                                                              i‚ààVi Wni (x)=1
                                    i‚ààVi0                                                         0
                                        Ô£´                                             Ô£∂
                                            X
                                  +Ô£≠                Wni (x)(Yi ‚àí E(Yi |Xi ))Ô£∏ 1P                                   
                                                                                                i‚ààVi Wni (x)=1
                                            i‚ààVi0                                                   0
                                        Ô£´                                Ô£∂
                                            1 X
                                  +Ô£≠                     Yi ‚àí r(x)Ô£∏ 1P                            := A + B + C.
                                            n
                                            b                                    i‚ààVi Wni (x)=0
                                                i‚ààVi0                                0




Applying Minkowski's inequality, we get



                 ‚à•rn (x) ‚àí r(x)‚à•2                   ‚â§      E1/2 [A]2 + E1/2 [B]2 + E1/2 [C]2 .                          (27)



Therefore, Theorem 1 follows from (27) and Lemmas 3, 4 and 5. ‚ñ°




Appendix A.2.2. Proof of Lemma 3

      By the Lipschitz condition on Assumption                                H2, there exists a constant C3 > 0
such that


                                                          Ô£ÆÔ£´                                    Ô£∂                         Ô£π2
                                                                 X
                            1/2         2               1/2 Ô£∞Ô£≠
                        E         [A]        ‚â§      E                    Wni (x)|r(Xi ) ‚àí r(x)|Ô£∏ 1P                     Ô£ª
                                                                                                       i‚ààVi     Wni (x)=1
                                                                 i‚ààVi0                                      0
                                                          Ô£ÆÔ£´                                     Ô£∂                         Ô£π2
                                                                 X
                                                        1/2 Ô£∞Ô£≠
                                             ‚â§      E                    Wni (x)(C3 √ó d(Xi , x))Ô£∏ 1P                     Ô£ª
                                                                                                        i‚ààVi     Wni (x)=1
                                                                 i‚ààVi0                                      0
                                                             Ô£Æ                          Ô£π2
                                                                    X
                                             ‚â§      C3 E1/2 Ô£∞√ó               Wni (x)bn Ô£ª .
                                                                    i‚ààVi0

                                                    Thus, the local stationarity assumption H3 implies
        Ô£Æ                          Ô£π2
             X
C3 E1/2 Ô£∞√ó           Wni (x)bn Ô£ª             =      O(bn ). ‚ñ°
             i‚ààVi0



                        Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                                    417



Appendix A.2.3. Proof of Lemma 4
Dene
                           Ô£´                                       Ô£∂
                                X
            G(x)    =      Ô£≠            Wni (x)[Yi ‚àí E(Yi |Xi )]Ô£∏ 1P                         
                                                                          i‚ààVi Wni (x)=1
                                i‚ààVi0                                         0

                           en (x) 
                    :=            1 P               ,
                           fn (x)    i‚ààVi Wni (x)=1
                                               0


where

                    1 X                                                                1 X
   en (x)    =          Ki (x)[Yi ‚àí E(Yi |Xi )]             and        fn (x) =            Ki (x).
                   an                                                                 an
                        i‚ààVi0                                                           i‚ààVi0

Note that, since Yi is bounded, we have ‚àÄi, 0 ‚â§ |Yi ‚àí E(Yi |Xi )| ‚â§ 2M . It follows
that |G(x)| ‚â§ 2M and


           |G(x)| =       |G(x)|1P                     + |G(x)|1
                                                                   P
                                                                                              
                                           i‚ààVi Ki (x)>c                  i‚ààVi Ki (x)‚â§c
                                               0                              0

                          |en (x)| 
                    ‚â§             1 P              + 2M √ó 1                ,
                           fn (x)
                                                              P
                                     i‚ààVi Ki (x)>c             i‚ààVi Ki (x)‚â§c
                                               0                                  0

                                             a      P                   an
where c is a given constant. Let us take c = n , if  i‚ààVi0 Ki (x) > c = 2 then
                                              2
            an  1
fn (x) >       > . It follows that
           2an  2
                                                     Ô£´ Ô£Æ                        Ô£πÔ£∂1/2
                                                           X                  an Ô£ªÔ£∏
              ‚à•G(x)‚à•2 ‚â§ 2‚à•en (x)‚à•2 + 2M Ô£≠P Ô£∞                       Ki (x) ‚â§               ,
                                                                               2
                                                           i‚ààVi0

and
                                                      Ô£Æ Ô£´   Ô£∂2 Ô£π1/2
                                                    1 Ô£Ø Ô£≠X Ô£∏ Ô£∫
                          ‚à•en (x)‚à•2        =          Ô£∞E  Œæi Ô£ª ,
                                                   an
                                                           i‚ààVi0


where


                                 Œæi = Ki (x) [Yi ‚àí E(Yi |Xi )] .

To prove Lemma 4, we have to show that

                                                        ‚àí1/2
                                          nœÅN
                            ‚à•en (x)‚à•2 = O(b n œÜx (bn ))      ,                                    (28)


and
                    Ô£Æ                       Ô£π
                         X               an Ô£ª                  ‚àí1/2
                   PÔ£∞           Ki (x) ‚â§         b œÅN
                                              ‚â§O n  n œÜx (bn )       .                            (29)
                                          2
                        i‚ààVi0



                    Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

418                                                  Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

Observe that, by Assumptions                        H1 and H3, we have
  X                      X       h                         i       X
          E Œæi2 ‚â§              E Ki2 (x) [Yi ‚àí E(Yi |Xi )]2 = 4M 2    2                   2
                                                                         E[K1i ]2 ‚â§ 4M 2 C22
            
                                                                     K2i                     kn œÜx (bn )
 i‚ààVi0               i‚ààVi0                                                        i‚ààVi0

                                                                            nœÅN
                                                                        = O(b n œÜx (bn )).


Now, let dn be a sequence of real numbers tending to ‚àû as n ‚Üí ‚àû and set


      S = {(i, k) ‚àà Vi20 , ‚à•i ‚àí k‚à• ‚â§ dn } and S c = {(i, k) ‚àà Vi20 , ‚à•i ‚àí k‚à• > dn }.


                                     Ô£´             Ô£∂2
                                         X                   X                        X                        X
      First, see that E Ô£≠                       Œæi Ô£∏ =                 E[Œæi2 ] +            E [Œæi Œæk ] +               E [Œæi Œæk ]
                                        i‚ààVi0                i‚ààVi0                  i,k‚ààS                   i,k‚ààS c

Using Assumption                H3, we have
      X                                   X
            E [Œæi Œæk ]     ‚â§     4M 2            E [Ki (x)Kk (x)]
   i,k‚ààS                                 i,k‚ààS
                                          X
                           ‚â§     4M 2            K2i K2k P [(Xi , Xk ) ‚àà B(x, bn ) √ó B(x, bn )]
                                         i,k‚ààS
                                                                                                                
                                             X                           i0 ‚àí i                           i0 ‚àí k
                           ‚â§     4M 2 C4            1[0,1]       œÅ‚àí1
                                                                  n                    1[0,1]       œÅ‚àí1
                                                                                                     n                 œÜx (bn )1+Œµ
                                            i,k‚ààS
                                                                           n                                 n
                                                                                     
                                                X                          i0 ‚àí i
                           ‚â§     4M 2 C4              1[0,1]       œÅ‚àí1
                                                                    n                     œÜx (bn )1+Œµ
                                            i,k‚ààVi0
                                                                             dn
                                                                                                 
                                             X          X                                  i0 ‚àí i
                           ‚â§     4M 2 C4                         1{u;‚à•u‚à•‚â§dn }          œÅ‚àí1
                                                                                        n           œÜx (bn )1+Œµ
                                            i‚ààVi0 i‚àíu‚ààVi0
                                                                                             dn

                           ‚â§     4M 2 C4 kn dN
                                             n œÜx (bn ))
                                                        1+Œµ
                                                            .

Since K1 and K2 are bounded, applying Lemma 2, we get

 X                          X                                              X                               N
                                                                                                                X        X
          E [Œæi Œæk ] ‚â§ C             {œà(1, 1)œá(‚à•i ‚àí k‚à•)} ‚â§ C                          œá(‚à•i ‚àí k‚à•) ‚â§ C2                          œá(‚à•i‚à•)
i,k‚ààS c                    i,k‚ààS c                                     i,k‚ààS c ‚à©Vi                             k‚ààVi k‚àíu‚ààVi
                                                                                  0                                0       0
                                                                                                                     ‚à•u‚à•>dn
                                X
                    ‚â§ Ckn                œá(‚à•i‚à•).
                               ‚à•i‚à•>dn


Since               X                               X                             X
                               œá(‚à•i‚à•) ‚â§ C                    ‚à•i‚à•‚àíŒ∏ ‚â§ C                     ‚à•i‚à•‚àíŒ∏ ‚à•i‚à•‚àíN ‚à•i‚à•N ,
                  ‚à•i‚à•>dn                           ‚à•i‚à•>dn                      ‚à•i‚à•>dn
                            ‚àíN                 ‚àíN
and ‚à•i‚à• > dn , ‚à•i‚à•                   ‚â§ (dn )        , we have
                     X                                                                           X
                C              ‚à•i‚à•‚àíŒ∏ ‚à•i‚à•‚àíN ‚àíŒµ ‚à•i‚à•N +Œµ                        ‚àíN ‚àíŒµ
                                                                         ‚â§ Cdn                            ‚à•i‚à•N +Œµ‚àíŒ∏ .
                    ‚à•i‚à•>dn                                                                      ‚à•i‚à•>dn

Then,
                                 X                                                X
                                                            ‚àíN ‚àíŒµ
                                          E [Œæi Œæk ] ‚â§ Ckn dn                              ‚à•i‚à•N +Œµ‚àíŒ∏ .
                                i,k‚ààS c                                        ‚à•i‚à•>dn


                            Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                                     419


                                   ‚àíŒµ
                                        +a                                              N
Choosing dn = (œÜx (bn )) N                   with a > 0 such that N a ‚â§ Œµ ‚àí
                                                                                       N +Œµ lead to

                                                             ‚àí(N +Œµ)(N a‚àíŒµ)‚àíN
                  d‚àí(N
                   n
                       +Œµ)
                               =      œÜx (bn )(œÜx (bn ))             N           = O (œÜx (bn )) ,

        ‚àí(N +Œµ)(N a‚àíŒµ)‚àíN
Since
                N        > 0, Moreover, this choice of dn implies that

               X
                       E [Œæi Œæk ] ‚â§      4M 2 C4 kn dN
                                                     n (œÜx (bn ))
                                                                  1+Œµ

              i,k‚ààS

                                                                          nœÅN
                                         ‚â§ 4M 2 C4 kn (œÜx (bn ))1+N a = O(b n œÜx (bn )).


Then, we deduce that

  Ô£´               Ô£∂2
      X                       X              X              X
                                     E Œæi2 +                                 b œÅN
                                                                                        
EÔ£≠            Œæi Ô£∏      =                      E [Œæi Œæk ] +   E [Œæi Œæk ] = O n  n œÜx (bn ) .
      i‚ààVi0                  i‚ààVi0                i,k‚ààS                i,k‚ààS c


Consequently,
                              Ô£Æ Ô£´      Ô£∂2 Ô£π1/2
                                  X
                                    Œæi Ô£∏ Ô£ª         nœÅN
                                               = O(b n œÜx (bn ))
                                                                1/2
                              Ô£Ø Ô£≠         Ô£∫
                              Ô£∞E
                                      i‚ààVi0



                                                                                       H1 and H3, an ‚â•
                                                ‚àí1/2
and                b œÅN
     ‚à•en (x)‚à•2 = O n  n œÜx (bn )                        since by Assumptions
 2
C11 kn œÜi,x (bn ).
Next, for (29), dene


                                        X                    1
                            Sn (x) =            Œõi (x) =       [fn (x) ‚àí E(fn (x))] .
                                                            an
                                        i‚ààVi0


Then, we have

              Ô£Æ                    Ô£π                 Ô£Æ                                       Ô£π
                  X             an Ô£ª                      X                              ‚àían Ô£ª
         PÔ£∞            Ki (x) ‚â§      =             PÔ£∞             (Ki (x) ‚àí E(Ki (x))) ‚â§
                                 2                                                        2
               i‚ààVi0                                      i‚ààVi0
                                                     Ô£Æ                             Ô£π
                                                       1 X                       1
                                              ‚â§    PÔ£∞      (Ki (x) ‚àí E(Ki (x))) ‚â• Ô£ª
                                                      an                         2
                                                              i‚ààVi0

                                              ‚â§    P [|Sn (x)| ‚â• Œµ] , for n large enough.

We will now introduce the spatial blocks decomposition introduced by Tran (1990)
which will be useful afterwards.                   Without loss of generality, we suppose that
nk = 2bqk , for 1 ‚â§ k ‚â§ N .                   The random variables Œõi (x) can be grouped into



                         Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

420                                             Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

2N q1 . . . qN cubic blocks of side b. Let,
                                    (2jk +1)b
                                      X
       U (1, n, x, j)      =                        Œõi (x),
                                  ik =2jk b+1,
                                    k=1,...,N.

                                    (2jk +1)b               2(jN +1)b
                                      X                        X
       U (2, n, x, j)      =                                                 Œõi (x),
                                  ik =2jk b+1,           iN =(2jN +1)b+1
                                  k=1,...,N ‚àí1.

                                    (2jk +1)b                 2(jN ‚àí1 +1)b              (2jN +1)b
                                      X                           X                       X
       U (3, n, x, j)      =                                                                         Œõi (x),
                                  ik =2jk b+1,           iN ‚àí1 =(2jN ‚àí1 +1)b+1         iN =2jN b+1
                                  k=1,...,N ‚àí2.

                                    (2jk +1)b                 2(jN ‚àí1 +1)b                (2jN +1)b
                                      X                           X                         X
       U (4, n, x, j)      =                                                                             Œõi (x)
                                  ik =2jk b+1,           iN ‚àí1 =(2jN ‚àí1 +1)b+1         iN =(2jN +1)b+1
                                  k=1,...,N ‚àí2.


and so on. Noting that

                                                           2(jk +1)b           (2jN +1)b
                                                              X                  X
                        N ‚àí1
                 U (2          , n, x, j)       =                                             Œõi (x)
                                                        ik =(2jk +1)b+1,     iN =2jN b+1
                                                          k=1,...,N ‚àí1.

                                                           2(jk +1)b
                                                              X
                          N
                   U (2 , n, x, j)              =                            Œõi (x)
                                                        ik =(2jk +1)b+1,
                                                           k=1,...,N.

                                                                                  Pqk ‚àí1
for each integer 1 ‚â§ l            ‚â§ 2N , we dene T (n, x, l) =              jk =0 U (l, n, x, j). We
                        P2N                                               k=1,...,N.
                                                                           P2N                     
obtain   Sn (x) =     l=1 T (n, x, l).                  For Œµ > 0, P ‚â§ P      l=1   T (n, x, l) > Œµ  ‚â§
2 P |T (n, x, 1)| > 2ŒµN . We enumerate in arbitrary manner the qb = q1 √ó ¬∑ ¬∑ ¬∑ √ó qN
 N
                         

terms U (1, n, x, j) of the sum T (n, x, 1), and refer to them as W1 , . . . , Wqb. Note
that  U (1, n, x, j) is a measurable œÉ -algebra generated by Xi , with i such that
2jk b + 1 ‚â§ ik ‚â§ (2jk + 1)b, k = 1, . . . , N . For all l = 1, . . . , qb, the sets of the sites
in Wl are separated by a distance of at least equal to b. In addition, since K1 and
                        N
K2 write |Wl | ‚â§ C ban with C = ‚à•K1 ‚à•‚àû ‚à•K2 ‚à•‚àû (where ‚à• ¬∑ ‚à•‚àû is the sup norm).
                                                                           ‚àó   ‚àó         ‚àó
Lemma 1 insures the existence of some random variables W1 , W2 , . . . , Wqb such
that
                   qb
                   X                                             bN
                          E|Wl ‚àí Wl‚àó |              ‚â§ 2b
                                                       qC              q ‚àí 1)bN , bN )œá(b)
                                                                    œà((b
                                                                 an
                   l=1
                                                                 b bN
                                                                 n
                                                           ‚â§ 2C N N     n, bN )œá(b).
                                                                      œà(b
                                                               2 b an
Markov inequality allows us to write

           qb
                                                    !
           X                                Œµ                   b bN
                                                                n
       P         |Wl ‚àí Wl‚àó | >                            ‚â§ 2C N N     n, bN )œá(b)2N +1 Œµ‚àí1 ,
                                                                     œà(b
                                       2N +1                  2 b an
           l=1


                        Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                                            421



and by Bernstein inequality, we have

              qb
                                         !                    (                                          )
              X                    Œµ                                           ‚àíŒµ2 /(2N +1 )2
        P           |Wl‚àó | >                    ‚â§ 2 exp               Pqb
                               2N +1                              4               ‚àó2    2Œµ bN
              l=1                                                         l=1 E(Wl ) + 2N +1 an C

which leads to
                                                          (                                          )
                                                                           ‚àíŒµ2 /(2N +1 )2
             P [|Sn (x)| ‚â• Œµ] ‚â§ 2N +1 exp                      Pqb                      N
                                                              4 l=1 E(Wl‚àó2 ) + 2‚àíN CŒµ ban
                                                       b bN
                                                       n
                                             +2N +1 C N N     n, bN )œá(b)2N +1 Œµ‚àí1 .
                                                            œà(b
                                                     2 b an
                                                1/2                                         1
                                                                          b œÅN
                                                                                         2N
                                   log n                                  n  n œÜx (bn )
Let Œ¥ > 0, Œµ = Œµn = Œ¥                                  and b =                                   .
                                       b
                               b œÅN
                               n  n œÜx (bn )                                  log n
                                                                                  b
                                       ‚àó
    Since the variables Wl and Wl         have the same distributions, we have
Pqb        ‚àó2
                Pqb         ‚àó
                                   Pqb
       EW l   =      var(W    ) =        var(W l ) ‚â§ In (x) + Rn (x), and according
   l=1           l=1
                      Pqb l      ‚àó2
                                    l=1
                                           nœÅn œÜx (bn )]‚àí1 . Then,
                                             N
                                                          
to Lemma 6, we have     l=1 EWl ‚â§ O [b
                                                      Ô£±                                                  Ô£º
                                                      Ô£≤                            ‚àíŒµ2                   Ô£Ω
       P [|Sn (x)| ‚â• Œµ] ‚â§              2N +1 exp                                          
                                                      Ô£≥ 22N +2 4      C            ‚àíN Œµ bN Ô£æ
                                                                 b œÅN œÜx (bn ) + C2
                                                                 n             n        an

                                                     n
                                             N +2
                                                        n, bN )b‚àíŒ∏ Œµ‚àí1 .
                                                     b
                                       +2           C œà(b
                                                     an
        ‚Ä≤‚Ä≤                              ‚Ä≤‚Ä≤                                ‚Ä≤‚Ä≤        ‚Ä≤‚Ä≤
Since C1 kn œÜx (bn ) ‚â§ an ‚â§ C2 kn œÜx (bn ), where C1 andC2 are positive constant and
       nœÅN
kn = O(b n ), we have


                                                              ‚àíŒ¥ 2 nbœÅNlog n
                                                     (                     b                 )
                                                                        œÜx (bn )
    P [|Sn (x)| ‚â• Œµn ]         ‚â§       2N +1 exp           22N +4 C
                                                                           n
                                                                               N +2 Œ¥
                                                         b œÅN
                                                         n
                                                                       + nbœÅC2
                                                                             N œÜ (b )
                                                            n œÜx (bn )       n x n
                                                                       N             1/2
                                             N +2n
                                                 b         N ‚àíŒ∏ ‚àí1      b œÅn œÜx (bn )
                                                                        n
                                       +2      C œà(b   n, b )b Œ¥
                                                 an                        log n
                                                                               b
                                          N +1             ‚àía
                                                   
                               ‚â§       C2      exp log nb
                                                                   N             N ‚àíŒ∏
                                         N +2     ‚àí1 n
                                                     b         N    b œÅn œÜx (bn ) 2N
                                                                    n
                                       +2      CŒ¥       œà(bn, b )
                                                     an                log n
                                                                           b
                                                                          N              N ‚àíŒ∏
                                          ‚àía      N +2    ‚àí1 n        N     b œÅn œÜx (bn ) 2N
                                                                            n
                               ‚â§
                                                              b
                                        b +2
                                       Cn              CŒ¥         n, b )
                                                                œà(b
                                                             an                log n
                                                                                   b
                                b ‚àía + C2N +2 Œ¥ ‚àí1 Dn ,
                           := C n

                    Œ¥2
with   a=                      > 0. Note that n           b œÅN
                                                    b 1‚àía n  n œÜx (bn ) tends to 0 for
           22N +4 C + C2N +2 Œ¥
                       ‚àía                    ‚àí1
                                   N
                                                
a > 1 and then C n        = o [bnœÅn œÜx (bn )]     . Moreover a > 1 if and only if
                 ‚àö
                     b
Œ¥ > 2N +1 C(1 + 4C) > 2N +1 C (with Œ¥ > 0). Now, we treat the second term.

                      Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

422                                               Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

      When (8) is satised, i.e. œà(n, m) ‚â§ C min(n, m), ‚àÄn, m ‚àà N, we have



                                                                                           2N2N‚àíŒ∏
                                                                            b œÅN
                                                                                      
                                                                         n  n  n œÜx (bn )
       b œÅN           N +2
                           CŒ¥ ‚àí1 Dn               ‚â§     b œÅN  N +2
                                                                   CŒ¥ ‚àí1
                                                                         b
       n  n œÜx (bn )2                                   n  n2
                                                                         an     log n
                                                                                    b
                                                                           N               2N ‚àíŒ∏
                                                       N N +2     ‚àí1 1      b œÅn œÜx (bn ) 2N
                                                                            n
                                                  ‚â§ n
                                                    b œÅn 2    CŒ¥
                                                                     œÅNn         log n
                                                                                     b
                                                                       2N ‚àíŒ∏
                                                                                             - 4N2N‚àíŒ∏
                                                                                       Œ∏‚àí2N
                                                            N
                                                                       4N ‚àíŒ∏
                                                  ‚â§ C n  b œÅn œÜx (bn )        (log nb) 4N ‚àíŒ∏




which tends to 0 as n ‚Üí 0 since Œ∏ > 4N .

   When (9) is satised, i.e. œà(n, m) ‚â§ C(n + m + 1) , ‚àÄn, m ‚àà N, and note that
                                                    Œ∫

              n + bN + 1)Œ∫ ‚â§ C n
  n, bN ) ‚â§ C(b
œà(b                             b Œ∫ , we have



                                                    ! 2N ‚àíŒ∏                                                      ! 2N ‚àíŒ∏
                N +2 ‚àí1   n         b œÅN
                                    n  n œÜx (bn )
                                                       2N
                                                                                ‚àí1   1           b œÅN
                                                                                                 n  n œÜx (bn )
                                                                                                                    2N
b œÅN                           bŒ∫                                 N N +2
                                                                                          bŒ∫
                          b
n  n œÜx (bn )C2     Œ¥          n                              ‚â§n
                                                               b œÅn 2      CŒ¥             n
                          an            log n
                                            b                                        œÅN
                                                                                      n                log n
                                                                                                           b
                                                                                                                # N (3+2Œ∫)‚àíŒ∏
                                                                                     N ‚àíŒ∏                Œ∏‚àíN
                                                                "
                                                                                                                    2N
                                                              ‚â§C nb œÅN
                                                                     n œÜx (bn )                  b ) N (3+2Œ∫)‚àíŒ∏
                                                                                 N (3+2Œ∫)‚àíŒ∏ (log n




which tends to 0 as n ‚Üí since Œ∏                        > N (3 + 2Œ∫).            Therefore, (29) follows, which
conclude the proof of Lemma 4. ‚ñ°




Appendix A.2.4. Proof of Lemma 5

Since Yi and r are bounded, we have


                               Ô£Æ                             Ô£π
                            1 X
  E1/2 [C] ‚â§         E1/2 Ô£∞     Yi ‚àí r(x) 1P               Ô£ª
                            n
                            b                i‚ààVi Wni (x)=0
                                      i‚ààVi0                                0

                                    "                                 #          Ô£´ Ô£Æ                                 Ô£πÔ£∂1/2
                                                                                               X
               ‚â§     2M E1/2 1P                                         = 2M Ô£≠P Ô£∞                    Ki (x) = 0Ô£ªÔ£∏
                                                i‚ààVi Wni (x)=0
                                                    0                                          i‚ààVi0
                               Ô£´ Ô£Æ                          Ô£πÔ£∂1/2
                                                                                    1/2
                                        X                an Ô£ªÔ£∏              1
               ‚â§     2M Ô£≠P Ô£∞                    Ki (x) ‚â§          =O                      ,
                                                          2            b œÅN
                                                                       n  n œÜx (bn )
                                      i‚ààVi0



by Lemma 4. ‚ñ°



                      Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                                               423



Appendix A.2.5. Proof of Lemma 6
                                                                     2 -                                   2
                                                             1                                   1
                                          P                                       P
Firstly, we deal with In (x) =                i‚ààVi E        an Ki (x)         ‚àí     i‚ààVi0       an E(Ki (x))        .
                                                 0


                        "               2 #
             X                1                           1 X 2  2       
                    E           Ki (x)           ‚â§ C      2
                                                             K2i E K1i (x)
                             an                          an
            i‚ààVi0                                             i‚ààVi0

                                                          1 X
                                                 ‚â§ C          kn œÜx (bn )
                                                         a2n
                                                              i‚ààVi0

                                                           C                         ‚àí1
                                                                        nœÅN
                                                                                        
                                                 ‚â§                 = O [b n œÜx (bn )]     ,
                                                       kn œÜx (bn )

for n suciently large.
                                           ‚àí1
                                              
Then, we have In (x) = O    nœÅN
                           [b   n œÜx (bn )]     . We now treat the term Rn (x). Since
the functions K1 (.) and K2 (.) are bounded, applying Lemma 1, we get


                                                         K2i K2k
                    |E [Œõi (x)Œõk (x)] |         ‚â§    C           œà(1, 1)Œ≥(‚à•i ‚àí k‚à•).
                                                           a2n

Let   En be a sequence of real numbers tending to ‚àû as n      b ‚Üí ‚àû. Set T =
{i, k ‚àà Vi0 , ‚à•i ‚àí k‚à• ‚â§ En } and denote by T c the complementary of T . Let
  (1)    P                                (2)   P
Rn =        i,k‚ààT |E [Œõi (x)Œõk (x)]| and Rn   =  i,k‚ààT c |E [Œõi (x)Œõk (x)]|. Hence,
              (1)         (2)
Rn (x) ‚â§ Rn + Rn . Moreover, using the same arguments     as in the proof of
                                                   ‚àí1
                                                      
                                      nœÅN
Lemma 4, we have In (x) + Rn (x) = O [b n œÜx (bn )]     .        ‚ñ°


Appendix A.2.6. Proof of Theorem 2
                                                                      1/s
      Recall that Ki (x) = K1i K2i . Set Tn = (nÃÇun )                       where


                                           N
                                           Y
                                  un =          (log ni )(log log ni )1+Œµ ,
                                           i=1

and dene

                                  1 X                                1 X
              gn (x)         =           Yi Ki (x),        fn (x) =         Ki (x),
                                 an                                 an
                                    i‚ààOn                               i‚ààOn
                                  1 X
              gen (x)        =           Yi 1{Yi ‚â§Tn } Ki (x).
                                 an
                                    i‚ààVi0


Then, we can write


                                  r(x)             1
         rn (x) ‚àí r(x) = ‚àí              A1 (x) +        [A2 (x) + A3 (x) + A4 (x)] ,                           (30)
                                 fn (x)          fn (x)

                        Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

424                                      Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

where

                                A1 (x)       =   fn (x) ‚àí 1,
                                A2 (x)       =      gn (x)) ‚àí r(x),
                                                 E (e
                                A3 (x)       =   gen (x) ‚àí E (e
                                                              gn (x)) ,
                                A4 (x)       =   gn (x) ‚àí gen (x).
Therefore Theorem 2 follows from (30) and Lemmas 7, 8, 9, 12. ‚ñ°

Lemma 7. Under assumptions H1-H4 and H6,
                                                                s                  !
                                                                        log n
                            gn (x)) ‚àí r(x)| = O bn +
                    sup |E (e
                                                                            b
                                                                        N
                                                                                       .
                    x‚ààD                                              b œÅn Œì(bn )
                                                                     n


Proof of Lemma 7
      Since

          gn (x)) ‚àí r(x)
       E (e
                   1      X                           
         =                 E Yi ‚àí Yi 1{|Yi |>Tn } Ki (x) ‚àí r(x)
              an œÜx (bn )
                           i‚ààVi0

               1 X                           1 X                       
         =         E [E (Yi |Xi ) Ki (x)] ‚àí     E Yi 1{|Yi |>Tn } Ki (x) ‚àí r(x)
              an                            an
                  i‚ààVi0                                 i‚ààVi0

               1 X                               1 X                       
         =         E [(r(Xi ) ‚àí r(x)) Ki (x)] ‚àí     E Yi 1{|Yi |>Tn } Ki (x) ,
              an                                an
                  i‚ààVi0                                         i‚ààVi0

we have

                                          1 X
              gn (x)) ‚àí r(x)|
          |E (e                     ‚â§         E [|r(Xi ) ‚àí r(x)| Ki (x)]
                                         an
                                             i‚ààVi0

                                          1 X                          
                                    +        E |Yi | 1{|Yi |>Tn } Ki (x) := I + II.
                                         an
                                             i‚ààVi0

Using assumptions         H1 and H2, we have
      |r(Xi ) ‚àí r(x)| ‚â§       sup       |r(x) ‚àí r(u)| = O(bn ), so that I = O (bn ) .
                           u‚ààB(x,bn )

For II, since s > 2, using Assumption            H4 and H6, we can write
                   Tn1‚àís    X            sTn1‚àís X                s
         II   ‚â§                    E [|Yi | Ki (x)] ‚â§ E [E (|Yi | |Xi ) Ki (x)]
                 an                         an
                     i‚ààVi0                      i‚ààVi0
                                             s              !
                   1‚àís
                           
                                  ‚àí1/2
                                                 log n
              ‚â§ CTn = o (b
                                                       b
                             nun )       =o                   ,
                                               b œÅN
                                               n   n Œì(bn )

which conclude the proof of Lemma 7. ‚ñ°



                     Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                               425



Lemma 8. If Assumption (H6) (i) holds, then
                                     sup |gn (x) ‚àí gen (x)| = 0
                                    x‚ààD

for suciently large n.

Proof of Lemma 8
                                  1/s
   Recall that Tn = (nÃÇun )             and note that

                                                1 X
                         gn (x) ‚àí gen (x) =         Yi 1{|Yi |>Tn } Ki (x).
                                               an
                                                   i‚ààVi0

                                                           ‚àís
By the Markov inequality, P (|Yi | > Tn ) ‚â§ Tn                  E|Yi |s for any i ‚àà ZN . Therefore
                            X                               X         1
                                  P (|Yn | > Tn ) ‚â§ C                     < ‚àû.
                                                                    nÃÇu n
                           n‚ààZN                             n‚ààZ   N



The Borel-Cantelli lemma ensures that almost surely |Yi | ‚â§ Tn for suciently large
n. Since Tn ‚Üí ‚àû as n ‚Üí ‚àû, we have almost surely |Yi | < Tn for all i ‚àà Vi0 and
for n suciently large enough, and thus the conclusion follows. ‚ñ°

Lemma 9. Under the assumptions of Theorem 2,
                                                                          1/2 !
                                                              log n
               sup |e
                    gn (x) ‚àí E (e                                                   a.s
                                                                  b
                                gn (x))| = O
              x‚ààD                                          b œÅN
                                                           n  n Œì(b n)


   Dene
                                                                                 
               Œõ
               e i (x)      =   Yi 1{|Yi |‚â§Tn } Ki (x) ‚àí E Yi 1{|Yi |‚â§Tn } Ki (x) ,

               1    X                 
                                            en (x) = 1
                               e i (x)2 and R
                                                         X h               i
     Ien (x) = 2            E Œõ                           E Œõ       e j (x) .
                                                             e i (x)Œõ                           (31)
              an                                     a2n
                    i‚ààVi0                                           iÃ∏=j


Then, arguing as in the proof of Lemma 6 with œÜi,x (bn ) replacing by Œì(bn ), one
can prove under assumptions             H1-H2, H4-H6 that,
                                                           
                                                   1
               Ien (x) + R
                         en (x) = O                                for any x ‚àà D.               (32)
                                              b œÅN
                                              n  n Œì(bn )

Let us dene
       s
              log n                                 N        ‚àí1
                       and choose ‚Ñìn ‚â§ C‚Ñ¶n œÜx (bn )œÅn Œì(bn )Tn
                  b
‚Ñ¶n =          N
                                                                for some constant C > 0.
           b œÅn Œì(bn )
           n

We suppose that the compact set D is covered with vn cubes Bk having sides of
length ‚Ñìn and centered at xk . We have



                    Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

426                                     Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom




                         gn (x) ‚àí E (e
                    sup |e           gn (x))| ‚â§ Q1n + Q2n + Q3n ,                        (33)
                    x‚ààD

where

                     Q1n     =                gn (x) ‚àí gen (xk )| ,
                                     max sup |e
                                 1‚â§k‚â§vn x‚ààBk

                     Q2n     =                   gn (xk )) ‚àí E (e
                                     max sup |E (e              gn (x))| ,
                                 1‚â§k‚â§vn x‚ààBk

                     Q3n     =                gn (xk ) ‚àí E (e
                                     max sup |e             gn (xk ))| .
                                 1‚â§k‚â§vn x‚ààBk

Lemma 10. Under Assumptions H1, H2 and H4, Q1n = O (‚Ñ¶n ) and Q2n =
O (‚Ñ¶n ) a.s.

Proof of Lemma 10
      By Assumptions       H1, H2 and H4, for all x ‚àà Bk ,
   gn (x) ‚àí gen (xk )| ‚â§ a‚àí1
  |e                      n œÜx (bn )  œÅn Œì(bn )‚àí1 Tn ‚à•x ‚àí xk ‚à•
                                    ‚àí1 ‚àíN

                                          ‚â§ CœÜi,x (bn )‚àí1 œÅ‚àíN
                                                           n Œì(bn )
                                                                   ‚àí1
                                                                      Tn ‚Ñìn = O (‚Ñ¶n ) a.s.
and Lemma 10 follows. ‚ñ°

      Next, we have to show that

                                      Q3n = O (‚Ñ¶n ) a.s.                                 (34)

Dene
                                          X
               Sen (x) = a‚àí2
                          n œÜx (bn )
                                     ‚àí2           e i (x) = gen (x) ‚àí E (e
                                                  Œõ                      gn (x)) .
                                          i‚ààVi0

           e (i, n, x, j) and Te(n, x, i) to be the same as U (i, n, j, x) and T (n, i, x)
Dene also U
                                                    e j . Arguing that Sen is a
in the proof of Lemma 4 except with Œõj replacing by Œõ
                 e(n, x, i), then showing (34) is equivalent to show that
nite sum of the T


                             max      Te(n, xk , 1) = O (‚Ñ¶n ) a.s.                       (35)
                            1‚â§k‚â§vn

                                 e(n, 1, x) is the sum of qb = q1 √ó ¬∑ ¬∑ ¬∑ √ó qN
By same arguments as in Lemma 4, T
of the UÃÉ (i, n, j, x)'s which are measurable with œÉ -eld generated by Xi , where i
belong to the set of sites which are separated by a distance at least p. Enumerate
these random variables as Z1 , . . . , Zqb and approximate them by the independent
                       ‚àó         ‚àó
random variables Z1 , . . . , Zqb as was done in Lemma 1. Dene


                                     p ‚àº ‚Ñ¶‚àí1/N
                                          n    Tn‚àí1/N ,
and

                       Œ≤en = Tn œÅ‚àíN
                                 n Œì(bn )
                                          ‚àí1
                                               n, pN )p‚àíŒ∏ ‚Ñ¶‚àí1
                                             œà(b           n .


                    Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

Nonparametric Prediction for Spatial Dependent Functional Data...                                        427



Lemma 11. Under assumptions of Theorem 2, there exist two positive constants
A and C such that, for any Œª > 0,
                                         h           i
                       e                 bŒ≤ n
           P max T (n, xk , i) > Œª‚Ñ¶n ‚â§ C n   b ‚àíA + Œ≤en .
                       1‚â§k‚â§vn


Proof of Lemma 11
                              Pqb
              e(n, x, i) =
        Since T                   i=1 Zi , we have, for any Œª > 0,
                                         qb                                        qb
                                                                         !                               !
                                       X                                         X
P       Te(n, x, i) > Œª‚Ñ¶n ‚â§ P                   |Zi ‚àí Zi‚àó | > Œª‚Ñ¶n /2         +P          Zi‚àó > Œª‚Ñ¶n /2 .
                                          i=1                                      i=1

By the boundedness of the functions K1 and K2 respectively, we have
                                                                                    ‚àí1
                     |Zi | ‚â§ CpN Tn a‚àí1
                                     n œÜx (bn )
                                               ‚àí1
                                                           b œÅN
                                                  ‚â§ CTn pN n  n Œì(bn )                     .
                        N N
          b=2
Note that n     p qb. Therefore Markov inequality gives: for any Œª > 0,
  qb
                      !
  X
            ‚àó
                                               ‚àí1
P    |Zi ‚àí Zi | > Œª‚Ñ¶n ‚â§ 2b          b œÅN
                            q pN Tn n  n Œì(bn )      n, pN )œá(p)Œª‚àí1 ‚Ñ¶‚àí1
                                                   œà(b               n ‚â§ C Œ≤n .
                                                                           e
        i=1

By Lemma 32, we get, for any Œª > 0, there exists a constant C > 0 such that

                                        qb
                                                          !
                                        X
                                  P           Zi‚àó > Œª‚Ñ¶n          b ‚àíA ,
                                                              ‚â§ Cn
                                        i=1

and the conclusion follows. ‚ñ°



Proof
P     of Lemma 9                      Note that by the Fubini's theorem, it can be seen that

    n‚ààZN         nun ) < ‚àû. By (33), Lemma 10 , and Lemma 11, proving Lemma 9 is
              1/(b
equivalent to show that

                          n    b Œ≤‚àíA ‚Üí 0 and n
                          b un n                  b Œ≤ Œ≤en ‚Üí 0 as n ‚Üí ‚àû.
                                             b un n                                                      (36)


        Note that, the rst part of (36) holds by choosing A such that A > Œ≤ + 2. For
                                                           N
its second part, when (8) is satised, œà(b
                                         n, p                  ) = pN for n large enough. Then
                                    1/s+1 ‚àíN                          (Œ∏‚àíN )/sN
         b Œ≤+1 un Œ≤en ‚â§ C n
         n                b Œ≤ (b
                               nun )     œÅn Œì(bn )‚àí1 ‚Ñ¶n
                                                      (Œ∏‚àí2N )/N
                                                                 nun )
                                                                (b
                                                                                                 sN +Œ∏
                                                                   ‚àíŒ∏         ‚àíŒ∏          Œ∏‚àí2N
                 b Œ≤+1/s+1+(Œ∏‚àíN )/(sN )+(2N ‚àíŒ∏)/(2N ) œÅn 2 Œì(bn ) 2N (log n
              = Cn                                                        b ) 2N un sN
                 h                              i 2sN (Œ≤+2)+Œ∏(2‚àís)
                                                         2sN
              = C nb œÅN Œ∏1    Œ∏1
                      n Œì(bn ) (log nb )Œ∏2 uŒ∏n3                    ,

which goes to zero when Œ∏ > (2N s(Œ≤ + 2)) / (s ‚àí 2).
                                                               N        b Œ∫ for n large enough. Then,
Similarly, when (9) is satised, we have œà(b
                                           n, p                    ) ‚â§ Cn
                                                                   Œ∏‚àíN
          n                b Œ≤+Œ∫ œÅ‚àíN
          b Œ≤+1 un Œ≤en ‚â§ C n      n Œì(bn )
                                           ‚àí1 1+Œ∏/N
                                             Tn     ‚Ñ¶n N
                                                                   ‚àíN ‚àíŒ∏         Œ∏‚àíN  N +Œ∏
                  b Œ≤+Œ∫+(N +Œ∏)/(sN )+(N ‚àíŒ∏)/(2N ) œÅN
               = Cn                                      n Œì(bn )
                                                                     2N
                                                                               b ) 2N unsN
                                                                          (log n
                                Œ∏1‚àó                 i N (2sŒ≤+2sŒ∫+s+2)+Œ∏(2‚àís)
                                             Œ∏2‚àó Œ∏3‚àó
                  h                                              2sN
               = C nb œÅN
                       n Œì(b n )     (log n
                                          b )   un                             ,


                        Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

428                                     Mamadou Ndiaye, Sophie Dabo-Niang & Papa Ngom

which goes to zero when          Œ∏ > (N (2sŒ≤ + 2sŒ∫ + s + 2)) / (s ‚àí 2) and Lemma 9
follows. ‚ñ°


Lemma 12. Under Assumptions H1, H2, H4 and H5,
  1. if (8) is satised and
                               Œ∏ 4         Œ∏
                 b œÅN
                 n  n Œì(bn )               b ) 5 uŒ∏n6 ‚Üí ‚àû with Œ∏ > 2N (Œ≤ + 2),
                                      (log n

  2. or if (9) is satised and
                         Œ∏4‚àó          ‚àó
                                          Œ∏‚àó
              b œÅN
              n  n Œì(bn )          b )Œ∏5 un6 ‚Üí ‚àû with Œ∏ > N (2Œ≤ + 2Œ∫ + 3),
                              (log n

then,
                                                                  1/2 !
                                                        log n
                     sup |fn (x) ‚àí 1| = O                                   a.s,
                                                            b
                     x‚ààD                             b œÅN
                                                     n  n Œì(b n)

where
            Œ∏                  Œ∏ ‚àí 2N                 2N
Œ∏4 =                  Œ∏5 =                 Œ∏6 =                 ,
      Œ∏ ‚àí 2N (Œ≤ + 2)       2N (Œ≤ + 2) ‚àí Œ∏        2N (Œ≤ + 2) ‚àí Œ∏
            ‚àíN ‚àí Œ∏                     Œ∏‚àíN                          2N
Œ∏4‚àó =                      Œ∏5‚àó =                       Œ∏6‚àó =                     .
      N (2Œ≤ + 2Œ∫ + 3) ‚àí Œ∏        N (2Œ≤ + 2Œ∫ + 3) ‚àí Œ∏         N (2Œ≤ + 2Œ∫ + 3) ‚àí Œ∏

Proof of Lemma 12
      To prove Lemma 12, just adapt the arguments considered in the proof of
Lemma 9 to the case where Yi ‚â° 1 and Tn = 1.



Appendix A.2.7. Proof of Theorem 3
      This result is derived directly from the proof of Theorem 1 where the regression
r is replaced with pj and for the particular response variable 1[Y =j] , we remark
that pj (x) = E(1[Y =j] |X = x) = P (Y = j|X = x).



Appendix A.2.8. Proof of Theorem 4
      This result is derived directly from the proof of Theorem 2 when the regression
r is replaced with the posterior probability pj and for the particular response
variable 1[Y =j] allows us to get the result.




                   Revista Colombiana de Estad√≠stica - Theorical Statistics 45 (2022) 391-428

