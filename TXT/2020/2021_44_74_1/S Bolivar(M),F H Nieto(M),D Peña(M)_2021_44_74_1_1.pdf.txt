On a New Procedure for Identifying a Dynamic Common Factor Model. Sobre un nuevo procedimiento para identiÔ¨Åcar un modelo de factores comunes din√°micos
Pontificia Universidad Javeriana, Bogot√°, Colombia.  Universidad Nacional de Colombia, Bogot√°, Colombia. Universidad Carlos III de Madrid, Madrid, Espa√±a
Abstract
In the context of the exact dynamic common factor model, canonical correlations in a multivariate time series are used to identify the number of latent common factors. In this paper, we establish a relationship between canonical correlations and the autocovariance function of the factor process, in order to modify a pre-established statistical test to detect the number of common factors. In particular, the test power is increased. Additionally, we propose a procedure to identify a vector ARMA model for the factor process, which is based on the so-called simple and partial canonical autocorrelation functions. We illustrate the proposed methodology by means of some simulated examples and a real data application.
Key words: Canonical correlations; Dynamic common factors; Multivariate time series.
Resumen
En el contexto del modelo exacto de factores comunes din√°micos, las correlaciones can√≥nicas en series de tiempo multivariadas son usadas para identiÔ¨Åcar el n√∫mero de factores latentes. En este art√≠culo, establecemos la relaci√≥n entre correlaci√≥n can√≥nica y la funci√≥n de autocovarianza del proceso de los factores, con el Ô¨Ån de modiÔ¨Åcar una prueba estad√≠stica dise√±ada para identiÔ¨Åcar el n√∫mero de factores comunes. En particular, se incrementa la potencia de la prueba. Adicionalmente, proponemos un procedimiento para identiÔ¨Åcar el modelo VARMA para el proceso de los factores, el cual est√° basado en lo que denominamos las funciones de autocorrelaci√≥n simple y parcial. Ilustramos la metodolog√≠a propuesta por medio de ejemplos simulados y una aplicaci√≥n con datos reales.
Palabras clave: Correlaci√≥n can√≥nica; Factores comunes din√°micos; Series de tiempo multivariadas.


1. Introduction
   The dynamic common factor model is of interest when an observable
multivariate stochastic process {yt }, of dimension m, is generated by an
unobservable stochastic process {ft }, of dimension r, with r < m, via the equation

                                     yt = Pft + Œµt ,                                    (1)

where {Œµt } is a multivariate stationary noise process of dimension m, with mean
0 and variance Œ£Œµ , and P is an m √ó r matrix, known as the loading matrix or the
weight matrix. The components of the ft vector are the common factors of the yt
data vector, while Œµt contains their speciÔ¨Åc or idiosyncratic components. A crucial
aspect in the analysis of this type of models is the identiÔ¨Åcation of r, the number
of common factors. Several studies have been carried out in this sense, mainly in
the high-dimension scenario, in which it is assumed that m goes to inÔ¨Ånity. For
complete details, see the papers, among others, of Stock & Watson (2011), Lam
& Yao (2012), Ahn & Horenstein (2013), and their associated references.
    This paper is based on the low-dimension approach (Ô¨Åxed m) proposed by Pe√±a
& Box (1987) (from this point forward Pe√±a-Box model), when the {ft } process is
stationary and {Œµt } is white noise, which is known as the Exact Dynamic Factor
Model (EDFM) because its speciÔ¨Åc components are orthogonal processes. Pe√±a
& Poncela (2006) extend this paper to the case where {ft } is non-stationary and
design a statistical test to specify r. This statistical test is a function of the
canonical correlations between yt and yt‚àík , for some lag k, k = 1, 2, . . . Under
the null hypothesis of r factors, the authors show that this statistic is distributed
asymptotically as a œá2(m‚àír)2 , for each lag k. Nevertheless, as is shown in Section
2, at each lag k the test detect the rank of the covariance matrix of ft and ft‚àík ,
but this matrix may not have full rank. Then, this alternative may detects less
than r common factors, which imply that the power of the test is reduced. Indeed,
let us consider this example: let ft = (f1t , f2t )‚ä§ , where f1t = a1t + Œ∏1 a1,t‚àí1 and
                                                                          (1)

              (2)
f2t = a2t + Œ∏3 a2,t‚àí3 , with {ait }, i = 1, 2, white noise processes. The number of
factors is 2 but the rank of matrix Cov(ft , ft‚àík ) is 1 if k = 1 or k = 3 and zero
otherwise. This fact makes that the Pe√±a & Poncela‚Äôs (2006) test does not detect
the correct number of factors at any lag k = 1, 2, . . .
    In this paper, we develop a modiÔ¨Åcation of the Pe√±a & Poncela‚Äôs (2006)
statistical test, which avoids the low-power problem quoted above. Essentially,
the idea is to use in the calculation of the test statistic, the canonical correlations
between yt and a linear combination of some lagged vectors yt‚àíi , for i ‚àà {1, 2, . . .}.

                   Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

On a New Procedure for Identifying a Dynamic Common Factor Model                                            3

Also, we propose a methodology to identify ARMA models for the factor processes,
using the canonical and partial canonical correlation to identify the dependence
orders of the factor models. We only consider the case in which {ft } is stationary.
   It is important to highlight that in the Pe√±a-Box model the observed data
vector yt depends on ft contemporaneously. Then, the model is known as the
DFM in static form. In the DFM in dynamic form, initially proposed by Geweke
(1977) (cited by Stock & Watson (2016); Doz & Fuleky (2020)), the vector of
observed time series can also depend on diÔ¨Äerent lags of the common factors.
Therefore, our contributions are based on the DFM in the static form.
    The paper is organized as follows. Section 2 presents the basic results that
relate canonical correlations to the marginal autocovariance functions of the factors
processes and their use in the modiÔ¨Åcation of Pe√±a & Poncela‚Äôs (2006) statistical
test. In section 3, we present a procedure to identify the ARMA factor models.
Section 4 includes some simulated examples and an empirical application to
precipitation data in Colombia. Section 5 concludes.


2. An Extension of the Statistical Test
     For each t, let ft = (f1t , . . . , frt )‚ä§ , where ‚ä§ denotes the matrix transpose
operation, and let Œ≥i (k) be the i-th component on the diagonal of the
autocovariance matrix of {ft } at lag k. Following Nieto et al.‚Äôs (2016) assumptions,
in particular that the marginal processes {fit } and {fjt } are orthogonal for all
i, j = 1, 2, . . . , r, with i Ã∏= j, the components outside of the diagonal are zero.
                                    ‚ä§
In addition, the restriction P Œ£‚àí1     Œµ P = Ir is imposed to solve the identiÔ¨Åcation
problem (Pe√±a & Poncela 2006), where In is the n √ó n identity matrix. The
remaining notation will be deÔ¨Åned as new deÔ¨Ånitions are introduced.
   From Pe√±a & Poncela‚Äôs (2006) paper, we consider the random matrix
          Ô£Æ                   Ô£π‚àí1                    Ô£Æ                       Ô£π‚àí1
               X
               T                     X
                                     T                     X
                                                           T                        X
                                                                                    T
 c(k) = Ô£∞
 M                    (yt yt‚ä§ )Ô£ª                 ‚ä§
                                            (yt yt‚àík )Ô£∞                  ‚ä§
                                                                  (yt‚àík yt‚àík )Ô£ª            (yt‚àík yt‚ä§ ),   (2)
              t=k+1                 t=k+1                 t=k+1                    t=k+1

where T denotes the sample size of an observed multivariate time series of the
process {yt }, and the statistic

                                                      X
                                                      m‚àír
                           Sm‚àír (k) = ‚àí(T ‚àí k)                          bj (k)),
                                                                log(1 ‚àí Œª                                 (3)
                                                          j=1


where Œª b1 (k) ‚â§ Œª                 bm (k) are the ordered eigenvalues of the matrix
                  b2 (k) ‚â§ ¬∑ ¬∑ ¬∑ ‚â§ Œª
c
M (k), for a given lag k = 1, 2, . . . The limit distributions of these statistics are
obtained by Pe√±a & Poncela (2006). In particular, they Ô¨Ånd that, when the process
{ft } is stationary, the limit matrix of the sequence Mc(k) is

                         ‚àí1                                   ‚àí1
                                   ‚ä§
M (k) = P E[ft ft‚ä§ ]P ‚ä§+Œ£Œµ P E[ft ft‚àík                ‚ä§
                                       ]P ‚ä§ P E[ft‚àík ft‚àík ]P ‚ä§+Œ£Œµ P E[ft‚àík ft‚ä§ ]P ‚ä§ .


                        Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

4                                      Stevenson Bol√≠var, Fabio H. Nieto & Daniel Pe√±a


    Before establishing our main results, it is worth noticing the following fact: in
Pe√±a & Poncela‚Äôs (2006) Theorem 3, it is claimed that the limit matrix of the
sequence {M c(k)}, indexed by T , has rank r for all lags k. However, we have found
that for some models and some lags k the rank is less than r. As mentioned before,
let us consider this example: let ft = (f1t , f2t )‚ä§ , where f1t = a1t + Œ∏1 a1,t‚àí1 and
                                                                          (1)

              (2)
f2t = a2t + Œ∏3 a2,t‚àí3 , with {ait }, i = 1, 2, white noise processes. The number of
                                             ‚ä§
factors is 2, but the rank of matrix E[ft ft‚àík   ] is 1 when k = 1 or k = 3 and zero
otherwise. This fact makes that the rank of the limit matrix in Pe√±a & Poncela‚Äôs
(2006) Theorem 3 depends on k. From now on, we denote the rank of that matrix
as r(k), k = 1, 2, . . .
    To avoid this drawback of the methodology, we propose the following results.

Proposition 1. Let {ft } be a stationary stochastic process, then, given the lag k,
the r(k) ‚â§ r non-zero eigenvalues of M (k) belong to the set
                                                                         
                                           |Œ≥j (k)|
            Œõ(k) := ¬µj (k) ‚àà R : ¬µj (k) =
                       2
                                                     , j = 1, 2, . . . , r ,    (4)
                                          Œ≥j (0) + 1

where ¬µj (k) is a canonical correlation between yt and yt‚àík , with respective
canonical variables a‚ä§         ‚ä§
                     j yt and bj yt‚àík where

                    ‚àí1
                    Œ£ Œµ Pj
        bj =                   ‚àà Rm           and          aj = sign{Œ≥j (k)}bj .        (5)
               (Œ≥j (0) + 1)1/2

Here R and Rm denote, respectively, the set of real numbers and the m-
dimensional real Euclidean space and Pj is the j-th column of the load
matrix P .

Proof . See Appendix A.1.

     Note that the largest value of the set Œõ(k) is the Ô¨Årst canonical correlation, the
second largest value of Œõ(k) is the second canonical correlation and so on up to the
r(k)-th canonical correlation (Anderson 1984). Additionally, note that r(k) = r if
|Œ≥j (k)| > 0 for all j = 1, . . . , r and the m ‚àí r remaining canonical correlations are
equal to zero.
    An important implication of Proposition 1 is the following: if for a given k Ã∏= 0,
Œ≥i (k) = 0 for some i = 1, . . . , r, then, at this lag, there is a maximum of r ‚àí 1 non-
zero canonical correlations. This fact is in line with the above comment about
the loss of power of the test. In order to improve the performance of Pe√±a &
Poncela‚Äôs
       X (2006) test, we propose to use the canonical correlations between yt and
yt‚Ä† =     yt‚àík , where K is a set of lags (not necessarily consecutive). To obtain K,
     k‚ààK
we propose the following two-step procedure: Ô¨Årst, we run Pe√±a and Poncela‚Äôs test
for lags k = 1, 2, . . . , k0 , for some k0 . Then, a lag k ‚àà K if the Pe√±a & Poncela‚Äôs
(2006) test detects at least one common factor at it. In the examples below, we
will give more suggestions to obtain K in practice.

                   Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

On a New Procedure for Identifying a Dynamic Common Factor Model                                                        5

                                                                    ‚ä§       ‚àí1
Proposition 2. Given K and the restriction P Œ£Œµ P = Ir , the r non-zero square
canonical correlations between yt and yt‚Ä† belong to the set
                Ô£±                                                                                             Ô£º
                Ô£≤                                             |Œ≥j (K)|                                        Ô£Ω
    ‚Ä†                             ‚Ä†
  Œõ (K) :=           j (K) ‚àà R : ¬µj (K) =
                    ¬µ2‚Ä†                                                               , j = 1, 2, . . . , r       ,   (6)
                Ô£≥                               (Œ≥j (0) + 1)1/2 (Œ≥‚Ä† + k‚Ä† )1/2                                 Ô£æ
                                                                        j


                                                               ‚Ä†‚ä§ ‚Ä†
and its respective canonical variables are given by b‚ä§
                                                     j yt and aj yt , with

                        ‚àí1                                                                      ‚àí1
                     Œ£ Œµ Pj                                                                  Œ£ Œµ Pj
         bj =                                 and             a‚Ä†j =sign{Œ≥j (K)}                           ,           (7)
                (Œ≥j (0) + 1)1/2                                                           (Œ≥j‚Ä† + k ‚Ä† )1/2
                                                              X                              X X
where k ‚Ä† is the cardinality of K, Œ≥j (K) =                         Œ≥j (k) and Œ≥‚Ä† =                           Œ≥j (|k2 ‚àí
                                                                                      j
                                                              k‚ààK                           k1 ‚ààK k2 ‚ààK
k1 |), j = 1, 2, . . . , r.

Proof . See Appendix A.2.

    Now, we deÔ¨Åne
                 Ô£Æ                    Ô£π‚àí1                      Ô£Æ                      Ô£π‚àí1
                      X
                      T                      X
                                             T
                                                          ‚ä§         X
                                                                    T
                                                                                  ‚ä§          X
                                                                                             T
   M ‚Ä† (K) = Ô£∞                (yt yt‚ä§ )Ô£ª             (yt yt‚Ä† ) Ô£∞            (yt‚Ä† yt‚Ä† )Ô£ª              (yt‚Ä† yt‚ä§ ),      (8)
                     t=kÃÑ+1                 t=kÃÑ+1                 t=kÃÑ+1                   t=kÃÑ+1


where kÃÑ = max K, and obtain the following result.
                                            X
                                  ‚ä§
Proposition 3. Let Œìf (k) = E[ft ft‚àík ]. If   Œìf (k) has rank r, then, as T goes
                                                              k‚ààK
to inÔ¨Ånity, the matrix sequence {M ‚Ä† (K)} converges in distribution to a constant
matrix that has rank r.

Proof . Using Q = Œ£‚àí1                                    ‚ä§               ‚ä§
                       Œµ [P P‚ä• ], where P‚ä• is such that P P‚ä• = 0 and P‚ä• P‚ä• =
Im‚àír , the proof follows the basic ideas in Pe√±a & Poncela‚Äôs (2006) paper (pages
1954-1955).

   Additionally, bearing in mind that the eigenvalues of M ‚Ä† (K) are the square
canonical correlations between yt and yt‚Ä† , we obtain the following proposition.

Proposition 4. Let ¬µb2‚Ä†
                     1 (K) ‚â§ ¬µb2‚Ä†              b2‚Ä†
                               2 (K) ‚â§ ¬∑ ¬∑ ¬∑ ‚â§ ¬µ m (K) be the ordered eigenvalues
                ‚Ä†
of the matrix M (K). Then, under the null hypothesis that the limit matrix in
Proposition 3 has m ‚àí r eigenvalues equal to zero, the asymptotic distribution of
the statistic
                                                           X
                                                           m‚àír
                              Sm‚àír (K) = ‚àí(T ‚àí kÃÑ)                         b2‚Ä†
                                                                   log(1 ‚àí ¬µ j (K))                                   (9)
                                                           j=1


is œá2(m‚àír)2 .

                         Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

6                                      Stevenson Bol√≠var, Fabio H. Nieto & Daniel Pe√±a


Proof . According to Proposition 2, there are m ‚àí r canonical correlations equal
to zero between yt and yt‚Ä† . This means that there are m ‚àí r linear combinations of
yt that are not correlated to m ‚àí r linear combinations of yt‚Ä† ; consequently, there
                                                  ‚ä§ ‚Ä†
are m ‚àí r regressions of the form a‚ä§     j yt = Wj yt + ut where Wj = 0m√ó1 for each
j = 1, . . . , m ‚àí r, where the aj ‚Äôs are the canonical vectors associated to the m ‚àí r
canonical correlations equal to zero. The rest of the proof follows the lines of the
corresponding result in Pe√±a & Poncela‚Äôs (2006) paper. We note that T ‚àí kÃÑ is the
number of observations that is used to compute the canonical correlations.

    Remark: To compute Œ≥j (K), we sum over all the lags in K the autocovariances
of the same jth factor (in the order established at the beginning of this section).
It may happen that we found autocovariances of the same absolute value but
diÔ¨Äerent sign and thus, Œ≥j (K) might be equal to zero, even if for some k ‚àà K,
Œ≥j (k) Ã∏= 0. Therefore, instead of using only the sum over all the lags in K, an
alternative is to use diÔ¨Äerent linear combinations to calculate yt‚Ä† . Indeed, to deÔ¨Åne
a linear combination, a lag in K is kept constant (1 is the coeÔ¨Écient) and the
coeÔ¨Écients corresponding to the other lags alternate between +1 and ‚àí1. In
              ‚Ä†
this way, 2(k ‚àí1) possible linear combinations can be analyzed. The main idea
behind the use of diÔ¨Äerent linear combinations yt‚Ä† is to avoid the cases, in which
the number of factors is underestimated; therefore, we propose to choose r as the
maximum number of factors detected with the diÔ¨Äerent linear combinations. The
examples below illustrate this point.
    In summary, the procedure for specifying r is the following:

STEP 1 Set the maximum number of lags k0 and run Pe√±a and Poncela‚Äôs test for
       lags k = 1, 2, . . . , k0 .
STEP 2 Set K such as a lag k ‚àà K if the Pe√±a and Poncela‚Äôs test detects at least
       one common factor at it, k = 1, 2, . . . , k0 .

STEP 3 DeÔ¨Åne the 2(k ‚àí1) possible linear combinations yt‚Ä† , keeping a lag constant
                        ‚Ä†


       (1 is the coeÔ¨Écient) and the coeÔ¨Écients corresponding to the other lags
       alternate between +1 and ‚àí1.
STEP 4 Run the test (4) with each linear combination yt‚Ä† and choose r as
       the maximum number of factors detected with the diÔ¨Äerent linear
       combinations.

    A simulated example
    To illustrate the issues remarked above about the statistical test performance,
we conduct a Monte Carlo experiment. The design of the simulation is the
following: we set m = 6 and r = 2 and consider the factor model




                   Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

On a New Procedure for Identifying a Dynamic Common Factor Model                          7
                                 Ô£Æ                   Ô£π
                                   1.00         0.00
                                 Ô£Ø 1.00         1.00Ô£∫
                                 Ô£Ø                   Ô£∫
                                 Ô£Ø                   Ô£∫
                                 Ô£Ø 0.00         1.00Ô£∫
                            yt = Ô£Ø                   Ô£∫ f t + Œµt ,                      (10)
                                 Ô£Ø 1.00         0.00Ô£∫
                                 Ô£Ø                   Ô£∫
                                 Ô£∞‚àí1.00         1.00Ô£ª
                                   0.00        ‚àí1.00

where ft = (f1t , f2t )‚ä§ , {Œµt } ‚àº W N (0, I6 ), f1t = a1t + 0.8a1,t‚àí1 and f2t =
a2t ‚àí 0.7a2,t‚àí3 , with {at = (a1t , a2t )‚ä§ } ‚àº W N (0, I2 ). We put T = 1000 and
simulate 1000 time series from the process {yt }. For each generated time series
and Ô¨Åxing a signiÔ¨Åcance level of 5%, Pe√±a and Poncela‚Äôs test was run sequentially
as a test on the maximum number of factors and we stop and identify r factors as
soon as the hypothesis is rejected, which will be denoted r‚Ä≤ from now on.
    Table 1 presents the percentage of times (in the cells) that the test identiÔ¨Åes r‚Ä≤
factors (columns) at each lag k (rows), k = 1, 2, . . . , 15. Clearly, we can see that
one common factor is identiÔ¨Åed at lags k = 1, 3 and zero factors at the other lags.

Table 1: Percentage of times that the test identiÔ¨Åes r‚Ä≤ factors in the simulated model.
                                 r‚Ä≤ = 0     r‚Ä≤ = 1     r‚Ä≤ = 2     r‚Ä≤ = 3
                        k=1         0.0      96.0         3.8        0.2
                        k=2       93.0         6.8        0.2        0.0
                        k=3         0.0      93.8         5.6        0.6
                        k=4       93.4         6.2        0.4        0.0
                        k=5       92.4         7.3        0.3        0.0
                        k=6       93.6         6.2        0.2        0.0
                        k=7       92.2         7.4        0.4        0.0
                        k=8       93.2         5.9        0.9        0.0
                        k=9       94.0         5.8        0.2        0.0
                        k = 10    93.2         6.7        0.1        0.0
                        k = 11    94.0         5.7        0.3        0.0
                        k = 12    94.4         5.6        0.0        0.0
                        k = 13    94.2         5.7        0.1        0.0
                        k = 14    93.7         6.2        0.1        0.0
                        k = 15    92.8         6.9        0.3        0.0


    For this model, we get K = {1, 3} with k ‚Ä† = 2; therefore, one have
22‚àí1 = 2 possible linear combinations. These are yt‚Ä† = yt‚àí1 + yt‚àí3 (1) and
yt‚Ä† = yt‚àí1 ‚àí yt‚àí3 (2). In Table 2 we present the results obtained using the two
linear combinations yt‚Ä† . We observe that r = 2 is clearly identiÔ¨Åed for any yt‚Ä† .

Table 2: Percentage of times that the proposed test identiÔ¨Åes r‚Ä≤ factors in the simulated
         model.

                  Linear combination      r‚Ä≤ = 0     r‚Ä≤ = 1     r‚Ä≤ = 2     r‚Ä≤ = 3
                          (1)                0.0        0.0      96.6         3.4
                          (2)                0.0        0.0      95.3         4.7



                   Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

8                                      Stevenson Bol√≠var, Fabio H. Nieto & Daniel Pe√±a


    In order to illustrate that the test proposed in this section stays valid even when
the covariance Œìf (k) is a full rank matrix for some lag k, we modiÔ¨Åed the factor
models in this example as follow: f1t = 0.8f1,t‚àí1 + a1t and f2t = ‚àí0.7f2,t‚àí3 + a2t .
Table 3 presents the percentage of times that the test identiÔ¨Åes r‚Ä≤ factors at each
lag k with this simulated AR model, k = 1, 2, . . . , 15.

Table 3: Percentage of times that the test identiÔ¨Åes r‚Ä≤ factors in the simulated model.
                                 r‚Ä≤ = 0     r‚Ä≤ = 1     r‚Ä≤ = 2     r‚Ä≤ = 3
                        k=1         0.0       76.0       23.5        0.5
                        k=2         0.0       78.8       20.7        0.5
                        k=3         0.0        0.0      95.5         4.3
                        k=4         0.0       78.4       21.4        0.2
                        k=5         0.0       79.8       19.4        0.8
                        k=6         0.0        1.4      94.5         3.9
                        k=7         4.8       79.7       15.4        0.1
                        k=8        13.3       75.6       10.9        0.2
                        k=9         0.0       30.0       68.2        1.8
                        k = 10     27.4       63.3        9.2        0.1
                        k = 11     37.4       56.0        6.5        0.1
                        k = 12      0.9       57.0       41.2        0.9
                        k = 13     45.0       50.4        4.6        0.0
                        k = 14     48.2       48.1        3.7        0.0
                        k = 15     10.3       66.4       23.3        0.0


   We can see that about 95% of times two common factor is identiÔ¨Åed at lags
k = 3, 6 and between one a two common factors at lags k = 1, 2, 4, 5.

Table 4: Percentage of times that the proposed test identiÔ¨Åes r‚Ä≤ factors in the simulated
         model.

                  Linear combination      r‚Ä≤ = 0     r‚Ä≤ = 1     r‚Ä≤ = 2     r‚Ä≤ = 3
                          (1)                0.0        0.0       96.1        3.8
                          (2)                0.0        0.0       95.9        4.1


    For this model, we use K = {1, 3} with k ‚Ä† = 2 with the two linear combinations
(1) yt‚Ä† = yt‚àí1 + yt‚àí3 (1) and (2) yt‚Ä† = yt‚àí1 ‚àí yt‚àí3 (2). In Table 4 we present the
results obtained using the two linear combinations yt‚Ä† . We observe that r = 2 is
clearly identiÔ¨Åed for any yt‚Ä† .


3. A Procedure for Identifying the Common-
   Factors Model
    Usually in practice, the factor models are identiÔ¨Åed using preliminary estimates
of the factor processes (see, among others, Pe√±a & Poncela‚Äôs (2006) and Nieto
et al.‚Äôs (2016) papers). However, if there is much uncertainty in these estimates, the
model identiÔ¨Åcation process might lead to wrong models. To avoid this problem,
we propose another alternative to the factors model identiÔ¨Åcation, which consists

                   Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

On a New Procedure for Identifying a Dynamic Common Factor Model                             9

in using the relationship between canonical correlations and the factor-processes
autocovariance function established in Proposition 1.
    The main idea is to plot the canonical correlations that are related to the
same factor against lag values. Because of Proposition 1, we plot at each lag the
absolute value of the autocovariance of factor fjt divided by the constant Œ≥j (0)+1,
for each j = 1, . . . , r. Loosely speaking, we plot a function that is proportional
to the absolute value of the autocorrelation function of the jth factor. For each
j = 1, . . . , r, we call the function that corresponds to the jth factor as the jth
canonical autocorrelation function (CACF).
    It is worth noticing that, when the canonical correlations are ordered in
descending way, given that each canonical correlation is proportional to the
autocovariance of a particular factor (see Proposition 1), a speciÔ¨Åc order is deÔ¨Åned
for the components of ft at each lag, but this ordering on the components of ft is
not necessarily the same at all lags. Then, to avoid this drawback, there are two
main goals to achieve. The Ô¨Årst one is to deÔ¨Åne a unique order for the components
of ft and the second, ordering at each lag the canonical correlations based on this
particular components order.
    From now on, we denote ¬µ2ji:k ‚àà Œõ(k) the ith squared canonical correlation
for a given lag k, in descending order of magnitude, and bji:k denote its related
eigenvector, where i = 1, 2, . . . , r(k) and ji:k ‚àà {1, 2, . . . , r}.
   Our proposal to deÔ¨Åne the same order for all lags is based on the following
lemmas.
Lemma 1. For any lag k, the canonical vector related to the factor fjt is given
by bj := (Œ≥j (0) + 1)‚àí1/2 Œ£‚àí1
                           Œµ Pj , j = 1, 2, . . . , r.

Proof . Let B = [b1 , b2 , . . . , br ] = Œ£‚àí1
                                           Œµ P (Œìf (0) + Ir )
                                                              ‚àí1/2
                                                                   , then
                  B ‚ä§ yt = B ‚ä§ (P ft + Œµt ) = (Œìf (0) + Ir )‚àí1/2 (ft + ŒΩt ),
where ŒΩt = P ‚ä§ Œ£‚àí1
                Œµ Œµt . Notice that {ŒΩt } is a white-noise process with mean 0(r√ó1)
and variance matrix Ir ; therefore, the canonical variables B ‚ä§ yt have covariance
matrix Ir and their associated canonical correlations are the absolute value of the
diagonal components of the matrix
                         ‚ä§
             E[B ‚ä§ yt , yt‚àík B] = (Œìf (0) + Ir )‚àí1/2 Œìf (k)(Œìf (0) + Ir )‚àí1/2 ,
as was shown in Proposition 1.
Lemma 2. Given the set of lags K, if P                              for all k ‚àà K
                                      bj is an eigenvector of M (k) P
then bj is an eigenvector of M S(K)1 = k‚ààK M (k), with eigenvalue k‚ààK ¬µ2j (k),.

Proof . Multiplying M S(K) by bj , we obtain
                       "          #     "          #
                         X                X
                                              2
                           M (k) bj =        ¬µj (k) bj .                                 (11)
                              k‚ààK                 k‚ààK


  1 A similar idea is applied in Lam & Yao‚Äôs (2012) paper to detect the number of factors.




                     Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

10                                                Stevenson Bol√≠var, Fabio H. Nieto & Daniel Pe√±a


    Based on Lemma 2, we propose to use as speciÔ¨Åc order of the components
of ft , the one speciÔ¨Åed by the eigenvalues of M S(K) ordered in descending
way. We denote as bj1:K , bj2:K , . . . , bjr:K their related eigenvectors, which are the
column vectors b1 , b2 , . . . , br deÔ¨Åned in Proposition 1, Lemma 1 and Lemma 2,
but rearranged according to the deÔ¨Åned order. Then, at each lag, we order the
canonical correlations by matching each one to the eigenvector of M S(K) that
is collinear to its canonical vector. That association is possible by means of
the cosine similarity between the eigenvectors of M S(K) with the eigenvectors
of M (k), which are the normalized canonical vectors. Hence, by Lemma 1, all
the canonical correlations that match with a particular eigenvector of M S(K) are
related to the same factor.
    This proposal, as stated in Proposition 5, is based on the fact that the sequence
of squared cosines of the angle between an eigenvector of M c(k) and an eigenvector
of MdS(K), indexed by T , converges in probability to 1 if they are related to the
same factor, otherwise it converges to 0.
Proposition 5. For any lag k ‚àà K, let bbji:K , bji:K , bbji:k and bji:k be the eigenvectors
associated to the ith non-zero largest eigenvalue of M      d S(K), M S(K), M    c(k) and
M (k), respectively. If M (k) has r(k) ‚â§ r eigenvalues diÔ¨Äerent of zero, then, as
T ‚Üí ‚àû, for i = 1, . . . , r and i‚Ä≤ = 1, . . . , r(k),
                                         !2                                 !2
                  bb‚ä§ bbj                               ‚ä§
                                                      bji‚Ä≤ :k bji:K                                 
                    ji‚Ä≤ :k i:K
                                              ‚Üí
                                              p
                                                                                 = cos2 Œ∏ji‚Ä≤ :k ji:K ,   (12)
                b
              ||bji‚Ä≤ :k || ||bbji:K ||            ||bji‚Ä≤ :k || ||bji:K ||

where Œ∏ji‚Ä≤ :k ji:K is the angle between bji‚Ä≤ :k and bji:K .

Proof . It follows using the consistency property of the estimators bbji‚Ä≤ :k and bbji:K ,
and the continuous mapping theorem.
                               
    Note that cos2 Œ∏ji‚Ä≤ :k ji:K takes its maximum value if bji‚Ä≤ :k and bji:K are collinear
to the same column vector of Œ£‚àí1   Œµ P ; hence, by Lemma 1, they are related to the
same particular factor. In this case, ji‚Ä≤ :k = ji:K .
   In our proposed methodology, we also deÔ¨Åne the partial canonical
autocorrelation function (PCACF), which, jointly with the CACF, let us identify
ARMA models for the factors, in a similar way to the Box-Jenkins methodology.
The main idea is to plot the partial canonical correlations that are related to the
same factor against lag values, based on the same order deÔ¨Åned on the CACF,
given that we face the same issues. We call the function that corresponds to the
jth factor as the jth partial canonical autocorrelation function (PCACF).
    To establish such deÔ¨Ånition, in Proposition 6 we show the relation between
partial canonical correlation and a modiÔ¨Åed partial autocorrelation of the latent
factors, in which we use Reinsel‚Äôs (1997) concept of partial canonical correlations
between two random vectors. To Ô¨Åx ideas, the partial canonical correlations
between yt and yt‚àík are the canonical correlations between yt and yt‚àík given yt‚àí1 ,
yt‚àí2 , ¬∑ ¬∑ ¬∑ , yt‚àík+1 and can be calculated as the non trivial canonical correlations
between [yt‚ä§ , yt‚àí1‚ä§            ‚ä§
                     , . . . , yt‚àík+1          ‚ä§
                                      ]‚ä§ and [yt‚àí1    ‚ä§
                                                   , yt‚àí2            ‚ä§ ‚ä§
                                                          , . . . , yt‚àík ] .

                        Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

On a New Procedure for Identifying a Dynamic Common Factor Model                                  11

                                                  ‚ä§
    Based on these ideas and being Yt;k = [yt‚ä§ , yt‚àí1            ‚ä§
                                                      , . . . , yt‚àík+1 ]‚ä§ , we obtain the
following result.

Proposition 6. Given a lag k, the rp (k) ‚â§ r partial canonical correlations
diÔ¨Äerent from zero between yt and yt‚àík are equal to the absolute values of the
                                  ‚àó       ‚àó
partial autocorrelation between fj,t and fj,t‚àík , j = 1, . . . , rp (k), with ft‚àó = ft + ŒΩt
and {ŒΩt } ‚àº W N (0, Ir ). Furthermore, the respective canonical variables are

          gj (k)‚ä§ Yt;k           and            hj (k)‚ä§ Yt‚àí1;k , j = 1, 2, . . . , rp (k),

with hj (k) = Œ≤j (k) ‚äó Œ£‚àí1
                         Œµ Pj ‚àà R
                                       km
                                               and gj (k) = Œ±j (k) ‚äó Œ£‚àí1
                                                                       Œµ Pj ‚àà R
                                                                                       km
                                                                                           , where
Œ±j (k) and Œ≤j (k) are the canonical vectors associated to the non trivial canonical
                          ‚àó    ‚àó                ‚àó
correlations between [fj,t  , fj,t‚àí1 , . . . , fj,t‚àík+1            ‚àó
                                                        ]‚ä§ and [fj,t‚àí1    ‚àó
                                                                       , fj,t‚àí2            ‚àó
                                                                                , . . . , fj,t‚àík ]‚ä§ .
Here, ‚äó denotes the Kronecker product.

Proof . See Appendix A.3.

    Because Proposition 6, on the PCACF we plot the absolute value of the partial
                                   ‚àó
autocorrelations of the processes fjt , for each j = 1, . . . , r. Loosely speaking, we
plot a function that shows the M A process behavior of the factors plus a noise
process in absolute value; therefore, if the variance of the added noise process
is negligible with respect to the variance of the factor we get the PACF of the
M A(qj ) process, otherwise an M A(pj + qj ) process is observed (Pe√±a 2010).
    It is worth noticing that, when the partial canonical correlations are ordered
in descending way, as in the CACF, a speciÔ¨Åc order is deÔ¨Åned for the components
of ft at each lag, but this ordering on the components of ft is not necessarily the
same at all lags. Then, using the same order deÔ¨Åne for the CACF, we order at
each lag the partial canonical correlations based on this particular components
order, as presented below.
    In what follows, let Œ∑ji:k (k) be the ith partial canonical correlation for a given
lag k, in descending order of magnitude, and let hji:k be its related eigenvector,
where i = 1, 2, . . . , rp (k) and ji:k ‚àà {1, 2, . . . , r}.
   Now, from Proposition 6, we note that for a given i, i = 1, 2, . . . , rp (k), the
coeÔ¨Écients of yt in the respective canonical variable form the vector hji:k [1 : m],
the m Ô¨Årst elements of the canonical vectors hji:k , which is collinear to one of
the columns of the matrix Œ£‚àí1    Œµ P . Therefore, a similar result to Proposition 5 is
obtained with the sequence of squared cosines of the angles between b    hji‚Ä≤ :k [1 : m],
a consistent estimator of hji‚Ä≤ :k [1 : m], and the previously deÔ¨Åned vector bbji:K ,
i = 1, 2, . . . , r. Hence, as in a similar way that in the CACF, we match all the
partial canonical correlations related to the same factor.
   Additionally, to test the number of rp (k) active factors on the partial canonical
correlations at lag k, we use the statistic

                                                       X
                                                       m
                Cm‚àírp (k) (k) = ‚àí(T ‚àí k ‚àí 1)                     log(1 ‚àí Œ∑bj2i:k (k)),         (13)
                                                    i=rp (k)+1



                      Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

12                                         Stevenson Bol√≠var, Fabio H. Nieto & Daniel Pe√±a


which is asymptotically a œá2(m‚àírp (k))2 , where the square partial canonical
correlations, Œ∑bj21:k (k) ‚â• Œ∑bj22:k (k) ‚â• ¬∑ ¬∑ ¬∑ ‚â• Œ∑bj2m:k (k), are the m smallest eigenvalues of
the matrix
          " T                 #‚àí1 T                     " T                   #‚àí1 T
            X                       X                     X                      X
Mcp (k) =                 ‚ä§
                 (Yt;k Yt;k )                   ‚ä§
                                        (Yt;k Yt‚àí1;k  )                ‚ä§
                                                             (Yt‚àí1;k Yt‚àí1;k )                 ‚ä§
                                                                                    (Yt‚àí1;k Yt;k ).
             k+1                   k+1               k+1                       k+1

For more details of the asymptotic distribution of this statistic see Reinsel
(1997), on the identiÔ¨Åcation stage in the scalar component models (SCM) of
Tiao & Tsay (1989).
    To use these ideas in practice, we propose the following methodology, which is
illustrated in the Ô¨Årst example of Section 4.

STEP 1 First, deÔ¨Åne the set K as the set of all lags k ‚â§ k0 , for a Ô¨Åxed k0 ‚â• 1,
       such that the Pe√±a-Poncela‚Äôs testP identify       at least one factor and get
                             d
       the r eigenvectors of M S(K) := k‚ààK M     c(k), related to the r maximum
       eigenvalues. Notice that the descending order of these eigenvalues deÔ¨Åne
       an speciÔ¨Åc order for the eigenvectors bbj1:K , bbj2:K , . . . , bbjr:K and by Lemma
       1 for the factors, which we propose to use as the unique order for all
       lags.
STEP 2 At each lag k, associate each canonical correlation to a particular
        factor via the association to a particular eigenvector of matrix M                d  S(K),
        according to Lemma 2.               For this purpose, start associating the
        estimated largest canonical correlation ¬µ            bj1:k (k) to one of the eigenvectors
       bbj , bbj , . . . , bbj , by selecting the one having the maximum cosine
          1:K   2:K           r:K

        similarity with its eigenvector bbj1:k , that is, the largest value of the
        squared cosine of the angle between both vectors (maximum correlation
        between two random canonical vectors). Similarly, to the next estimated
        canonical correlations ¬µ   bj2:k (k) ‚â• ¬µ     bj3:k (k) ‚â• ¬∑ ¬∑ ¬∑ ‚â• ¬µ bjr(k):k (k) assign one
        of the eigenvectors bbj1:K , bbj2:K , . . . , bbjr:K , but excluding eigenvectors that
        were already assigned to higher canonical correlations.
STEP 3 At each lag k, associate each partial canonical correlation to a particular
       factor via the association to a particular eigenvector of matrix M          d S(K).
       Follow the same ideas of the STEP 2, using the partial canonical
       correlations Œ∑bj1:k (k) ‚â• Œ∑bj2:k (k) ‚â• ¬∑ ¬∑ ¬∑ ‚â• Œ∑bjrp (k):k (k) and theirs respective
       eigenvectors bhj [1 : m], b
                             1:k
                                    hj [1 : m], . . . , b
                                            2:k
                                                        hj         [1 : m].
                                                               rp (k):k



STEP 4 For each i = 1, 2, . . . , r, plot the ith sample CACF deÔ¨Åned by œëbi (k, K) =
       bji:K (k), 0 < k < T , where ¬µ
       ¬µ                                  b2ji:K (k) is the ith eigenvalue of the matrix
       c(k), ordering on STEP 2.
       M
STEP 5 For each i = 1, 2, . . . , r, the ith sample PCACF deÔ¨Åned by œÜ         bi (k, K) :=
       Œ∑bji:K (k), 0 < k < T , where Œ∑bj2i:K (k) is the ith of the m smallest eigenvalues
       of the matrix M   cp (k), ordering on STEP 3.


                      Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

On a New Procedure for Identifying a Dynamic Common Factor Model                          13

STEP 6 Based on the CACF and the PCACF plots, identify ARMA models for
       the factor processes, in a similar way to the Box-Jenkins methodology,
       bearing in mind that the ith CACF is proportional to the ACF of the ith
       factor process, see Proposition 1 and the ith PCACF shows the PACF
       of fit‚àó , see Proposition 6.

    For the last step, it is important to highlight that, in terms of absolute
values, the CACFs show the AR behavior of each factor process because the
CACFs are proportional to theirs ACFs (see Proposition 1). In the same way,
the PCACFs show the MA behavior of each factor process plus a noise process
(see Proposition 6). In summary, in absolute values, the ith canonical and partial
canonical correlations show the ARM A(pj , qj ) behavior of the associated factor if
the variance of the added noise process is negligible with respect to the variance
of the factor, otherwise an ARM A(pj , pj + qj ) behavior is observed (Pe√±a 2010),
where pj and qj are, respectively, the autoregressive and moving average order
of the factor related with the jth partial canonical autocorrelation correlation
function.


4. Some Examples
4.1. A Simulated Model
   We simulate again model (11), using as sample size T = 1000. As was found
previously, we obtain K = {1, 3} after setting k0 = 13. We recall that using the
two possible linear combinations we identify 2 common factors. With the simulated
data, we get ¬µb2j1:K (K) = 0.22 and ¬µb2j2:K (K) = 0.18, the ordered eigenvalues of the
matrix M d S(K), with eigenvectors bbj1:K = (‚àí0.56, ‚àí0.58, ‚àí0.31, ‚àí0.38, 0.27, 0.20)‚ä§
and bbj2:K = (‚àí0.24, 0.18, 0.40, ‚àí0.09, 0.63, ‚àí0.59)‚ä§ , respectively.
     The next step is to use this speciÔ¨Åc order at all lags. Then, for each eigenvector
bbj and bbj , we match a canonical correlation and a partial canonical correlation
   1:K        2:K
 at each lag k = 1, 2, . . . , k0 , based on the methodology mentioned before. As
 an illustration of our proposed ordering methodology, we calculate the cosine
 similarity to order the canonical correlations at lags k = 1 and k = 3. For lag k = 1,
 bj1:1 (1) = 0.46 with eigenvector bbj1:1 = (0.61, 0.48, 0.17, 0.37, ‚àí0.47, 0.04)‚ä§ and
 ¬µ
 bj2:1 (1) = 0.10 with eigenvector bbj2:1 = (0.62, ‚àí0.47, ‚àí0.52, ‚àí0.12, ‚àí0.03, 0.31)‚ä§ .
 ¬µ
 The cosine similarity of bbj1:1 with the vectors bbj1:K and bbj2:K are 0.87 and 0.12,
 respectively. Then, we relate ¬µ                            bj2:1 (1) to bbj2:K . In the same
                                    bj1:1 (1) to bbj1:K and ¬µ
 way, at lag k = 3, we got 0.16 and 0.85 as the cosine similarity of the vector
bb1:3 with bbj and bbj , respectively; hence, we relate ¬µ      bj1:3 (3) = 0.42 to bbj2:K and
              1:K        2:K

 bj2:3 (3) = 0.07 to bbj1:K .
 ¬µ
     In other words, œëb1 (1, K) = 0.46, œëb2 (1, K) = 0.07, œëb1 (3, K) = 0.10 and
 b
 œë2 (3, K) = 0.42 as is shown in the Figure 1, where we plot the CACF and the
 PCACF according to the order speciÔ¨Åed by bbj1:K and bbj2:K . We use gray bars
 in both graphics to indicate the canonical correlations and the partial canonical

                    Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

14                                       Stevenson Bol√≠var, Fabio H. Nieto & Daniel Pe√±a


correlations that are statistically diÔ¨Äerent from zero, according to the tests (3) and
(13) mentioned before.

      0.4                cacf                                             pcacf




                                                        0.4
œë1(k, K )




                                                  œï1(k, K )
 0.2




                                                   0.2
      0.0




                                                        0.0
            1   3   5      7    9   11   13                   1   3   5     7     9   11   13
                         (a) CACF and PCACF of the Ô¨Årst factor process
      0.4




                                                        0.4
œë2(k, K )




                                                  œï2(k, K )
 0.2




                                                   0.2
      0.0




                                                        0.0


            1   3   5      7    9   11   13                   1   3   5     7     9   11   13
                        (b) CACF and PCACF of the second factor process
Figure 1: Plot of CACF and PCACF of the simulated data. Gray bars indicate
          the canonical correlations and the partial canonical correlations that are
          statistically diÔ¨Äerent from zero, according to the tests (3) and (13) mentioned
          before.

    Notice that the Ô¨Årst CACF and PCACF show an M A(1) behavior; hence they
are related to the factor f1t and the second ones, an M A(3), as it is factor f2t . In
this example, the CACF and PCACF show exactly the same expected behavior
of the ACF and PACF proposed by Box & Jenkins (1970), because an M A(q)
process plus a white noise process still being an M A(q) process (Pe√±a 2010).


4.2. A Real Data Application
    This example is taken from Nieto et al.‚Äôs (2016) paper, where the total monthly
rainfall time series were used. The rainfalls were measured in meteorological
stations located at the airports of six cities in Colombia: Bucaramanga(y1 ),
C√∫cuta(y2 ), Ibagu√©(y3 ), Medell√≠n(y4 ), Manizales(y5 ) and Bogot√°(y6 ). Figure 2
presents the deseasonalized time series and, with the Pe√±a & Poncela‚Äôs (2006)
test at the lags 1, 2, . . . , 13, we get that the lags 1, 4 and 6 present at leat one
factor. With K = {1, 4, 6} we detect two common factors using the test proposed
in Section 2.




                    Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

On a New Procedure for Identifying a Dynamic Common Factor Model                                  15

         Bucaramanga (y1)                                       C√∫cuta (y2)
   200
                                                          200
   100                                                    100

     0                                                      0

                                                         ‚àí100
  ‚àí100
                                                         ‚àí200
                1980         1990      2000       2010                 1980     1990   2000      2010


         Ibagu√© (y3)                                            Medell√≠n (y4)
                                                          200
   200
                                                          100
   100

     0                                                      0

  ‚àí100
                                                         ‚àí100

                1980         1990      2000       2010                 1980     1990   2000      2010


         Manizales (y5)                                         Bogot√° (y6)
   200                                                    150

                                                          100
   100
                                                           50

     0                                                      0

                                                         ‚àí50
  ‚àí100
                                                         ‚àí100
                1980         1990      2000       2010                 1980     1990   2000      2010



                                     Figure 2: Rainfall time series.


    Figure 3 presents the CACF and the PCACF of the deseasonalized time series
following our proposed methodology. To the Ô¨Årst factor, Figure 3(a), in the CACF
non-zero correlations are observed at lags 1, 4 and 6 (according to Pe√±a and
Poncela‚Äôs test) and in the PCACF at lags 1 and 6 (according to the test 13).
Also, a possible decreasing behavior in the CACF from the Ô¨Årst correlation, that
suggests an M A(1) process. For the second factor, Figure 3(b), in the CACF and
the PCACF a non-zero correlations are observed at lag 1 (according to the test
(3) and (13)) and a possible decreasing behavior is observed in the CACF, that
suggests an AR(1) process.
    To the estimation of the parameters, we maximize the likelihood function
using the EM algorithm. On step E, we use the Kalman Ô¨Ålter and the
smoothing algorithm. On step M , we use the space-state representation proposed
by Metaxoglou & Smith (2007) for VARMA models, intending to simplify the
maximization process from step M , as the authors mention in their paper. Also,
to solve the identiÔ¨Åcation problem of the model, restriction P ‚ä§ Œ£‚àí1
                                                                  Œµ P = Ir was
imposed, and using Jungbacker & Koopman (2015) ideas we transform the data
yt‚àó = AL yt in step E, with AL = P ‚ä§ Œ£Œµ‚àí1 , obtaining the transformed model
yt‚àó = AL yt = ft + AL Œµt , where AL P = Ir and var[AL Œµt ] = Ir .




                            Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

16                                             Stevenson Bol√≠var, Fabio H. Nieto & Daniel Pe√±a

                               cacf                                                pcacf



         0.20




                                                                0.20
 œë1(k, K )




                                                        œï1(k, K )
0.10




                                                       0.10
        0.00




                                                               0.00
                1   3    5      7     9   11   13                      1   3   5     7     9   11   13

                              (a) CACF and PCACF of the Ô¨Årst factor process
         0.20




                                                                0.20
 œë2(k, K )




                                                        œï2(k, K )
0.10




                                                       0.10
         0.00




                                                                0.00
                1   3    5      7     9   11   13                      1   3   5     7     9   11   13
                             (b) CACF and PCACF of the second factor process
                    Figure 3: Plot of CACF and PCACF of Colombian rainfalls

    Based on the above speciÔ¨Åcation, the following model with two common factors
is estimated:
                              Ô£Æ                 Ô£π
                                 7.52 ‚àí18.19
                              Ô£Ø11.14 ‚àí32.96Ô£∫
                              Ô£Ø                 Ô£∫
                              Ô£Ø                 Ô£∫
                              Ô£Ø19.73        8.14Ô£∫
                         Yt = Ô£Ø                 Ô£∫ f t + Œµt ,
                              Ô£Ø22.60      14.33Ô£∫
                              Ô£Ø                 Ô£∫
                              Ô£∞16.52 ‚àí6.73Ô£ª
                                12.46 ‚àí3.03

where f1t = 0.12f1,t‚àí6 + 0.117a1,t‚àí1 + 0.122a1,t‚àí4 + a1t , f2t = 0.36f2,t‚àí1 + a2t ,
Œ£a = diag(4.01, 0.69) and Œ£Œµ = diag(2226.9, 1853.7, 3463.2, 1279.2, 1566.2, 712.7).
    The structure of the factors can be seen by columns of the P matrix. The Ô¨Årst
one has a positive eÔ¨Äect on the time series, with a minor scale on the Bucaramanga
rainfall (y1t ). The second separates Ibagu√© (y3t ) and Medellin (y4t ) from the others
cities precipitations.


5. Conclusions
    In this paper, (1) we establish the relationship between canonical correlations
and the autocovariance function of the factor process. Based on this relation, we
modify Pe√±a & Poncela‚Äôs (2006) test to detect the number of common factors,
increasing the test power. Additionally, (2) we establish the relationship between

                         Revista Colombiana de Estad√≠stica - Theoretical Statistics 44 (2021) 1‚Äì21

On a New Procedure for Identifying a Dynamic Common Factor Model                          17

partial canonical correlations and the partial autocorrelation function of the factor
process. Finally, (3) we propose to use the canonical vectors to link the canonical
and partial canonical correlations at each lag to a speciÔ¨Åc factor process. These
three Ô¨Åndings allow us to propose a procedure to identify a vector ARMA model
for the factor process, which is based on the so-called simple and partial canonical
autocorrelation functions.
                                                                          
                  Received: March 2019 ‚Äî Accepted: September 2020


References
Ahn S C, Horenstein A R. Eigenvalue Ratio Test for the Number of Factors.(2013). Econometrica.
Anderson T. An Introduction to Multivariate Statistical Analysis- Wiley Series in Probability and Statistics - Applied Probability and Statistics Section Series.(1984). Wiley.
Box G E P, Jenkins G M. Time series analysis: forecasting and control.(1970).  Holden-Day.
Doz C, Fuleky P. Dynamic factor models in Macroeconomic Forecasting in the Era of Big Data.(2020). Springer.
Geweke J. The dynamic factor analysis of economic timeseries models.(1977). Latent Variables in Socio-Economic Models.
Jungbacker B, Koopman S J. Likelihood-Based Dynamic Factor Analysis for Measurement and Forecasting.(2015). The Econometrics Journal.
Lam C, Yao Q. Factor modeling for high-dimensional time series: Inference for the number of factors1.(2012). Annals of Statistics.
Metaxoglou K, Smith A. Maximun likelihood estimation of VARMA models using a state-space EM algorithm.(2007). Journal of Time Series Analysis.
Nieto F H, Pe√±a D, Saboy√° D. Common seasonality in multivariate time series.(2016). Statistica Sinica.
Pe√±a D. An√°lisis de series temporales El Libro Universitario - Manuales.(2010). Alianza Editorial.
Pe√±a D, Box G E P. Identifying a Simplifying Structure in Time Series.(1987). Journal of the American Statistical Association.
Pe√±a D, Poncela P. Nonstationary dynamic factor analysis.(2006). Journal of Statistical Planning and Inference.
Reinsel G C. Elements of Multivariate Time Series Analysis 2 edn.(1997). Springer-Verlag.
Stock J H, Watson M. Dynamic factor models in P C Michael and D F Hendry eds Oxford Handbook on Economic Forecasting.(2011). Oxford University Press.
Stock J H, Watson M W. Dynamic factor models factor-augmented vector autoregressions and structural vector autoregressions in macroeconomics in J B Taylor and H Uhlig eds Handbook of macroeconomics.(2016). Handbook of Macroeconomics.
Tiao G C, Tsay R S. Model speciÔ¨Åcation in multivariate time series.(1989). Journal of the Royal Statistical Society.