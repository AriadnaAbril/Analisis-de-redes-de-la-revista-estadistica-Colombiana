Elicitation of the Parameters of Multiple Linear Models. Elicitación de los parámetros de un modelo de regresión lineal múltiple
Universidad Nacional de Colombia, Medellín, Colombia. Instituto Tecnológico Metropolitano, Medellín, Colombia
Abstract
Estimating the parameters of a multiple linear model is a common task in all areas of sciences. In order to obtain conjugate distributions, the Bayesian estimation of these parameters is usually carried out using noninformative priors. When informative priors are considered in the Bayesian estimation an important problem arises because techniques are required to extract information from experts and represent it in an informative prior distribution. Elicitation techniques can be used for such purpose even though they are more complex than the traditional methods. In this paper, we propose a technique to construct an informative prior distribution from expert knowledge using hypothetical samples. Our proposal involves building a mental picture of the population of responses at several speciﬁc points of the explanatory variables of a given model and indirectly eliciting the mean and the variance at each of these points. In addition, this proposal consists of two steps: the ﬁrst step describes the elicitation process and the second step shows a simulation process to estimate the model parameters.
Key words: Bayesian statistics; Conjugate distribution; Elicitation; Informative distribution.
Resumen
La estimación de los parámetros de un modelo de regresión lineal múltiple es una tarea común en todas las áreas de las ciencias. Con la idea de obtener distribuciones conjugadas, la estimación Bayesiana de estos parámetros se lleva a cabo usando distribuciones a priori no informativas. Un problema importante resulta cuando se incorporan distribuciones a priori informativas en la estimación Bayesiana, puesto que se hace necesario usar técnicas para extraer información de expertos, y representar dicha información en una distribución a prior informativa. Así, los métodos de elicitación pueden ser implementados para tal ﬁn, a pesar de la complejidad de esta tarea en relación con las metodologías tradicionales. En este paper, se propone un técnica para construir una distribución a priori informativa a partir de muestras hipotéticas usando información de expertos. Esta propuesta se basa en la construcción de un mapa mental de la población de respuestas en diferentes valores especíﬁcos de la variable explicativa en el modelo, y luego elicitar de forma indirecta la media y la varianza en cada uno de dichos valores de interés. La propuesta es presentada en dos pasos, el primer paso describe el proceso de elicitación, y el segundo paso muestra un proceso de simulación para estimar los parámetros del modelo.
Palabras clave: Distribución conjugada; Distribución informativa; Elicitación; Estadística Bayesiana.



1. Introduction
    One of the main characteristics of the Bayesian inference approach is
the incorporation of a prior distribution into the analysis. For this reason,
incorporating a prior distribution that actually represents a prior belief about the
parameters under study is paramount, so that elicitation can play an important
role in obtaining a prior distribution that captures previous beliefs about the
parameters and may be used in Bayesian analysis.
    Elicitation allows experts to quantify their personal knowledge via probability
distributions. This technique has been used in complex problems, where
traditional methods (which use noninformative priors) are not applicable or
do not perform well (Andrade and Gosling, 2011; Aaron et al., 1995; Truong
and Heuvelink, 2013; Nemet et al., 2013; Wilcox et al., 2016). Unfortunately,
this complex task has been ignored by many analysts who prefer working with
noninformative prior distributions. According to Biedermann et al. (2017), “in
essence, a probability expresses a reasoner’s uncertainty about something—for
example a state of nature of the past, present or future—that is not completely
known to this person.” For their part, O’Hagan and Oakley (2004) and Kadane
and Wolfson (1998) discuss the diﬃculties of the elicitation process.
    Proportion is the parameter that has received the most attention in the
elicitation process in both nonparametric and parametric approaches (Winkler,
1967a,b; Raiﬀa, 1970; Chaloner and T., 1983; Gavasakar, 1988; Umesh, 1988).
In his study, Tversky (1974) addresses the problems that arise when eliciting
subjective probabilities. Gzyl et al. (2017) consider the problem of experts
providing intervals of uncertainty rather than point estimates of the parameters
of interest. Shadbolt and Burton (1995) describe in detail the steps to execute an
elicitation process. O’Hagan (2019) presents a complete description of a number
of best practices through which elicitation can be made as rigorous and scientiﬁc

                   Revista Colombiana de Estadística - Applied Statistics 44 (2021) 159–170

Elicitation of the Model Parameters                                                    161

as possible in order to minimize the cognitive biases that experts tend to have
when making probabilistic judgments.
    Several techniques to help experts elicit their personal knowledge in terms
of probability distributions have been proposed, such as the betting- and lottery-
based methods (Holloway, 1979; Harrison et al., 2014). These two methods require
a very strong assumption of linearity of the personal utility function (DeGroot,
1970). Other methods resort to a more intuitive approach, such as creating a
mental picture of the population. This allows experts to obtain mental samples of
a population that will hopefully contain a sample that preserves its structure. The
quality of its personal information is quantiﬁed in terms of the equivalent sample
size. Christov et al. (2017) apply several elicitation techniques; however, their
study does not provide general conclusions given its extreme limitations. Renooij
and Witteman (1999) and Witteman and Renooij (2003) propose using verbal
expression to quantify personal probabilities. Furthermore, although diﬀerent
software tools for Expert Knowledge Elicitation (EKE) have been developed, none
of them has executed, or simpliﬁed, parameter elicitation in linear models (Fisher
et al., 2012; Seynaeve et al., 2019).
    One of the main diﬃculties when eliciting expert knowledge is to select and
formulate the appropriate questions in such a way that experts understand what is
being asked and actually provide the expected information (Andrade and Gosling,
2018). For this purpose, a list of questions should be carefully prepared. However,
during the elicitation process, the structure of a question could be slightly changed,
provided that its underlying meaning is not altered. According to Barrera-Causil
et al. (2019), numerical skills do not play an important part in the accuracy of the
estimation when elicitation is used. The way questions are asked and language is
used is considered a major issue because experts may have a low or high level
of education. Therefore, all elicitation methods should be examined in order
to identify the appropriate vocabulary for the questions and compare all those
characteristics based on the diﬀerent parameters to estimate. In this paper, we use
generic and simple questions that experts usually interpret correctly. Nevertheless,
in some cases, we must change the words we often use to achieve our ﬁnal goal.
In other words, rather than using structural questions in an elicitation process,
we must adapt them to each expert and try to interact with them during the
interview/survey process.
    An example of a situation in which elicitation would be diﬃcult to apply is
when trying to estimate areas with a particular characteristic, such as those that
need ecological restoration, based on maps and the knowledge of farmers. In this
case, farmers are the experts, but they often have no mathematical or statistical
skills. Thus, for a successful elicitation, this process must be adapted to their
abilities in such a way that they can provide relevant information.
    In this study, the elicitation process is based on the construction of a mental
picture (or mental model) of the population of responses at several speciﬁc points
of the explanatory variables in a linear model. Hence, we deﬁne a mental
model as a representation of the way human beings see the world based on their
lessons learned and their interaction with the things around them. In his studies,

                   Revista Colombiana de Estadística - Applied Statistics 44 (2021) 159–170

162                               Juan Carlos Correa-Morales & Carlos Barrera-Causil


Johnson-Laird (2010), Johnson-Laird (1994), and Johnson-Laird (1980) provides
a comprehensible description of what a mental model is. He describes, in a deeper
sense, how human reasoning, probabilistic thinking, and cognitive processes act to
reproduce a mental model.
   A simple example of a mental model could be a witness’ image of the
appearance or physical features of a criminal. That graphical representation
would be the mental model of the witness, which is constructed based on his/her
experience. Thus, expert knowledge elicitation via the mental model involves
extracting all the experts’ information about a parameter of interest. This process
considers how experts are able to express their probabilistic thinking and how
their reasoning and cognitive processes could inﬂuence a good estimation of such
parameter.
    Eliciting an unknown vector parameter of a normal linear model is really
important. In particular, James et al. (2010) developed a software tool to help
with this task. However, one of the drawbacks of their study and software is that
it requires a direct elicitation of the model parameters. This could be easier if
there were previous studies providing direct information about them.
   Our proposal involves constructing a mental picture of the population of
responses at several speciﬁc points of the explanatory variables in a linear model
and indirectly eliciting the mean and the variance at each of these points. This
task is by far easier than the direct elicitation of the model parameters of a linear
model and represents the ﬁrst step of the algorithm shown in Section 2. Also,
Section 2 presents the second step of the algorithm. This step includes a simulation
to generate samples of the response variable and repeatedly estimate the model
parameters in order to obtain the conjugate prior distribution of a regression
model. Section 3 provides a hypothetical example, in which the parameters of
a multiple linear model are estimated. Finally, section 4 draws the conclusion of
the study.



2. The Algorithm
    Let us assume, by simpliﬁcation, that we are interested in the simple linear
model presented below. Note that this proposal may be extended to multiple
linear regression, as reported in the hypothetical example in Section 3. However,
if the number of model parameters increase, the elicitation process could become
exhausting. Then, let
                                 y ∼ β0 + β1 · x + ϵ,

where ϵ is assumed to follow a normal distribution with mean 0 and precision
τ = σ12 . Some Bayesian statisticians prefer to use the inverse of the variance,
which they call precision (DeGroot, 1970). This facilitates the algebraic work to
get conjugate distributions, working with the inverse gamma distribution instead
of the traditional gamma distribution. Our basic problem here is to determine the
conjugate prior joint distribution of the model parameters, say ξ (β0 , β1 , σ).

                   Revista Colombiana de Estadística - Applied Statistics 44 (2021) 159–170

Elicitation of the Model Parameters                                                                  163

   Now, we present our two-step proposal. In the ﬁrst step, some quantiles of
the distribution of the response variable in the regression model are elicited with
respect to a particular value of the explanatory variable. The mean, the variance,
and the corresponding equivalent sample size are also obtained in this step. Note
that eliciting the quantiles of a random variable is easier that eliciting the model
parameters directly (Demuynck, 2013).
    In the second step, a simulation is performed to generate samples of the
response variable, considering their corresponding design points, in order to
repeatedly estimate the model parameters several times. It is easier for experts
to provide their opinions around a central value than around any other value in
the range of possible values of a variable. This argument is based on the fact
that people ﬁnd it easier to describe events that occur more frequently than those
that are rare. For this reason, it is recommended to establish, as design points,
values close to the mean of the explanatory variable. At this point, any type
of bias (e.g., anchoring, availability, or overconﬁdence) during elicitation should
be avoided, as it may lead the elicitation process on the wrong track and any
implemented method would fail to make a good estimate of the prior distributions
(O’Hagan, 2019).
   Step 1: Elicitation
    First, the expert is asked to choose a value for the explanatory variable within
its logical range, say x0 . Then, he/she is asked to imagine the distribution of the
responses at this level of the explanatory variable, x0 , and to select a value for the
response within its logical range, say y0 .
    Subsequently, the expert is presented with the following situation: If we
had a representative sample of a conditional population of size n0 , how many
observations would you believe are below y0 ? Let us call this number ny0 . Then,
the expert is asked for the minimum number of observations in the sample that
he/she would accept below y0 (let us call this number kl ) and for the maximum
number of observations in the sample that he/she would accept above y0 (lest us
call this number ku ).
   At each elicited value, the expert must produce a hypothetical sample size
that reﬂects his/her self-conﬁdence in this elicited distribution. At the end of the
process, we will have

                                                                     k
                              {ξ (yi |xi1 , xi2 , · · · , xip ) , ni }i=1.

   Let us suppose that we obtain the following values:
   Question 1:

                          Level of the explanatory variable (X = x0 )
                        Hypothetical sample    Number given        Expected percentile
                                                                                    ny
    The most likely             n0                  n y0          E [P ercentile] = n 0
                                                                                              0
                                                                                           ny0 +ku
    More likely                  n0                   n y0 + k u         Eu [P ercentile] =  n0
                                                                                           ny0 −kl
    The least likely             n0                   n y0 − k l         El [P ercentile] = n
                                                                                               0




                       Revista Colombiana de Estadística - Applied Statistics 44 (2021) 159–170

164                                        Juan Carlos Correa-Morales & Carlos Barrera-Causil


      Question 2:

                            Level of the explanatory variable (X = x0 )
                          Hypothetical sample    Number given        Expected percentile
                                                                                      ny
      The most likely             n1                  n y1          E [P ercentile] = n 1
                                                                                                       1
                                                                                                    ny1 +ku
      More likely                    n1                      n y1 + k u           Eu [P ercentile] =  n1
                                                                                                    ny −k
      The least likely               n1                      n y1 − k l           El [P ercentile] = 1n l
                                                                                                        1



   Now, let us assume that, for the same value of explanatory variable x0 and
under n0 , we can standardize y0 such that
                                                  
                            y0 − µ x 0         ny0
                                       ≈ Φ−1         .
                                σ              n0

Similarly, but under n1 , we have
                                                                         
                                     y1 − µ x 0                     ny1
                                                ≈ Φ−1                         .
                                        σ                           n1

      Then, we solve the following equations for µx0 and σ:
                                                       y0 − y 1
                                 σ=                               
                                                    ny 0          n
                                          Φ−1       n0    − Φ−1 ny11

                                                         
                                                                     
                                          y   − y          −1   ny0
                    µ x 0 = y0 −           0     1
                                                         Φ            .
                                        n
                                   Φ−1 ny00 − Φ−1 ny11
                                                       n          n0

    Next, we must ﬁnd an equivalent sample size (nequ ) that reﬂects the expert’s
self-conﬁdence in the information they provided. For this purpose, we could use
the following binomial conﬁdence interval for a proportion:
                                        s
                                          π̂ (1 − π̂)
                              π̂ ± 1.96               .
                                              nequ

                                                           ny0 +ku
      If we assume that the upper limit is                   n0    , then
                                                v
                                                u ny         
                                                u 0 1 − ny 0
                           ny0 + k u  ny        t n0       n0
                                     = 0 + 1.96                 .
                              n0      n0              nequ

Thus, the equivalent (nequ ) to the expert’s self-conﬁdence at this design point is
approximated as follows:
                                                     2
                                               1.96
                               nequ1 =                      ny0 (n0 − ny0 ) .
                                                ku

                         Revista Colombiana de Estadística - Applied Statistics 44 (2021) 159–170

Elicitation of the Model Parameters                                                    165

                                           ny0 −kl
   If we assume that the lower limit is      n0 , then
                                            v
                                            u ny         
                                            u 0 1 − ny 0
                      ny0 − k l   ny0       t n0       n0
                                =     − 1.96                .
                         n0       n0              nequ

Thus, the equivalent (nequ ) to the expert’s conﬁdence at this design point is
approximated as follows:
                                      2
                                  1.96
                       nequ2 =            ny0 (n0 − ny0 ) .
                                   kl
Since we would rather be cautious regarding the expert’s information, we choose
the following equivalent sample size: nx0 = min {nequ1 , nequ2 }.
   A similar process is considered, assuming x1 is a diﬀerent level of the
explanatory variable.
     In summary, note that, for two points of the explanatory variable, say x0 and
x1 , we have two tables as the ones presented above. From the two “Most likely”
rows, we obtain the following two equations:

                                                  
                           x0 − µ           −1nx 0
                                      = Φ            , and
                              σ               n0
                                                  
                           x1 − µ             nx 1
                                      = Φ−1          .
                              σ               n1

    To clarify the elicitation process described above (in which we need to obtain
speciﬁc information from experts), let us suppose that we have a population of
soccer players, and our purpose is to model their weight (y0 ) using their height (x0 )
as the explanatory variable. Then, if we have a sample of size n0 which includes
soccer players with x0 = 170 cm, we could ask the expert the following: how many
soccer players, at most, would you believe weigh less than 70 kg? His/Her answer
would be ny0 . If we ask the expert what he/she would consider to be the maximum
acceptable number of soccer players in that particular sample that weigh 70 kg,
his/her answer would be ku . Now, if we ask the expert what he/she would consider
to be the minimum possible number of soccer players in that sample that weigh
less than 70 kg, his/her answer would be kl .
    Likewise, if we use another hypothetical sample, say n1 , the questions could be
as follows: in a sample of soccer players who are 170 cm tall, how many of them,
at most, would you believe weigh less than 80 kg? What would you consider to be
the maximum acceptable number of players in that particular sample that weigh
80 kg? What would you consider to be the minimum possible number of players
in that sample that weigh less than 80 kg? This process can be repeated as many
times as the researcher deems necessary.
   Once we have the populations at the several proposed points of the explanatory
variables, along with their respective equivalent sample sizes, we proceed to
construct the conjugate prior distribution of the regression parameters.

                   Revista Colombiana de Estadística - Applied Statistics 44 (2021) 159–170

166                                     Juan Carlos Correa-Morales & Carlos Barrera-Causil


      Step 2: Simulation

  1. For the i-th population speciﬁed above, obtain a simulated sample of size
     nxi , say yi .

  2. Construct
                                                              
                                                          y1
                                               y=
                                                          y2
        and
                                                                  
                                                      1 x1
                                            X=                         .
                                                      1 x2
                                                                      2
           the model
  3. Estimate     y = β0 + β1 x + e, where E [e] = 0 and V ar (e) = σ .
        Keep β̂0 , β̂1 , σ̂ 2 .

  4. Repeat the above steps several times, say M .

    After the above process is completed, we estimate the parameters of a
multinormal distribution for the β’s and a Gamma for the variance. The conjugate
prior is the normal-inverse-gamma distribution, which is expressed as follows:

            
 ξ β, σ 2       =    ξ(β | σ 2 )ξ(σ 2 ) = N (µβ , σ 2 Σβ ) × IG(α0 , γ0 )
                      (α0 +p/2+1)                                                            
                       1                               1          1             ′
                ∝                         ×  exp    −       γ 0 +   (β −  µ β )   Σ β (β − µ β )    ,
                       σ2                              σ2         2

   where p is the number of regressors, and the hyperparameters α0 and γ0 should
be estimated using a noninformative prior or through elicitation.
    Determining α0 and β0 is often surrounded by uncertainty. In this case,
                                              ′
researchers place a distribution on (α0 , γ0 ) , which is known as a hyper-prior
distribution.
   Finally, with the elicitation method mentioned above, Bayesian inference can
be performed, considering informative priors.


3. Hypothetical Example
   To illustrate this procedure, let us assume that we are interested in modeling
the weight of undergraduate students based on their height and sex using a linear
model without interaction.

                           W eight = β0 + β1 Sex + β2 Height + e,

                       Revista Colombiana de Estadística - Applied Statistics 44 (2021) 159–170

Elicitation of the Model Parameters                                                         167
                    
where e ∼ N 0, σ 2 . If we choose four points to elicit the distribution of the
students’ weight (two points for each sex, say x1M = 170 cm and x2M = 180 cm,
and x1F = 160 cm and x2F = 170 cm), we elicit the parameters of four population
normal distributions; here,eliciting the mean and the variance of each distribution
can be easier than eliciting the original parameters of the model.
   We could ask questions to the expert using each design point and diﬀerent
hypothetical samples, as follows:
    For male students: In a sample of size n0 which includes undergraduate
students that are 170 cm tall, how many students at most would you believe weigh
less than 70 kg? What would you consider to be the maximum acceptable number
of students in that particular sample that weigh 70 kg? What would you consider
to be the minimum possible number of students in that sample that weigh less
than 70 kg?
    Now, using the two tables, as in the previous examples, from the
two “Most likely” rows, we could obtain the mean and variance of each
population and generate the corresponding             yki , k = 1, 2, 3, 4, and i =         
                                        2                           2                       2
1, 2, . . . , m from N{M,x=170}
                               µ 1 , σ 1   , N {M,x=180}   µ 2 , σ 2 , N {F,x=160} µ 3 , σ 3   ,
                         2
and N{F,x=170} µ4 , σ4 .
    Now, with                                                        
                               y11            1          1       170
                             .             .          ..       .. 
                             ..            ..          .        . 
                                                                     
                             y             1                  170 
                             nx 0 1                   1              
                                                                     
                             y12           1          1       180 
                             .             .                    .. 
                             .             .           ..            
                             .             .            .        . 
                                                                     
                             y nx 2                           180 
                          Y=           , X 1          1              .
                             y13           1                  160 
                                   1

                                                      0              
                             .             .            ..       .. 
                             ..            ..                     . 
                                                         .           
                                                                     
                             y nx 2 3      1          0       160 
                                                                     
                             y14           1          0       170 
                                                                     
                             ..            ..            ..       .. 
                             .             .              .        . 
                              y nx 3 4        1          0       170

   Next, we estimate (β0 , β1 , β2 , σ 2 ) following step 3 of the algorithm. Finally,
with steps 2, 3, and 4, we obtain the conjugate prior distribution.


4. Conclusions
    Since elicitation is an extremely complex and undervalued process, further
research is needed to scientiﬁcally compare the diﬀerent elicitation methods
that have been proposed. Psychologists and cognitive scientists are required to
thoroughly study the process that takes place when an expert is faced with a
particular elicitation task.

                     Revista Colombiana de Estadística - Applied Statistics 44 (2021) 159–170

168                                  Juan Carlos Correa-Morales & Carlos Barrera-Causil


    In this study, we proposed using an algorithm based on a hypothetical
mental sample to determine the parameters of the conjugate distribution
of a normal population with unknown parameters.         In our experience,
experts feel more comfortable when they are asked questions about quantiles
of this type of hypothetical sample.     Moreover, it is easy to extend
this algorithm to other situations, including more complex models such
as regression ones.    The R code of the algorithm for a linear model
with two design points is provided at https://github.com/cbarrera2101/
Code-elicitation-of-the-parameters-for-LM.git
   Our proposal could be easily applied to multiple linear models with categorical
variables, such as independent and continuous variables, or a mix of both.
However, the response variable should always be quantitative.


Acknowledgements
      C.B.-C. thanks Instituto Tecnológico Metropolitano -ITM- for their support.
                                                                           
                    Received: March 2019 — Accepted: December 2020


References
Aaron R, DeWispelare A R, Herren L T, Clemen R T. The use of probability elicitation in the high-level nuclear waste regulation program. (1995). International Journal of Forecasting.
Andrade J A A, Gosling J P. Predicting rainy seasons: quantifying the beliefs of prophets.(2011). Journal of Applied Statistics.
Andrade J A A, Gosling J P. Expert knowledge elicitation using item response theory.(2018). Journal of Applied Statistics.
Barrera-Causil C J, Correa J C, Marmolejo-Ramos F. Experimental investigation on the elicitation of subjective distributions.(2019). Frontiers in Psychology.
Biedermann A, Bozza S, Taroni F, Aitken C. The consequences of understanding expert probability reporting as a decision.(2017). Science and Justice.
Chaloner K, T D. Assessment of a beta prior distribution: Pm elicitation.(1983). The Statistician.
Christov S C, Marquard J L, S, G, Avrunin G S, Clarke L A. Assessing the eﬀectiveness of ﬁve process elicitation methods: A case study of chemotherapy treatment plan review.(2017). Applied Ergonomics.
DeGroot M H. Optimal Statistical Decisions.(1970). McGraw Hill.
Demuynck T. A mechanism for eliciting the mean and quantiles of a random variable.(2013). Economics Letters.
Fisher R, O’Leary R A, Low-Choy S, Mengersen K, Caley M J. A software tool for elicitation of expert knowledge about species richness or similar counts.(2012). Environmental Modelling and Software.
Gavasakar U. A comparison of two elicitation methods for a prior distribution for a binomial parameter.(1988). Managment Science.
Gzyl H, ter Horst E, Molina G. Inferring probability densities from expert opinion.(2017). Applied Mathematical Modelling.
Harrison G W, Martínez-Correa J, Swarthout J T. Eliciting subjective probabilities with binary lotteries.(2014). Journal of Economic Behavior and Organization.
Holloway C A. Decison Making Under Uncertainty: Models and Choices.(1979). Prentince-Hall Inc.
James A, Choy S L, Mengersen K. Elicitator: An expert elicitation tool for regression in ecology.(2010). Environmental Modelling and Software.
Johnson-Laird P. Mental models in cognitive science.(1980). Cognitive Science.
Johnson-Laird P N. Mental models and probabilistic thinking.(1994). Cognition.
Johnson-Laird P N. Mental models and human reasoning.(2010). Proceedings of the National Academy of Sciences.
Kadane J B, Wolfson L J. Experiences in elicitation.(1998). The Statistician.
Nemet G F, Baker E, Jenni K E. Modeling the future costs of carbon capture using experts? elicited probabilities under policy scenarios.(2013). Energy.
O’Hagan A. Expert knowledge elicitation: Subjective but scientiﬁc.(2019). The American Statistician.
O’Hagan A, Oakley J E. Probability is perfect but we can’t elicit it perfectly.(2004). Reliability Engineering and System Safety.
Raiﬀa H. Decision Analysis: Introductory Lectures on Choice Under Uncertainty.(1970). Addison-Wesley: Reading.
Renooij S, Witteman C. Talking probabilities: Communicating probabilistic information with words and numbers.(1999). International Journal of Approximate Reasoning 22.
Seynaeve D, Varewyck M, Verbeke T. Extension of the monte-carlo web application and expert knowledge elicitation web application.(2019). EFSA Supporting Publications.
Shadbolt N, Burton M. Knowledge elicitation: A systematic approach.(1995). Evaluation of Human Work: A Practical Ergonomics Methodology.
Truong P N, Heuvelink G B M. Uncertainty quantiﬁcation of soil property maps with statistical expert elicitation.(2013). Geoderma.
Tversky A. Assessing uncertainty.(1974).Journal of the Royal Statistical Society.
Umesh G A. Comparison of two elicitation methods for a prior for a binomial parameter.(1988). Management Science.
Wilcox C, Mallos N J, Leonard G H, Rodriguez A, Hardesty B D. Using expert elicitation to estimate the impacts of plastic pollution on marine wildlife.(2016). Marine Policy.
Winkler R L. The assessment of prior distributions in bayesian analysis.(1967). Journal of the American Statistical Association.
Winkler R L. The quantiﬁcation of judgement: Some methodological suggestions.(1967).Journal of the American Statistical Association.
Witteman C, Renooij S. Evaluation of a verbal numerical probability scale.(2003). International Journal of Approximate Reasoning.