Bayesian Analysis of Multiplicative Seasonal Threshold Autoregressive Processes. Análisis Bayesiano de procesos autorregresivos de umbrales estacionales multiplicativos
Ciencias, Universidad del Tolima, Ibagué, Colombia. Universidad Nacional de Colombia, Bogotá, Colombia
Abstract
Seasonal ﬂuctuations are often found in many time series. In addition, non-linearity and the relationship with other time series are prominent behaviors of several, of such series. In this paper, we consider the modeling of multiplicative seasonal threshold autoregressive processes with exogenous input (TSARX), which explicitly and simultaneously incorporate multiplicative seasonality and threshold nonlinearity. Seasonality is modeled to be stochastic and regime dependent. The proposed model is a specialcase of a threshold autoregressive process with exogenous input (TARX). We develop a procedure based on Bayesian methods to identify the model, estimate parameters, validate the model and calculate forecasts. In the identiﬁcation stage of the model, we present a statistical test of regime dependent multiplicative seasonality. The proposed methodology is illustrated with a simulated example and applied to economic empirical data.
Key words: Bayesian analysis; Exogenous variable; Multiplicative model; Nonlinearity; Seasonality; Threshold autoregressive models.
Resumen
Las ﬂuctuaciones estacionales son frecuentes en series de tiempo. En adición, la no linealidad y la relación con otras series de tiempo son comportamientos prominentes de muchas series. En este artículo, se considera el modelamiento de procesos autorregresivos de umbrales estacionales multiplicativos con entrada exógena (TSARX), los cuales incorporan en forma explícita y simultánea estacionalidad multiplicativa y no linealidad de umbrales. La estacionalidad es estocástica y dependiente del régimen. Se desarrolla un procedimiento basado en métodos Bayesianos para identiﬁcar el modelo, estimar sus parámetros, validarlo y calcular pronósticos. En la etapa de identiﬁcación del modelo, se presenta una prueba estadística de estacionalidad multiplicativa por regímenes. La metodología propuesta es ilustrada con un ejemplo simulado y aplicada a datos empíricos económicos.
Palabras clave: Análisis bayesiano; Estacionalidad; Modelos autorregresivos de umbrales; Modelo multiplicativo; No linealidad; Variable exógena.



1. Introduction
    The threshold autoregressive models (TAR) proposed by Tong & Chen (1978)
and Tong & Lim (1980) have been widely applied in several areas, including
economics, ﬁnance, hydrology, meteorology and biology. The TAR models assume
that the values of a stochastic process {Zt } (threshold process) determines both
the values of the stochastic process {Xt } (interest process) and its dynamics.
When the threshold process is the same process of interest but lagged, the model
is known as SETAR (Self-Exciting TAR), Tong (1990). The TAR models can be
easily extended, including some exogenous time series and called TARX. The use
of Bayesian methods applied to the TAR and SETAR models, can be found in
Chen & Lee (1995), So & Chen (2003), Nieto (2005), Nieto (2008), Nieto, Zhang
& Li (2013), Zhang & Nieto (2015) and Calderón & Nieto (2017). While to the
TARX models, can be found in Chen (1998), So, Chen & Liu (2006), Chen &
So (2006), Chen, Gerlach & Lin (2010), among other works. Aditionally, Hansen
(2011) and Chen, Liu & So (2011) give a review of the theory and applications of
the TAR and TARX models in economics and ﬁnance, respectively.
    TAR models may be useful for nonseasonal or seasonally adjusted data that
display nonlinearity by means of thresholds. However, diverse time series present
some seasonal patterns. In addition, the nonlinearity of thresholds and the
relationship with other time series are typical characteristics of many such time
series in practice. Tong (2015) gives a compendium of what has been developed
with respect to the TAR models, and possible issues to be investigated, including
the study of seasonality. In many cases, it is convenient to study the seasonal
patterns present in time series, since they can carry relevant information regarding
the dynamic behavior of the series.
    Thus, using a frequentist approach and data without seasonal adjustment,
Franses, de Bruin & van Dijk (2000) and Franses & Van Dijk (2005) examine
the performance of various models of linear and smooth transition autoregressive
(STAR) time series, considering deterministic seasonality of series of quarterly
industrial production data. Crespo (2001) considers seasonality as deterministic
and dependent of the regime in the SETAR models and uses his model in time
series of quarterly unemployment rates. De Gooijer & Vidiella-i Anguera (2003)
deﬁne a seasonal SETAR model, where each regime has the form of a multiplicative
seasonal autoregressive model. They carry out the study of time series of monthly
inﬂation rates in several countries, ﬁnding more realistic dynamic characteristics

                   Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                              253

than those explained by the usual SETAR or linear seasonal time series models.
In this paper, we propose a statistical model called the multiplicative seasonal
threshold autoregressive model with exogenous input (TSARX), which explicitly
and simultaneously incorporates multiplicative seasonality by regimes that arises
from periodic autocorrelation structures and threshold nonlinearity. The proposed
model arises from imposing certain restrictions on the parameters of a TARX
model. Bayesian methods are used to determine the presence of multiplicative
seasonality by regimes and to obtain joint estimates of parameters, generalized
residuals and forecasts. The developed methodology is illustrated with a simulated
TSARX model and with an empirical application in the Colombian economy. The
variables to be used are the growth rates of total monthly unemployment and a
monthly coincident index that traces the Colombian economy (ISE for its Spanish
acronym of índice de seguimiento económico).
    The paper is organized as follows: In Section 2, the TSARX model and the
proposed methodology are presented. Section 3 shows a simulated example. The
real-data application is presented in Section 4 and, ﬁnally, Section 5 concludes.


2. The TSARX Model
2.1. Model Speciﬁcation
   Let {Xt } and {Zt } be stochastic processes related by means of the equation

                     (j)
                              X
                              kj
                                  (j)
                                           X
                                           Kj
               Xt = a0 +         ai Xt−i +    b(j)
                                               u Xt−su
                               i=1               u=1
                                                                                                (1)
                          X  X
                          kj Kj
                                     (j)
                                                         X
                                                         qj
                      −             ai b(j)
                                         u Xt−i−su +           c(j)       (j)
                                                                v Zt−v + h ϵt ,
                          i=1 u=1                        v=1

if rj−1 < Zt−d ≤ rj , for all t ∈ Z (Z is the set of integers numbers) and some
j = 1, . . . , l. The model assumes l regimes deﬁned by the threshold values rj that
satisfy −∞ = r0 < r1 < · · · < rl−1 < rl = ∞ and the threshold variable lagged d
periods Zt−d . In addition, the threshold variable is considered an exogenous input,
in the sense that there is no feedback from {Xt } towards {Zt }. The parameters
of the model can be divided into two groups (Nieto 2005):

  • Structural parameters: the number of regimes l, the l − 1 thresholds
    r = (r1 , . . . , rl−1 )′ , the delay parameter d, the autoregressive orders of the l
    regimes k1 , . . . , kl , K1 , . . . , Kl , q1 , . . . , ql and seasonal period s.
                                                                                  (j)    (j)    (j)
  • Nonstructural parameters: the autoregressive coeﬃcients ai , bu , cv ,
    i = 0, 1, . . . , kj , u = 1, . . . , Kj , v = 1, . . . , qj , j = 1, . . . , l and the variance
    weights h(1) , . . . , h(l) .

   We assume that the seasonal period of model s is known, where s = 4 is usually
taken for quarterly time series and s = 12 for monthly time series. Moreover, model

                     Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

254                                                                   Joaquín González & Fabio H. Nieto


(1) could be used for time series that exhibit another type of seasonal patterns, as,
for example, either daily (hour data) or weekly (daily observations). We consider
kj < s for all j(j = 1, . . . , l).
    Also, {ϵt } is a zero mean Gaussian white noise process with variance 1
(GW N (0, 1)) such that E(Xw ϵt ) = 0 for w < t, Zw and the set {Xt , Xt−1 , . . .} are
mutually independent for all w > t and {Zt } and {ϵt } are mutually independent.
To describe the stochastic behavior of {Zt }, we additionally assume that {Zt } is a
homogeneous Markov chain of order m ≥ 1, with initial density function f (·) and
kernel density function fm (· | ·), in the Lebesgue - measure sense. Additionally,
the Markov chain converges weakly to a distribution F . For more details about
Markov chains with general state space, see Meyn & Tweedie (2009). Equation
(1) describes a dynamic system without feedback, with observable input {Zt } and
observable output {Xt }, which is presented in Tong (1990) but without considering
the modeling of multiplicative seasonality by regimes.
    The symbol TSARX(l; k1 , . . . , kl ; K1 , . . . , Kl ; q1 , . . . , ql )s , is used to denote
model (1) and it is said that {Xt } is a threshold multiplicative seasonal
autoregressive process with exogenous input, with {Zt } as its threshold process
and s as its seasonal period. The vector of nonstructural parameters of the
TSARX model is deﬁned as θ ns = (A′1 , . . . , A′l , B1′ , . . . , Bl′ , C1′ , . . . , Cl′ , h′ )′ , where
         (j) (j)            (j)             (j)        (j)                   (j)          (j)
Aj = (a0 , a1 , . . . , akj ), Bj = (b1 , . . . , bKj ), Cj = (c1 , . . . , cqj ), j = 1, . . . , l
and h = ((h(1) )2 , . . . , (h(l) )2 ) and θ s = (k1 , . . . , kl , K1 , . . . , Kl , q1 , . . . , ql , r ′ , d, s, l)′
is the vector of structural parameters of the model. θ = (θ x , θ z ) is denoted as the
complete parameter vector, where θ x = (θ ′ns , θ ′s ) is the parameter vector in the
TSARX model and θ z is the parameter vector of the Markov chain.
    Following the theoretical results regarding the TAR models, given in Nieto
& Moreno (2016), and making an extension to the TSARX models, we have the
following considerations:

   (i) Let K = max{kj + sKj , qj , j = 1, . . . , l}, the distribution of Xt for all
       t, conditional on x1,t−1 = (x1 , . . . , xt−1 ), z 1,t−1 = (z1 , . . . , zt−1 ) and
       zt−d ∈ Rj = (rj−1 , rj ], for some j = 1, . . . , l, t > K, which is denoted as
       Ft−1,j (xt | x1,t−1 , z 1,t−1 , zt−d ∈ Rj ) is a normal distribution with mean

           (j)
                    X
                    kj
                        (j)
                                 X
                                 Kj
                                               X  X (j)
                                               kj Kj
                                                                     X
                                                                     qj
          a0 +         ai xt−i +    bu xt−su −
                                     (j)                 (j)
                                                     ai bu xt−i−su +    c(j)
                                                                         v zt−v
                    i=1                  u=1                   i=1 u=1                             v=1

                               (j) 2
        and variance (h           ) , for each j = 1, . . . , l.
  (ii) The conditional cumulative distribution function of Xt given x1,t−1 , z 1,t−1 ,
       t > K, is given by
                                                 X
                                                 l
                Ft (xt |x1,t−1 , z 1,t−1 ) =           pt,j Ft−1,j (xt |x1,t−1 , z 1,t−1 , zt−d ∈ Rj ),
                                                 j=1
                                      Pl
        where pt,j = P r(zt−d ∈ Rj ),    j=1 pt,j = 1 and Ft−1,j (· |· ) (j = 1, . . . , l)
        is given in (i). Now, being that {Zt } converges weakly to F , pt,j → pj =

                          Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                                               255

        F (rj ) − F (rj−1 ) when t → ∞ for all j = 1, 2, . . . , l. Of course, if {Zt } is a
        strictly stationary process, then the cumulative distribution function of Zt
        is F for all t and, thus, pt,j = pj for all t and for all j = 1, . . . , l.

The theoretical considerations (i) and (ii) above are taken into account for the
calculation of the generalized residuals of the TSARX model.
   The model (1) can be considered as a special case of a TARX model, as
described below. A TARX( l; k1 + sK1 , . . . , kl + sKl ; q1 , . . . , ql ) model is of the
form
                     (j)
                           X (j)
                         kj +sKj
                                               Xqj
               Xt = a0 +         ai Xt−i +         c(j)
                                                    v Zt−v + h ϵt ,
                                                                     (j)
                                                                                        (2)
                                         i=1                    v=1

if rj−1 < Zt−d ≤ rj for each t ∈ Z, some j = 1, . . . , l, kj < s for all j, and
{ϵt } ∼ GW N (0, 1).
    The complete parameter vector of the TARX model is conveniently deﬁned as
θ x = (θ ′ns , θ ′s ) being θ ns = (A′11 , . . . , A′l1 , A′12 , . . . , A′l2 , C1′ , . . . , Cl′ , h′ )′ (vector of
                                                          (j) (j)               (j) (j)                (j)
nonstructural parameters) where Aj1 = (a0 , a1 , . . . , akj , as , . . . , asKj ), Aj2 =
  (j)             (j)    (j)           (j)            (j)                        (j)                   (j)
(a1+kj , . . . , as−1 , a1+s , . . . , akj +s , . . . , a(1+kj )+s(Kj − , . . . , a(s−1)+s(Kj −1) , a1+sKj ,
        (j)                    (j)           (j)
. . . , akj +sKj ), Cj = (c1 , . . . , cqj ), j = 1 . . . , l, h = ((h(1) )2 , . . . , (h(l) )2 ) and θ s =
(k1 + sK1 , . . . , kl + sKl , q1 , . . . , ql , r ′ , d, l)′ (vector of structural parameters) where
r = (r1 , . . . , rl−1 )′ . If Aj2 = (0, . . . , 0, −a1 as , . . . , −akj as , . . . , 0, . . . , 0, −a1
                                                              (j) (j)        (j) (j)                     (j)

 (j)              (j) (j)
asKj , . . . , −akj asKj ), for each j = 1, . . . , l, the TARX model given in (2) becomes
the TSARX model given in (1). Related to the restrictions given regarding the
coeﬃcients of Aj2 of a TARX model, in a later subsection a statistical test is
presented to determine multiplicative seasonality by regimes


2.2. The Conditional Likelihood Function
   Let x1,T = (x1 , . . . , xT ) and z 1,T = (z1 , . . . , zT ) be observed data vectors for
the processes {Xt } and {Zt }, respectively, where T is the length of the sample
period. Following Nieto (2005), it is assumed that the probabilistic mechanism
that generates z 1,T does not depend on θ x and the joint distribution of x1,T
conditional on z 1,T and θ, does not depend on θ z . With these conditions it can
be seen that, initially, it is possible to estimate the parameters of {Zt } and then
conditional on these parameters, we proceed to estimate the parameters of the
TSARX model considering the likelihood function1

                  f (x1,T , z 1,T | θ) = f (z 1,T | θ x , θ z )f (x1,T | z 1,T , θ x , θ z )
                                          = f (z 1,T | θ z )f (x1,T | z 1,T , θ x ).

Our interest is to calculate the conditional likelihood function of a TSARX(l; k1 ,
. . . , kl ; K1 , . . . , Kl ; q1 , . . . , ql )s model given in (1); that is to say, f (x1,T |
z 1,T , θ x ). Additionally, it is assumed that the ﬁrst K values of x1,T ; that is,
   1 Future research can be directed to obtain joint estimates of the parameters θ
                                                                                                  x and θ z .



                          Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

256                                                                  Joaquín González & Fabio H. Nieto


x1,K = (x1 , . . . , xK ) are ﬁxed and known with K = max{kj +sKj , qj , j = 1, . . . , l};
consequently,

  f (xK+1,T | x1,K , z 1,T , θ x ) =
                      f (xK+1 | xK , . . . , x1 , z 1,T , θ x ) · · · f (xT | xT −1 , . . . , x1 , z 1,T , θ x ).

     Now, since {ϵt } ∼ GW N (0, 1) for t = (K +1), . . . , T , the variable xt | xt−1 , . . . ,
x1 , z 1,T has normal distribution with mean

      (j )
                X
                kjt
                     (jt )
                              X
                              Kjt
                                             X   X (j )
                                             kjt Kjt
                                                                     X
                                                                     qjt
µt = a0 t +         ai xt−i +     bu xt−su −
                                   (jt )               t (jt )
                                                     ai bu xt−i−su +     cv(jt ) zt−v
                i=1                   u=1                    i=1 u=1                               v=1

and variance (h(jt ) )2 . The sequence {jt } is the observed time series for the
stochastic process {Jt }, where Jt = j if rj−1 < zt−d ≤ rj , for some j = 1, . . . , l.
Then,
                                                                                          
                                                                              1        
                                                        Y                X     xt − µt 2 
                                                        T                T
                                              (T −K)
                                          −                      (jt ) −1
 f (xK+1,T | x1,K , z 1,T , θ x ) = (2π)         2  (h    ) exp
                                                                   2           h(jt )     
                                              t=K+1                    t=K+1
                                                                                           (3)
           −(T −K) Y
                    l                    1Xl                                            
                                −n                     ∗ ∗  ′       −2            ∗    ∗
    = (2π)    2        (h ) j exp −
                          (j)
                                               (Xj − Aj Bj ) ((h ) Inj )(Xj − Aj Bj ) ,
                                                                (j)
                                         2                                              
                      j=1                         j=1


where
            ′
         a∗t = (1, xt−1 , . . . , xt−kj , 0, . . . , 0, xt−s , xt−(1+s) , . . . , xt−(kj +s) , . . . ,
             0, . . . , 0, xt−sKj , xt−(1+sKj ) , . . . , xt−(kj +sKj ) , zt−1 , . . . , zt−qj ),
          ∗
         Aj = (a∗t1 ,j , . . . , a∗tn ,j ),
                                     j


         Bj∗ = (a0 , a1 , . . . , akj , 0, . . . , 0, b1 , −a1 b1 , . . . , −akj b1 , . . . ,
                      (j)     (j)       (j)                (j)       (j) (j)            (j) (j)

                                (j)     (j) (j)             (j) (j)     (j)        ′
                0, . . . , 0, bKj , −a1 bKj , . . . , −akj bKj , c1 , . . . , c(j)
                                                                               qj ) ,

Xj = (xt1 ,j , . . . , xtnj ,j )′ , {t1,j , . . . , tnj ,j } are the indexes in time, where rj−1 <
zt−d ≤ rj and nj is the number of observations in the regime j, j = 1, . . . , l.
Henceforth, the conditional likelihood function of a TSARX model is given by (3).


2.3. Estimation of Parameters of a TSARX Model
   Stochastic search ideas are used to identify autoregressive orders in a TSARX
model with l regimes; in particular, the Gibbs variable selection method given
by Dellaportas, Forster & Ntzoufras (2002) and denoted by GVS. This method
achieves the estimation of autoregressive orders in a single stage and can involve
these estimates in the MCMC sampling scheme, along with the remaining
parameter estimates, assuming that the number of regimes is known. The GVS
method is a hybrid between the method for the selection of variables proposed by
Kuo & Mallick (1998), denoted KM, and the stochastic search for the selection of


                            Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                                       257

variables (SSVS) given by George & McCulloch (1993). These and other Bayesian
model selection techniques can be reviewed in O’Hara & Sillanpä (2009).
    So & Chen (2003) use the SSVS method to determine the autoregressive orders
and the remaining parameters, when the number of regimes in the SETAR models
is known. Calderón & Nieto (2017) use the KM and GVS methods in multivariate
TARX models.
    The GVS method for a TSARX model with l regimes, is described as follows:
let kj , Kj and qj , j = 1, . . . , l, be the maximum autoregressive orders . We deﬁne
the 0 − 1 latent indicator variables sij , muj and nvj , for each i = 0, 1, . . . , kj ,
u = 1, . . . , Kj and v = 1, . . . , qj in the following way:
                                                        
                           (j)
                1, then ai is included                            (j)
                                                         1, then bu is included
        sij =        in the model,                 muj =      in the model,
                
                                                        
                                                         
                  0, otherwise,                            0, otherwise,

                                               
                                                         (j)
                                               1, then cv is included
                                and      nvj =      in the model,
                                               
                                               
                                                 0, otherwise.

   Let Sj = (s0j , s1j , . . . , skj j )′ , Mj = (m1j , . . . , mKj j )′ and Nj = (n1j , . . . , nqj j )′ ,
j = 1, . . . , l, latent indicator vectors associated with nonseasonal autoregressive,
seasonal autoregressive and the exogenous input coeﬃcients, respectively.
   Model (1) is rewritten with the vectors Sj , Mj and Nj , j = 1, . . . , l as

        (j)
                       X
                       kj
                           (j)
                                        X
                                        Kj
                                                            X  X (j)
                                                            kj Kj
Xt =a0 s0j +              ai sij Xt−i +    b(j)
                                            u   muj Xt−su −       ai b(j)
                                                                      u sij muj Xt−i−su
                       i=1                       u=1                            i=1 u=1
           X
           qj

                  v nvj Zt−v + h ϵt , if rj−1 < Zt−d ≤ rj ,
                 c(j)           (j)
       +
           v=1


   for some j = 1, . . . , l and the other speciﬁcations given in subsection 2.1 are
met, except that the vector of structural parameters of the model is now

                        θs = (S1 , . . . , Sl , M1 , . . . , Ml , N1 , . . . , Nl , r ′ , d, s, l)′ .

    To use the GVS method, it is necessary to assume that:
                 (j)
              ai       | sij ∼ (1 − sij )N (0, 1/φ2ij ) + sij N (0, 1/ηij
                                                                       2 2
                                                                          φij ),
               u | muj ∼ (1 − muj )N (0, 1/χuj ) + muj N (0, 1/ξuj χuj ), and
              b(j)                          2                   2   2


               v | nvj ∼ (1 − nvj )N (0, 1/ψvj ) + nvj N (0, 1/λvj ψvj ),
              c(j)                          2                   2   2


where P r(sij = 1) = πij , P r(muj = 1) = fuj and P r(nvj = 1) = ωvj , i = 0,
1, . . . , kj , u = 1, . . . , Kj , v = 1, . . . , qj , j = 1, . . . , l. According to George &
McCulloch (1993), the interpretation of this formulation is as follows. First, we


                             Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

258                                                           Joaquín González & Fabio H. Nieto

                                                  (j)
set 1/φ2ij small so that if sij = 0, then ai would probably be so small that it could
                                                2 2
be safely estimated by 0. Second, we set 1/ηij   φij large so that if sij = 1, then a
                         (j)
non-0 estimate of ai should probably be included in the ﬁnal model. A similar
deduction can happen for the other mixtures of normal distributions. Additionally,
those mixtures of normal distributions can be carried to a multivariate structure
in the following way:

                        Aj | Sj ∼ Nkj +1 (0, (DSj VAj0 DSj )−1 )′ ,
                        Bj | Mj ∼ NKj (0, (DM j VBj0 DM j )−1 )′ , and
                        Cj | Nj ∼ Nqj (0, (DN j VCj0 DN j )−1 )′ ,

where VAj0 , VBj0 and VCj0 are matrices of prior covariances, DSj is a diagonal
matrix diag{1/a0j φ0j , . . . , 1/akij φkij } with aij = 1 if sij = 0 and aij = ηij if
sij = 1, DM j = diag{1/b1j χ1j , . . . , 1/bKj j χKj j } with buj = 1 if muj = 0 and
buj = ξuj if muj = 1, and DN j = diag{1/c1j ψ1j , . . . , 1/cqj j ψqj j } with cvj = 1 if
nvj = 0 and cvj = λvj if nvj = 1. The above is valid, assuming priori independence
of the sij , muj , nvj , i = 0, 1, . . . , kj , u = 1, . . . , Kj , v = 1, . . . , qj , j = 1, . . . , l.
   The conditional likelihood function of a TSARX model with l regimes
considering the vectors Sj , Mj and Nj , j = 1, . . . , l is given in (3), except now,

      Bj∗ = (a0 s0j , a1 s1j , . . . , akj skj j , 0, . . . , 0, b1 m1j , −a1 b1 s1j m1j , . . . ,
                (j)         (j)          (j)                   (j)          (j) (j)

                  (j) (j)                               (j)           (j) (j)
             − akj b1 skj j m1j , . . . , 0, . . . , 0, bKj mKj j , −a1 bKj s1j mKj j , . . . ,
                  (j) (j)               (j)                      ′
             − akj bKj skj j mKj j , c1 n1j , . . . , c(j)
                                                       qj nqj j ) ,

with, kj , Kj , and qj , j = 1, . . . , l, deﬁned previously.
   Once MCMC samples are obtained for Sj , Mj , Nj , j = 1, . . . , l, the
autoregressive orders of the model can be identiﬁed considering a particular
combination of Sj , Mj and Nj , j = 1, . . . , l which possesses the highest posterior
probability.
    Prior independence is assumed for Aj , Bj and Cj so VAj0 = Ikj +1 , VBj0 = IKj
and VCj0 = Iqj , j = 1, . . . , l (I is the identity matrix). Also, it is assumed that
each autoregressive coeﬃcient is equally likely to be included in the model; then,
πij = 1/2, fuj = 1/2 and ωvj = 1/2, i = 0, 1, . . . , kj , u = 1, . . . , Kj , v = 1, . . . , qj ,
j = 1, . . . , l.
   The prior distributions for parameter groups Aj , Bj , Cj , (h(j) )2 , j = 1, . . . , l,
r and d are:

  (i) For Aj | Sj a multivariate normal distribution with mean 0kj+1 and
      covariance (DSj DSj )−1 , j = 1, . . . , l.
 (ii) For Bj | Mj a multivariate normal distribution with mean 0Kj and
      covariance (DMj DMj )−1 , j = 1, . . . , l.
 (iii) For Cj | Nj a multivariate normal distribution with mean 0qj and covariance
       (DNj DNj )−1 , j = 1, . . . , l.

                       Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                                    259

 (iv) For (h(j) )2 an inverse Gamma distribution (IG) with position parameter
      νj /2 and scale parameter νj λj /2, j = 1, . . . , l.
 (v) r = (r1 , . . .R, rl−1R)′ follows the constant prior distribution f (r) = C1 I(A)
     where C = . . . A dr1 . . . drl−1 , and A is a region that satisﬁes:
        (1) a ≤ r1 < . . . < rl−1 ≤ b, with a and b convenient quantiles of Zt−d , and
        (2) each regime contains at least one H% from the sample of Zt−d (this to
            ensure valid inference). The value of H is preset.
      I(A) is the indicator function of A on Rl−1 . For the particular case of two
      regimes, f (r) is a uniform distribution deﬁned in (a, b).
 (vi) d follows a discrete uniform distribution, with probability mass function
      P r(d = i) = 1/(d0 + 1), for i = 0, 1, . . . , d0 ; d0 being a maximum delay
      given.

     The hyperparameters {φij , ηij , χuj , ξuj , ψvj , λvj , νj , λj , (i = 0, 1, . . . , kj , u =
1, . . . , Kj , v = 1, . . . , qj , j = 1, . . . , l), a, b, d0 } are assumed known. Combining the
conditional likelihood function for a TSARX model, considering the vectors Sj ,
Mj and Nj , j = 1, . . . , l, with each of the prior distributions given in (i) to (vi),
the posterior distributions of the unknown parameters of the model are obtained.
MCMC samples of Aj , Bj , Cj , (h(j) )2 , Sj , Mj , Nj , j = 1, . . . , l, r and d are
generated from convenient complete conditional distributions as follows.
    Algorithm 1.
                       (0)       (0)     (0)                    (0)      (0)      (0)
   1. Initialize: Aj , Bj , Cj , [(h(j) )2 ](0) , Sj , Mj , Nj , j = 1, . . . , l,
      r (0) , d(0) .
   2. Generate Aj (independent of Ai , i ̸= j) from

                             f (Aj | x1,T , z 1,T , θ x−Aj ) ∼ Nkj +1 (θ Aj , VA−1
                                                                                 j
                                                                                   )
                                         ′                                                       ′
      where VAj = [1/(h(j) )2 ]Sj∗ Sj∗ + DSj DSj and θ Aj = VA−1          [1/(h(j) )2 ]Sj∗ (Xj −
                           ′                   P                        j

      Mj∗ Bj −Nj∗ Cj ), s∗t = (s0j , s1j xt−1 − u=1
                                                Kj   (j)
                                                    bu s1j muj xt−1−su , . . . , skjj xt−kj −
      PKj (j)                             ∗      ∗                           ′
        u=1 bu skj j muj xt−kj −su ), Sj = (st1 ,j , . . . , st∗
                                                               n ,j
                                                                    )′ , m∗t = (m1j xt−s ,
                                                                        j
                                                                                  ′
      m2j xt−s2 , . . . , mKj j xt−sKj ), Mj∗ = (m∗t1 ,j , . . . , m∗tn ,j )′ , n∗t = (n1j z t−1 , . . . ,
                                                                        j
      nqjj z t−qj ), Nj∗ = (n∗t1 ,j , . . . , n∗tn ,j )′ , Xj = (xt1 ,j , . . . , xtnj ,j )′ and nj the
                                                  j
      number of observations in the regime j, j = 1, . . . , l.
      Here θ x−Aj is the parameter vector θ x without the subvector Aj .
   3. Generate Bj (independent of Bi , i ̸= j) from

                              f (Bj | x1,T , z 1,T , θ x−Bj ) ∼ NKj (θ Bj , VB−1
                                                                               j
                                                                                 )
                                         ′                                                       ′
      where VBj = [1/(h(j) )2 ]Tj∗ Tj∗ +DMj DMj and θ Bj = VB−1   [1/(h(j) )2 ]Tj∗ (Xj −
                            ′             Pkj (j)              j

      Uj∗ Aj − Nj∗ Cj ), t∗t = (m1j xt−s − i=1 ai sij m1j xt−i−s , . . . , mKj j xt−sKj −


                      Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

260                                                              Joaquín González & Fabio H. Nieto

      Pkj         (j)                         ∗           ∗          ∗    ′  ∗′
           i=1 ai sij mKj j xt−i−sKj ), Tj = (tt1 ,j , . . . , ttnj ,j ) , µt     = (s0j , s1j xt−1 ,
                               ∗     ∗                ∗      ′   ∗
      . . . , skj ,j xt−kj ), Uj = (µt1 ,j , . . . , µtn ,j ) , Nj , Xj and nj , j = 1, . . . , l are
                                                        j
      deﬁned above.
  4. Generate Cj (independent of Ci , i ̸= j) from
                               f (Cj | x1,T , z 1,T , θ x−Cj ) ∼ Nqj (θ Cj , VC−1
                                                                                j
                                                                                  )
                                          ′                                                      ′
      where VCj = [1/(h(j) )2 ]Nj∗ Nj∗ +DNj DNj and θ Cj = VC−1
                                                              j
                                                                [1/(h(j) )2 ]Nj∗ (Xj −
                                              ′
      Fj∗ Ej − Uj∗ Aj − Mj∗ Bj ), ft∗ = (0, . . . , 0, s1j m1j xt−1−s , . . . , skj j m1j xt−kj −s ,
      0, . . . , 0, s1j mKj j xt−1−sKj , . . . , skj j mKj j xt−kj −sKj ), Fj∗   = (ft∗1 ,j , . . . ,
      ft∗nj ,j )′ , Ej = (a1+kj , . . . , as−1 , −a1 b1 , . . . , −akj b1 , . . . , a(1+kj )+s(Kj −1) ,
                               (j)            (j)    (j) (j)           (j) (j)        (j)


      . . . , a(s−1)+s(Kj −1) , −a1 bKj , . . . , −akj bKj ), Nj∗ , Uj∗ , Mj∗ , Xj y nj ,
             (j)                      (j) (j)          (j) (j)
                                                                                                     j       =
      1, . . . , l are deﬁned above.
  5. Generate (h(j) )2 (independent of (h(i) )2 , i ̸= j) from
                                                                                             !
                                                                    νj + nj νj λj + nj s2j
              f ((h     ) | x1,T , z 1,T , θ x−(h(j) )2 ) ∼ IG
                     (j) 2
                                                                           ,                     ,
                                                                       2          2

      where nj s2j = (Xj − A∗j Bj∗ )′ (Xj − A∗j Bj∗ ), j = 1, . . . , l.
  6. Generate r from
                    f (r | x1,T , z 1,T , θ x−r ) ∝ f (xK+1,T | x1,K , z 1,T , θ x )I(A)
      where f (· |· ) is the conditional likelihood function of the TSARX model
      taking into account, that Sj , Mj and Nj , j = 1, . . . , l are latent indicator
      variables and A is the region speciﬁed in the prior distribution for r.
  7. Generate d from the multinomial distribution, with probability mass function

         P r(d = i | x1,T , z 1,T , θ x−d )
                                       f (xK+1,T | x1,K , z 1,T , θ x−d , d = i)P r(d = i)
                               = Pd0                                                                     ,
                                     m=0 f (xK+1,T | x1,K , z 1,T , θ x−d , d = m)P r(d = m)

      i = 0, 1, . . . , d0 .
  8. Generate vector Sj = (s0j , s1j , . . . , skj j )′ (independent from Si , Mi and Ni ,
     i ̸= j), obtaining samples from sij , i = 0, 1, . . . , kj , j = 1, . . . , l individually
     based on the Bernoulli distribution, with probability mass function
                                                                   αij
                      P r(sij = 1 | x1,T , z 1,T , θ x−sij ) =            ,
                                                                αij + βij
      where

         αij = f (xK+1,T | x1,K , z 1,T , θ x−sij , sij = 1)f (Aj | Sj−sij , sij = 1)πij
      and

         βij = f (xK+1,T | x1,K , z 1,T , θ x−sij , sij = 0)f (Aj | Sj−sij , sij = 0)(1−πij ).

                        Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                         261

  9. Generate vector Mj = (m1j , m2j , . . . , mKj j )′ (independent from Mi , Si
     and Ni , i ̸= j), obtaining samples from muj , u = 1, . . . , Kj , j = 1, . . . , l
     individually based on the Bernoulli distribution, with probability mass
     function
                                                                γuj
                    P r(muj = 1 | x1,T , z 1,T , θ x−muj ) =           ,
                                                             γuj + ϱuj
     where

        γuj =
          f (xK+1,T | x1,K , z 1,T , θ x−muj , muj = 1)f (Bj | Mj−muj , muj = 1)fuj

     and

        ϱuj =
     f (xK+1,T | x1,K , z 1,T , θ x−muj , muj = 0)f (Bj | Mj−muj , muj = 0)(1−fuj ).

 10. Generate vector Nj = (n1j , n2j , . . . , nqj j )′ (independent from Ni , Si and Mi ,
     i ̸= j), obtaining samples from nvj , v = 1, 2, . . . , qj , j = 1, . . . , l individually
     based on the Bernoulli distribution, with probability mass function
                                                                      ςvj
                        P r(nvj = 1 | x1,T , z 1,T , θ x−nvj ) =             ,
                                                                   ςvj + ξvj

     where

        ςvj = f (xK+1,T | x1,K , z 1,T , θ x−nvj , nvj = 1)f (Cj | Nj−nvj , nvj = 1)ωvj

     and

        ξvj =
       f (xK+1,T | x1,K , z 1,T , θ x−nvj , nvj = 0)f (Cj | Nj−nvj , nvj = 0)(1 − ωvj ).

    All the posterior distributions of Algorithm 1, except that of r, are standard.
To simulate values of r, a Gaussian random walk Metropolis algorithm with step
sizes σr1 , . . . , σrl−1 is used (Metropolis, Rosenbluth, Rosenbluth & Teller 1953).
We set the MCMC sample size N suﬃciently large, discarding the burn-in iterates,
and keep the last G = N − M iterates for posterior analysis.
     The means and standard deviations of the posterior distributions of Aj , Bj ,
Cj , (h(j) )2 , j = 1, . . . , l and r are calculated to obtain point estimates and a
measure of uncertainty for such estimates, respectively. Also, with the samples
generated, 100(1 − α)% credible intervals or 100(1 − α)% Highest-Density Regions
(HDR), for α, 0 < α < 1, can be obtained. The estimation of the delay parameter
d is taken as the posterior mode and for the estimates of the vectors of zeros and
ones, Sj , Mj , Nj , j = 1, . . . , l the highest occurrence probabilities are taken.
   In order to examine each of the parameters, if the MCMC samples obtained
converge to the posterior distribution, the Geweke’s Z-score plot (Geweke 1992)

                    Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

262                                                          Joaquín González & Fabio H. Nieto


of the geweke.plot function of coda in R software (Plummer, Best, Cowles &
Vines 2006) is used. Also, we review the evolution of the point estimate
(posterior averages) of each of the parameters, when the number of iterations is
increased, by means of the cumuplot function of coda in R. This plot presents the
sample quantiles 0.025, 0.50 and 0.975, as a function of the number of iterations
(accumulated averages) of the Markov chains.


2.4. A Bayesian Test of Multiplicative Seasonality
     by Regimes
   De Gooijer & Vidiella-i Anguera (2003) using a frequentist approach, present
a model that captures multiplicative seasonality by regimes and nonlinearity of
thresholds simultaneously in SETAR models.
    In this Subsection, to test the presence of multiplicative seasonality in each of
the regimes of the TARX model, a Bayesian statistical test is proposed where an
approximate technique is used for the calculation of the Bayes factor. In particular,
we use the Savage-Dickey distributions ratio given in Dickey (1971) paper, which
is an approximation of the Bayes factor (see, Verdinelli & Wasserman, 1995).
   The methodology consists in comparing the TSARX model with a model where
such seasonality is not captured (a TARX model). That is, that the parameter
vector Aj2 deﬁned for the TARX model given in (2), equals the vector
                          (j)                (j)                        (j) (j)            (j) (j)
                           s , . . . , −akj as , . . . , 0, . . . , 0, −a1 asKj , . . . , −akj asKj ),
Aj20 = (0, . . . , 0, −a1 a(j)               (j)


for each j = 1, . . . , l, so that a TSARX model is a special case of a TARX model.
   Formally, we want to test the hypotheses H0j : Aj2 = Aj20 versus Haj : Aj2 ̸=
Aj20 , for each j = 1, . . . , l. The Bayes factor is given by
                                R
                                   f (xK+1,T | x1,K , z 1,T , θ x )f (θ x )dθ x
                  F Bj = R                                                       , (4)
                                 f (xK+1,T | x1,K , z 1,T , θ x0 )f (θ x0 )dθ x0
where, respectively, f (·) and f (· | ·) denote the prior distribution and the
conditional likelihood function of the TARX and θ x0 summarizes the parameters
of the TARX model in the case Aj2 = Aj20 , for j = 1, . . . , l.
      The Bayes factor (4) is equal to
                                     f (Aj2 | x1,T , z 1,T ) |Aj2 =Aj20
                            F Bj =                                      ,
                                           f (Aj2 ) |Aj2 =Aj20
for j = 1, . . . , l; that is, the ratio of the weights of the conditional posterior
distribution of Aj2 and the weights of the prior distribution of Aj2 , both evaluated
in Aj20 , j = 1, . . . , l.
   The weight of the marginal posterior distribution of Aj2 in Aj20 can be obtained
with the calculation of the average of the conditional posterior distribution of Aj2
over the MCMC samples of the other parameters; thus,

                                             1 X
                                                   G
                                                                             (i)
      f (Aj2 | x1,T , z 1,T ) |Aj2 =Aj20 =         f (Aj2 | x1,T , z 1,T , θ x−Aj2 ) |Aj2 =Aj20 ,
                                             G i=1


                       Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                               263

for j = 1, . . . , l, if the complete conditional posterior distribution of Aj2 has a
known standard distribution (see, Gelfand & Smith, 1990) and θ x−Aj2 is the
parameter vector θ x without subvector Aj2 . Here it is necessary to obtain MCMC
samples of the posterior distributions of Aj2 . Given the number of regimes l and
autorregresive orders kj + sKj , qj , j = 1, . . . , l, the remaining parameters of the
TARX model deﬁned in (2), are estimated using a Gibbs sampler.
    Returning to the Bayes factor calculation, because
                      (i)        (i)  −1 (i)
                   Aj2 ∼ N (θ j2 , (Vj2 ) ), i = 1, . . . , G, j = 1, . . . , l,

the parameters θ j2 and Vj2 are used from the posterior distribution and θ j20 and
Vj20 from the prior distribution for Aj2 , for the calculation of the Bayes factor by
regimes as indicated in equation (4). Thus,
               PG       q
                               −1 (i)
                                      | exp{− 12 (Aj20 − θ j2 )′ Vj2 (Aj20 − θ j2 )}
                                                             (i)   (i)            (i)
                 i=1 1/ | (Vj2 )
             1
             G
     F Bj =         q                                                                 ,
                           −1
                 1/ | (Vj20   ) | exp{− 12 (Aj20 − θ j20 )′ Vj20 (Aj20 − θ j20 )}

j = 1, . . . , l. H0j : Aj2 = Aj20 is not rejected if 2 ln(F Bj ) > 6, (strong or very
strong evidence in favor of H0j ) for each j = 1, . . . , l, according to the decision
criterion given by Kass & Raftery (1995).
   We decide to use a TSARX(l; k1 , . . . , kl ; K1 , . . . , Kl ; q1 , . . . , ql )s model to adjust
the data, instead of a TARX(l; k1 + sK1 , . . . , kl + sKl ; q1 , . . . , ql ) model, if in all
the regimes j, H0j is not rejected, j = 1, . . . , l.


2.5. Estimation of the Number of Regimes
    The identiﬁcation of l, the number of regimes, can be seen as a problem of
Bayesian model choice. The decision among models Mj , j = 1, . . . , l0 , Mj being
a TSARX model with j regimes and l0 being a maximum number of regimes, is
performed by the calculation of posterior probabilities, where the model Mj is
chosen if P r(Mj | xK+1,T , z 1,T ) is the highest one over j = 1, . . . , l0 . Congdon
(2006) developed the following posterior probability estimator, which requires
separate independent MCMC samples for each of the candidate models and is
                       (i)           (i)
denoted as {θ (i) = (θ 1 , . . . , θ l0 ), i = 1, . . . , G}. An approximate Monte Carlo
estimate of P r(Mj | xK+1,T , z 1,T ) is then

  P r(Mj | xK+1,T , z 1,T ) ≈
                            1 X                                     1 X
                               G                                       G      (i)
                                                              (i)           φj
                                  P r(Mj | xK+1,T , z 1,T , θ j ) =       Pl0     (i)
                                                                                      , (5)
                            G i=1                                   G i=1       φ   k=1   k

          (i)                                     (i)           (i)
where φk = f (xK+1,T | x1,K , z 1,T , θ k , Mk )f (θ k | Mk )P r(Mk ), θ k is the
                               (i)
parameter vector of model k, θ k is the MCMC i-th iteration of the posterior
                                                                     (i)
distribution of model k, P r(Mk ) is chosen as P r(Mk ) = l10 , f (θ k | Mk ) is the
                                                                          (i)
prior distribution for model k and f (xK+1,T | x1,K , z 1,T , θ k ) is the conditional

                      Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

264                                                            Joaquín González & Fabio H. Nieto


likelihood function for Mk , for each k = 1, . . . , l0 . For numerical eﬃciency, the
calculation of (5) is based on scaled versions of the log-likelihoods. The scale uses
                 (i)
the maximum Lmax of the log-likelihoods in each iteration and subtracts this from
each log-likelihood model, that is
  (i)            (i)                (i)
               max )f (θk | Mk )P r(Mk ), i = 1, . . . , G, for some k = 1, . . . , l0 .
φk = exp(Lk − L(i)

   Some results support that the method is quite accurate and powerful for
model selection. For example, Chen et al. (2010) compare TARX models with
GARCH errors for diﬀerent regimes, while Gerlach & Chen (2008) use it for STAR
models with GARCH errors. The eﬀectiveness of this approach is examined,
comparing it with the deviance information criterion (DIC), which is described
below. Spiegelhalter, Best, Carlin & Van Der Linde (2002) propose a Bayesian
model comparison criterion deﬁned as:

                   DIC = 2Eθj |x1,K ,z1,T (D(θ j )) − D(Eθj |x1,K ,z1,T (θ j )),                 (6)

where D(A                                                e j ), with f (· |· ) the conditional
                e j ) = −2 ln f (xK+1,T | x1,K , z 1,T , A
likelihood function of the TSARX model with j regimes, j = 1, . . . , l0 . If
  (1)           (G)
θ j , . . . , θ j are MCMC samples from the distribution f (θ j | x1,T , z 1,T ), then
the DIC can be approached via Monte Carlo by

                                       2 X                1 X (i)
                                          G                  G
                                                 (i)
                             DIC =           D(θ j ) − D(      θ ),
                                       G i=1              G i=1 j

        e (i) ) = −2 ln f (xK+1,T | x1,K , z 1,T , A
where D(A                                              e (i) ), i = 1, . . . , G, j = 1, . . . , l0 .
          j                                               j
The model Mj , j = 1, . . . , l0 is chosen if its DIC is the smallest among the candidate
models.


2.6. Diagnostic Checking
    Testing for model adequacy is an important part of any time series analysis.
Based on MCMC techniques and Bayesian inference, it is natural to consider
techniques that take into account the uncertainty of the parameter estimators in
the calculation of the residuals. In this paper, the method of Gerlach, Carter &
Kohn (1999) is used, which is based on MCMC techniques, importance sampling
and the time series ut = Ft (xt | x1,t−1 , z 1,t−1 ), t = (K + 1), . . . , T , where Ft (· |· )
is the cumulative conditional distribution function given in Subsection 2.1, and
K = max{kj + sKj , qj , j = 1, . . . , l}. Gerlach et al. (1999) show that for k ≥ t,
                  PG                                    (i)                                (i)
                       i=1 Ft (xt | x1,t−1 , z 1,t−1 , θk )/f (xt,k | x1,t−1 , z 1,t−1 , θ k )
          bt =
          u                         PG                                   (i)
                                                                                                 (7)
                                      i=1 1/f (xt | x1,t−1 , z 1,t−1 , θ k )

                                                                            (i)
converges in distribution to ut when G → ∞. Here θ k is the i-th MCMC
iterated sampled from the posterior distribution f (θ k | x1,k , z 1,k ) for a given k and

                         Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                                                  265

f (· | ·) is the conditional likelihood function for the TSARX model with l regimes.
Because the variance of u    bt in equation (7) increases with (k − t), it is necessary
to calculate u  bt with t reasonably close to k. This can be achieved by increasing
k sequentially, say to 100, 200, . . . , T and evaluate u bt using the equation (7) with
(k − t) not greater than the increments. Based on the convergence properties of
ubt , the generalized residuals vbt = Φ−1 (b ut ) (Φ is the standard cumulative normal
distribution function) are approximately independent and identically distributed
N (0, 1), under the correct model. Standard diagnostic tests can be applied to
vbt such as the Ljung-Box test to determine autocorrelation, the Jarque-Bera test
to verify normality, the CUSUM plot to determine the correct speciﬁcation of
model and the CUSUMSQ plot to check marginal heteroscedasticity, among others.
Chen & So (2006) and Chen et al. (2010) conduct the diagnostic check on TARX
models with GARCH errors using generalized residuals and their results were very
satisfactory for determining the adequacy of the model.


2.7. Forecasting

    Here, the idea is to ﬁnd X    bT +h = E(XT +h | x1,T , z 1,T ), where h ≥ 1 is the
forecast horizon, x1,T = (x1 , . . . , xT ), z 1,T = (z1 , . . . , zT ), and T is the length of
the sample period. X   bT +h is the best prediction in the sense of the minimum value
that minimizes the quadratic lose function and its analytical expression is diﬃcult
or impossible to obtain in the context of nonlinear time series (see, Franses &
Van Dijk 2000). For this reason, we focus on the so-called predictive distribution
of XT +h , that is, f (xT +h | x1,T , z 1,T ). The predictive distributions of interest can
be obtained marginally from the joint predictive distribution

                    f (xT +1 , . . . , xT +h , zT +1 , . . . , zT +h , θ x , θ z | x1,T , z 1,T ),                 (8)

with θ x the parameters vector of the TSARX model and θ z the parameters vector
of the variable Zt . Previous work in this direction is presented in Nieto (2008)
and Vargas (2012), among others. It will be assumed in what follows, that the
speciﬁcations given in previous subsections, with respect to the chosen model,
are fulﬁlled. To obtain samples from the predictive distribution (8), we take into
account that the joint predictive distribution can be expressed as

  f (xT +1 , . . . , xT +h , zT +1 , . . . , zT +h , θ x , θ z | x1,T , z 1,T ) =
            f (xT +1 , . . . , xT +h , zT +1 , . . . , zT +h , θ z | θ x , x1,T , z 1,T )f (θ x | x1,T , z 1,T )
     ∏
     h
={         f (zT +i | z 1,T +i−1 , θ z )f (xT +i | zT +i , x1,T +i−1 , z 1,T +i−1 , θ x )}f (θ x | x1,T , z 1,T ),
     i=1


where

  (i) f (zT +i | z 1,T +i−1 , θ z ) is the kernel density function of the Markov chain
      {Zt },

                           Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

  266                                                           Joaquín González & Fabio H. Nieto


   (ii) f (xT +i | zT +i , x1,T +i−1 , z 1,T +i−1 , θ x ) is a normal distribution with mean


            (j)
                   X
                   kj
                                          X
                                          Kj
           a0 +          a(j)
                          m xT +i−m +           b(j)
                                                 u xT +i−su
                   m=1                    u=1

                                               X  X
                                               kj Kj
                                                                                  X
                                                                                  qj
                                           −                 a(j) (j)
                                                              m bu xT +i−m−su +         c(j)
                                                                                         v zT +i−v
                                               m=1 u=1                            v=1


         and variance (h(j) )2 if rj−1 < zT +i−d ≤ rj , for some j = 1, . . . , l,

   (iii) f (θ x | x1,T , z 1,T ) is the posterior distribution of the parameters of the
         TSARX model;

  Also, x1,T +i−1 = (x1 , . . . , xT +i−1 ) and z 1,T +i−1 = (z1 , . . . , zT +i−1 ). Thus, from
  the joint predictive distribution, zT +1 , xT +1 , zT +2 , xT +2 , . . . , zT +h , xT +h can be
  extracted sequentially as follows (Congdon 2007):
        Algorithm 2.

     1. Generate a MCMC sample of θ (k)
                                    x of the posterior distribution
        f (θ x | x1,T , z 1,T ).
                      (k)
     2. Generate zT +1 from f (zT +1 | z 1,T , θ z ).

                      (k)                       (k)
     3. Generate xT +1 from f (xT +1 | zT +1 , x1,T , z 1,T , θ (k)
                                                                x ).

                      (k)                              (k)         (k)
     4. Generate zT +i from f (zT +i | z 1,T , zT +1 , . . . , zT +i−1 , θ z ).

                      (k)                        (k)             (k)        (k)             (k)
     5. Generate xT +i from f (xT +i | zT +i , x1,T , xT +1 , . . . , xT +i−1 , z 1,T , zT +1 , . . . ,
          (k)
         zT +i−1 , θ (k)
                     x ).

     6. Repeat steps 4 and 5 for i = 2, 3, . . . , h.

                            (k)   (k)
  With the samples {zT +h , xT +h }, k = 1, . . . , G, with G being the length of the chain
  and h ≥ 1, we calculate the means (point forecasts), the standard deviations, and
  credible intervals or HDR, for both variables.
     The procedure described above includes the uncertainty of the estimation of
  the model parameters in the calculation of the forecasts, as is discussed by Vargas
  (2012) in TAR models.
      In summary, our proposed methodology for ﬁtting a TSARX model to a time
  series of interest that exhibits seasonality, consists of the following steps:

Step 1. An exploratory analysis is made for the threshold and interest variables,
        to detect the presence of seasonality. For this, plots of the time series,
        correlograms, and plots of the time series for seasonal periods are used.

                        Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

  Bayesian Analysis of TSARX Models                                                        267

Step 2. Maximum autoregressive orders are ﬁxed, which are obtained by ﬁtting
        candidate ARX models to the data and choosing that order with minimum
        DIC. The threshold nonlinearity test proposed by Tsay (1998) is carried out
        and the presence of multiplicative seasonality is tested, using the statistical
        test proposed in Subsection 2.4.

Step 3. We proceed to estimate the number of regimes, autoregressive orders and
        the remaining parameters of the TSARX model, following the procedures
        described in Subsections 2.3 and 2.5.

Step 4. The estimated model is validated, using the generalized residuals as described
        in Subsection 2.6.

Step 5. Finally, the ﬁtted model is used to obtain forecasts of the threshold and
        interest variables, as indicated in Subsection 2.7.

  All procedures were implemented in R package (Team 2016).


  3. A Simulated Example
     In this section we present a simulation example in order to ilustrate the
  performance of the proposed methodology2 .


  3.1. The model
      We assume that {Xt } follows the TSARX(2; 1, 1; 2, 1; 1, 3)12 model given by
              
              
                  2.34 + 0.50Xt−1 + 0.20Xt−12 − 0.10Xt−13 + 0.10Xt−24
              
              
              
               −0.05Xt−25 + 1.23Zt−1 + ϵt ,         if Zt−2 ≤ 4.46,
         Xt =                                                                    (9)
              
              
              
                −4.50 + 0.60Xt−1 + 0.10Xt−12 − 0.06Xt−13 − 1.15Zt−1
              
               +3.30Z
                         t−2 − 1.92Zt−3 + 4ϵt ,     if Zt−2 > 4.46,

  where {Zt } obeys the AR(1) model Zt = 1.80 + 0.60Zt−1 + at , with {at } a zero-
  mean Gaussian white noise process with variance 1, which is independent of {ϵt }
  and r = 4.46 is the median of Zt−2 . Notice that {Zt } is a homogeneous ﬁrst-order
  Markov chain, with kernel density function f1 (zt | zt−1 , θz ) and corresponds to a
  N (1.80 + 0.60zt−1 , 1).


  3.2. Exploratory Analysis of the Data
     Time series plots, the sample autocorrelation function (ACF), the sample
  partial autocorrelation function (PACF), and the average mutual information
  index (AMI) were used to preliminarily determine the presence of seasonality.
     2 Other simulated examples are given in González (2019).




                       Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

268                                                  Joaquín González & Fabio H. Nieto


The AMI measures the mutual dependence between variables Wi and Wi−τ ,
τ = 0, 1, . . . , τ ∗ , where τ ∗ is a speciﬁed maximum number of lags. If Wi and
Wi−τ are independent, then knowing Wi does not give information about Wi−τ
and viceversa, so their mutual information is zero. The mutual function of the
package tseriesChaos in R (Di Narzo & Di Narzo 2013) is used to estimate the
AMI.
    In Figure 1, the two simulated time series are ploted, with a sample size T = 600
observations. Seasonal behavior is not detected at ﬁrst sight. For {Xt } (see
Figure 2) it is observed that signiﬁcant autocorrelations can be identiﬁed in the
ﬁrst lags and lag 12, essentially in the PACF. The AMI only shows the ﬁrst three
lags to be signiﬁcant. For {Zt } (see Figure 2), only the ﬁrst lag is signiﬁcant, as
indicated by the ACF, PACF and AMI plots. Now, looking at Figure 3(a), (the
armasubsets function of TSA in R) each row in this plot represents an AR model;
the shaded rectangles in the columns indicate the variables included in the given
model. The numbers on the left margin are the values of Bayesian Information
Criterion (BIC). We have that an appropiate model for {Xt } is a multiplicative
AR(13), according to the minimum BIC. Additionally, at Figure 3(b), the box plots
by months indicate that the function of the means of the series is not constant,
which leads to suggest the presence of a seasonal cycle in the process {Xt }.




                     Figure 1: (a) Xt variable, (b) Zt variable.




                   Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                      269




Figure 2: For Xt (left) and Zt (right), (a) sample ACF, (b) sample PACF, (c) AMI
          sample.




Figure 3: For Xt , (a) multiplicative AR with minimum BIC, (b) box plots by months.



3.3. Estimation of the TSARX Model Parameters
    100 simulated time series of sample size T = 600 are generated from model (9).
For each simulated time series, the MCMC sampler is run for 12.000 iterations and
the ﬁrst 6.000 iterations are taken as the burn-in period. The posterior inference is
based on the remaining 6.000 iterations. The prespeciﬁed maximum autoregressive
orders k1 , K1 , and q1 , are chosen from an ARX(k1 + sK1 ; q1 ) model that best ﬁts
the simulated data, according to the minimum DIC. We take candidate ARX
models, with k1 = 0, 1, 2, 3, 4, 5, K1 = 0, 1, 2, 3, and q1 = 0, 1, 2, 3, . . . , 15 and
s = 12. The values k1 = 2, K1 = 2, and q1 = 3 were obtained. The Tsay threshold
nonlinearity test (Tsay 1998) is applied for delay d = 0, 1, 2, 3. The null hypothesis
of a linear ARX(24; 3) model is rejected for d = 2 at the 1% signiﬁcance level. In
the Bayesian test of multiplicative seasonality by regimes, it is required to estimate
parameters of a TARX model with two regimes, with k1 = k2 = 2, K1 = K2 = 2,
q1 = q2 = 3, and s = 12.

                   Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

270                                                        Joaquín González & Fabio H. Nieto

Table 1: Averages of posterior probabilities and DICs for selection of the number of
         regimes (100 replications).
                                  l=1              l=2     l=3      l=4           l=5
            Aver. post. prob.   0.00026       0.95415    0.03290   0.00429       0.00840
              Average DIC       3569.24       2603.58    2608.90   2700.77       2704.05



    For the hyperparameters the following values were taken: θ j10 = 0kj +Kj +1 ,
Vj10 = diag{0.10}kj +Kj +1 , θ j20 = 0Kj (s−1) , Vj20 = diag{0.10}Kj (s−1) , θ j0 = 0qj ,
Vj0 = diag{0.10}qj , j = 1, 2; also νj = 3, λj = σe3 , where σ
                                                              2
                                                                     e2 is the sample
variance of {Xt }, j = 1, 2; a = min{Zt−d }, b = max{Zt−d }, H = 10 (assures
at least 60 observations in each regime) and d0 = 5. The prior distributions are
noninformative, thus the likelihood dominates the inference. The initial values
                                (0)                   (0)                   (0)
for the parameters were: Aj1 = 0.05kj +Kj +1 , Aj2 = 0.05Kj (s−1) , Cj = 0.05qj ,
[(h(j) )2 ](0) = 0.20, j = 1, 2; d(0) = 3; the step size to execute the Metropolis
algorithm for drawing samples of r was σr = 0.025, and r(0) the 0.50 quantile of
Zt−d . When we run the Bayesian test for the 100 simulated series, the presence
of multiplicative seasonality it is detected in both regimes, with average values of
2ln(F B1 )=3725.30 and 2 ln(F B2 ) = 15072.52. In the identiﬁcation of the number
of regimes, separate and independent MCMC samples are used for the TSARX
candidate models, with l = 1, 2, 3, 4, 5 regimes (l0 = 5). Additionally, we set
φij = 25, ηij = 1.50 for all i, j, χuj = 25, ξuj = 1.50 for all u, j, ψvj = 25,
λvj = 1.50 for all v, j, i = 0, 1, 2, u = 1, 2, v = 1, 2, 3, and j = 1, 2, 3, 4, 5. These
values are the same as those chosen by Calderón & Nieto (2017). Furthermore, νj
and λj , j = 1, 2, 3, 4, 5; a, b, H and d0 are the same hyperparameters that were
assumed for the TARX model used in the seasonality test. Now, the initial values
                                                          (0)              (0)
for the parameters under the null hypothesis were Aj = 0.05kj +1 , Bj = 0.05Kj ,
  (0)                (0)                     (0)             (0)
Cj = 0.05qj , Sj = 1kj +1 , Mj = 1Kj , Nj = 1qj (1 is the vector of
ones), [(h(j) )2 ](0) = 0.20, j = 1, 2, 3, 4, 5; also, d(0) = 3, r(0) = q0.50 {Zt−d }
for two regimes, r (0) = (r1 , r2 )′ = (q0.25 {Zt−d }, q0.75 {Zt−d })′ for three regimes,
r (0) = (r1 , r2 , r3 )′ = (q0.25 {Zt−d }, q0.50 {Zt−d }, q0.75 {Zt−d })′ for four regimes
and r (0) = (r1 , r2 , r3 , r4 )′ = (q0.20 {Zt−d }, q0.40 {Zt−d }, q0.60 {Zt−d }, q0.80 {Zt−d })′
for ﬁve regimes, qα {Zt−d } being the quantile α of Zt−d . With the step sizes
σr1 = σr2 = σr3 = σr4 = 0.025 of the Metropolis algorithm we draw from the
distribution of r.
    The results of the estimation of the number of regimes are shown in Table
1. Here we see the averages of the posterior probabilities given in (5), which are
computed using each one of the 100 time series, and the average of the standard
DICs given in (6), as an alternative to doing this task. We ﬁnd that the true model
is selected.
   Considering l = 2 and maximum autoregressive orders k1 = k2 = 2, K1 =
K2 = 2 and q1 = q2 = 3, the true model can be expressed as:
                                                                              
                    S1     M1   N1                 1 1 0    1 1    1   0     0
                                         =                                           ,
                    S2     M2   N2                 1 1 0    1 0    1   1     1

                     Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                                  271

         Table 2: The best three models identiﬁed using the GVS method.
                                                                                    !
                                           1     1    0     1    1     1   0    0
                            Best
                                           1     1    0     1    0     1   1    1
                                                          (0.1801)*
                                                                                    !
                                           1     1    0     1    1     1   0    1
                        Second best
                                           1     1    0     1    0     1   1    1
                                                          (0.1379)
                                                                                    !
                                           1     1    0     1    1     1   1    0
                         Third best
                                           1     1    0     1    0     1   1    1
                                                          (0.1156)
                        *posterior probability.




where the ones indicate that the coeﬃcients associated with these latent variables
are present in the model. The three best selected models, are reported in
Table 2. Using the GVS method, the best model that is selected matches the
true model with a posterior probability of 0.1801 and the second and third best
models diﬀer from the true model only in the presence or not of some coeﬃcients of
the exogenous input in the ﬁrst regime. The three selected models are associated
with d = 2. Also, the proportion of times that the model is declared as either the
best or the second best are 88% and 95%, respectively.

        Table 3: Estimation of parameters for model 1 from 100 replications.
          Parameter         True      Estimate       S.D.            C.I. 95%           Coverage
               (1)
             a0             2.34        2.66         0.19        (2.29, 3.01)             96
               (1)
             a1             0.50        0.50         0.01        (0.49, 0.51)             93
               (1)
              b1            0.20        0.19         0.01        (0.17, 0.21)             97
               (1)
              b2            0.10        0.10         0.01        (0.08, 0.11)             96
               (1)
              c1            1.23        1.15         0.04        (1.06, 1.24)             95
               (2)
             a0            −4.50       −4.32         1.40       (−7.08, −1.45)            98
               (2)
             a1             0.60        0.57         0.02        ( 0.52, 0.61)            94
               (2)
              b1            0.10        0.09         0.03        ( 0.03, 0.15)            97
               (2)
              c1           −1.15       −1.15         0.18       (−1.49, −0.81)            97
               (2)
              c2            3.30        3.23         0.27        (2.72, 3.76)             95
               (2)
              c3           −1.92       −1.92         0.20       (−2.32, −1.53)            94
            (h(1) )2         1          1.08         0.07        (0.96, 1.24)             97
            (h(2) )2         16        16.14         1.01       (14.28, 18.22)            96
               r            4.46        4.46         0.01        (4.30, 4.72)             94
               d             2         2(96)∗
          *Number of times (out of a total of 100) where delay 2 is chosen.




                       Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

272                                                      Joaquín González & Fabio H. Nieto




                                                                                         (1)
Figure 4: Cumuplot function (left) and Geweke’s Z-score plot (right) for: (a) a1 , (b)
           (1)      (1)      (1)      (2)      (2)
          b1 , (c) b2 , (d) c1 , (e) a0 , (f) b1 , (g) (h(1) )2 , (h) (h(2) )2 , (i) r, simulated
          model.

    We proceed now, to estimate the other parameters of the TSARX model. The
estimation of the autoregressive parameters in each regime, the variance weights by
regimes, the threshold and delay values of the 100 replications are summarized in
Table 3, showing each of the true values, plus the average, the standard deviation,
the 0.025 and 0.975 quantiles of the 100 posterior means for each of the parameters.
In addition, the percentage of coverage is given, which is the number of times that
the true value of the parameter fall within the credible interval. For d, the average
of the 100 posterior mode is given. All the averages of the posterior means are
close to the true values and the 95% conﬁdence intervals of the posterior means
contain the true values. The percentages of coverage are reasonable and very close
to 95%. Also the delay d = 2 is correctly identiﬁed with the sampling scheme
considered.
    In order to ensure that for each parameter, the MCMC samples converge to the
posterior distribution, cumuplots function and Geweke’s Z-score plots are used in
one of the one hundred simulated time series. Because there are several parameters
in the model, only some of them are shown (Figure 4), where we observe that
convergence is reached in each case.


3.4. Model Diagnostics
       For each one of the 100 simulated time series we estimate ut , t = 101, . . . , 600
(see equation 7). This is done by setting the value of k sequentially at 150, 200, 250,
. . . , 600, and for each t such that k − t < 50; then, vbt is calculated, which is the
generalized residual at time t. The Ljung-Box tests for lags 1, 12 and 24 and the
Jarque-Bera test are used to check whether vbt violates the hypothesis that it is
independent and identically distributed N (0, 1). We reports the number of non-
rejections out of 100 replications (not shown in table). The model (9) is correctly

                     Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                      273

ﬁtted, it is good to see that the empirical sizes of the Ljung-Box tests are 96%,
96% and 92% and the Jarque-Bera test is 94%, respectevely, match the nominal
values of 95% very closely. Using one of the 100 simulated time series, CUSUM and
CUSUMSQ plots of the generalized residuals are presented in Figure 5, indicating
that there is no evidence of an incorrect speciﬁcation of the model nor the presence
of marginal heteroscedasticity in the generalized residuals, respectively.




Figure 5: (a) CUSUM plot, (b) CUSUMSQ plot, of generalized residuals in the
          simulated model.



3.5. Forecasts Computation
    Now, the forecast procedure developed in Subsection 2.7 is illustrated. In order
to check the forecasting performance of the model, we considered as sample period
1-587 and the forecast horizon was 588-600. In Table 4, the simulated values, point
forecasts, standard deviations and 95% credible interval averages for the variables
X and Z are presented. It is worth noticing that these estimates are obtained via
the averages of the corresponding statistics in each one od the 100 simulated time
series. We put h = 1, 2, 3, 11, 12, 13. Additionally, in the last column of the table,
the coverage percentage is presented.
    We ﬁnd that the forecasts are very close to the simulated values, all the
simulated values fall within the corresponding 95% credible intervals, the standard
deviations increase as the forecast horizon increases, and the coverage percentage
is close to the 95% conﬁdence level. The posterior distributions of the predictive
distributions present a high variability. In this way, We assume that it is due to the
use of priori noninformative distributions. Similar results to those found in Table
4, are given in Nieto (2008) and Vargas (2012), for TAR models. The behavior
of the uncertainty measure of the long-term forecasts for TSARX models, maybe
investigated, since it escapes the purpose of this paper.




                   Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

274                                                   Joaquín González & Fabio H. Nieto

          Table 4: Forecasts for variables X and Z with 100 replications.
           Horizon (h)    XT +h    bT +h
                                   X        S.D.      C.I. 95%       Coverage
               1           6.49     5.80    2.88     (0.10, 11.30)       94
               2           5.76     5.74    3.48    (−1.12, 12.51)       96
               3           7.09     6.36    5.39    (−4.62, 15.19)       95
               11          6.72     6.35    8.54   (−11.96, 17.80)      100
               12          7.48     6.41    8.56   (−11.89, 17.89)      100
               13          6.12     6.34    8.60   (−12.05, 17.97)      100
           Horizon (h)    ZT +h    bT +h
                                   Z        S.D.      C.I. 95%       Coverage
               1           4.25     4.36    0.99     (2.39, 6.32)        93
               2           4.39     4.41    1.16     (2.13, 6.69)        95
               3           4.14     4.44    1.21     (2.06, 6.83)        99
               11          4.59     4.49    1.24     (2.05, 6.94)        98
               12          4.72     4.49    1.25     (2.05, 6.93)       100
               13          4.56     4.50    1.25     (2.04, 6.95)       100




4. An Empirical Application
   In this section, we apply the proposed methodology to Colombian monthly
economic time series. The variables are the total monthly unemployment rate,
TDt , and a monthly coincident index that traces the Colombian economy, ISEt .
In our analysis, we focus on the growth of the total monthly unemployment
rate, Xt = T Dt − T Dt−1 , as the interest variable, and the monthly growth of
the logarithmic transformation of ISEt , Zt = (ln(ISEt ) − ln(ISEt−1 )) × 100 (in
percent) as the threshold variable. The sample period is from February, 2000
to December, 2016 (203 observations). The data is provided by the DANE, the
Colombian oﬃcial agency for the study and diﬀusion of oﬃcial statistics.


4.1. Exploratory Analysis of the Data
   The time series {Xt } and {Zt } are given in Figure 6(a) and (b), respectively.
{Xt } presents annual positive peaks (Januaries), while {Zt} presents very
pronounced annual negative peaks (Januaries). This indicates some seasonal
behavior in both series, inherited from the original time series. It can also be
observed that the series have no trends, but present seasonal cycles.




                    Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                     275




Figure 6: (a) Xt , growth of the Colombian total monthly unemployment rate, (b) Zt ,
          monthly growth of the logarithmic transformation of ISEt .


    In Figure 7, autocorrelograms and the AMI for Xt and Zt are shown. In both
cases, the samples ACF show seasonal lags that do not decrease and the PACF
and AMI identify signiﬁcant correlations in the ﬁrst lags and lags 12, 24 and 36.
Figure 8 suggestes ﬁtting a multiplicative AR(26) model to the two time series,
following the minimum BIC. Looking at the box plots, Xt presents a distribution
with higher values in the months of January, and a distribution with lower values
in the months of March. On the other hand, for Zt there is a distribution with
lower values in the months of January, and a distribution with higher values in
the months of October. In this way, there is some empirical evidence about the
presence of seasonality in the time series.




Figure 7: For Xt (left) and Zt (right), (a) sample ACF, (b) sample PACF, (c) sample
          AMI, for the empirical data.




                  Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

276                                                   Joaquín González & Fabio H. Nieto




Figure 8: For Xt (top) and Zt (bottom), (a) multiplicative AR with minimum BIC, (b)
          box plots by months, empirical data.



      An adequate linear AR model ﬁtted to the threshold process is

        Zt = − 0.53Zt−1 − 0.21Zt−2 + 0.60Zt−12 + 0.32Zt−13 + 0.13Zt−14
                                                   √                                   (10)
             + 0.38Zt−24 + 0.20Zt−25 + 0.08Zt−26 + 0.57at .


4.2. Estimation of the TSARX Model Parameters
   To obtain the maximum autoregressive orders, the same candidate ARX models
of Subsection 3.3 are considered. The values k1 = 3, K1 = 2 and q1 = 2
were achieved. These values are ﬁxed to apply the Tsay threshold nonlinearity

                    Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                                 277

test (Tsay 1998), the proposed Bayesian seasonality statistical test, the Congdon
method and the GVS technique.
    Then, the threshold nonlinearity test is applied for delay d = 0, 1, . . . , 10,
autoregressive orders k1 + sK1 = 27 and q1 = 0, 2 and 15. The null hypothesis of a
linear ARX(k1 + sK1 ; q1 ) model is rejected for diﬀerent lags at the 1% signiﬁcance
level; in particular, for d = 0, k1 + sK1 = 27, q1 = 0 and for d = 3, k1 + sK1 = 27,
q1 = 0 and 2. These results are shown in Table 5.

                 Table 5: Threshold nonlinearity test for the empirical data.
                                         k1 + sK1 = 27 and q1 = 0
 d                 0        1      2          3     4      5        6     7         8      9     10
 F statistics     2.54    1.37    0.96      1.58   1.01   1.51   1.67    1.06      1.18   1.19   1.52
 p value          0.00    0.13    0.53      0.05   0.46   0.07   0.03    0.40      0.26   0.25   0.07
                                         k1 + sK1 = 27 and q1 = 2
 d                 0        1      2          3     4      5        6     7         8      9     10
 F statistics     2.47    1.39    0.87      1.86   0.86   1.52   1.32    0.93      1.45   1.51   1.85
 p value          0.00    1.39    0.67     0.001   0.68   0.06   0.14    0.58      0.08   0.06   0.01
                                       k1 + sK1 = 27 and q1 = 15
 d                 0        1      2          3     4      5        6     7         8      9     10
 F statistics     1.32    1.12    1.13      1.08   0.64   1.13   0.99    1.12      0.84   0.72   1.53
 p value          0.14    0.32    0.31      0.37   0.95   0.31   0.50    0.32      0.74   0.88   0.05


   The above results allows us to consider a TARX model with a minimum of
two regimes, which is speciﬁed in the seasonality test. For the Bayesian test of
multiplicative seasonality by regimes, we considered l = 2 and l = 3 regimes in a
TARX model. It is intrinsically required to estimate parameters of a TARX(2; 3 +
12(2), 3 + 12(2); 2, 2) model and of a TARX(3; 3 + 12(2), 3 + 12(2), 3 + 12(2); 2, 2, 2)
model.
    The MCMC sampler for posterior analysis is again based on 6.000 iterations
after a burn-in period of 6.000 iterations. The hyperparameters and initial values
for each of the parameters of the TARX models, are the same as those in Subsection
3.3. In Table 6, the results of the seasonality test are listed. A multiplicative
TSARX model with two regimes is selected. For the case of l = 3 regimes, the
second regime does not show the presence of multiplicative seasonality.

                Table 6: Multiplicative seasonality test for the empirical data.
                                 l=2                             l=3
                       2 ln(F B1 ) = 321.20          2 ln(F B1 ) = 9.464 × 1032
                       2 ln(F B2 ) = 240611.40       2 ln(F B2 ) = 1.698 × 10−12
                                                     2 ln(F B3 ) = 1.649 × 1028


   Now, we estimate the number of regimes and the autoregressive orders of a
TSARX model. The hyperparameters and initial values of the parameters for each
possible TSARX model are the same, as those described in Subsection 3.3. The

                         Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

278                                                            Joaquín González & Fabio H. Nieto


posterior probability of the number of regimes of a TSARX with j = 1, 2, 3, 4, 5
regimes, is given in Table 7, where it can be seen that the number of regimes
associated with the highest posterior probability is two. This result is conﬁrmed
with the smallest DIC value.
Table 7: Posterior probabilities and DIC for chosing the number of regimes in the
         empirical data.
                                 l=1           l=2            l=3         l=4         l=5
           Posterior prob.      0.00021    0.91054        0.00138        0.00168     0.08619
                DIC             2088.29    1304.98        1830.86        1838.24     1312.73


   In Table 8, the three best models are observed based on the highest posterior
probabilities, for the latent variable matrices Sj , Mj and Nj , j = 1, 2. The
probabilities of the best three TSARX models with two regimes are 0.2122, 0.1536
and 0.1078. The three models are associated with d = 3 and they look very similar.
Indeed, they have the same structure in the second regime and diﬀer mainly in the
                         (1)     (1)
entries of coeﬃcients a3 and b2 . The best model is chosen and the remaining
parameters are estimated, which are shown in Table 9. Following the obtained
results, the TSARX model is explicitly given by
                                                       √
         −0.22 − 0.47Xt−1 + 0.53Xt−12 + 0.25Xt−13 + 0.36ϵt ,       if Zt−3 ≤ 1.80,
      
      
          −0.70Xt−1 − 0.58Xt−2 − 0.47Xt−3 + 0.40Xt−12 +
Xt =
      
         0.28Xt−13 + 0.23Xt−14 + 0.19Xt−15 + 0.47X   t−24 +
                                               √
          0.33Xt−25 + 0.27Xt−26 + 0.22Xt−27 + 0.46ϵt ,             if Zt−3 > 1.80,

where the model for Zt is given in model (10).

Table 8: The best three models identiﬁed using the GVS method, for the empirical
         data.
                                                                                
                                           1    1    0    0    1     0   0   0
                         Best                                                   
                                           0    1    1    1    1     1   0   0
                                                         (0.2122)*
                                                                                
                                           1    1    0    0    1     1   0   0
                      Second best                                               
                                           0    1    1    1    1     1   0   0
                                                         (0.1536)
                                                                                
                                           1    1    0    1    1     0   0   0
                      Third best                                                
                                           0    1    1    1    1     1   0   0
                                                         (0.1078)
                      *posterior probability.


   An interpretation of the ﬁtted TSARX model is the following: ﬁrst of all, only
two regimes for the growth of the Colombian total monthly unemployment rate
are detected, which could be termed as regimes of the monthly growth of the
logarithmic transformation of the ISEt , low and high. In the low regime, the most

                   Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                              279

pronounced negative peaks are also included. In addition, it is interesting to note
that for the ﬁrst regime, the intercept is negative and aﬀects the epochs of recession
of the economy by 22%, this reﬂects the economic impact that the growth of the
unemployment rate has in that period; on the contrary, in the periods of expansion
of the economy that are modeled by the second regime, the intercept is zero, giving
evidence of a rapid economic recovery. Another interesting characteristics are the
following: (1) the multiplicative AR model of the second regime has autoregressive
orders higher than those of the ﬁrst regime, (2) the coeﬃcients of the nonseasonal
component have negative signs, and the coeﬃcients of the seasonal component
have positive signs of similar magnitude, in the two regimes of the model, (3) the
variances of the regimes are similar, and (4) the monthly growth of the logarithmic
transformation of the index, aﬀects the growth of the unemployment rate, which
took place three months earlier.

                  Table 9: Estimation of parameters for empirical data.
                       Parameter     Estimate    S.D.       C.I. 95%
                            (1)
                          a0           −0.22     0.06    (−0.35, −0.09)
                           (1)
                          a1           −0.47     0.07    (−0.61, −0.33)
                           (1)
                          b1            0.53     0.08     (0.37, 0.68)
                           (2)
                          a1           −0.70     0.13    (−0.94, −0.44)
                           (2)
                          a2           −0.58     0.14    (−0.84, −0.31)
                           (2)
                          a3           −0.47     0.13    (−0.73, −0.21)
                           (2)
                          b1            0.40     0.09     (0.22, 0.58)
                           (2)
                          b2            0.47     0.09     ( 0.30, 0.66)

                         (h(1) )2      0.36     0.05     (0.27, 0.48)
                         (h(2) )2      0.46     0.07     (0.34, 0.63)
                            r          1.80     0.09     (1.56, 1.94)
                            d        3(96%)∗
                       * Percentage frequency of estimated delay.




                                                                                         (1)
Figure 9: Cumuplot function (left) and Geweke’s Z-score plot (right) for: (a) a0 , (b)
           (1)      (1)      (2)      (2)      (2)
          a1 , (c) b1 , (d) a1 , (e) b1 , (f) b2 , (g) (h(1) )2 , (h) (h(2) )2 , (i) r, empirical
          data.




                     Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

280                                                      Joaquín González & Fabio H. Nieto


    In Figure 9 the cumuplots function and Geweke’s Z-score plots are shown,
respectively, for some of the MCMC chains of the estimated parameters. The
other chains can be provided by the authors upon request. The convergence,
to the posterior distributions, is almost immediate and clearly reached, after the
burn-in period in each case considered.


4.3. Model Diagnostics
    In Table 10 we present the results of applying the Ljung-Box test for lags 1, 2,
3, 12 and 24 and the Jarque-Bera statistical test to the generalized residuals. In all
cases, the null hypotheses of zero autocorrelations and normality are not rejected,
under the 5% signiﬁcance level. These results suggest that the TSARX model with
two regimes ﬁt reasonably well the empirical data. Figure 10 shows the CUSUM
and CUSUMSQ plots of the generalized residuals, which complements the good
ﬁt of the model.




Figure 10: (a) CUSUM plot, (b) CUSUMSQ plot, of the generalized residuals in the
           real data.


Table 10: Ljung-Box test for diﬀerent lags (LB) and Jarque-Bera test (JB) in the real
          data. p-values in parentheses.
            LB1           LB2          LB3        LB12        LB24         JB
           1.01313       1.06389     1.33908      8.35656    16.56653    38.55404
          (0.31415)     (0.58746)   (0.71987)   (0.75668)    (0.86655)   (0.25323)




4.4. Forecasts of the Variables
   As in the simulation example, we compute now forecasts for the variables X and
Z. Our goal is double: ﬁrst, to compute point predictions and second, to check the
model performance for forecasting. We use 6.000 MCMC iterations in obtaining
samples from the corresponding predictive distributions. We present the results in

                      Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

Bayesian Analysis of TSARX Models                                                      281

Table 11, beginning in January, 2017 (h = 1) until January, 2018 (h = 13), period
for which we include additional observations. The table includes the observed
values, point forecasts, standard deviations of the predictive distributions and 95%
conﬁdence-level credible intervals. It can be noted that in both variables, (1) the
point forecasts are very close to the observed values, (2) the standard deviations
increase with larger values of h, and (3) all the observed values fall within the
credible intervals.

 Table 11: Forecasts for threshold and interest variables in the empirical application.
               Horizon (h)   XT +h     bT +h
                                       X         S.D.        C.I. 95%
                    1         2.99      2.16     0.76      (0.67, 3.66)
                    2        −1.23     −0.99     0.80      (−2.64, 0.81)
                    3        −0.80     −0.36     0.80      (−2.10, 1.31)
                   11        −0.19     −0.74     0.85      (−2.47, 0.91)
                   12         0.26      0.96     0.90      (−0.76, 2.79)
                   13         3.13      2.42     1.08      (0.28, 4.56)
               Horizon (h)   ZT +h     bT +h
                                       Z         S.D.        C.I. 95%
                    1        −15.64    −14.79    1.25    (−17.23, −12.32)
                    2        −5.64     −4.95     1.40     (−7.74, −2.18)
                    3          3.46     2.97     1.41      (0.19, 5.75)
                   11         2.17      1.46     1.43      (−1.32, 4.25)
                   12         2.26      2.10     1.45      (−0.67, 4.89)
                   13        −14.78    −14.77    1.61    (−17.93, −11.61)


   In future research, we will compare forecasts from the TSARX models with
those from linear seasonal models and other nonlinear seasonal models, following
the ideas given in Franses & Van Dijk (2005) and Vaca (2018).



5. Conclusions
    In this paper, an open-loop threshold autoregressive model is speciﬁed for
explaining the presence of seasonality in a nonlinear time series. The autoregressive
model is, essentially, multiplicative but depending on the regimes. A Bayesian test
is proposed for detecting this kind of seasonality. To ﬁt the model to a time series, a
full Bayesian methodology is developed that consists in the phases of (i) identifying
the model, (ii) estimating the unknown parameters, (iii) checking the diagnostic
via generalized residuals, and (iv) using the model to compute forecasts of the
variables. The proposed methodology was illustrated with a simulated example
and a real-data application. In future research, a more extensive characterization
of the model may be conducted, in order to detect in the data more closely this
kind of seasonality. Also, an extension to nonlinear multivariate time series may
be investigated.

                   Revista Colombiana de Estadística - Applied Statistics 43 (2020) 251–285

282                                                 Joaquín González & Fabio H. Nieto


Acknowledgements
   We gratefully acknowledge the very useful comments and suggestions of an
anonymous referee, which helped to improve substantially the paper.
                                                                
                Recibido: julio de 2019 — Aceptado: enero de 2020


References
Calderón S A, Nieto F H. Bayesian analysis of multivariate threshold autoregressive models with missing data.(2017). Communications in Statistics-Theory and Methods.
Chen C W. A bayesian analysis of generalized threshold autoregressive models.(1998). Statistics and Probability Letters.
Chen C W, Gerlach R H, Lin A M. Falling and explosive dormant and rising markets via multiple-regime ﬁnancial time series models.(2010). Applied Stochastic Models in Business and Industry.
Chen C W, Lee J C. Bayesian inference of threshold autoregressive models.(1995). Journal of Time Series Analysis.
Chen C W, Liu F C, So M K. A review of threshold time series models in ﬁnance.(2011). Statistics and its Interface.
Chen C W, So M K. On a threshold heteroscedastic model.(2006). International Journal of Forecasting.
Congdon P. Bayesian model choice based on monte carlo estimates of posterior model probabilities.(2006). Computational Statistics and Data Analysis.
Congdon P. Bayesian statistical modelling.(2007). John Wiley and Sons.
Crespo J. Modelling seasonal asymmetries using seasonal setar models.(2001). Working Paper.
De Gooijer J G, Vidiella-i, Anguera A. Nonlinear stochastic inﬂation modelling using seasetars.(2003). Insurance: Mathematics and Economics.
Dellaportas P, Forster J J, Ntzoufras I. On bayesian model and variable selection using mcmc.(2002). Statistics and Computing.
Di Narzo A F, Di Narzo F. Tserieschaos: Analysis of nonlinear time series.(2013). R package.
Dickey J M. The weighted likelihood ratio linear hypotheses on normal location parameters.(1971). The Annals of Mathematical Statistics.
Franses P H, de Bruin P, van Dijk D. Seasonal smooth transition autoregression.(2000). Erasmus University.
Franses PH, Van Dijk D. Non-linear time series models in empirical ﬁnance.(2000). Cambridge University Press.
Franses P H, Van Dijk D. The forecasting performance of various models for seasonality and nonlinearity for quarterly industrial production.(2005). International Journal of Forecasting.
Gelfand A E, Smith A F. Sampling-based approaches to calculating marginal densities.(1990). Journal of the American Statistical Association.
George E I, McCulloch R E. Variable selection via gibbs sampling.(1993). Journal of the American Statistical Association.
Gerlach R, Carter C, Kohn R. Diagnostics for time series analysis.(1999). Journal of Time Series Analysis.
Gerlach R, Chen C W. Bayesian inference and model comparison for asymmetric smooth transition heteroskedastic models.(2008). Statistics and Computing.
Geweke J. Evaluating the accuracy of sampling-based approaches to the calculation of posterior moments In Bayesian Statistics.(1992). Oxford University Press.
González J. Modelamiento de procesos autorregresivos de umbrales estacionales.(2019). Universidad Nacional de Colombia.
Hansen B E. Threshold autoregression in economics.(2011). Statistics and its Interface.
Kass R E, Raftery A E. Bayes factors.(1995). Journal of the American Statistical Association.
Kuo L, Mallick B. Variable selection for regression models.(1998). Sankhaya: The Indian Journal of Statistics.
Metropolis N, Rosenbluth A W, Rosenbluth M N, Teller A H. Equation of state calculations by fast computing machines.(1953). The Journal of Chemical Physics.
Meyn S P, Tweedie R L. Markov chains and stochastic stability.(2009). Springer Science and Business Media.
Nieto F H. Modeling bivariate threshold autoregressive processes in the presence of missing data.(2005). Communications in Statistics - Theory and Methods.
Nieto F H. Forecasting with univariate tar models.(2008). Statistical Methodology.
Nieto F H, Moreno E C. Univariate conditional distributions of an open-loop tar stochastic process.(2016). Revista Colombiana de Estadística.
Nieto F H, Zhang H, Li W. Using the reversible jump mcmc procedure for identifying and estimating univariate tar models.(2013). Communications in Statistics-Simulation and Computation.
O’Hara R B, Sillanpä M J. A review of bayesian variable selection methods: what, how and which.(2009). Bayesian Analysis.
Plummer M, Best N, Cowles K, Vines K. CODA: convergence diagnosis and output analysis for MCMC.(2006). R news.
So M K, Chen C W. Subset threshold autoregression.(2003). Journal of Forecasting.
So M K, Chen C W, Liu F C. Best subset selection of autoregressive models with exogenous variables and generalized autoregressive conditional heteroscedasticity errors.(2006). Journal of the Royal Statistical Society.
Spiegelhalter D J, Best N G, Carlin B P, Van Der Linde A. Bayesian measures of model complexity and ﬁt.(2002). Journal of the Royal Statistical Society.
Team R D C. R: A language and environment for statistical computing.(2016). R Foundation for Statistical Computing.
Tong H. Non-linear time series: a dynamical system approach.(1990). Oxford University Press.
Tong H. Threshold models in time series analysis-some reﬂections.(2015). Journal of Econometrics.
Tong H, Chen C H. Pattern recognition and signal processing.(1978). Springer Netherlands.
Tong H L, Lim K. Threshold autoregression limit cycles and cyclical data.(1980). Journal of the Royal Statistical Society.
Tsay R S. Testing and modeling multivariate threshold models.(1998). Journal of the American Statistical Association.
Vaca P A. Analysis of the forecasting performance of the threshold autoregressive model.(2018). Universidad Nacional de Colombia.
Vargas L. Cálculo de la distribución predictiva en un modelo TAR.(2012). Universidad Nacional de Colombia.
Verdinelli I, Wasserman L. Computing bayes factors using a generalization of the savage-dickey density ratio.(1995). Journal of the American Statistical Association.
Zhang H, Nieto F H. Tar modeling with missing data when the white noise process follows a student’s t-distribution.(2015). Revista Colombiana de Estadística.