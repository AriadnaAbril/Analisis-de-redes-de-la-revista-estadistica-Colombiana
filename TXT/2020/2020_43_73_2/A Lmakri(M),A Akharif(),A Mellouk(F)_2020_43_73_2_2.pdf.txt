Optimal Detection of Bilinear Dependence in Short Panels of Regression Data. Detección óptima de dependencia bilineal en regresión con datos de panel cortos
Abdelmalek Essaadi University, Tangier, Morocco. Centre Régional des Métiers de l’Education et de la Formation, Tangier, Morocco
Abstract
In this paper, we propose parametric and nonparametric locally and asymptotically optimal tests for regression models with superdiagonal bilinear time series errors in short panel data (large n, small T ). We establish a local asymptotic normality property– with respect to intercept µ, regression coeﬃcient β, the scale parameter σ of the error, and the parameter b of panel superdiagonal bilinear model (which is the parameter of interest)– for a given density f1 of the error terms. Rank-based versions of optimal parametric tests are provided. This result, which allows, by Hájek’s representation theorem, the construction of locally asymptotically optimal rank-based tests for the null hypothesis b = 0 (absence of panel superdiagonal bilinear model). These tests –at speciﬁed innovation densities f1 – are optimal (most stringent), but remain valid under any actual underlying density. From contiguity, we obtain the limiting distribution of our test statistics under the null and local sequences of alternatives. The asymptotic relative eﬃciencies, with respect to the pseudo-Gaussian parametric tests, are derived. A Monte Carlo study conﬁrms the good performance of the proposed tests.
Key words: Bilinear process; local asymptotic normality; local asymptotic linearity; panel data; pseudo-Gaussian tests; rank tests.
Resumen
En este artículo, se proponen pruebas paramétricas y no paramétricas locales y asintóticamente óptimas para modelos de regresión con errores de series temporales bilineales superdiagonales en datos de panel cortos (n grande, T pequeño). Se establece una propiedad de normalidad asintótica local con respecto a la intercepción µ, el coeﬁciente de regresión β, el parámetro de escala σ del error y el parámetro b del modelo bilineal superdiagonal con datos de panel (que es el parámetro de interés) para una densidad determinada f1 de los términos de error. Se proporcionan versiones basadas en rangos de pruebas paramétricas óptimas. Este resultado permite, por el teorema de representación de Hájek, la construcción de pruebas locales basadas en rangos asintóticamente óptimas para la hipótesis nula b = 0 (ausencia del modelo bilineal superdiagonal con datos de panel). Estas pruebas, en densidades de innovación especicadas f1 , son óptimas (más estrictas), pero siguen siendo válidas en cualquier densidad subyacente. A partir de la contigüidad, se obtiene la distribución limitante de las estadísticas de prueba, bajo la hipótesis nula y una secuencia de alternativas locales. Se deriva eﬁciencia relativa asintótica de las pruebas, con respecto a las pruebas paramétricas pseudo-Gaussianas. Un análisis basado en simulaciones de Monte Carlo conﬁrma el buen desempeño de las pruebas propuestas.
Palabras clave: Datos de panel; Linealidad asintótica local; Normalidad asintótica local; Proceso bilineal; Prueba pseudo-gaussiana; Pruebas de rango.



1. Introduction
   Recent evolution in theory and applications has provided very powerful
convenient tools for the modelling of time series data, and in the last decades,
we have seen a growing interest in nonlinear models. It has been shown that
nonlinear time series models gives better approximations than higher-order linear
ones simple in modelling nonlinear dynamic systems. One of the approaches to
nonlinear time series modelling is the class of bilinear processes, introduced by
Granger & Andersen (1978). Assuming (εt ) is i.i.d. (0, σ 2 ),

                    X
                    p                 X
                                      q                 P X
                                                        X Q
             Xt =         aj Xt−j +         cj εt−j +             bjk εt−j Xt−k + εt
                    j=1               j=1               j=1 k=1


deﬁnes the bilinear process (Xt ) of order (p, q; P, Q)–shortly BL(p, q; P, Q).
    This interest is due to its widespread use in various ﬁelds, see for example,
Maravall (1983), Rao & Gabr (1984), Weiss (1986). Regardless of theoretical
diﬃculties, the fundamental probabilistic properties have been solved for several
particular cases, for example, the stationarity and invertibility have been solved
for ﬁrst-order superdiagonal model by Guegan (1981). Testing problems and there
power properties have been treated for null hypothesis of white noise against
bilinear dependence in Hallin & Mélard (1988), Saikkonen & Luukkonen (1991),
Benghabrit & Hallin (1992), Benghabrit & Hallin (1996) and Guegan & Pham
(1992). The statistical problem of estimation of the parameters for some simple
models have been considered in Pham & Tran (1981), Grahn (1995), Hristova
(2005) and Tan & Wang (2015).

                Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                              145

   Regression models with correlated errors have been the focus of considerable
attention in econometrics and statistics. Various manuscripts treat the problem
of correlated errors in regression models in which the errors follow the linear
models such as autoregressive (AR), moving average (MA) (e.g., Baltagi & Li,
1995), the mixed autoregressive and moving average (ARMA) models (e.g., Allal
& El Melhaoui, 2006), or the nonlinear models such as RCAR, ARCH, fractional
ARIMA and bilinear models (e.g., Hwang & Basawa, 1993, Dutta, 1999, Hallin,
Taniguchi, Serroukh & Choy, 1999, and Elmezouar, Kadi & Gabr, 2012, etc.).
   Consider the following panel data regression model in Pesaran (2015):

                yi,t = µ + β ′ xi,t + ei,t , i = 1, 2, . . . , n; t = 1, 2, . . . , T,   (1)

where yi,t is the observation on the ith cross-sectional unit for the tth time period,
xi,t denotes the K × 1 vector of observations on the non-stochastic regressors.
(µ, β ′ )′ ∈ RK+1 is the corresponding regression coeﬃcients. Here, the error terms
ei,t are assumed to follow a simple case of bilinear model with panel data, which
takes the following form

                     ei,t = bei,t−l εi,t−k + εi,t           with l > k > 1,              (2)

where εi,t ∼ i.i.d.(0, σ 2 ) for all i and t.
    Test of homogeneity for panel bilinear time series model have been treated in
Lee, Kim, & Lee (2013) and Kim (2014). Furthermore, probabilistic properties
such as stationarity and invertibility have been studied in Quinn (1982) remains
valid in panel bilinear model (2). Denote by Fi,t (ε) and Fi,t (e) the σ−algebras
generated by {εi,s |s 6 t} and {ei,s |s 6 t}, respectively. Then,

   1. Equation (2) admits a unique stationary solution ei,t if and only if b2 σ 2 < 1,
      and given by
                                    ∞
                                    X            Y
                                                 j
                      ei,t = εi,t +   bj εi,t−lj   εi,t−k−(s−1)l .
                                            j=1            s=1


   2. Equation (2) is invertible if and only if 2b2 σ 2 < 1, in this case, one can write
                                          ∞
                                          X                     Y
                                                                j
                          εi,t = ei,t +         (−b)j ei,t−kj         ei,t−l−(s−1)k .
                                          j=1                   s=1


Clearly, model (1) reduces to the classical multiple regression model

                                    yi,t = µ + β ′ xi,t + εi,t ,

with constant coeﬃcients µ and β if and only if b = 0. The detection problem we
are addressing consists of testing the null hypothesis H0 : b = 0 with unspeciﬁed
µ, β, σ 2 and f1 against the alternative H1 : b 6= 0. Clearly this testing problem
corresponds to testing serial independence against bilinear serial dependence in
model (1).

                 Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

146                                     Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk


    In this research, to derive optimal tests, the uniform local asymptotic normality
(ULAN) property is established for a class of panel regression models with
superdiagonal bilinear time series errors via the quadratic mean diﬀerentiability
of f 1/2 , where f is the density of εi,t . This last property (see, Le Cam & Yang,
2000), has recognized success in a variety of testing problems: see, Swensen (1985),
Akharif & Hallin (2003), Cassart, Hallin & Paindaveine (2011), Bennala, Hallin &
Paindaveine (2012) and Fihri, Akharif, Mellouk & Hallin (2020).
   Our statistical tests are based on the ULAN property. These tests are shown
to be asymptotically eﬃcient and their asymptotic power is also derived.
    ULAN plays a fundamental role in this treatment and leads us to construct
locally and asymptotically optimal parametric tests. The special case of the
pseudo-Gaussian tests (optimal under Gaussian densities but valid under ﬁnite-
variance non-Gaussian ones) is derived, but unfortunately, their local asymptotic
power under non-Gaussian g1 (especially the skew and heavy-tailed ones), can be
extremely poor, which leads us to construct a rank-based optimal tests (van der
Waerden, Wilcoxon, Laplace, data-driven scores, etc.) based on the Hájek-Le Cam
approach.
    Asymptotic relative eﬃciencies with respect to the pseudo-Gaussian procedure
show that the van der Waerden version of our rank-based tests uniformly dominates
its pseudo-Gaussian counterpart.
    The paper is organized as follows. In Section 2 we introduce notations,
assumptions and state the ULAN property for model (1)-(2). Section 3 is devoted
to prove a local asymptotic linearity property. These results are used in the
derivation of locally asymptotically optimal (most stringent) tests, and in the
computation of their asymptotic powers. The particular case of the pseudo-
Gaussian tests is investigated in Section 3.2. Optimal rank tests are derived in
Section 4 and some special cases (van der Waerden, Wilcoxon and Laplace scores)
are considered in Section 4.3. Section 5.1 provides asymptotic relative eﬃciencies,
and simulations are carried out in Section 5.2 to investigate the ﬁnite-sample
performance of our tests. Finally, we provide some conclusions.



2. Uniform Local Asymptotic Normality

2.1. Notations and Main Assumptions
                    (n)
   Denote by Pµ,β ′ ,σ2 ,b;f1 the probability distribution of the observations
                        ′
  (n)′ (n)′         (n)′
                            , where yi := (yi,1 , . . . , yi,T )′ is generated by (1) and (2),
                                     (n)
 y1 , y2 , . . . , yn
           (n)
and by Pµ,β ′ ,σ2 ,0;f1 the probability distribution under the null hypothesis ei,t =
εi,t ∼ i.i.d.(0, σ 2 ). Assume that {εi,t }(1≤i≤n,1≤t≤T ) is unobservable sequence, with
density f : ε 7→ f (ε) := (1/σ)f1 (ε/σ), where f1 belongs to some adequate class of
standardized densities (3). We suppose that the vector of starting values

                 Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                                  147

    (n)
   e0     :=
        (n)             (n)                    (n)            (n)             (n)     (n)
   {(ei,1−l εi,1−k , ei,2−l εi,2−k , . . . , ei,k−l εi,0 , ei,k+1−l , . . . , ei,−1 , ei,0 ), i = 1, . . . , n}

is observable for each individual i.
    Throughout this paper, we consider the class of standardized densities
                                    Z 1                   Z 0          
       F0 := f1 : f1 (u) > 0 ∀u ∈ R,     f1 (u)du = 0.5 =       f1 (u)du .                                    (3)
                                                         −1                         −∞

Note that, for f such that f1 ∈ F0 , the median and median absolute deviation
are 0 and σ, respectively. This standardization, contrary to the usual one based
on the mean and the standard deviation, avoids all moment assumptions; it plays
the role of an identiﬁcation constraint, and has no impact on subsequent results.
    The main technical tool in our derivation of optimal tests is the uniform local
asymptotic normality, with respect to (µ, β ′ , σ 2 , b)′ , at (µ, β ′ , σ 2 , 0)′ , of the families
of distributions
             n                                                                            o
    Pf1 := Pµ,β,σ2 ,b;f1 : (µ, β) ∈ RK+1 , σ 2 > 0, b ∈ R∗ and 2b2 σ 2 < 1 .
      (n)        (n)
                                                                                                (4)

   Establishing ULAN property requires some technical assumptions about the
innovation density f1 (Assumption (A)) and the asymptotic behavior of the
regressors (Assumption (B)).
Assumption (A)

(A.1) f1 ∈ F0 ;

(A.2) f1 is C 1 on R, withZ ﬁrst derivative f1′ and letting  Z       Φf1 = −f1′ /f1 ,
      assume that I(f1 ) :=      Φ2f1 (u)f1 (u)du, J(f1 ) :=    u2 Φ2f1 (u)f1 (u)du and
                Z              R                              R

      K(f1 ) :=   uΦ2f1 (u)f1 (u)du are ﬁnite.
                       R

Denote by FA the set of all densities satisfying Assumption (A).
               1 XX
                           n   T
    Let C(n) :=          xi,t x′i,t , the following assumption concern the asymptotic
               n i=1 t=1
behavior of regression coeﬃcients, it is standard in the context of rank-based
inference.
Assumption (B)

(B.1) The limits lim C(n) =: C, where C is positive deﬁnite. Letting K(n) :=
                       n→∞
        (C(n) )−1/2 , note that lim K(n) =: K = C−1/2 ;
                                      n→∞


                                           1 XX
                                               n     T
                               (n)
(B.2) for all k and n, xk            :=              xk;i,t = 0;
                                          nT i=1 t=1


                     Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

148                                            Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk


(B.3) the classical Noether (1949) conditions hold:

                        max x2k;i,t
                       1≤i≤n
                 lim                       =0         k = 1, 2, . . . , K, t = 1, 2, . . . , T.
                    n X
                n→∞ X T
                                 x2k;i,t
                       i=1 t=1


      Interesting special cases are

  (i) The Student distributions (with ν > 2 degrees of freedom), with standardized
      density

                                           Γ((ν + 1)/2) p
                f1 (u) = ftν (u) :=                       aν /πν(1 + aν u2 /ν)−(ν+1)/2 ,
                                              Γ(ν/2)

        with I(f1 ) = aν (ν + 1)/(ν + 3) and J(f1 ) = 3(ν + 1)/(ν + 3), the normalizing
        constant aν > 0 is such that ftν ∈ FA .
 (ii) The Gaussian distributions, with standardized density (with mean zero and
      variance 1/a)                       p
                       f1 (u) = fN (u) := a/2π exp(−au2 /2),

        with I(f1 ) = a ' 0.4549 and J(f1 ) = 3; these values also can be obtained by
        taking limits, as ν → ∞, of the corresponding Student values since aν → a
        as ν → ∞.
 (iii) The double-exponential or Laplace distributions, with standardized density

                             f1 (u) = fL (u) := (1/2d) exp(−|u|/d),

        with I(f1 ) = 1/d2 and J(f1 ) = 2, the normalizing constant d = 1/ ln(2) '
        1.4426 is such that fL ∈ FA .
 (iv) The logistic distributions, with standardized density
                                      √       √             √
                 f1 (u) = fLog (u) := b exp(− bu)/(1 + exp(− bu))2 ,

        with I(f1 ) = b/3 and J(f1 ) = (12 + π 2 )/9, the normalizing constant
        b = (ln 3)2 ' 1.2069 is such that fL ∈ FA .


2.2. Uniform Local Asymptotic Normality
    In this section, we shall state the uniform local asymptotic normality property
for the model (1), with respect to intercept µ, regression coeﬃcient β, scale
parameter σ 2 and the parameter of interest b, for ﬁxed density f1 ∈ FA , the
reader is referred to Le Cam & Yang (2000).
                                  (n) (n)′   (n) (n) ′
For this purpose, let τ (n) := τ1 , τ2 , τ3 , τ4        be a sequence of real vectors
                           ′
in RK+3 such that τ (n) τ (n) is uniformly bounded as n → ∞ and let θ :=

                  Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                 149

(µ, β ′ , σ 2 , b = 0)′ . In addition, we consider sequences of local alternatives of the
form θ + ν (n) τ (n) where
                                                            
                                                1   0    0 0
                                                   (n)      
                                              0 K       0 0
                               ν (n) := n−1/2               
                                              0    0    1 0
                                                0   0    0 1

   The test is equivalent to
                      (n)     (n)                     (n)               (n)
                    Pθ;f1 : τ4      = 0 against Pθ+ν (n) τ (n) ;f1 : τ4       6= 0.

              (n)                                                                          (n)
Denote by Λθ+ν (n) τ (n) /θ;f the logarithm of the likelihood ratio (conditional on e0 )
      (n)                         (n)
for Pθ+ν (n) τ (n) ;f against Pθ;f . Then,


    (n)
  Λθ+ν (n) τ (n) /θ;f =
          "                 ∞
                                                                                #
  n X
  X  T                      X                  Y
                                               j
                                 − 21 (n) j
              log f (ei,t +   (−n τ4 ) ei,t−kj   ei,t−l−(s−1)k ) − log f (ei,t ) . (5)
  i=1 t=1                   j=1                         s=1

Deﬁne the standardized residuals as

                       Zi,t = Zi,t (µ, β, σ 2 ) := σ −1 (yi,t − µ − β ′ xi,t ),

for i = 1, 2, . . . , n; t = 1, 2, . . . , T and note that, under the null hypothesis, it
coincides with εi,t /σ. We have then the following result.
                                                                                            (n)
Proposition 1. Let Assumption (B) holds, ﬁx f1 ∈ FA . Then, the family Pf1
is ULAN (for n → ∞ with T ﬁxed ) at any θ = (µ, β ′ , σ 2 , 0)′ , with (K + 3)-
dimensional central sequence

                                                                             
                                   n−1/2 X X
                                            n   T
                                                  Φf (Zi,t )                 
                                     σ i=1 t=1 1                             
                                                                           
                                  −1/2 X   n X T                             
                  (n)
                ∆f1 ;1 (θ)        n                                          
               (n)                                              (n) ′
                                                   Φf1 (Zi,t )(K ) xi,t       
                                   σ                                       
                ∆       (θ)                                                  
   ∆f1 (θ) :=               := 
    (n)                                    i=1 t=1
                  f1 ;2
               ∆(n) (θ)            −1/2 X n X                               ,            (6)
               f1 ;3                         T
                                                                            
                                  n                Φ    (Z     )Z    −  1    
                  (n)                  2             f1    i,t   i,t         
                ∆f1 ;4 (θ)        2σ i=1 t=1                                 
                                                                             
                                           Xn X  T                           
                                  n −1/2
                                          σ          Φf1 (Zi,t )Zi,t−k Zi,t−l 
                                                    i=1 t=l+1


   and (K + 3) × (K + 3)-information matrix

                    Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

150                                            Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk


                    
  Γf1 (θ) := Γf1 ;ij 1≤i,j≤4
                                                                                                
               T                                           T
             σ 2 I(f1 )           0
                                                          2σ 3
                                                               K(f1 )                 0          
                                                                                                
                                                                                                
                                                                                                
                            T                                                                   
                   0            I(f1 )IK                     0                       0          
                            σ 2                                                                 
                                                                                                
          = T
                                                                                                 .
                                                                                                 
                                                     T                                         
                   K(f1 )         0                      J(f1 ) − 1                  0          
             2σ 3                                   4σ 4                                        
                                                                                                
                                                                                                
                                                                                           2 4 
                   0              0                          0               (T − l)I(f1 )σ σf1 

                                                                                                     (7)
                                                               ′
More precisely, for any θ(n) = (µ(n) , β (n) , σ 2 , 0)′ such that µ(n) − µ,
                                                                     (n)



(K(n) )−1 (β (n) − β) and σ 2 − σ 2 are O(n−1/2 ), and for any bounded sequence
                             (n)


                                 (n)
τ (n) ∈ RK+3 , we have under Pθ(n) ;f1 , as n → ∞ with T ﬁxed ,

                                                dP(n)                    
        (n)                                         θ (n) +ν (n) τ (n) ;f1
       Λθ(n) +ν (n) τ (n) /θ(n) ;f1   :=   log             (n)
                                                      dPθ(n) ;f1                                     (8)
                                                ′ (n)                      ′
                                      =    τ (n) ∆f1 (θ(n) ) − 12 τ (n) Γf1 (θ)τ (n) + op (1),

               (n)
    and ∆f1 (θ(n) ) converges in distribution to a (K + 3)2 -variate normal
distribution with mean zero and covariance matrix Γf1 (θ).

      Proof. See appendix.
                                              (n)
From this result, we have under Pθ;f1 ,
 "           (n)
                               #                                                      
          ∆f1 (θ)                  D                 0            Γf1 (θ)     Γf1 (θ)τ
                                 −
                                 − −−→ N                       ,                             . (9)
    (n)
   Λθ(n) +ν (n) τ (n) /θ(n) ;f   n→∞        − 21 τ ′ Γf1 (θ)τ    τ ′ Γf1 (θ) τ ′ Γf1 (θ)τ
                               1

                                                    (n)            (n)
Consequently, since the hypotheses Pθ;f1 and Pθ+ν (n) τ (n) ;f1 are contiguous, Le
                                                                    (n)               (n)
Cam’s third lemma leads to the convergence of ∆f1 (θ) under Pθ+ν (n) τ (n) ;f1 . In
this case we have
                       (n)     D
                     ∆f1 (θ) −−−−→ N (Γf1 (θ)τ, Γf1 (θ)).                     (10)
                                           n→∞



3. Locally Asymptotically Optimal Tests
   In this section, we are interested in testing the null hypothesis b = 0 of
randomness of the error regression model in (1), with unspeciﬁed error density
f1 ∈ F0 , unspeciﬁed µ, β and unspeciﬁed error scale σ– formally can be written as


                      Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                         151

             (n)
                         [        (n)
                                                   [ [         [     [           (n)
           H0      :=            H0 (g1 ) :=                                 {Pµ,β ′ ,σ2 ,0;g1 }.
                        g1 ∈F0                   g1 ∈F0 µ∈R β ′ ∈RK σ 2 >0

Parametric alternatives takes the form (for some ﬁxed standardized f1 ∈ FA )
                   (n)
                               [ [ [ [             (n)
                 H1 (f1 ) :=                    {Pµ,β ′ ,σ2 ,b;f1 }.
                                          µ∈R β ′ ∈RK σ 2 >0 b∈R∗


The parameters µ, β and σ 2 thus are nuisance parameters, while b is the parameter
                                                                    (n)
of interest. Before turning to this semiparametric hypothesis H0 (unspeciﬁed
                                                                      (n)
density), let us ﬁrst investigate the parametric problem of testing H0 (f1 ) (while
                                  (n)
f1 remains speciﬁed) against H1 (f1 ).


3.1. Optimal Parametric Tests
    In this subsection, we construct a locally asymptotically optimal (namely, most
stringent) tests in presence of nuisance parameters for testing serial independence
in model (1). The notion of most stringency is a concept of optimality (see e.g.,
Wald (1943)). We suppose that the innovation density f1 is speciﬁed, the main
consequence of the ULAN results of Proposition 1 is that for each θ, and for given
f1 ∈ FA , the sequences of local experiments
                    (n)                        (n)                     
                   ζf1 (θ) := Rn , B n , P n = Pθ+ν (n) τ ;f1 |τ ∈ RK+3

converge weakly to the (K + 3)−dimensional Gaussian shift experiments
                                                                   
         Gf1 (θ) := RK+3 , B K+3 , P = N Γf1 (θ)τ, Γf1 (θ) |τ ∈ RK+3 .

    The classical theory of hypothesis testing in Gaussian shifts (see Section 11.9
of Le Cam, 1986) provides the general form for locally asymptotically most
                     [ [ in[ULAN
stringent tests of hypotheses             models. In this case, the null hypothesis
  (n)          (n)                    (n)                                        (n)
H0 (f1 ) =: Hf1 =                 {Pµ,β ′ ,σ2 ,0;f1 } and the local alternative H1 (f1 )
                         µ∈R β ′ ∈RK σ 2 >0
can be expressed as
                        (n)                                 (n)
                                                        / M(Ω),
                    Hf1 : τ ∈ M(Ω) against H1 (f1 ) : τ ∈

where M (Ω) is the linear subspace of dimension K + 2 of RK+3 generated by the
matrix Ω′ := (IK+2 , 0). Such tests, should be based on
                                                                         
            (n)                   (n)′         −1          ′
                                                                     −1 ′ (n)
           Qf1 (θ)       :=      ∆f1 (θ)      Γf1 (θ) − Ω Ω Γf1 (θ)Ω    Ω ∆f1 (θ)
                                                                                                    (11)
                                   (n)2
                         =       ∆f1 ;4 (θ)/Γf1 ;44 (θ).

    As θ remains unspeciﬁed under the null, we will need to replace it with some
estimate. For this purpose, we assume the existence of θb := θbn satisfying the
following assumption


                   Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

152                                         Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk


      Assumption (C). The estimate θbn is such that

             √
  (i) θbn is n-consistent, i.e., for all f1 ∈ FA and all ε > 0, there exist
                                                                (n)
      c := c(f1 , θ, ε) and N := N (f1 , θ, ε) such that under Pµ,β ′ ,σ2 ,0;f1 , we have
                                     √
                                  P ( n k θbn − θ k> c) < ε ∀n > N.


 (ii) θbn is locally asymptotically discrete, i.e., for all ﬁxed value s > 0, the number
      of possible values of θbn in

                             B = {u ∈ RK+3 , n−1/2 k u − θ k6 s}

        is bounded as n → ∞.

Note that the condition (i) on the rate of convergence in probability of the
estimates is satisﬁed by several estimates such as the maximum likelihood
estimates, the Yule-Walker estimates, the M-estimates and the least square
estimates; part (ii) has little practical implications.
    The following proposition shows that substituting θbn for θ does not inﬂuence
the asymptotic behavior of the test statistic (11).

Proposition 2 (Asymptotic linearity). Suppose that Assumptions (A),(B) and
(C) hold. Let θbn be a deterministic sequence satisfying n1/2 (θbn − θ) is bounded by
                                  (n)
a constant c > 0. Then, under Pµ,β ′ ,σ2 ,0;f1 , as n → ∞, we have

  (i)
                     ∆f1 (θbn ) − ∆f1 (θ) + n1/2 Γf1 (θ)(θbn − θ) = oP (1).
                      (n)          (n)
                                                                                        (12)

 (ii)
                                    ∆f1 ;4 (θbn ) − ∆f1 ;4 (θ) = oP (1).
                                      (n)            (n)
                                                                                        (13)

Proof . See appendix.

The following proposition then results from classical results on ULAN families
(see, Le Cam, 1986, chapter 11).

Proposition 3. Suppose that Assumptions (A), (B) and (C) hold. Then,

  (i) Qf1 (θbn ) = Qf1 (θ) + oP (1) is asymptotically chi-square, with 1 degrees of
         (n)          (n)

                            (n)
        freedom under Pθ;f1 , and asymptotically noncentral chi-square, still with
        1 degrees of freedom but with noncentrality parameter λf1 := τ42 σ 2 (T −
                            (n)
        l)I(f1 )σf41 under Pθ+ν (n) τ (n) ;f1 ;


                 Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                          153

                                                                             (n)
 (ii) the sequence of tests rejecting the null hypothesis Hf1 (with standardized
      density f1 ) whenever Qf1 (θbn ) exceeds the (1 − α)-quantile of a chi-square
                              (n)

      distribution with one degree of freedom, is locally asymptotically optimal
                                                     (n)
      (most stringent), at asymptotic level α, for Hf1 against
                                 [       [     [ [              (n)
                                                           {Pµ,β ′ ,σ2 ,b;f1 };
                                 µ∈R β ′ ∈RK σ 2 >0 b∈R∗


(iii) the sequence of tests has asymptotic power 1 − F (χ21,1−α , λf1 ), at
          (n)
        Pθ+ν (n) τ (n) ;f1 , where F (., λf1 ) denotes the noncentral chi-square distribution
        function with one degree of freedom and non centrality parameter λf1 .

Proof . See appendix.
                                     (n)                              (n)
   The Gaussian versions of ∆f1 ;4 (θ), Γf1 ;44 (θ) and Qf1 (θ) are obtained by letting
f1 = fN (standardized normal density N (0, 1/a)), this case is an exception,
however, as Φf1 (u), I(f1 ) and σf41 reduce to au, a and 1/a2 , respectively, then
one easily checks that
                             n X
                             X T
                                                                                       σ2
      ∆N ;4 (θ) = n−1/2 σa
       (n)
                                         Zi,t Zi,t−k Zi,t−l ,           ΓN ;44 (θ) =      (T − l),
                             i=1 t=l+1
                                                                                       a

and
                                                                  2
                                        −1 X X
                                            n  T
                     (n)          a3
                   QN (θ) =            n2        Zi,t Zi,t−k Zi,t−l ,                            (14)
                                 T −l      i=1      t=l+1

respectively.
                           (n)
The Gaussian tests QN (θ) unfortunately are valid under normal densities only,
i.e., needs f1 to be indicated as a standardized Gaussian one, then the parameter
a also has to be ﬁxed. In the following section, we demonstrate that a proper
version–namely, pseudo-Gaussian test, that is, tests that are valid under a broad
class of non-Gaussian densities with ﬁnite variance, while remaining optimal under
Gaussian ones– in general, are preferable.


3.2. Pseudo-Gaussian Test
                                                                                               (n)
    Herein, we construct a pseudo-Gaussian version of the Gaussian test QN (θ).
                                    (n)
The Gaussian central sequence ∆N ;4 (θ) allows us to construct asymptotically
optimal tests under f1 = fN , hence for eﬃcient detection of bilinear dependence
in the parametric Gaussian model characterized by Gaussian disturbances.
Extending the validity of the Gaussian optimal test to densities g1 in a broad
class of densities is of course highly desirable. Let us show that this is indeed
                                          ∗(n)
possible and that a slight modiﬁcation, ∆N ;4 , say, of the eﬃcient central sequence
  (n)
∆N ;4 leads to a pseudo-Gaussian test which remains valid when the actual density

                  Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

154                                            Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk

         (2)
g1 ∈ FA of all densities in FA with ﬁnite variance. Note that Zi,t for Zi,t (µ, β, σ 2 )
                                         1 XX
                                            n    T
                                                                            √
and let m1 = m1 (µ, β ′ , σ 2 ) :=                 Zi,t (µ, β ′ , σ 2 ) is a n−consistent
          (n)     (n)
                                        nT i=1 t=1
                                        Z
                  (n)
estimator, under Pθ;g1 , of µ1 (g1 ) :=    ug1 (u)du. Deﬁne
                                                  R



      ∗(n)
                                n X
                                X T
  ∆N ;4 (θ) = n−1/2 σa
                                                        (n)             (n)                   (n)
                                            (Zi,t − m1 )(Zi,t−k − m1 )(Zi,t−l − m1 ).               (15)
                                i=1 t=l+1


                                (n)                                              (n)
Decomposing Zi,t − m1 into (Zi,t − µ1 (g1 )) + (µ1 (g1 ) − m1 ), then, it easily
                          (n)
follows from that, under Pθ;g1 , as n → ∞ with T ﬁxed

      ∗(n)
  ∆N ;4 (θ) =
               n X
               X T
 n−1/2 σa                   (Zi,t − µ1 (g1 ))(Zi,t−k − µ1 (g1 ))(Zi,t−l − µ1 (g1 )) + op (1). (16)
               i=1 t=l+1


                     (n)       ∗(n)
Then, under Pθ;g1 , ∆N ;4 (θ) is asymptotically normal with mean 0 and variance
                                                  Z
Γ∗N ;g1 ;44 (θ) = a2 σ 2 (T − l)σg61 where σg21 := (z − µ1 (g1 ))2 g1 (z)dz.
                                                              R
                                                                  (n)                  ∗(n)
On the other hand, it is easy to see that, still under Pθ+ν (n) τ (n) ;g1 , ∆N ;4 (θ) and the
                      (n)
log-likelihood Λθ+ν (n) τ (n) /θ;g1 are jointly binormal; the desired result then follows
from a routine application of Le Cam’s third lemma. Since the intercept µ, the
regression coeﬃcients β, and the scale parameter σ 2 under the null hypothesis
remain unspeciﬁed, some care has to be taken with the asymptotic impact of
estimating µ, β, and σ 2 under unspeciﬁed density g1 .
      Deﬁne the non-standardized centered residuals

                                                                               1 XX
                                                                                   n   T
             Vi,t (β) := σ(Zi,t (µ, β, σ 2 ) − m1 ) = yi,t − β ′ xi,t −
                                                  (n)
                                                                                         yi,t .
                                                                              nT i=1 t=1

A pseudo Gaussian test may then be based on a statistic of the form

         ∗(n)                 ∗(n)2
       QN ;g1 (θ) := ∆N ;4 (θ)/Γ∗N ;g1 ;44 (θ)
                                        Xn X  T                              2
                         1         −1/2
                  :=             n               Vi,t (β)Vi,t−k (β)Vi,t−l (β)                       (17)
                     (T − l)σg6          i=1            t=l+1
                              ∗(n)
                      =: QN ;g (β),

                                                                    ∗(n)
with g is deﬁned by g(u) = (1/σ)g1 (u/σ). Clearly QN ;g (β) depends only on β,
which justiﬁes the notation.

                     Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                155

In practice, the pseudo-Gaussian tests will be based on the statistics
                                      Xn XT                             2
         †(n) b          1        −1/2             b         b         b
        QN (β)  :=              n            Vi,t (β)Vi,t−k (β)Vi,t−l (β) ,                (18)
                     (T − l)s6         i=1         t=l+1


where βb is an arbitrary n1/2 (K(n) )−1 -consistent estimator of β and
      1 XX 2 b
         n   T
 2
s :=                                                        b
               V (β) is the empirical variance of the Vi,t (β)’s. Consider the
     nT i=1 t=1 i,t
        (2)                                                                          (n)
class FA of all densities g1 ∈ FA such that σg21 < ∞. Then under Pθ;g1 , and
                                     (n) (n)′ (n) ′
for any bounded sequence τ (n) = τ1 , τ2 , τ3 , 0 ∈ RK+3 , as n → ∞ with T
ﬁxed
             ∗(n)                    ∗(n)
            ∆N (θ + ν (n) τ (n) ) − ∆N (θ) = −Γ∗N ;g1 (θ)τ (n) + oP (1), (19)
with
                                                   
                                    ∗(n)         ′
              Γ∗N ;g1 (θ) := E             (n)
                                   ∆N (θ) ∆g1 (θ)
                                                                            
                           aT
                          σ2            0            0     a(T − l)µ21 (g1 )
                                                                            
                                                                            
                                                                            
                                     aT                                     
                          0             IK           0           0          
                                     σ2                                                  (20)
                                                                            
                        =
                         
                                                                             .
                                                                             
                                                  aT 2                      
                          0             0            σ           0          
                                                  σ 4 g1                    
                                                                            
                                                                            
                                                                     2 4 
                          0             0            0     a(T − l)σ σg1 


The following result is immediate from (19). Let Assumption (B) holds, assume
that θbn satisﬁes Assumptions (C) and ﬁx θ ∈ RK+3 , we have

                              ∆N ;4 (θbn ) − ∆N ;4 (θ) = oP (1).
                               ∗(n)           ∗(n)
                                                                                           (21)
                        (n)                            b −Q
Showing that, under Pθ;g1 , as n → ∞, with T ﬁxed, QN (β)
                                                                 †(n)        ∗(n)
                                                           N ;g (β) = op (1).
  The following result summarizes the asymptotic properties of the pseudo-
Gaussian tests.
                                                                                    (2)
Proposition 4. Let Assumptions (A), (B) and (C) hold, for any g1 ∈ FA . Then,
        †(n) b
  (i) QN (β)      is asymptotically chi-square with 1 degrees of freedom under
        (n)
      Pµ,β,σ2 ,0;g1 , and asymptotically noncentral chi-square, still with 1 degrees
      of freedom but with noncentrality parameter λN = (T − l)σg2 τ42 under
                                             (n)
                                        Pθ+n−1/2 ν (n) τ ;g1 ;


               Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

156                                           Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk


 (ii) the sequence of tests rejecting the null hypothesis
                           (n)2
                                     [ [ [ [ n (n)                 o
                         HA :=                       Pµ,β,σ2 ,0;g1
                                          g1 ∈FA
                                                (2)    µ   β σ2


      whenever Q†N         > χ21,1−α , is locally asymptotically most stringent, at
                                                       (n)2
      asymptotic probability level α, for HA against alternatives of the form
                              [ [ [ [ n (n)              o
                                            Pµ,β,σ2 ,b;fN ;
                                      µ   β   σ b∈R∗


                                              (n)
(iii) the asymptotic power under Pθ+n−1/2 ν (n) τ ;g1 is 1 − F (χ21,1−α , λN ).

                     †(n) b
The test statistic QN (β)   thus deﬁnes a pseudo-Gaussian test, that is, a test
which is optimal under Gaussian assumptions but remains valid under a much
broader class of densities.


4. Optimal Rank Tests
   General results by Hallin & Werker (2003) indicate that semiparametrically
eﬃcient rank-based procedures can be obtained in relation to ranks being maximal
                                                                  (nT )
invariants under model-generating groups of transformations (G          , ⋆). More
                                          (n)
                                                   [ [ [ n (n)                 o
precisely, note that the null hypothesis Hβ :=                    Pµ,β,σ2 ,0;g1 is
                                                                    g1 ∈F0 µ∈R σ 2 >0
invariant under the action of the group (G             (nT )
                                                               , ⋆) of all transformations Gh of RnT
such that

 Gh (y1,1 , . . . , yn,T ) := (β ′ x1,1 + h(y1,1 − β ′ x1,1 ), . . . , β ′ xn,T + h(yn,T − β ′ xn,T )),

where u 7→ h(u) is continuous and increasing and lim h(u) = ±∞. It is easy to
                                                                   u→±∞
                                                                                                   (n)
check that (G (nT ) , ⋆) is actually a generating group for the null hypothesis Hβ .


4.1. Rank-Based Versions of Central Sequences
   A maximal invariant for the group (G (nT ) , ⋆) is known to be the vector
                    (n)            (n) ′     (n)    (n)
R(n) = R(n) (β) := R1,1 , . . . , Rn,T where Ri,t = Ri,t (β) denotes the rank of
            (n)                 (n)              (n)
residual Zi,t (β) among Z1,1 (β), . . . , Zn,T (β). Moreover, µ and σ 2 have no impact
on residual ranks, hence we can assume that they are speciﬁed, which justiﬁes the
           (n)                 (n)                     (n)
notation Zi,t (β) (instead of Zi,t (µ, β, σ 2 )) and Ri,t (β).
   General results on semiparametric eﬃciency indicate that in such context, the
                                                                 (n)
expectation (under the null hypothesis) of the central sequence ∆f1 ;4 (θ) conditional
                  (n)
on those ranks R      yields a version of the semiparametrically eﬃcient central
sequence (at f1 and θ) given by:

                  Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                        157
                                                 (n)             
                                   ∆(n) (θ) := E ∆f1 ;4 (θ) | R(n) .                               (22)
                                       ∼ f1 ;4


      In practice, the conditional expectation deﬁnition (22) of ∆(n) (θ) (an exact-
                                                                                  ∼ f1 ;4
score linear rank statistic) is not convenient, and the explicit approximate-score
form (for simplicity, we are using the same notation as for the exact-score version)
is preferable and given by (the notation ∆(n) (β, σ) reﬂects the fact that it only
                                                                 ∼ f1 ;4
depends on β and σ)

    ∆(n) (β, σ) :=
    ∼ f1 ;4
                 n X
                 X T                  (n)            (n)              (n)             
                                       Ri,t (β)         Ri,t−k (β)         Ri,t−l (β)
    n−1/2 σ                  φf1                  F1−1               F1−1               − mf1 ,
                 i=1 t=l+1
                                       N +1              N +1               N +1
                                                                                                   (23)

with N = n(T − l), φf1 := Φf1 ◦ F1−1 and
                        1         XXX      t1  −1  t2  −1 t3
    mf1 :=                            φf1      F1       F      ).
                 N (N − 1)(N − 2)         N +1     N +1 1 N +1
                                          16t1 ̸=t2 ̸=t3 6N

Let
                                  XXX                                                        2
     (n)2               1                                              t1  −1 t2  −1 t3
    sf1     :=                                                  φf1        F       F      )
                 N (N − 1)(N − 2)                                     N +1 1 N +1 1 N +1
                                        16t1 ̸=t2 ̸=t3 6N

                     2            XXXX       t1      t2  −1 t2 
     +                                 φ f1      φf1      F
          N (N − 1)(N − 2)(N − 3)           N +1     N +1 1 N +1
                                            16t1 ̸=t2 ̸=t3 ̸=t4 6N

                                                         2
                                                     t3          t4 
                                        × F1−1           ) F1−1
                                                    N +1        N +1
                   2          XXXXX                            t1  −1  t2  −1 t3
      +                                                  φ f1      F1       F      )
          N (N − 1)(N − 2)                                    N +1     N +1 1 N +1
                             16t1 ̸=t2 ̸=t3 ̸=t4 ̸=t5 6N
              (N − 3)(N − 4)
                                            t3  −1 t4  −1 t5
                              × φf1             F       F      )
                                           N +1 1 N +1 1 N +1
             N −5           XXXXXX                                t1  −1  t2  −1 t3
+                                                            φf1      F1       F      )
    N (N − 1)(N − 2)                                             N +1     N +1 1 N +1
                            16t1 ̸=t2 ̸=t3 ̸=t4 ̸=t5 ̸=t6 6N
      (N − 3)(N − 4)(N − 5)
                                                     t4  −1 t5  −1 t6 
                                          × φf1          F       F        − N m2f1 .           (24)
                                                    N +1 1 N +1 1 N +1

The following asymptotic representation result (25) shows that both (22) and (23)
                                                  (n)
yield rank-based version of the central sequence ∆f1 ;4 (θ).

Proposition 5. Fix θ = (µ, β ′ , σ 2 , 0)′ , let f1 and g1 ∈ FA . Then,

                      Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

158                                               Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk

                     (n)
  (i) under Pθ;g1 , as n → ∞ with T ﬁxed
                                         (n)  (n)        (n)               (n)    
              ∆(n) (β, σ) :=            Eg1 ∆f1 ;4 (θ) | R1,1 (β), . . . , Rn,T (β) + oL2 (1)
              ∼ f1 ;4                                                                                     (25)
                                            (n)
                                =       ∆f1 ,g1 ;4 (θ) + oL2 (1),

        with
               (n)
          ∆f1 ,g1 ;4 (θ) :=
                           n X
                           X T
                                                                                        
                n−1/2 σ                 φf1 G1 (Zi,t ) F1−1 G1 (Zi,t−k ) F1−1 G1 (Zi,t−l ) ; (26)
                           i=1 t=l+1

        where G1 is the distribution function associated with g1 ,
                     (n)
 (ii) under Pθ;g1 , ∆(n) (β, σ) has mean zero and variance
                            ∼ f1 ;4

                                                               (n)2
                             Γ(n) (σ 2 ) := (T − l)σ 2 sf1            = Γf1 ;44 (σ 2 ) + o(1)
                             ∼f1 ;44


        as n → ∞ with T ﬁxed, where Γf1 ;44 (σ 2 ) := (T − l)I(f1 )σ 2 σf41 ;
          (n)                                                                                      (n)
(iii) ∆f1 ,g1 ;4 (θ) is asymptotically normal, with mean zero under Pθ;g1 , mean
                                                                 (n)
        (T − l)I(f1 , g1 )σ 2 (f1 , g1 )σ 2 τ4 under Pθ+ν (n) τ ;g1 and variance Γf1 ;44 (σ 2 )
        under both, with
                                           Z 1
                          I(f1 , g1 ) =        Φf1 (F1−1 (u))Φg1 (G−1
                                                                    1 (u))du
                                                  0

        and                                             Z 1
                                        σ(f1 , g1 ) =         F1−1 (v)G−1
                                                                       1 (v)dv.
                                                         0

Proof . See appendix.


4.2. Optimal Rank Tests
    The parameters µ, β and σ 2 remain unspeciﬁed under the null, since β has only
an inﬂuence on the ranks, a consistent estimator βb := βb(n) has to be substituted for
the actual β value, yielding aligned ranks Ri,t (βb(n) ). The eﬀect of this alignment
                                             (n)

procedure is taken care of in a similar way as in Section 3, via the asymptotic
linearity results of Propositions 6 and 7 below.
Proposition 6. Let Assumption (B) holds and ﬁx µ ∈ R, β ∈ RK , σ 2 > 0, f1
                                              (n)             (n)
and g1 ∈ FA . Then, for any bounded sequence τ2 ∈ RK , under Pµ,β,σ2 ,0;g1 , as
n → ∞ with T ﬁxed, we have

 ∆(n) (µ, β + n−1/2 K(n) τ2 , σ 2 , 0) − ∆(n) (µ, β, σ 2 , 0) = −Γ
                                      (n)
                                                                                           τ (n) + oP (1), (27)
 ∼ f1                                                 ∼ f1                       ∼f1 ;g1


                        Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                                  159

with                                                     
                                     (n)         (n)   ′
                   Γ           := E ∆f1 ,g1 (θ) ∆g1 (θ)
                   ∼f1 ;g1
                                                                                              
                                           T
                                              I(f1 , g1 )IK                    0
                                          σ2                                                              (28)
                                                                                               
                               =                                                               .
                                                                                              2
                                                0              (T − l)I(f1 , g1 )σ (f1 , g1 )σ 
                                                                                   2




   The following proposition then is an immediate corollary of Proposition 6 and
Lemma 4.4 in Kreiss (1987).
Proposition 7. Let Assumption (B) holds, assume that βb satisﬁes Assumption
                                                                  (n)
(C) and ﬁx µ ∈ R, β ∈ RK , σ 2 > 0, f1 and g1 ∈ FA . Then, under Pµ,β,σ2 ,0;g1 , as
n → ∞ with T ﬁxed
                             ∆(n) (µ, βb(n) , σ 2 , 0) − ∆(n) (µ, β, σ 2 , 0) = oP (1).                     (29)
                             ∼ f1 ;4                          ∼ f1 ;4

Local asymptotic optimality with density f1 is achieved by the test based on
      (n)            (n)2             2
  Q         (θ) := ∆      (θ)Γ      (σ ) =
  ∼f               ∼ f ;4    ∼f ;44
    1                 1        1
                                                                                                     
                                     ∑
                                     n  ∑T   {    ( R(n) (β) )    ( R(n) (β) )     ( R(n) (β) )      } 2
               1
                        n−1/2                φf1
                                                     i,t       −1
                                                              F1
                                                                     i,t−k      −1
                                                                               F1
                                                                                      i,t−l
                                                                                                − mf1 
               (n)2                                  N +1             N +1            N +1
       (T − l)sf                   i=1 t=l+1
                 1

                                                                                           =: Q
                                                                                               (n)
                                                                                              ∼f
                                                                                                     (β).   (30)
                                                                                                1


More precisely, we have the following result.
Proposition 8. Let Assumptions (A), (B) and (C) hold. Then
            b = Q(n) (β) + oP (1) is asymptotically chi-square, with 1 degrees of
  (i) Q(n) (β)
            ∼ f1              ∼ f1
                                         (n)
        freedom under Pµ,β,σ2 ,0;g1 , and asymptotically noncentral chi-square, still
        with 1 degrees of freedom but with noncentrality parameter
                                       (T − l)I 2 (f1 , g1 )σ 4 (f1 , g1 )σ 2 2        (n)
                       λf1 ,g1 :=                                            τ4 under Pθ+ν (n) τ ;g1 ;
                                                   I(f1 )σf41

 (ii) the sequence of tests rejecting the null hypothesis
                         (n)
                                  [ [ [ [               (n)
                       HA :=                         {Pµ,β ′ ,σ2 ,0;g1 }
                                                   g1 ∈FA µ∈R β ′ ∈RK σ 2 >0

                       b exceeds the (1−α)-quantile of a chi-square distribution with
        whenever Q(n) (β)
                            ∼ f1
        one degree of freedom, is locally asymptotically optimal (most stringent), at
                                             (n)
        asymptotic probability level α, for HA against
                              [ [ [ [               (n)
                                                 {Pµ,β ′ ,σ2 ,b;f1 };
                                               µ∈R β ′ ∈RK σ 2 >0 b∈R∗


                         Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

160                                                   Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk

                                                                                                (n)
(iii) the sequence of tests has asymptotic power 1−F (χ21,1−α , λf1 ), at Pθ+ν (n) τ ;f1 ,
      where F (., λf1 ,g1 ) denotes the noncentral chi-square distribution function
      with one degree of freedom and non centrality parameter λf1 ,g1 .



4.3. Important Particular Cases

                          b is providing a general form for the optimal rank tests of
      The statistic Q(n) (β)
                         ∼ f1
the null hypothesis of serial independence of model (1). The three most important
particular cases for the test statistic presented are the van der Waerden (normal
scores), Wilcoxon (logistic scores) and Laplace (double exponential scores) test
statistics, which are respectively optimal at normal, logistic and double exponential
distributions.
(i) van der Waerden’s test statistic is given by

        b :=
  Q(n) (β)
  ∼ vdW
                                                                                             
                           Xn   XT         (n) b                b 
                                                           R(n) (β)                b 
                                                                            R(n) (β)         2
      a2                                    Ri,t (β)
                  n−1/2              Ψ −1
                                                     Ψ −1    i,t−k
                                                                       Ψ−1    i,t−l
                                                                                        − mfN 
           (n)  2
(T − l)sf                  i=1 t=l+1
                                             N +1            N +1             N +1
            N



with

                             XXX                                
                   1                    t1          t2           t3
mfN =                            Ψ−1         Ψ−1          Ψ−1
            N (N − 1)(N − 2)           N +1        N +1         N +1
                                       16t1 ̸=t2 ̸=t3 6N


where Ψ is the standard normal distribution function.
(ii) Wilcoxon’s test statistic is given by

                                                  X
                                                   n X
                                                     T  (n) b                         (n)    b     
                           1                             2Ri,t (β)                       Ri,t−k (β)
        b :=
  Q(n) (β)                                 n−1/2                       − 1 log
  ∼W                 (T − l)bsl
                                (n)2                           N +1                               b
                                                                                                (n)
                                                                                  N + 1 − Ri,t−k (β)
                                                   i=1 t=l+1
                                                                          (n)    b             2
                                                                          Ri,t−l (β)
                                                               × log                       − ml
                                                                       N +1−R
                                                                                 (n)  b
                                                                                     (β)
                                                                                 i,t−l



with


  ml =
                 XXX                                                                       
       1                                             2t1             t2                 t3
                                                         −1 log                log               .
N (N − 1)(N − 2)                                    N +1          N + 1 − t2         N + 1 − t3
                           16t1 ̸=t2 ̸=t3 6N




                       Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                                                161

(iii) Laplace’s test statistic is given by
                                             X
                                              n X
                                                T                                (n) b       (n) b 
         b :=        d2                                                            Ri,t (β)       Ri,t−k (β)
Q (n)
        (β)               (n)2
                                     n −1/2
                                                           sign         F1−1                  −1
                                                                                             F1
∼L              (T − l)sDe                    i=1 t=l+1
                                                                                   N +1            N +1

                                                                                        (n)    b                  2
                                                                                        Ri,t−l (β)
                                                                         ×F1−1                           − mDe
                                                                                         N +1
with

    mDe =
                 XXX                                     
       1                   −1    t1      −1    t2     −1    t3
                     sign F1            F1          F            ,
N (N − 1)(N − 2)                N +1          N +1 1       N +1
                       16t1 ̸=t2 ̸=t3 6N


where F1 is the distribution function of the double-exponential
                                         
                                                d log(2u)    if                0 < u 6 21
                      F1−1 (u) =
                                              −d log(2 − 2u) if                2 6 u < 1.
                                                                               1



It is worth noting that the scale factors a (for van der Waerden), b (for
Wilcoxon) and d (for Laplace) disappear in the ﬁnal expression of the test
                                                 (n)   (n)      (n)
statistics, due to the exact standardization by sfN , sl , and sDe respectively.
This conﬁrms that the choice of the median of absolute deviations as a scale
parameter in the deﬁnition of F0 has no impact on the results.


5. Power Comparison and Simulations
5.1. Asymptotic Relative Eﬃciencies
                                                                             b
     The Asymptotic Relative Eﬃciencies (AREs) of the rank-based tests Q(n) (β)
                                                                                                                    ∼ f1
                                                                     †(n)
with respect to the pseudo-Gaussian tests         directly follow as ratios of
                                                                    QN
noncentrality parameters under local alternatives. In order to compare the
performance of the parametric and nonparametric tests presented, we calculate
the AREs of nonparametric tests compared to the pseudo-Gaussian tests.
                                                                                               (2)
Proposition 9. Let f1 ∈ FA . Then, the AREs under g1 ∈ FA , of the rank tests
               b with respect to the pseudo-Gaussian tests based on Q†(n) , when
based on Q(n) (β)                                                    N
             ∼ f1
            (n)                  (n)
testing Pθ;g1 against Pθ+ν (n) τ ;g1 , are
                                                              2                                         2
                       (n)    b    †(n)              λf1 ,g1                I 2 (f1 , g1 )σ 4 (f1 , g1 )
           AREg1 (Q          (β)/Q N )=                             =                                           .          (31)
                     ∼ f1                             λN                         I(f1 )σg21 σf41

                    Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

162                                       Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk


The table (1) gives the numerical values of (31) for


                b Q(n) (β),
      b = Q(n) (β),
Q(n) (β)                        b Q(n) (β),
                        b Q(n) (β),     b Q(n)                             b and Q(n)
                                                                          (β)                    b
                                                                                                (β)
∼ f1          ∼ vdW       ∼W          ∼ La         ∼ t5       ∼ sN (10)            ∼ st5 (10)


under the densities g : N ormal, Logistic, Double exponential, Student-t5 , skew
normal sN (10) and skew Student st5 (10) 1 .
    The results obtained are satisfactory and all are good, particularly so under
heavy tails. Also, note that the AREs of the proposed van der Waerden tests with
respect to the parametric Gaussian tests are uniformly larger than or equal to one
for all distributions considered in Table 1, and are equal to one in the Gaussian
case only (this result is proved in Chernoﬀ & Savage (1958)), which means that
rank-based tests are asymptotically more powerful than Gaussian tests. Note also
that each value is maximum in its corresponding column. Thus, at each of the
densities, nonparametric tests perform better, compared to pseudo-Gaussian tests,
among the eﬃciencies achieved by the van der Waerden, Wilcoxon and Laplace
tests.
Table 1: AREs, under normal, logistic, Double exponential, Student (5 degree of
         freedom), skew normal sN (δ) and skew Student st5 (δ) (with δ = 10) densities,
         of various rank tests based on van der Waerden, Wilcoxon, Laplace, Student,
         skew normal and skew Student scores, with respect to their pseudo-Gaussian
         counterpart.
                      Actual density g1
                                             N        l      De        t5     sN (10)   st5 (10)
 Scores f1
 Van der Waerden                          1.0000   1.0613   1.3944   1.1435   2.0752    3.4375
 Wilcoxon                                 0.8825   2.3115   2.1514   1.4804   4.1503    2.9597
 Laplace                                  0.4486   1.6468   4.0000   1.8985   5.2279    4.0672
 Student-t5                               0.7318   2.1393   2.3002   2.5625   3.7472    5.5718
 skew normal sN (10)                      0.5117   1.8205   2.5651   1.9317   5.9721    4.1755
 skew Student st5 (10)                    0.7285   1.6414   1.8435   1.8540   3.2328    6.1059




5.2. Results of Monte Carlo Simulations
   In this section, we conduct a Monte Carlo experiment to investigate the ﬁnite
sample performance of the proposed procedures and behavior of our rank tests
under a variety of error distributions. More precisely, we considered the model
                         
                            yi,t = µ + β ′ xi,t + ei,t
                                                                             (32)
                            ei,t = bei,t−4 εi,t−1 + εi,t , ,

   1 See, for instance, Azzalini & Capitanio (2003) for a deﬁnition of skew normal and skew-t

densities.


                  Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                163

with

    ⋆ i = 1, 2, . . . , 100 and t = 1, 2, . . . , 14 2 ,
                                                    
                            ′     x1;i,t        0   10 1
    ⋆ µ = 1, β = (1, 1) , xi,t =           ∼N     ,          ,
                                  x2;i,t        0    1 20

    ⋆ b = 0 for null hypothesis, and b = 0.025, 0.05, 0.075, 0.1 for increasingly
      several alternatives,

    ⋆ the (εi,t )s are i.i.d. with a symmetric density - Gaussian (N ), logistic (l),
      double exponential (De), Student (t5 ) - or with an asymmetric density - the
      skew normal sN (10) and skew Student st5 (10) densities.

    In order to examine the ﬁnite sample performances of the proposed procedures,
we generated 2500 replications independent samples of size N = n(T − 4) = 1000
from (32). For each replication, we performed the following tests at the asymptotic
                                                        †(n)
level α = 5%, the pseudo-Gaussian test based on QN in (18), the van der
Waerden test, Wilcoxon test and Laplace test are based on, respectively, Q        ,
                                                                                       ∼ vdW
Q      and Q in (4.3), as well the rank tests based on Student scores with 5 degrees
∼W         ∼L
of freedom and the rank tests with data-driven skew Student scores stν̂ (δ̂).
    A data-driven choice of the reference density adapting, for instance, to f ’s
actual skewness and kurtosis. Hallin & Mehta (2015) propose selecting the
reference density f by ﬁtting a skew-t distribution (see Azzalini & Capitanio,
2003) with location zero, scale one, and density
                                                         1/2 
                                                    ν+1
                          fδ,ν (z) = 2tν (z)Tν+1 δz               ,
                                                    ν + z2

where δ ∈ R is a skewness parameter, ν > 0 is the number of degrees of freedom
governing the tails, tν and Tν+1 are the density distribution and cumulative
distribution functions of the Student-t distributions with ν and ν + 1 degrees
                                                                                 (n)
of freedom, respectively. Estimators δ̂ and ν̂ are obtained from the residuals Zi,t
using a maximum likelihood method (namely, maximizing a skew-t likelihood with
respect to (δ, ν)). The f -score functions to be used in the testing procedure then
are those associated with the skew-t density fδ̂,ν̂ . This approach is also related
to the theory of eﬃcient (adaptive) estimation. Additionally, these data-driven
scores tests as adaptive tests are valid and asymptotically optimal.
    Rejection frequencies are reported in Table 2, they amply conﬁrm the excellent
overall performances of our rank-based procedure with data-driven scores. It also
appears from the skew normal and skew Student simulations that asymmetry
signiﬁcantly improves the superiority of rank tests over the pseudo-Gaussian one.
   2 The use of large number of individuals and short period of time is the most common type of

data in dynamic panel analysis. It is called Short panels, see Lillo & Torrecillas (2018)


                   Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

164                                      Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk

Table 2: Rejection frequencies (out of 2500 replications), for b = 0 (null hypothesis)
         and various non-zero values of b (alternative hypotheses), with error density
         g1 that is Gaussian (N ), logistic (l), double exponential (De), Student (t5 ), the
         skew normal (sN (10)) and skew Student t5 (st5 (10)) of the pseudo-Gaussian
         and rank tests based on van der Waerden, Wilcoxon, Laplace, Student-t5 and
         data-driven scores.
      Underlying densities g1        Test                              b
                                                    0      0.025     0.05    0.075     0.1
                                Pseudo Gaussien   0.0480   0.2040   0.6194   0.9522   0.9978
                                Van der Waerden   0.0516   0.2142   0.6418   0.9718   0.9950
             N ormal               Wilcoxon       0.0520   0.2208   0.6266   0.9320   0.9986
                                    Laplace       0.0506   0.2256   0.5536   0.8596   0.9880
                                   Student-t5     0.0540   0.2120   0.6100   0.9236   0.9956
                                  Data-Driven     0.0428   0.2640   0.5400   0.7760   0.9200
                                Pseudo Gaussien   0.0480   0.3552   0.7420   0.9512   0.9908
                                Van der Waerden   0.0500   0.2640   0.5884   0.9232   0.9960
            logistique             Wilcoxon       0.0516   0.2224   0.7272   0.9612   0.9984
                                    Laplace       0.0410   0.2628   0.6688   0.9324   0.9952
                                   Student-t5     0.0456   0.2360   0.6096   0.9536   0.9972
                                  Data-Driven     0.0540   0.2400   0.5320   0.8560   0.9910
                                Pseudo Gaussien   0.0536   0.3736   0.7316   0.8992   0.9964
                                Van der Waerden   0.0492   0.3748   0.6376   0.9476   0.9888
        Double exponentiel         Wilcoxon       0.0480   0.2860   0.6156   0.9308   1.0000
                                    Laplace       0.0612   0.4604   0.7596   0.9952   1.0000
                                   Student-t5     0.0518   0.3132   0.6248   0.9512   0.9996
                                  Data-Driven     0.0550   0.3800   0.6400   0.8040   0.9440
                                Pseudo Gaussien   0.0440   0.2620   0.7456   0.9748   0.9988
                                Van der Waerden   0.0502   0.2544   0.7368   0.9944   1.0000
            Student-t5             Wilcoxon       0.0486   0.3988   0.6996   0.9976   1.0000
                                    Laplace       0.0552   0.4204   0.7040   0.9964   1.0000
                                   Student-t5     0.0528   0.3984   0.7192   0.9988   1.0000
                                  Data-Driven     0.0480   0.2040   0.5840   0.8280   0.9940
                                Pseudo Gaussien   0.0510   0.4150   0.6994   0.9026   0.9915
                                Van der Waerden   0.0532   0.3792   0.7092   0.8584   0.9906
       skew N ormal-sN (10)        Wilcoxon       0.0518   0.2836   0.6160   0.8402   0.9902
                                    Laplace       0.0480   0.3228   0.6028   0.8006   0.9892
                                   Student-t5     0.0506   0.3138   0.6180   0.8126   0.9880
                                  Data-Driven     0.0560   0.5200   0.7700   0.9820   0.9990
                                Pseudo Gaussien   0.0512   0.2276   0.6298   0.9064   0.9858
                                Van der Waerden   0.0504   0.2096   0.6480   0.8984   1.0000
       skew Student-st5 (10)       Wilcoxon       0.0458   0.2136   0.6148   0.9092   0.9996
                                    Laplace       0.0468   0.2068   0.5504   0.8404   0.9932
                                   Student-t5     0.0500   0.2544   0.6154   0.9128   0.9940
                                  Data-Driven     0.0476   0.4460   0.7968   0.9998   1.0000




6. Conclusions
    In the present article, we derive a pseudo-Gaussian and rank-based tests for
testing white noise against panel superdiagonal bilinear dependence in a multiple
regression model for speciﬁed and unspeciﬁed error density. Moreover, the pseudo-
Gaussian test appears to have quite poor performances under skewed and heavy-

                 Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                          165

tailed distributions, which leads as to consider rank-based tests. These tests are
nonparametric and they have better performance in terms of empirical power for
van der Waerden, Wilcoxon, Laplace, Student t and data-driven scores.


Acknowledgements
   The authors would like to express their gratitude to the two referees and
the Editor for their constructive comments and suggestions which improved the
presentation of the paper.


Appendix

Proof of Proposition 1. The proof of Proposition 1 relies on Swensen
(1985) conditions 1.2 to 1.7 of Lemma 1, and the only delicate one actually is
condition 1.2. The main point consists in showing that
                                                    X∞        Yj              1
                           1         1      1      ′
                                                                               2
(µ, β, σ , b) 7→ qµ,β,σ2 ,b;f1 (y) =
           2               2
                                       f1                  j
                                              y−µ−β x+ (−b) ukj     ul−(s−1)k
                                     σ      σ         j=1       s=1


is quadratic mean diﬀerentiability, at any (µ, β, σ 2 , 0), with x := (x1 , x2 , . . . , xK )′ ∈
                                                                                        1
RK . In order to establish the quadratic mean diﬀerentiability of qµ,β,σ
                                                                   2
                                                                         2 ,b;f
                                                                               1
                                                                                 it is
suﬃcient to show that the four conditions (i)-(iv) of Lemma A.1 in Bennala et al.
(2012) hold. This last is established in the following Lemma.

Lemma
     Let Assumption (B) holds and ﬁx f1 ∈ F1 . Deﬁne, for y ∈ R,

               1                            1 12                            ′ 
      Dµ qµ,β,σ
          2
                2 ,0;f (y)             =      qµ,β,σ2 ,0;f1 (y)Φf1 y−µ−β
                                                                       σ
                                                                             x
                                                                                ,
                      1                    2σ
               1                            1 12                            ′ 
      Dβ qµ,β,σ
          2
                2 ,0;f (y)             =      qµ,β,σ2 ,0;f1 (y)Φf1 y−µ−β
                                                                       σ
                                                                             x
                                                                                (K(n) )′ x,
                      1                    2σ
                                                                                               
                   1                        1 21                  y−µ−β ′ x       y−µ−β ′ x
                                                                                            
      Dσ2 qµ,β,σ
           2
                 2 ,0;f (y)            =       q      2      (y)            Φf1               −1 ,
                       1                   4σ 2 µ,β,σ ,0;f1          σ               σ


and
                       1                            1 21                         ′ 
               Db qµ,β,σ
                   2
                         2 ,b;f (y)|b=0       =       qµ,β,σ2 ,0;f1 (y)Φf1 y−µ−β
                                                                              σ
                                                                                  x
                                                                                     uk ul .
                               1                   2σ
     Then, as τ , s, v and r → 0,
      Z  1                         1                             1
                                                                                             2
1.                  2 +v,r;f (y) − qµ+τ,β+s,σ 2 +v,0;f (y) − rDb qµ+τ,β+s,σ 2 +v,b;f (y)|b=0
          2                         2                             2
         qµ+τ,β+s,σ                                                                             dy =
                                   1                        1                           1
       R
                                                                                     o(r2 ),


                           Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

166                                             Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk

                                                               ′       1
                                                                          2
                                                                                            
      Z  1                                                          Dµ qµ,β,σ 2 ,0;f (y)
                                                          
                                                            τ
                                                                                    1      2
                                                              ′                           
                                       1                                  1
2.        2
         qµ+τ,β+s,σ            (y) − q 2
                                                    (y) −  s       D  q 2
                                                                                        (y)  dy =
                    2 +v,0;f
                             1        µ,β,σ 2 ,0;f1                β µ,β,σ 2 ,0;f
                                                                                            
       R                                                                   1
                                                                                      1
                                                            v              2
                                                                     Dσ2 qµ,β,σ 2 ,0;f (y)
                                                                                       1     
                                                                                           τ     
                                                                                              2
                                                                                   o      s′      ,
                                                                                             
                                                                                            v
and                                                                                                    
                                                                                    1
                                                                 ′            2
                                                                            Dµ qµ,β,σ
                                                             τ                       2 ,0;f (y)        
                                                        ′                                            
                                                                                           1
      Z  1                                                                         1
                                                        s                    2
                                                                            Dβ qµ,β,σ 2 ,0;f (y)
                                                                                                         2
                                                                                                      
                                    1
                                                       
                    2 +v,r;f (y) − qµ,β,σ 2 ,0;f (y) − 
3.                                                                                                     dy =
          2                         2
         qµ+τ,β+s,σ                                                                        1
                                                        v                                            
                                                                                    1
                            1                   1
       R                                                                        2
                                                                            Dσ2 qµ,β,σ                  
                                                                                       2 ,0;f (y)
                                                                               1
                                                                                            1           
                                                         r                     2
                                                                           Db qµ,β,σ 2 ,b;f (y)|b=0
                                                                                           1
                                                                                                         
                                                                                                   τ
                                                                                              ′          2
                                                                                              s           
                                                                                          o 
                                                                                                    
                                                                                                     
                                                                                                             .
                                                                                                             
                                                                                              v           
                                                                                                    r
Proof of Lemma

                       ∞
                       X                 Y
                                         j
     1. Let Υ(b) =           (−b)j ukj         ul−(s−1)k and y−(µ+τ )−(β+s)′ x = z(µ, β) := z.
                       j=1               s=1
       Then (1) takes the form
                 Z                                      2
                     1           1     r 1
                    f z + Υ(r) − f (z) − f (z)Φf (z)uk ul dz = o(r2 ),
                     2            2       2

                  R                     2

       is equivalent to
            Z                                                 2
                   1    1             1      1 1
                r2
                      f 2 z + Υ(r) − f 2 (z) − f 2 (z)Φf (z)uk ul dz = o(r2 ).
              R    r                          2

       Then, it is suﬃcient to prove

                 Z                                            2
                    1   1             1      1 1
              lim     f 2 z + Υ(r) − f 2 (z) − f 2 (z)Φf (z)uk ul dz = 0.
              r→0 R r                         2

       We have
                                                                                             
              1   1             1                          1     1             1                       Υ(r)
           lim  f 2 z + Υ(r) − f 2 (z)             =   lim      f 2 z + Υ(r) − f 2 (z)              ×
          r→0 r                                        r→0 Υ(r)                                           r
                                                                ′
                                                          1
                                                   =    f 2 (z)       × (−1)uk ul
                                                       1 1
                                                   =     f 2 (z)Φf (z)uk ul ,
                                                       2

       and just show

                     Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                                                                        167



        Z                         2      Z                     2
           1    1             1                 1 1
              f 2 z + Υ(r) − f 2 (z)    dz 6      f 2 (z)Φf (z)uk ul dz < ∞.
         R r                                  R 2


      We know that
                                                            Z z+Υ(r)                      ′
                           1             1                                           1
                         f 2 z + Υ(r) − f 2 (z) =                                   f 2 (v) dv,
                                                                    z

      then
       Z                                  2             Z                 Z z+Υ(r)                     ′        2
                 1   1             1                                1                              1
                   f 2 z + Υ(r) − f 2 (z)         dz    =             2
                                                                                                   f 2 (v)        dv        dz
        z∈R      r                                              z∈R r             v=z

                                                                         Z       Z z+Υ(r)                                   2
                                                            Υ(r)                                    1 1
                                                        6                                             f 2 (v)Φf (v)               dv dz
                                                             r2           z∈R      v=z              2
                                                                         Z        Z z                                      2
                                                            Υ(r)                                   1 1
                                                        6                                            f 2 (v)Φf (v)               dz dv
                                                             r2           v∈R      z−Υ(r)          2
                                                                         2 Z                                   2
                                                                Υ(r)                        1 1
                                                        6                                     f 2 (v)Φf (v)            dv
                                                                 r              v∈R         2
                                                                              Z                                   2
                                                                                            1 1
                                                        6 (−uk ul )2                          f 2 (v)Φf (v)             dv
                                                                                 v∈R        2
                                                            Z                                          2
                                                                        1 1
                                                        6                 f 2 (z))Φf (z))uk ul               dz.
                                                                R       2


      This completes the proof of part (1) of the Lemma.
   2. The problem here reduces to the classical case of linear models considered
      by Swensen (1985).
   3. The result here follows from (1) and (2) above. This completes the proof of
      Lemma.                                                                   

  Lemma above and Lemma A.1 in Bennala et al. (2012) jointly imply the desired
mean square diﬀerentiability property. The proof of Proposition 1 is thus complete.

Proof of Proposition 2 (i) Follows from Proposition 1 and the fact that
                          (n)                     (n)
                        Λθ+ν (n) τ (n) /θ;f1 + Λθ/θ+ν (n) τ (n) ;f1 = oP (1),

           (n)
under Pµ,β ′ ,σ2 ,0;f1 , as n → ∞.
                                                                                                             (n)
   (ii) From (12) and by algebra calculations we obtain under Pµ,β ′ ,σ2 ,0;f1 , as
n → ∞,
                         (n)            (n)
                        ∆f1 ;4 (θn ) − ∆f1 ;4 (θ) = oP (1).

                   Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

168                                                    Aziz Lmakri, Abdelhadi Akharif & Amal Mellouk


Then, we can replace the deterministic sequence θn by the sequence of estimates
θbn , so we have the result.                                                 

Proof of Proposition 3 (i) Letting Γf1 (.) has been assumed continuous;
Γf1 ;44 (θbn ) − Γf1 ;44 (θ) = oP (1). Then, Proposition 2 (ii) implies that, under Pθ;f1 ,
                                                                                     (n)

as n → ∞,
                                         2
                                                       (n)2
                               ∆f ;4 (θbn )
                                (n)
                                                     ∆f ;4 (θ)
 Qf (θbn ) − Qf (θ)
  (n)         (n)
                         =           1
                                                −        1
   1           1
                               Γf1 ;44 (θbn )        Γf1 ;44 (θ)


                                    (n)2                (n)2                  (n)2                (n)2
                               ∆f ;4 (θbn )           ∆f ;4 (θ)             ∆f ;4 (θ)           ∆f ;4 (θ)
                         =           1
                                                −        1
                                                                       +       1
                                                                                            −        1

                               Γf1 ;44 (θbn )        Γf1 ;44 (θbn )        Γf1 ;44 (θbn )       Γf1 ;44 (θ)

                                                                        
                                         1        (n)2           (n)2
                         =                       ∆f ;4 (θbn ) − ∆f ;4 (θ)
                               Γf1 ;44 (θbn )      1              1

                                                                                                                                       
                                                                                       (n)2                1                  1
                                                                                +∆f ;4 (θ)                            −
                                                                                        1
                                                                                                     Γf1 ;44 (θbn )       Γf1 ;44 (θ)

                                                                                                 
                                         1
                                                 ∆f ;4 (θbn ) − ∆f ;4 (θ)   ∆f ;4 (θbn ) + ∆f ;4 (θ) + oP (1)
                                                  (n)            (n)         (n)            (n)
                         =
                               Γf1 ;44 (θbn )      1              1           1              1



                         = oP (1).
                                               (n)                 D                                        
      From (10), we have ∆f1 ;4 (θ)                            −−−−→           N Γf1 ;44 (θ)τ4 , Γf1 ;44 (θ) , under
                                                               n→∞
  (n)
Pθ+ν (n) τ (n) ;f1 . So that

                                         (n)
                                ∆ (θ)         D
                               p f1 ;4                1/2
                                            −−−−→ N (Γf1 ;44 (θ)τ4 , 1).
                                Γf1 ;44 (θ) n→∞
Cochran’s Theorem leads to
                             (n)2                                (n)               D
                        ∆f1 ;4 (θ)/Γf1 ;44 (θ) = Qf1 (θ) −−−−→ χ21 (λf1 );
                                                                               n→∞

                  1/2               2
with λf1 = Γf1 ;44 (θ)τ4                 = τ42 σ 2 (T − l)I(f1 )σf41 , which gives the desired result
       (n)
under Pθ+ν (n) τ (n) ;f1 .
   (ii) Stringency is a consequence of the weak convergence of local experiments
to Gaussian shifts (see Le Cam, 1986).
      (iii) Follows from (i) and (ii).                                                                                                  

Proof of Proposition 5. The proof of Part (i) of the proposition use the Hájek’s
projection theorem (see, Hájek & Šidák, 1967) and follows along the same lines as
in Hallin & Mélard (1988), therefore it is omitted. Part (ii) is obtained by direct
                                          (n)
computation. As for Part (iii), under Pθ;g1 , the result straightforwardly follows
from classical central limit theorems. On the other hand, it is easy to see that,

                   Revista Colombiana de Estadística - Theoretical Statistics 43 (2020) 143–171

Optimal Detection of Bilinear Dependence in Regression Data                               169

               (n)           (n)                                     (n)
still under Pθ+ν (n) τ ;g1 , ∆f1 ,g1 ;4 (θ) and the log-likelihood Λθ+ν (n) τ /θ;g1 are jointly
multinormal. Then, the desired result follows from an application of Le Cam’s
third lemma.                                                                                 
                                                                   
               Recibido: noviembre de 2019 — Aceptado: abril de 2020


References
Akharif A, Halli M. Eﬃcient detection of random coeﬃcients in autoregressive models.(2003). Annals of Statistics.
Allal J, El Melhaoui S. Tests de rangs adaptatifs pour les modèles de régression linéaire avec erreurs arma.(2006). Annales des sciences mathématiques du Québec.
Azzalini A, Capitanio A.Distributions generated by perturbation of symmetry with emphasis on a multivariate skew t-distribution.(2003). Journal of the Royal Statistical Society.
Baltagi B, Li Q. Testing AR(1) against MA(1) disturbances in an error component model.(1995). Journal of Econometrics.
Benghabrit Y, Hallin M. Optimal rank-based tests against ﬁrst-order superdiagonal bilinear dependence.(1992). Journal of Statistical Planning and Inference.
Benghabrit Y, Hallin M. Rank-based tests for autoregressive against bilinear serial dependence.(1996). Journal of Nonparametric Statistics.
Bennala N, Hallin M, Paindaveine D. Pseudo-gaussian and rank-based optimal tests for random individual eﬀects in large n small t panels.(2012). Journal of Econometrics.
Cassart D, Hallin M, Paindaveine D. A class of optimal tests for symmetry based on local Edgeworth approximations.(2011). Bernoulli.
Chernoff H, Savage I R. Asymptotic normality and efficiency of certain nonparametric tests.(1958). Annals of Mathematical Statistics.
Dutta H. Large sample tests for a regression model with autoregressive conditional heteroscedastic errors.(1999). Communications in Statistics Theory and Methods.
Elmezouar Z C, Kadi A M, Gabr M M. Linear regression with bilinear time series errors.(2012). Panamerican Mathematical Journal.
Fihri M, Akharif A, Mellouk A, Hallin M. Efficient pseudo-gaussian and rank-based detection of random regression coefficients.(2020). Journal of Nonparametric Statistics.
Grahn T. A conditional least squares approach to bilinear time series.(1995). Journal of Time Series Analysis.
Granger C W J, Andersen A P. An Introduction to Bilinear Time Series Models.(1978). Vandenhoeck and Ruprecht.
Guegan D. Etude d’un modèle non linéaire- le modèle superdiagonal d’ordre 1.(1981). CRAS Série.
Guegan D, Pham D T. Power of the score test against bilinear time series models.(1992). Statistica Sinica.
Hájek J, Šidák Z. Theory of Rank Tests.(1967). Academic Press.
Hallin M, Mehta C. R-estimation for asymmetric independent component analysis.(2015). Journal of the American Statistical Association.
Hallin M, Mélard G. Rank-based tests for randomness against ﬁrst-order serial dependence.(1988). Journal of the American Statistical Association.
Hallin M, Taniguchi M, Serroukh A, Choy K. Local asymptotic normality for regression models with long-memory disturbance.(1999). The Annals of Statistics.
Hallin M, Werker B J M. Semi-parametric efficiency - distribution-freeness and invariance.(2003). Bernoulli.
Hristova D. Maximum likelihood estimation of a unit root bilinear model with an application to prices.(2005). Studies in Nonlinear Dynamics and Econometrics.
Hwang S Y, Basawa I V. Parameter estimation in a regression model with random coeﬃcient autoregressive errors.(1993). Journal of Statistical Planning and Inference.
Kim I. A study on the test of homogeneity for nonlinear time series panel data using bilinear models.(2014). Journal of Digital Convergence.
Kreiss J P. On adaptive estimation in stationary ARMA processes.(1987). The Annals of Statistics.
Le Cam L M. Asymptotic Methods in Statistical Decision Theory.(1986). Springer-Verlag.
Le Cam L M, Yang G L. Asymptotics in Statistics: Some Basic Concepts.(2000). Springer-Verlag.
Lee S H, Kim S W, Lee S D. Test of homogeneity for panel bilinear time series model.(2013). The Korean Journal of Applied Statistics.
Lillo R L, Torrecillas C. Estimating dynamic panel data - A practical approach to perform long panels.(2018). Revista Colombiana de Estadística.
Maravall A. An application of nonlinear time series forecasting.(1983). Journal of Business and Economic Statistics.
Noether G E. On a theorem by wald and wolfowitz.(1949). The Annals of Mathematical Statistics.
Pesaran H. Time Series and Panel Data Econometrics.(2015). Oxford University Press.
Pham T D, Tran L T. On the ﬁrst-order bilinear time series model.(1981). Journal of Applied Probability.
Quinn B G. Stationarity and invertibility of simple bilinear models.(1982). Stochastic Processes and their Applications.
Rao T S, Gabr M. An introduction to bispectral analysis and bilinear time series models.(1984). Springer Science and Business Media.
Saikkonen P, Luukkonen R. Power properties of a time series linearity test against some simple bilinear alternatives.(1991). Statistica Sinica.
Swensen A R. The asymptotic distribution of the likelihood ratio for autoregressive time series with a regression trend.(1985). Journal of Multivariate Analysis.
Tan L, Wang L. The lasso method for bilinear time series models.(2015). Communications in Statistics - Simulation and Computation.
Wald A. Tests of statistical hypotheses concerning several parameters when the number of observations is large.(1943). Transactions of the American Mathematical Society.
Weiss A A. ARCH and bilinear time series models: Comparison and combination.(1986). Journal of Business and Economic Statistics.