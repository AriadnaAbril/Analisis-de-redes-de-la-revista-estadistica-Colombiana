Medidas repetidas con datos faltantes estimación de parámetros vı́a análisis de covarianza
Universidad Nacional de Colombia
Resumen
En este artı́culo se lleva a cabo la estimación de parámetros y se obtienen diferentes sumas de cuadrados ajustadas para diseños balanceados, en medidas repetidas, con información incompleta a través de tres procedimientos: el método de análisis de varianza de Bartlett; un método multivariado con base en los datos completos y finalmente un método multivariado alterno usando toda la información disponible en el arreglo experimental. Con los tres procedimientos anteriores se llevan acabo aplicaciones numéricas.
Palabras Clave: Análisis de covarianza, información faltante, datos longitudinales, medidas repetidas, mı́nimos cuadrados generalizados, análisis multivariado.
Abstract
In this paper the estimation of parameters and the different adjusted sums of squares for balanced designs in repetead measures with incomplete information is done through three procedures: the Bartlett’s method of covariance analysis; a multivariate method with complete data, and finally, an alternative multivariate method using the available information in the experimental arrangements. Numerical applications using the above procedures are done.
Keywords: Covariance analysis, missing information, longitudinal
data, repeated measures, generalized least squares, multivariate analysis.
Introducción
    Las investigaciones con datos longitudinales involucran observaciones de un
conjunto de unidades experimentales (humanos, lugares geográficos, animales,
etc.) clasificados en diferentes subpoblaciones teniendo en cuenta uno o más
factores (raza, lugar de origen, tipo de dieta, etc.) a lo largo de diversas condi-
ciones de evaluación (tiempos, dosis, etc.). En este sentido, se pueden destacar
los trabajos de Laird y Ware [10], Ware [16], Andrade y Singer [2], Liang y
Zeger [11] y Andreoni [3] entre otros.

    La diferencia entre un estudio longitudinal y uno de medidas consiste en
que en el primero, los individuos participantes son seguidos por periodos exten-
sos y en el segundo, las observaciones son recolectadas en periodos de tiempo
relativamente cortos y, frecuentemente, bajo condiciones experimentales. Esta
diferencia se puede ver más en detalle en Crowder y Hand [5].

    Otra caracterı́stica fundamental asociada a los estudios con medidas repe-
tidas es la posibilidad de correlación no nula entre las observaciones realizadas
en las mismas Unidades Experimentales.

     Infortunadamente, en muchos casos no se pueden usar las técnicas clásicas
de análisis porque se pierde observaciones o porque el diseño es desbalanceado
por alguna razón, o porque hay covariables que varı́an en el tiempo. Una revi-
sión de literatura sobre observaciones faltantes en datos multivariables puede
encontrarse en Afifi y Elashoff [1], donde se resaltan los trabajos de Yates [18]
en 1933, Bartlett [4] en 1937, Tocher [15] en 1952, Wilkinson [17] en 1958 y
Dear [6] en 1959 entre otros, como los pioneros en estudiar métodos para la
estimación de información faltante.
   Algunos autores que han tratado este tema son Timm y Mieczkowski [14],
Crowder y Hand [5] y Laird et al [9]; pero no han hecho propuestas de esti-
mación basados implicitamente en el método de Bartlett, el cual es apropiado
cuando se tiene poca información faltante.
2.    Estimación de parámetros en medidas
      repetidas
    En esta sección se llevan a cabo los desarrollos teóricos y se muestran apli-
caciones de la técnica del análisis de covarianza, como método propuesto para
la estimación de parámetros en diseños de medidas repetidas con información
faltante. Inicialmente se implementa el método de Bartlett particionando en
forma adecuada el vector de respuestas, según contenga o no información fal-
tante, luego se procede a la imputación de la información faltante en forma
multivariada y posteriormente se muestra el procedimiento para la estimación
de los parámetros ası́ como, para la obtención de las sumas de cuadrados del
modelo y del error corregida una vez hecha la imputación.
2.1.   Método del análisis de covarianza en medidas repe-
       tidas

   En esta subsección se implementa el método de Bartlett para la imputación
de información faltante en modelos con medidas repetidas bajo el supuesto
de perdida de información en forma aleatoria. Se supone que se observan n
individuos bajo t condiciones de evaluación y que se presentan m0 valores
perdidos en n0 de los n individuos iniciales (n0 ≤ m0 ), pudiendo en este caso
representar esa información con el modelo de covarianza (Véase [13]):
siendo y el vector respuesta de orden nt×1 ya que n individuos fueron evaluados
en t diferentes ocasiones, X la matriz diseño de orden nt × p, β el vector de
parámetros desconocidos de orden p × 1, Z la matriz de covariables de orden
nt × m0 , γ el vector de coeficientes para las covariables de orden n0 × 1 y e
el vector de desviaciones de orden nt × 1. Sin perder generalidad, se puede
ordenar el vector de observaciones de forma tal que las primeras componentes
correspondan a los tiempos en los cuales se perdió algún dato. Si en total se
tienen m0 datos faltantes en n0 individuos, entonces el resto de componentes
(n0 + j) con j = 1, . . . , n, corresponden a los individuos con al menos una
observación en el tiempo, como se muestra en (2):
En forma equivalente a como se arregla el vector de respuestas, se ordena la
matriz diseño y los parámetros del modelo como:
con p número de parámetros poblacionales desconocidos, X l de orden tl × p,
l = 1, 2, ..., n0 , matriz diseño asociada a la información faltante en los individuos
donde se perdió alguna información, Xi , i = n0 + j; j = 1, ..., n matriz diseño
de orden ti × p asociada con la información observada. En el modelo en estudio,
y de orden nt × 1 es el vector de observaciones, X de orden nt × p es una matriz
de valores conocidos, β de orden p × 1 es el vector de parámetros, γ de orden
m0 × 1 es el vector de coeficientes para las covariables de los valores faltantes,
e de orden nt × 1 es la matriz de desviaciones e = y − E(y) no observable, y Z
de orden nt × m0 es la matriz de constantes conocidas de la forma:
con k = i=1 ti . La notación propuesta se ilustra con la información del ejem-
plo 2.1.1.
    Ejemplo 2.1.1: La siguiente información tomada de Crowder y Hand [5]
presenta el efecto de una dieta suplementaria de vitamina E en el crecimiento
de cerdos raza guinea. El peso corporal de cada animal fue registrado al final
de las semanas 1, 3, 4, 5, 6 y 7. A cada uno de estos animales se les dio una
sustancia inhibidora durante la semana uno, la terapia de la vitamina E se
comenzo en la semana cinco. Tres grupos de animales, cinco en cada grupo,
recibieron dosis de vitamina E: cero, baja y alta, respectivamente. Para la
comprensión de este modelo solo se registra en la Tabla 1, el peso corporal (en
gramos) de las semanas uno, tres y cuatro, con cinco animales del grupo uno y
cuatro animales del grupo dos, eliminando en forma aleatoria cuatro datos del
conjunto de información.
Tabla 1: Efecto de dietas suplementarias sobre las tazas de crecimiento en
cerdos guinea con pérdida aleatoria de datos.
   De la tabla se tiene que: n = 9, t = 3, m0 = 4, n0 = 3, p = 4; β1 , β2 , β3
parámetros asociados con el efecto de semana 1, 3 y 4, respectivamente, y β4
parámetro asociado con el efecto del grupo.
   Inicialmente, el vector respuesta esta dado por:
Al ordenarlo y reemplazar los datos faltantes por valores iniciales cero, se tiene:
de orden s y Jr vector de unos de tamaño r × 1 y donde Is |Jr es una matriz
aumentada.
    El estimador mı́nimos cuadrados generalizados de β se obtiene minimizando
                     nP
                      0 +n
la forma cuadrática       Qi (β, Σi ), donde Σi de orden ti ×ti es una submatriz de
                       i=1
Σ de componentes de varianzas asociadas a los tiempos donde hay información
para yi .
    Si Σ es conocida, entonces β tiene como estimador a:
Si Σ es desconocida, la estimación de β se obtiene a partir de la expresión:
Crowder y Hand [5] muestran que si hay datos faltantes entonces no hay so-
luciones explı́citas para β̂ y Σ̂ en forma separada, y ası́, la solución para las
ecuaciones debe hacerse en forma iterativa. Para efectos de este trabajo, se
tomó como estimación de la matriz de covarianza (Σ) las estimaciones de las
componentes dadas en el PROC MIXED de SAS1 y la matriz de covarianza
combinada.
   Al considerar el modelo 1, con las caracterı́sticas descritas y tener en cuenta
que existen datos faltantes se tiene como función a minimizar:
Nuevamente, teniendo en cuenta los resultados de Bartlett, se separa la infor-
mación en dos partes, una con los tiempos en los cuales se presentan datos
faltantes y la otra con los individuos y tiempos con datos observados, es decir:
Por la construcción de Z, la expresión (7) es equivalente a:
Al minimizar la segunda parte de la expresión (8) y tener Σ desconocida, la
estimación de β se obtiene a partir de la expresión:
Para los datos de la Tabla 1, se muestra la estimación obtenida. Como se des-
conoce la matriz de covarianzas (Σ), se estima usando la matriz de covarianza
combinada, obtenida a partir de un procedimiento iterativo implementado en
SAS-IML (véase González L. M. [7]), el resultado de esta estimación es:
  1 Vease la guia del usuario de SAS [12].
en forma iterativa, la estimación de (9) dió los siguientes resultados:
Estas estimaciones fueron usadas para la imputación de la información faltan-
te. Con este estimador, y despejando de las ecuaciones normales asociadas al
modelo (1), se tiene que Z γ̂ = y − X β̂ y para las primeras m0 componentes se
satisface:
con l = 1, . . . , n0 , para las demás componentes Zi γ̂ = 0, con i = n0 +1, . . . , n0 +
n al tenerse en cuenta que Zi = 0 para todo i > n0 , reemplazando esta estima-
ción en (8) se obtiene:
al minimizar (11) respecto a β, se llega a la solución encontranda en (9), con
esta solución y despejando γ de (10) se halla que:
Nótese que k = 1, ..., m0 , donde ỹ [k] es el valor inicial “conjeturado” para el
k-ésimo valor faltante, X[k] es la fila de la matriz diseño asociada al k-ésimo valor faltante y γ̂k es el coeficiente estimado de la covariable para el k-ésimo
valor faltante.
   Como:
al reemplazar en (12) se tiene que el predictor ŷ [k] para el k-ésimo dato faltante
es igual al valor conjeturado para el k-ésimo dato faltante menos el coeficiente de
la covariable para el k-ésimo valor faltante, es decir ŷ [k] = ỹ [k] − γ̂k . Utilizando
la estimación de β se encuentran los valores estimados para la información
faltante. Esta predicción es presentada en la tabla (2).
Tabla 2: Resultados de la predición de la información faltante usando análisis
de covarianza.
2.2.     Enfoque multivariado para la imputación de infor-
         mación
    Una alternativa para el problema propuesto consiste en imputar la infor-
mación haciendo uso de un enfoque multivariado. Para ello se utilizan los desa-
rrollos encontrados en Timm y Mieczkowski [14] quienes muestran inicialmente
un modelo lineal multivariado para analizar medidas repetidas cuando no se
ha perdido información. Ası́, en la subsección 2.2.1 se sigue la metodologı́a
presentada por ellos usando solo la información de aquellas unidades que se
observaron en su totalidad, y posteriormente, en la subsección 2.2.2, se utiliza
toda la información disponible a la vez que se encuentra una relación entre
ellas. Debido a que el segundo método es iterativo, la relación se busca a nivel
de la primera iteración antes de imputar los datos. Estos resultados se ilustran
con los datos de la tabla 1.
2.2.1.    Enfoque multivariado - Casos completos
   Timm y Mieczkowski [14] muestran que un diseño en medidas repetidas
univariado con información completa puede ser presentado como un modelo
lineal multivariado. Partiendo de este resultado, se ajusta un modelo donde
solamente se tienen en cuenta los individuos que tienen información completa
(n − n0 ) y reordenando las observaciones se llega a un modelo univariado para
medidas repetidas:
con E (yC ) = XC β (1) y Cov (yC ) = In−n0 ⊗ Σ = ΩC donde yC es el vec-
tor de respuestas de orden (t (n − n0 )) × 1, XC es la matriz diseño de orden
(t (n − n0 )) × p, con p = p∗ t , β (1) es el vector de parámetros desconocidos de
orden p × 1, eC vector de errores de orden (t (n − n0 )) × 1 y Σ es la matriz
de covarianzas. Ahora, si se tiene en cuenta que el haber observado la infor-
mación completa significa que todos los individuos fueron observados en todas
las ocasiones de evaluación (t-tiempos), entonces el vector de respuestas yC ,
se puede escribir como una matriz Y de orden n − n0 filas por t columnas,
XC β (1) como el producto de tres matrices: XW de orden t × t que corresponde
a la matriz diseño de los tiempos en un modelo reparametrizado, B de orden
p∗ × t matriz de parámetros desconocidos, XB de orden (n − n0 ) × p∗ matriz
diseño correspondiente a los factores en un modelo reparametrizado y eC como
U((n−n0 )×t) matriz de errores. Con lo anterior (14) se reescribe como:
El hecho de utilizar sólo los casos completos permite que la matriz asociada
a estos se pueda escribir como XC = XB ⊗ XW , es decir, XC es separable 2 ,
entonces el mejor estimador lineal insesgado (MELI) de B es:
que es el estimador multivariado.
    Ahora, al aplicar el operador V ec(.) a la traspuesta de la ecuación (16), se
tiene:
Por otro lado, teniendo en cuenta que XC = XB ⊗XW , el estimador univariado
   2 la condición que señala que la matriz diseño univariada X puede ser representada como
el producto kronecker X = XB ⊗ XW es llamada condición de separabilidad
de mı́nimos cuadrados generalizados de (14) es:
      Para efectos de estimación de β̂ (1) , la matriz de covarianza Σ se puede
estimar usando la información completa (casos completos) o toda la información
disponible.
      Si la matriz diseño XW es de rango completo y XC es separable, en-
                           ¡ t −1      ¢−1 t −1           −1      t −1  t
tonces se satisface que XW     Σ XW           XW Σ = XW      Σ (XW  ) XW  Σ−1 =
  −1       −1     −1
XW ΣΣ = XW . Este resultado muestra la equivalencia entre la estimación
multivariada y univariada, es decir, (17) y (18) producen resultados idénticos,
ası́,
Obtenida la estimación de β (1) a partir de (19), se procedio a encontrar la
estimación del vector de predicción, a partir de la siguiente expresión:
siendo XB:C la matriz diseño con toda la información.

    La matriz de covarianza estimada cuando se tiene la información completa
es obtenida a partir de la expresión:
siguiendo con los datos propuestos para ilustrar este trabajo, se sigue que la
estimación de la matriz de covarianzas con el conjunto completo de datos es:
y la estimación de β (1) , con la ecuación (19), arrojo los siguientes resultados:
Finalmente, obtenida la estimación de β̂ (1) , se encontraron los valores de pre-
dicción a partir de la ecuación (20); estos resultado se ilustran en la tabla 3.
Tabla 3: Resultados de la predición de la información faltante usando casos
completos.
2.2.2.   Método alternativo de estimación
    En esta sección se propone una variante al método de estimación de in-
formación faltante presentado en la sección 2.2.1, el método tiene en cuenta
toda la información disponible. En este proceso de estimación, se complementa
el modelo (14) incluyendo los individuos que tenı́an alguna información, esto
llevó a plantear el modelo:
con E(y) = Xβ (2) y E (eet )µ= Ω.
    En (22) se satisface que      ,X =         con yF vector respuesta asocia-
do con los individuos observados parcialmente, XF matriz diseño de los mismos
individuos observados parcialmente, yC y XC como se definieron en la sección
2.2.1, esto es, XC = XB ⊗ XW .
   La matriz Ω se particiona como,
donde ΩF = Cov (yF ) y ΩC como se definió en la sección 2.2.1. Para efectos
de este trabajo se asume independencia entre yF y yC ; por tanto se tiene que
ΩF C = ΩCF = 0. El estimador de mı́nimos cuadrados generalizados para β (2)
en el modelo (22) es:
Los resultados (24), (25) y (26) son de Henderson y Searle [8]:
para A matriz no singular, U , B y V matrices rectangulares o cuadradas;
con I + P no singular e I matriz idéntica;
con I + P Q y I + QP no singulares.
   Se puede reescribir
   Por facilidad, en (27) se usa (25) y (26), con Q = M = XFt Ω̂−1
obteniendo entonces:
Reemplazando M y N , se tiene finalmente:
Ası́, β̂ (2) se puede expresar usando β̂ (1) y la varianza de β̂ (1) . Se observa en la
expresión anterior que si no hay información faltante, β̂ (2) es igual a β̂ (1) .
usando (27) y reemplazando a M y N se tiene finalmente que:
     Del resultado anterior, se concluye que la covarianza de β̂ (2) puede expre-
sarse en términos de la covarianza de β̂ (1) , y si la información esta completa,
éstas coinciden.
     Con los datos del ejemplo y Σ̂ obtenida en (∗) se encontraron los siguientes
valores de estimación para β (2) :
En la tabla 4 se muestran los valores inputados por este método.
Tabla 4: Resultados de la predicción de la información faltante usando el méto-
do alternativo.
2.2.3.             Relación entre sumas de cuadrados del enfoque multivariado-
                   casos completos y el método alternativo.
    Finalmente se presenta en esta sección una relación entre las dos propuestas
del enfoque multivariado, basada en la comparación de las sumas de cuadrados
del modelo y del error, considerando únicamente la primera iteración, es decir,
sin tener en cuenta los datos inputados.
    Se inicia con la suma de cuadrados del modelo y a partir de desarrollos
algebraicos (véase González L. M. [7]), se encuentra que:
Y la suma de cuadrados del error, cuando se usan todos los datos es:
Las ecuanciones (31) y (32) permiten encontrar una relación entre las sumas
de cuadrados de los dos enfoques multivariados, esto es, se expresan las sumas
de cuadrados (del modelo y del error) del enfoque multivariado-método alter-
nativo en términos de las sumas de cuadrados del enfoque multivariado-casos
completos. De estos resultados se observa que la SCE (2) es igual a SCE (1) ,
siempre que no haya pérdida de información.
3.     Conclusiones
    En este artı́culo se llevó a cabo la implementación del método basado en el
análisis de covarianza para la estimación de parámetros en medidas repetidas
cuando se pierden datos en forma aleatoria encontrando que la estimación del
vector de parámetros β no depende de los valores iniciales çonjeturados”para
los datos perdidos.
    Tanto para el enfoque multivariado conocido en el texto como casos comple-
tos, como para el método alternativo, se muestran las expresiones algebraicas
que permiten encontrar las predicciones para el vector respuesta, las covarian-
zas de β̂ (1) y β̂ (2) , y las expresiones algebraicas para las sumas de cuadrados
del modelo y del error, respectivamente.
    Finalmente, en la Tabla 5 se comparan los resultados de las predicciones
frente a los datos originales, observando que la predicción del método alterna-
tivo es la que más se acerca a los datos originales.3 .
  3 Los métodos de imputación se programaron en SAS/IML (véase González, L. M. [7])
Tabla 5: Resultados de la predición de la información faltante usando el método
alternativo.
 Grupo-Animal-      Valores           Método de       Casos           Método
 Tiempo             originales        covarianza       completos       alternativo
 1-1-Sem. 3         460               527.15865        535.6667        520.9435
 1-3-Sem. 3         530               527.15865        535.6667        520.9435
 2-6-Sem. 3         560               549.82606        546.6667        553.8301
 2-6-Sem. 4         565               586.21752        571.6667        576.9306


Bibliografía
Afifi, A. and Elashoff, R. Missing Observations in Multivariate Statistics I: Review of the Literature, Journal of the American Statistical Association, 61, 595-604 (1966).
Andrade, D. y Singer, J. Análise de Dados Longitudinais, VII Simpósio Nacional de Probabilidade e Estatı́stica, Universidade de Sao Paulo, Brasil (1986).
Andreoni, S. Modelos de Efeitos Aleatórios para Análise de Datos Longitudunais Não Balanceados em Relacão ao Tempo, Dissertacão Apresentada
ao Instituto de Matemática e Estatı́stica da Universidade de São Paulo para Obtencão do Grau de Mestre em Estatı́stica,São Paulo, Brasil (1989).
Bartlett, M. Some Examples of Statitical Methods of Research in Agriculture, Journal of the Royal Statistical Society Supplement, 4, 137-183 (1937). Citado por Affifi y Elashoff (1966.
Crowder, M. y Hand, D. Analysis of Repeated Measures, Chapman and Hall (1990).
Dear, R. E. A Principal-Component Missing-Data Method for Multiple Regression Models . SP-86. System Developed Corporation, Santa Monica, California (1959). Citado por: Affifi y Elashoff (1966).
González, L. M. Medidas Repetidas con Datos Faltantes: Estimación de Parámetros Vı́a Análisis de Covarianza, Tesis de Maestrı́a en Estadı́stica. Departamento de Estadı́stica. Facultad de Ciencias. Universidad Nacional de Colombia (2002).
Henderson, H. and Searle, S. On Deriving the Inverse of a Sum of Matrices. SIAM Review. Society for Industrial and Applied Mathematics. Vol 23 No. 1. 53-60 (1981).
Laird, N., Lange, N. and Stram D. Maximum Likelihood Computations With Repeated Measures: Application of the EM Algorithm. Journal of the American Statistical Association, Vo. 82, No. 397 (1987).
Laird, N. and Ware, J. Random-Effects Models for Longitudinal Data. Biometrics 38, 963-974 (1982).
Liang, K. and Zeger, S. Longitudinal Data Analysis Using Generalized Linear Models. Biometrika, 73, 1, 13-22 (1986).
SAS Institute Inc. SAS/STAT User’s Guide, Release 6.03 Edition. Cary, NC: SAS Institute Inc. 1028 pp. (1988).
Searle, S. Linear Models, John Wiley and Sons. (1971).
Timm, N. and Mieczkowski, T. General Linear Models, SAS. (1997).
Tocher, K. The Design and Analysis of Block Experiments. Journal of the Royal Statistical Society. Series B. 14, 45-100 (1952). Citado por Affifi y Elashoff (1966).
Ware, J. Linear Models for the Analysis of Longitudinal Studies”. The American Statistician, Vol. 39 No. 2 (1985).
Wilkinson, G. Estimation of the Missing Value for the Analysis of Incomplete Data. Biometrics, 14, 257-86 (1958). Citado por Affifi y Elashoff (1966).
Yates, F. The Analysis of Replicated Experimental when the Field Results are Incomplete. The Empire Journal of Experimental Agriculture, 1, 129-142 (1933). Citado por Affifi y Elashoff (1966).