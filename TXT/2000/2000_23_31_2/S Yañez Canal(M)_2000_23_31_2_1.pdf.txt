LA ESTADÍSTICA UNA CIENCIA DEL SIGLO XX. R.A. FISHER, EL GENIO
Universidad Nacional de Colombia
Resumen
La Estadı́stica como ciencia independiente es un desarrollo del siglo XX. La χ2 de Karl Pearson (1900) puede considerarse la epifanı́a de la disciplina, pero el genio fundamentador, cuyas ideas y conceptos consolidaron el estatus cientı́fico de la estadı́stica, es Sir Ronald Aylmer Fisher. Se presenta en esta charla el contexto histórico donde surge la estadı́stica y sus principales referentes de desarrollo. Con Fisher como núcleo, se bosqueja la historia desde K. Pearson y Student hasta hoy. Dicho recorrido se concentra alrededor de los fundamentos de la estadı́stica donde el artı́culo de Fisher (1922) es revolucionario y da solidez lógica al objeto y métodos de estudio de la estadı́stica. Este artı́culo es el texto escrito de la conferencia inagural del Simposio de Estadı́stica 2001 de la Universidad Nacional de Colombia.
Palabras Claves: Estadı́stica, fundamentos de la estadı́stica, inferencia, probabilidades, máxima verosimilitud, pruebas de hipótesis, Bayes, frecuentista, Fisher, Galton, K. Pearson, E. S. Pearson, Neyman, Wald.
Introducción
La Estadı́stica como ciencia independiente es un desarrollo del siglo XX. Sir Ronald Aylmer Fisher (1890-1962) es su genio, el transformador de ideas que cohesionó y estableció los fundamentos teóricos de la inferencia estadı́stica, como método de razonamiento inductivo que da un nuevo sentido al procesamiento de datos e intenta medir su grado de incertidumbre.
Sus resultados le dieron a la estadı́stica el estatus de disciplina cientı́fica, reafirmado por los innumerables campos de aplicación de sus metodologı́as. Me concentraré en su aporte a los fundamentos que convierten a la estadı́stica en ciencia, no sin advertir que su estatura genial destaca en muchos otros campos, como el diseño experimental para citar sólo uno.
Estas ideas se presentaron en su primera versión, a manera de conferencia, dentro del ”SEMINARIO GRANDES PENSADORES DEL FIN DEL MILENIO, CUARTO CICLO: MATEMÁTICOS 1999” organizado por la Facultad de Ciencias Humanas y Económicas de la Universidad Nacional de Colombia, Sede Medellı́n (se trataba de cinco ciclos, los otros cuatro fueron en Filosofı́a (1996),
Economı́a (1997), Fı́sica (1998) y Literatura (2000)). Al recibir la invitación a participar en el ciclo de matemáticos donde se habları́a de Fermat, Gauss, Laplace, Galois, Hilbert, Cantor, Riemann y muchos otros de los grandes de la Matemática cuyos monumentales aportes recogen ideas que transcienden el milenio y nos llevan a las raı́ces de nuestra civilización occidental, a Pitágoras, a Euclides a la cultura griega- pensé en Fisher; era el momento de hacer un homenaje a su obra y permitı́a la oportunidad de reflexionar sobre la identidad de la estadı́stica que orgullosa de sus ancestros podı́a ya erigirse en disciplina cientı́fica independiente, trascendiendo aquello de rama de la Matemática aplicada.
El texto que hoy se presenta en el Simposio de Estadı́stica 2001, se enriqueció durante el debate para la creación del Departamento de Estadı́stica de la Universidad Nacional de Colombia, Sede Medellı́n donde al despuntar del siglo XXI, además de a los colegas matemáticos, habı́a que presentar a los quı́micos, biólogos y fı́sicos nuestras pretensiones de disciplina digna de ser considerada en pie de igualdad con dichos tradicionales campos del saber.
Argumentar sobre lo obvio, al menos para uno, es en primera instancia difı́cil, se tiende a rechazar la idea por trivial, pero reflexionando se hace necesario explicar que LA ESTADÍSTICA ES UNA CIENCIA DEL SIGLO XX.
No soy historiador, ni especialista en la obra de Fisher, por lo tanto no se presenta aquı́ en forma sistemática su obra, sólo se pretende mostrar el origen de la autonomı́a disciplinaria de la estadı́stica apoyado en la siguiente bibliografı́a básica: Box, J. F. (1978); Rao, C. R. (1998);. Efron, B.(1998); Hald, A. (1998); Folks, J.L. (1981).
La épica de los pueblos es elemento fundamental de su identidad. De manera análoga, la estadı́stica tiene sus mitos alrededor del azar, los dioses y los oráculos. Sus ilustres ancestros en la Teorı́a de la Probabilidad: Fermat, Pascal. Sus monumentales precursores, creadores de la Estadı́stica Matemática, Laplace y Gauss (todavı́a matemáticos). Sus próceres: K. Pearson, Neyman, Student, E.Pearson, Snedecor entre otros. Su genio: Sir R. A. Fisher.
Parafraseando a Efron(1998) incluso los cientı́ficos necesitan sus héroes, y R. A. Fisher fue sin duda el héroe de la estadı́stica del siglo XX. Sus ideas transformaron nuestra disciplina de tal forma que hasta un César o un Alejandro hubieran envidiado.
Antes de entrar en materia propongo institucionalizar una Conferencia de Historia de la Estadı́stica que de cuenta de la necesidad de toda comunidad de reflexionar sobre su propia historia.
Bosquejo Histórico
El carácter genial de Fisher y su importancia histórica son resumidas por Hald (1998) al afirmar que hay tres revoluciones en la inferencia estadı́stica paramétrica debidas a Laplace (1774), Gauss y Laplace entre 1809-1812 y Fisher (1922) respectivamente. Les tomó a cada uno de estos autores alrededor de 20 años, y muchos artı́culos para desarrollar sus ideas básicas en detalle, y al resto de la comunidad estadı́stica medio siglo para entender y desarrollar los nuevos métodos y sus aplicaciones.
En la figura se presentan estos tres colosos con sus obras capitales. La de Fisher establece los fundamentos de la que a nuestro juicio es la ESTADÍSTICA como disciplina independiente. La χ2 de Karl Pearson (1900) se considera la epifanı́a y a Pearson el Padre de esta ciencia del siglo XX. En la figura se presenta una sinopsis de la historia de la estadı́stica que describimos brevemente a continuación. Los antecedentes de la estadı́stica, siguiendo a Folks (1981), son la Aritmética Polı́tica, la Teorı́a de la Probabilidad y los cientficos experimentales del siglo XIX. La Aritmética Polı́tica que comprende los censos poblacionales, los registros de natalidad, mortalidad y de matrimonios, las tarifas de impuestos y otros temas relativos a la descripción de los estados, se puede encontrar desde antes de Cristo, y da origen a la palabra estadı́stica atribuida al profesor de la Universidad de Gotinga (Alemania) Gotfried Achenwall (1719-1772). Es claro que la disciplina estadı́stica trasciende esos estrechos lı́mites primitivos y es precisamente la confluencia de la Aritmética Polı́tica con la Teorı́a de la Probabilidad bajo la influencia de los cientı́ficos experimentales del siglo XIX, lo que configura la estadı́stica en el sentido moderno, en el sentido del siglo XX. Ese 1900, de apariencia casual y caprichosa, como fecha de nacimiento, registrada por su “padre” Karl Pearson en su artı́culo en el Philosofical Magazine, es el resultado de la influencia del Darwinismo a través de Galton que impulsó a este gran matemático a aplicar la Teorı́a de la Probabilidad a los temas de la evolución. Se redescubre a Mendel también en 1900, su obra sobre las leyes estadı́sticas de la herencia habı́a sido publicada en 1856 y la polémica entre Darwinistas y Mendelianos en el primer cuarto del siglo XX, influye también a la estadı́stica.
En términos simples, la genética era discreta y la evolución asumı́a continuidad, la una trabaja con muestras pequeñas y la otra con muestras grandes, estas diferencias en términos estadı́siticos enmarcan el trasfondo conceptual de la controversia Pearson-Fisher. Estos debates se resuelven a favor de la ciencia, las distintas hipótesis logran coexistir, se enriquece el acervo de conocimientos, se avanza en la diferencia bajo el mismo gran techo disciplinar. La parte anecdótica enriquece la leyenda, muestra facetas humanas de los genios, las pequeñeces al lado de las grandezas; y nos ayuda a recordar que la forma neutral del conocimiento avanza entre lo conflictual humano. Una medida de la vitalidad de una ciencia, es la importancia de sus debates, de sus contradicciones irresolubles según los actores; ası́ comienza la estadı́stica y continúa hoy su muestra de vitalidad en los debates entre bayesianos y frecuentistas, no sin mencionar los analistas de datos que no aceptarı́an ninguna de las casillas anteriores.
Retomando las coordenadas de los orı́genes mencionemos algunos hechos de importancia siguiendo la figura 2. Pearson y Galton fundaron en 1901 Biometrika, revista cimera de la nueva disciplina y donde Fisher publicó en 1915 su artı́culo sobre la distribución del coeficiente de correlación; fue su único artı́culo en dicha revista. A la muerte de Galton se estableció en el University College Londres la Galton Chair de Eugenesia, cátedra que pasó a ocupar Pearson renunciando a la de matemáticas aplicadas y mecánica que regentaba desde 1884. Al posesionarse Pearson de su cátedra fundó un nuevo departamento, el DEPARTAMENTO DE ESTADÍSTICA APLICADA, el primero en la disciplina, 1911 su año de inicio. Fisher publicó su primer artı́culo estadı́stico en
En 1933 Pearson renuncia y su departamento se divide, a Fisher se le concedió la Galton Chair como director del Departamento de Eugenesia y Egon S. Pearson, hijo de Karl, fue nombrado director del Departamento de Estadı́stica Aplicada, en pisos diferentes del mismo edificio. Neyman fue contratado por Egon en 1934 y trabajaron juntos hasta 1938 cuando Neyman viajó a Berkeley. La sociedad Neyman-Pearson desarrolló el punto de vista Pearsoniano hacia una teorı́a de decisiones en contraposición a la visión de Fisher más de análisis de datos. Esto fomentó la controversia Pearson-Fisher de importantes consecuencias en el mundo estadı́stico.
Después de la segunda guerra mundial Fisher trabajó como profesor de genética en Cambridge hasta 1957 cuando se retiró. Luego viajó a Australia en 1959 a trabajar como investigador honorario en el CSIRO Commonwealth Scientific and Industrial Research Organization en Adelaide, donde falleció el 29 de julio de 1962. Paradójicamente, a quien consideramos el gran genio de la estadı́stica, nunca fue profesor de estadı́stica.
En 1933 Snedecor funda el Laboratorio Estadı́stico en Iowa State University en los Estados Unidos y establece allı́, también, el primer Departamento de Estadı́stica en América. Fisher visitó a Iowa State University en los veranos de 1931 y 1936 por invitación de Snedecor, contactos que tuvieron gran influencia en el desarrollo de la estadı́stica. Mahalanobis, también en 1933, funda Sankhya revista de gran influencia en la comunidad estadı́stica, editada por el Indian Statistical Institute, Calcuta. Fisher fue invitado por Mahalanobis a la India, donde difundió sus ideas durante seis semanas entre 1937-1938.
En 1935, se funda el Institute of Mathematical Statistics IMS en Estados Unidos, otro de los puntos de referencia obligatorios de nuestra disciplina y responsable de otro de los ı́conos, la revista Annals of Mathematical Statistics. Fisher fue miembro de su primer comité editorial. Recientemente el Annals fue reemplazado por dos publicaciones: el Annals of Probability y el Annals of Statistics. Según Gifi (1990) esto fue una consecuencia del debate de los analistas de datos, Tukey (1962) de un lado, Benzécri (1973) de otro y de la confrontación de la escuela norteamericana responsable del Annals e inglesa relativa a la estadı́stica matemática. Estos debates aclaran la autonomı́a disciplinaria de la estadı́stica con métodos completamente diferentes y donde la demostración matemática no es estándar único de validez, sino también su relación con la experiencia que constantemente retroalimenta el desarrollo metodológico aplicado de la estadı́stica. Esa relación de los cientı́ficos experimentales con los datos es lo que potencia la creación de la estadı́stica y la mantiene.
Al respecto Fisher afirmaba ver Box (1997) que la estadı́stica matemática en sı́ misma debe su origen y continuo crecimiento a su confrontación con los datos cientı́ficos más que a problemas teóricos
Fisher y Student
William Sealy Gosset (1876-1937), quien escribió con el seudónimo de Student, famoso por su distribución t, la que desarrolló como respuesta a problemas prácticos de variedades de cebada, en su trabajo en la cervecerı́a Guinness, es un ejemplo de que los grandes desarrollos de la estadı́stica han surgido, generalmente, como respuesta a necesidades prácticas.
Lo que se llamarı́a la t de Student aparece por primera vez en un artı́culo de Gosset en 1908. El trabajo era con muestras pequeñas, la deducción teórica de la distribución no estaba completa, pero sı́ verificada numéricamente la curva teórica contra la muestral. Esto último lo hace precursor de la simulación. Fisher en 1912 formalizó la prueba de la distribución “t” y mantuvo una buena relación con Gosset quien no tenı́a una gran formación matemática ver Pearson(1968), pero compartı́a con Fisher el interés por los datos experimentales, tema que K. Pearson, quien habı́a sido profesor de Gosset, no aceptaba y con todo su poder académico combatı́a. Inspirado por Gosset, Fisher desarrolló entre 1922 y 1925 la teorı́a de muestras pequeñas bajo normalidad que con el nombre de Análisis de Varianza y Covarianza tuvo gran impacto en la teorı́a y la práctica de la estadı́stica. Fisher trabajó en Rothamsted, Inglaterra, centro experimental agrı́cola, de 1919 a 1933, donde también desarrolló el diseño de experimentos
Egon Pearson, ya casi octogenario, en artı́culo sobre el impacto del trabajo de Fisher, Pearson (1974), da un clarificador resumen de las diferencias conceptuales entre su padre Karl Pearson y Fisher. Comenta que entre 1890 y 1920, Galton y K. Pearson establecen la escuela biométrica, bajo la influencia de Darwin, lo cual los lleva a trabajar con muestras grandes, pues su interés es la reproducción de las especies (humanos, animales, plantas), libremente en su medio natural. Esta teorı́a de muestras grandes no necesitaba estudiar en detalle la lógica de la inferencia estadı́stica para interpretar sus resultados. Mientras tanto, Fisher estaba interesado en datos experimentales, lo cual lo obligaba a trabajar con muestras pequeñas que exigı́an un examen cuidadoso de las bases de la inferencia cientı́fica. Dice textualmente Pearson hijo, Lo que fue y será importante para mı́ es cómo Fisher, en los 1920..., hizo que los estadı́sticos reflexionáramos acerca de las ideas fundamentales
Egon reconoce también la influencia de Fisher en Neyman-Pearson, dando argumentos para reafirmar la genialidad de Fisher que lo erige como la figura dominante de la estadı́stica del siglo XX.
Fisher y la χ2 de Pearson
Karl Pearson en 1900 desarrolló el estadı́stico χ2 y encontró su distribución asintótica cuando los parámetros son conocidos, pero erróneamente afirmó que al tener los parámetros desconocidos y reemplazándolos por sus estimativos, la distribución asintótica era la misma. Fisher, en su gran trabajo seminal de 1922, citado en la figura 1, introduce la noción de grados de libertad y su teorı́a de estimación por máxima verosimilitud Pearson usaba el método de momentos, lo que le permite encontrar la distribución asintótica correcta de la χ2 con parámetros desconocidos. K. Pearson nunca aceptó la teorı́a de la máxima verosimilitud y consecuentemente jamás corrigió el error de su resultado.
Menciono esta discusión por su importancia histórica y como prólogo a la discusión de los fundamentos de la estadı́stica que Fisher introdujo en su ya mencionado artı́culo de 1922. Es del caso anotar que Fisher publicó cerca de 300 artı́culos cientı́ficos y seis libros que abarcan literalmente todos los temas estadı́sticos ver Rao(1992) y Savage (1976)
Fundamentos de la Estadı́stica Teórica
La influencia de Fisher en el desarrollo de la estadı́stica como ciencia es definitiva. Su artı́culo de 1922 marca época y permite que la disciplina establezca sus sólidos fundamentos y reflexione sobre su objeto de estudio y sus metodologı́as. Sus ideas desataron y desatan controversias que han enriquecido y solidificado la arquitectura del bello edificio estadı́stico.
Para Fisher ver Hald (1998) pág. 713 el objeto de los métodos estadı́sticos es la reducción de los datos, lo cual se logra al considerar los datos disponibles como una muestra aleatoria de una población hipotética infinita, cuya distribución con respecto a las caracterı́sticas bajo discusión es especificada por relativamente pocos parámetros. Establece tres tipos de problemas
Especificación: Sobre la escogencia de la distribución de probabilidad para la población
Estimación: Cómo calcular los estadı́sticos de la muestra aleatoria para representar los parámetros de la población teórica
Distribución: Sobre distribuciones muestrales de los estadı́sticos
También establece tres criterios de estimación Consistencia Eficiencia Suficiencia
Hald (1998) afirma que los tres tipos de problemas y los tres criterios de estimación dan el marco para un programa de investigación que dominó la estadı́stica teórica durante todo el siglo. Otro aspecto importante de su trabajo es la creación de todo un nuevo vocabulario técnico. Los siguientes términos fueron acuñados por Fisher: parámetro, estadı́stico, varianza, verosimilitud, score ideal, ancilaridad, información, hipótesis nula, test de significancia, nivel de significancia, punto crı́tico, aleatorización, diseños factoriales, interacción, confusión. Un punto clave de estos avances es la clara distinción expresada por Fisher entre valores muestrales y poblacionales, que se reflejó en el aspecto notacional al utilizar las letras griegas para la población y latinas para la muestra
Máxima Verosimilitud
El método de máxima verosimilitud es el método de estimación introducido por Fisher(1922), que intuitivamente pretende obtener el estimativo de un parámetro seleccionado aquél que maximiza la probabilidad de observar los datos que realmente fueron observados. Este es un gran ejemplo de la lógica reduccionista de Fisher basada en los datos y con un gran sentido práctico en cuanto a su facilidad de utilización.
Fisher siempre prefirió resultados exactos en muestras pequeñas pero paradójicamente las propiedades optimales de los estimadores máximo verosı́miles son asintóticas. En 1925 Fisher probó que los estimadores eran los mejores asintóticamente normales bajo ciertas condiciones de regularidad
es el número de información de Fisher, que representa la mı́nima varianza y tal que N I(θ) recoge la información acerca de θ contenida en la muestra. Estas ideas intuitivas fáciles de aplicar y además las mejores en el sentido mencionado, sin tener que apelar a razonamientos Bayesianos ni a desarrollos matemáticos artificiosos, es el resultado culminante de la filosofı́a de pensamiento Fisheriano.
Los logros de Fisher generaron un gran interés en resultados optimales. El producto más espectacular de ese entusiasmo fue el lema de Neyman-Pearson para pruebas de hipótesis óptimas, seguido por la teorı́a de intervalos de confianza de Neyman. A pesar de que Fisher nunca aprobó las ideas anteriores, filosóficamente las podemos ubicar dentro de lo Fisheriano.
Bajo la influencia de las ideas de Neyman, Abraham Wald (1950) coloca la estadı́stica dentro del campo de la teorı́a de decisiones. Ese afán de lo óptimo lleva al frecuentismo según Neyman-Wald a una teorı́a rigurosa con un enorme atractivo matemático, muy lejos de la lógica inferencial de Fisher que pretendı́a aprender de los datos. Al respecto Fisher (1956) decı́a: todavı́a es cierto que las Ciencias Naturales pueden ser conducidas exitosamente solo por pensadores responsables e independientes, que concentran sus mentes e imaginación a la interpretación detallada de observaciones verificables. La idea de que esa responsabilidad puede ser delegada a un gran computador programado con funciones de decisión, pertenece a la fantası́a, muy lejana de la investigación cientı́fica
Fisher frente a la controversia Bayesianos vs. Frecuentistas
El punto de vista frecuentista de Neyman-Wald, con pretensiones estructuralistas y universales en la búsqueda del óptimo generó su propia contrarreforma, el Bayesianismo. Estos nuevos Bayesianos enfatizan las probabilidades subjetivas y las decisiones de tipo personal existen tambien los objetivistas y los empı́ricos que tienen todos en común la escogencia de la probabilidad apriori. Ası́ llegamos al comienzo del siglo XXI con esta controversia Bayesianos vs Frecuentistas como prueba de vitalidad de nuestra disciplina, polémicas generadoras de nuevos conocimientos
En la figura tomada de Efron (1998) vemos a Fisher en comparación con los Frecuentistas y Bayesianos. Efron (1998) interpretando la gráfica nos dice que da la impresión de que la estadı́stica Fisheriana concilia entre las otras dos escuelas pero en un punto crucial no transa: en su facilidad de uso. Si algo va a reemplazar a la mirada fisheriana en el siglo XXI deberá ser una metodologı́a que sea fácil de aplicar en el dı́a a dı́a. El pensamiento de Fisher se caracterizaba por esa naturalidad computacionalmente algorı́tmica de sus metodologı́as, siempre expresable en términos prácticos. En esta dirección se piensa que la influencia de Fisher perdurará
Fisher y el futuro de la estadı́stica
Este intento predictivo lo hago basado en un artı́culo de Bradley Efron (1998), uno de los más grandes estadı́sticos de hoy, creador del boostrap. La figura tomada de Efron (1998) presenta los principales temas actuales de investigación en función de la influencia de los tres polos: Bayesiano, Frecuentista y Fisheriano.
Si bien la mayorı́a de las ideas de Fisher no se usan hoy, su influencia expresada a través de su pensamiento como se trató en la sección anterior, se espera que perviva y contribuya como elemento unificador en la estadı́stica del siglo XXI. El artı́culo de Efron viene acompañado de comentarios de un selecto grupo de estadı́sticos. De ellos vale la pena anotar el de Hinkeley quien llama la atención sobre la ausencia de la escuela de análisis de datos de Tukey. Efron replica En su forma más pura esta lı́nea de trabajo es estadı́stica sin teorı́a de probabilidad y como tal no la puedo colocar en ninguna parte del triángulo estadı́stico Pienso que observaciones y respuestas como la anterior nos invitan a intentar nuestra propia representación gráfica, a reflexionar sobre nuestro quehacer en el contexto de la dinámica contemporánea de la estadı́stica, de su gran diversidad de intereses y aplicaciones que constituyen nuestra actual comunidad, ya centenaria.
Comentarios Finales
Kruskal (1980) en un comentario al libro sobre Fisher, de su hija Joan Fisher Box ver Box 1998 cita a otro genio creativo, latinoamericano esta vez, Jorge Luis Borges, para ilustrar la complejidad de la obra de Fisher. Yo no puedo resistir la tentación de citarlo en referencia al triángulo de la figura donde en un claro juego de espejos borgiano la estadı́stica en ese calidoscopio toma múltiples y agradables formas según la posición que se tome sin perder su inasible unidad Tan compleja es la realidad, tan fragmentaria y tan simplificada la historia, que un observador omnisciente podrı́a redactar un número indefinido y casi infinito,de biografı́as de un hombre, que destacaran hechos independientes y de las que tendrı́amos que leer muchas antes de comprender que el protagonista es el mismo Borges 1960).
Referencias
Benzécri J P.Analyse des Donées.(1973).Dunod.Paris.
Borges J L.Sobre el Vathek de William Beckford, Otras Inquisiciones.(1960).Alianza Editorial.
Box J F,R A Fisher.The life of a Scientest.(1978).Wiley and Sons.New York.
Box J F,R A Fisher.Leading Personalities in Statistical Sciences.(1997).John Wiley and Sons.New York.
Efron B,R A Fisher.In the 21st Century Statistical Science.(1998)...
Fisher R A.On the mathematical foundations of the theoretical statistics.(1922).Philosophical Transactions of the Royal Society.London.
Fisher R A.Statistical methods and Scientific inference.(1981).Oliver and Boyd.
Folks J L.Ideas of Statistics.(1956).Wiley and Sons.
Gifi A.Nonlinear Multivariate Analysis.(1990).Wiley.
Hald A.A History of Mathematical Statistics from 1750 to 1930.(1998).Wiley and Sons.
Kruskal W.The Significance of Fisher: A Review of R A Fisher: The life of a Scientist.(1980).Journal of the American Statistical Association.
Pearson E S.Studies in the History of Probability and statistics.(1968).Biometrika.
Pearson E S.Memories on the impact of Fisher’s work in the 1920’s.(1974).International Statistical Review.
Rao C R,R A Fisher.The Founder of Modern Statistics.(1992).Statistical Science.
Savage L J H.On rereading R A Fisher.(1976).Annals of Statistics.
Tukey J W.The future of data analysis.(1962).Annals of Mathematical Statistics.
Wald A.Statistical Decision Fuctions.(1950).Wiley.