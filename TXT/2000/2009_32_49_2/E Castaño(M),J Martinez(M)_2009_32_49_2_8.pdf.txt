Tendencia aleatoria o determinística: una nueva prueba basada en la teoría tradicional
Universidad Nacional de Colombia;Universidad de Antioquia
Resumen
En la literatura de series de tiempo se encuentran diferentes procedimientos para probar la hipótesis sobre el origen aleatorio o determinístico de la componente de tendencia de una serie. La mayoría de ellos se basan en establecer la existencia de una raíz unitaria ya sea en el polinomio autorregresivo o en el polinomio de medias móviles. El desarrollo de las pruebas para verificar estas hipótesis se basa fundamentalmente en el empleo de la teoría no estándar asociada a procesos de Wiener. Este artículo presenta una nueva prueba que hace uso de las funciones de autocorrelación (ACF) de los residuales de los modelos bajo la hipótesis nula, y bajo la hipótesis alterna. A partir de la teoría tradicional, con el supuesto que at es un ruido blanco gaussiano, se obtiene por simulación la distribución nula del estadístico de prueba para muestras finitas y se deriva una aproximación asintótica. Para el caso en el cual at es un proceso autocorrelacionado, se generaliza la prueba y se obtiene la distribución nula asintótica del estadístico de prueba. Los resultados muestran que la prueba asintótica tiene, en general, una potencia alta y mayor que la potencia de la prueba de Dickey y Fuller Aumentada (ADF), particularmente cuando una raíz del polinomio AR o MA está cerca de 1. La prueba asintótica propuesta también presenta menos distorsiones en el tamaño que la prueba ADF.
Palabras clave: tendencia aleatoria, tendencia determinística, función de autocorrelación, modelo ARMA, raíz unitaria, prueba de Dickey y Fuller aumentada.
Introducción
    Uno de los problemas de interés en medición económica tiene que ver con la
determinación del tipo de tendencia presente en una serie de tiempo: se debe decidir
si una tendencia aleatoria o una determinística está presente en una serie de tiempo
dada. Esta distinción es importante puesto que la naturaleza de la permanencia
de los choques macroeconómicos sobre la serie depende del tipo de tendencia que
posea: mientras que en una serie con tendencia determinística el choque solamente
tiene una permanencia temporal, en una con tendencia aleatoria dichos impactos
son de naturaleza permanente. En la literatura de series de tiempo se encuentran
diferentes enfoques para contrastar esta hipótesis. Algunos de ellos son:

   i) Contraste de raíz unitaria en el polinomio autorregresivo.

  ii) Contraste de raíz unitaria en el polinomio de medias móviles.

 iii) Contraste sobre la variabilidad de la componente de tendencia en series de
      tiempo estructurales o de componentes no observables.

 iv) Contraste basado en errores de predicción.

A continuación se describen cada uno de los casos mencionados.

Caso 1. Nelson & Plosser (1982) proporcionan un contraste de la hipótesis

            H0 : Zt = β0 + Zt−1 + at contra H1 : Zt = β0 + β1 t + at

                                       Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                              303

    El procedimiento se basa en probar la existencia de una raíz unitaria en el
polinomio autorregresivo del proceso. Su contraste usa el modelo

                                  Z t = β0 + β1 t + a t
                                  at = ρat−1 + ut

donde ut es un proceso de ruido blanco N (0, σu2 ). El modelo puede escribirse como

                   Zt = β0 + β1 t + ρ[Zt−1 − β0 − β1 (t − 1)] + ut

o, en forma reducida,
                              Zt = α + δt + ρZt−1 + ut

   Restando Zt−1 a ambos lados de la ecuación se tiene

                             ∆Zt = α + δt + πZt−1 + ut

donde ∆Zt = Zt − Zt−1 y π = (ρ − 1).

    Con este modelo, la hipótesis H0 se puede expresar como H00 : π = 0 y δ =
0, la cual puede analizarse usando el contraste Dickey & Fuller (1979) o, si ut
está autocorrelacionado, el de Dickey y Fuller Aumentado. Otros contrastes de
raíces unitarias, como el de Phillips & Perron (1988), Sargan & Bhargava (1983),
Cochrane (1988), Hall (1989), Choi (1992), Elliot et al. (1996), Ng & Perron (1996)
pueden usarse para contrastar H00 .
    Sin embargo, para valores de ρ cercanos a 1 (π cercanos a cero) y muestras
pequeñas, Schwert (1989) y DeJong et al. (1992a) señalan que la potencia del
contraste es baja y aun menor en presencia de correlaciones entre las ut . DeJong
et al. (1992b) argumentan que, en general, las pruebas de raíces unitarias tienen
baja potencia contra la alternativa de tendencia determinística y concluyen la
necesidad de desarrollar nuevas pruebas que tengan potencias mayores.
    Cochrane (1991) señala que cualquier contraste de la hipótesis H0 : θ = θ0
tiene una baja potencia contra la hipótesis H1 : θ = θ0 − ε, en muestras pequeñas
y valores arbitrariamente bajos de ε, pero que en muchos casos la diferencia entre
θ y θ0 − ε puede no ser importante. Sin embargo, en el caso de una raíz unitaria,
la baja potencia tiene una importancia particular debido a la discontinuidad de la
teoría de la distribución en la raíz unitaria y sus implicaciones en la interpretación
del proceso bajo estudio.
Caso 2. Considere el modelo
                                   Zt = µt + et
                                  ∆et = (1 − θB)at

donde at es un proceso estacionario, µt es una componente determinística y B
es el operador de retraso, BXt = Xt−1 . Si θ = 1, es decir la componente MA
tiene una raíz unitaria, el modelo es estrictamente no invertible. En este caso (por
sustitución repetida),
                                 e t = at + e 0 − a0

                                      Revista Colombiana de Estadística 32 (2009) 301–331

304                                                     Elkin Castaño & Jorge Martínez

siendo et un proceso estacionario, por tanto el proceso Zt tiene tendencia deter-
minística. Si |θ| < 1, el proceso es invertible y et tiene una raíz unitaria lo que
implica que el proceso Zt tiene tendencia aleatoria. Por tanto, el contraste de la
hipótesis H0 : θ = 1 contra la hipótesis H1 : |θ| < 1 es equivalente al contraste de
la hipótesis H0 : Zt tiene tendencia determinística contra la hipótesis H1 : Zt tiene
tendencia aleatoria. Para contrastar esta hipótesis algunos autores, como Arellano
& Pantula (1995), Saikkonen & Luukkonen (1993), Tsay (1993), Tanaka (1990),
Choi & Yu (1997), proponen distintos contrastes sobre la existencia de una raíz
unitaria en la componente MA.

Caso 3. Enfoque basado en el análisis de modelo de componentes no observables
o modelos de series de tiempo estructurales. Esta aproximación está descrita en
Harvey (1989), Jones (1993), Kitagawa & Gersch (1996), West & Harrison (1989),
Young (1984), Shephard & Harvey (1990) y Shephard (1993). El modelo de series
de tiempo más simple para el análisis de la tendencia es el modelo que considera
una tendencia aleatoria con un término irregular aleatorio de la forma

                        yt = µt + εt
                        µt = µt−1 + ηt ,      t = 1, 2, . . . , n,
                                                                               
donde εt y ηt son ruidos blancos independientes distribuidos N 0, σε2 y N 0, ση2 ,
respectivamente. Este modelo se denomina modelo de nivel local, la tendencia
sigue una caminata aleatoria. Cuando ση2 es cero, el nivel es constante. Un modelo
más general, que permite que la componente de tendencia tenga una pendiente
aleatoria, es el modelo de tendencia local

                     yt = µt + εt
                    µt = µt−1 + βt−1 + ηt ,        t = 1, 2, . . . , n,
                    βt = βt−1 + ωt
                                                                                 
siendo εt , ηt y ωt ruidos blancos mutuamente distribuidos N 0, σε2 , N 0, ση2 y
         
N 0, σω2 , respectivamente. Si ση2 y σω2 son iguales a cero, la tendencia es determi-
nística, es decir,
                                    µt = β0 + βt

  Cuando solamente σω2 = 0, la tendencia se reduce a una caminata aleatoria
más deriva,
                           µt = µt−1 + β + ηt

   La decisión sobre el tipo de tendencia se basa en el contraste de la hipótesis
que considera a ση2 y σω2 iguales a cero (Harvey (1989, 2000)).

Caso 4. Recientemente, Flores de Frutos & Jerez (2002) proponen una prueba
para determinar si un modelo ARIMA(p, 1, q) es invertible, la cual se basa en
comparar los pronósticos de un modelo probablemente sobrediferenciado con los
obtenidos por el correspondiente modelo sin diferenciar. Debido a que la no in-
vertibilidad del modelo está asociada a la sobrediferenciación, la prueba permite

                                     Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                              305

concluir que si el modelo es invertible (la diferenciación es adecuada) entonces exis-
tirá una tendencia aleatoria en la serie; si el modelo no resulta invertible (existe
sobrediferenciación), la tendencia será determinística. El estadístico del contraste
tiene una distribución estándar χ2 (1) bajo la hipótesis nula de que el proceso sea
invertible.
    El plan del documento es el siguiente. La sección 2 presenta el procedimiento
empleado para la prueba de la hipótesis nula H0 : Zt = β0 + Zt−1 + at contra la
hipótesis alternativa H1 : Zt = β0 + β1 t + at , cuando at es ruido blanco gaussiano,
basado en la información contenida en la ACF de los residuales del modelo bajo
H0 y en la ACF de los residuales del modelo bajo H1 . Se obtienen la distribución
simulada y la distribución asintótica del estadístico de prueba bajo H0 , y se inves-
tigan las propiedades del contraste. En la sección 3 se generaliza la prueba al caso
donde at es un proceso autocorrelacionado normal y se estudian su potencia y ta-
maño. En la sección 4 se comparan la potencia y el tamaño de la prueba propuesta
con la prueba de Dickey y Fuller Aumentada. La sección 5 presenta una aplicación
del procedimiento con datos reales. Finalmente, se exponen las conclusiones.


2. Estadístico de la prueba cuando at es un proceso
   de ruido blanco normal
Demostración. Bajo H0 , por construcción T A estará cercano a cero. Entonces,
si T M IN = T A valores pequeños de T M IN conducirán al no rechazo de H0 .
Por tanto, si T M IN (α, n, K) es el percentil α-superior de la distribución nula de
T M IN , no rechace H0 a un nivel de significancia α∗ si T M IN = T A y T M IN ≤
T M IN (α, n, K).
   Rechace H0 si T M IN = T D o T M IN > T M IN (α, n, K), donde

 α∗ = P [T M IN = T D       o T M IN > T M IN (α, K, n)|H0 ]
     = 1 − P [T M IN ≤ T M IN (α, K, n)|T M IN = T A, H0 ]P [T M IN = T A|H0 ]
     = 1 − (1 − α)P [T M IN = T A|H0 ]



2.1. La distribución simulada de T MIN
    La distribución nula para T M IN puede ser derivada por simulación. Los expe-
rimentos de simulación Monte Carlo presentados en este documento, fueron reali-
zados empleando el paquete estadístico SCA (SCA-Corp. (2001), versión VI. 3a).
Para la derivación de la distribución, es importante observar que ella es invariante
al valor de los parámetros β0 y σa2 .
    El modelo simulado fue Zt = 2 + Zt−1 + at , donde at ∼ N (0, 1). Los valo-
res iniciales de las series simuladas son aleatorios. La tabla 1 presenta los per-
centiles superiores de la distribución de T M IN , para niveles de significancia
de α = 0.01, 0.025, 0.05, valores de K = 5, 10, 15 y diferentes tamaños mues-
trales. Se usaron 100000 simulaciones para cada n, K y α. Los resultados se

                                      Revista Colombiana de Estadística 32 (2009) 301–331

306                                                       Elkin Castaño & Jorge Martínez

suavizaron usando la técnica de suavizamiento denominada Lowess, descrita por
Cleveland(1993, 1994).
    En la tabla se incluyen los valores de la estadística para series de tamaño
pequeño con el fin de prever el uso inadecuado de la prueba cuando este sea
el caso. El lector debe considerar que en esta situación las estimaciones de los
coeficientes de autocorrelación deben modificarse teniendo en cuenta por ejemplo
las sugeridos por Fuller (1976) o las modificaciones de los niveles de significancia
propuestas por Pankratz (1983).

 Tabla 1: Percentiles superiores suavizados para la distribución de T M IN bajo H0 .
                       K=5                    K = 10                  K = 15
          n     0.05   0.025    0.01   0.05    0.025    0.01   0.05    0.025   0.01
           30   9.2    10.8     13.2   14.8     17.0    20.2   18.7     21.3   24.7
           40   9.4    11.4     13.8   15.8     17.8    21.5   20.1     24.0   27.4
           50   9.6    12.1     14.3   16.5     18.6    22.5   21.4     25.1   29.5
           60   9.8    12.2     14.9   17.0     19.5    23.1   22.8     25.9   30.6
          100   10.7   12.5     14.9   17.6     20.0    23.2   23.4     26.9   30.7
          150   10.8   12.6     15.0   17.8     20.1    23.3   23.9     27.2   31.0
          200   10.9   12.6     15.0   18.0     20.3    23.4   24.4     27.3   31.1
          250   10.9   12.7     15.0   18.1     20.4    23.4   24.6     27.4   31.0
          300   11.0   12.7     15.0   18.1     20.4    23.4   24.7     27.4   31.0
          350   11.0   12.8     15.1   18.1     20.4    23.4   24.7     27.5   31.0
          400   11.0   12.8     15.1   18.2     20.4    23.4   24.8     27.5   30.9
          450   11.0   12.8     15.1   18.2     20.4    23.3   24.8     27.5   30.9
          500   11.0   12.8     15.1   18.2     20.4    23.3   24.9     27.5   30.8
         1000   11.1   12.8     15.1   18.2     20.4    23.3   24.9     27.5   30.7
         5000   11.1   12.9     15.1   18.2     20.3    23.2   25.0     27.5   30.7




2.1.1. Obtención del nivel de significancia de la prueba

    Dada la regla de decisión de la prueba, su verdadero nivel de significancia es
α∗ = 1 − (1 − α)P [T M IN = T A |H0 ], donde P [T M IN = T A] se calculó usando
las 100000 simulaciones realizadas para el cálculo de la distribución exacta de
T M IN bajo H0 , para los casos en los cuales T M IN = T A. La tabla 2 presenta
la probabilidad de que T M IN = T A, para diferentes valores de n y de K.

                        Tabla 2: P [T M IN = T A] bajo H0 .
                           n       K=5        K = 10    K = 15
                           30     0.95433     0.95552   0.96044
                           40     0.98984     0.98858   0.98826
                           50     0.99816     0.99732   0.99727
                           60     0.99972     0.99961   0.99931
                          100     1.00000     1.00000   1.00000
                          150     1.00000     1.00000   1.00000
                          200     1.00000     1.00000   1.00000
                          250     1.00000     1.00000   1.00000



                                       Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                              307

    Los resultados muestran que bajo H0 hay una rápida convergencia de la P [T M IN =
T A] a 1, lo que indica que la distribución de T M IN converge rápidamente a la
distribución marginal de T A a medida que n crece.
    Usando la tabla 2 podemos encontrar el verdadero nivel de significancia de la
prueba para cada nivel α en la distribución de T M IN . Por ejemplo, para n = 30,
K = 5 y α = 0.05, el verdadero nivel de significancia de la prueba es α∗ = 1 −
(0.95)(0.95433) = 0.093. La tabla 3 presenta los verdaderos niveles de significancia
para los diferentes valores considerados de n, K y α.

        Tabla 3: Verdaderos niveles de significancia α∗ de la prueba T M IN .
                 K=5                        K = 10                     K = 15
   n     0.05     0.025    0.01     0.05     0.025    0.01     0.05     0.025    0.01
   30   0.0934   0.0695   0.0552   0.0923   0.0684   0.0540   0.0876   0.0636   0.0492
   40   0.0597   0.0349   0.0201   0.0608   0.0361   0.0213   0.0612   0.0364   0.0216
   50   0.0517   0.0268   0.0118   0.0525   0.0276   0.0127   0.0526   0.0277   0.0127
   60   0.0503   0.0253   0.0103   0.0504   0.0254   0.0104   0.0507   0.0257   0.0107
  100   0.0500   0.0250   0.0100   0.0500   0.0250   0.0100   0.0500   0.0250   0.0100
  150   0.0500   0.0250   0.0100   0.0500   0.0250   0.0100   0.0500   0.0250   0.0100
  200   0.0500   0.0250   0.0100   0.0500   0.0250   0.0100   0.0500   0.0250   0.0100
  250   0.0500   0.0250   0.0100   0.0500   0.0250   0.0100   0.0500   0.0250   0.0100


    Como era de esperarse, para tamaños muestrales mayores que 60, los niveles
de significancia nominales son iguales a los verdaderos. Con tamaños muestra-
les pequeños, entre 30 y 40, para obtener un nivel de significancia verdadero α∗
alrededor de 0.05 deberíamos usar un α aproximado de 0.01.

Ejemplo 1. Aplicación de la prueba a datos simulados. Se simularon n = 60
datos del modelo Zt = β0 + Zt−1 + at , con β0 = 1.5 y at ∼ N (0, 1). Para aplicar
el procedimiento de la prueba, se obtuvo T A = 4.267, T D = 382.746, entonces
T M IN = mı́n{T A, T D} = 4.267. Para K = 5 y un nivel α = 0.025 en la Tabla
1 se tiene que el valor crítico es T M IN (0.025, 5, 60) = 12.2. Como T M IN = T A
y T M IN < 12.2, no se rechaza H0 , es decir, se concluye correctamente que los
datos son generados por un proceso de caminata aleatoria con deriva, a un nivel
de significancia α∗ = 0.0253 (tabla 3).


2.2. Potencia de la prueba T MIN
    La tabla 4 presenta la potencia de la prueba para los diferentes valores con-
siderados de n, K y α. Se usaron 20000 simulaciones. El modelo simulado fue
Zt = 2 + 0.7t + at , donde at ∼ N (0, 1).
   De la tabla 4 observamos lo siguiente:

   • La potencia de la prueba depende del valor de K. Para la elección del valor de
     K es importante tener en cuenta que la prueba está diseñada para datos no
     estacionales. Para datos de baja frecuencia, los resultados obtenidos apoyan
     la sugerencia de Ljung (1986) de escoger a K relativamente pequeño, por

                                      Revista Colombiana de Estadística 32 (2009) 301–331

308                                                            Elkin Castaño & Jorge Martínez

                          Tabla 4: Potencia de la prueba T M IN .
                     K=5                           K = 10                    K = 15
        n     0.05   0.025     0.01         0.05    0.025    0.01   0.05      0.025    0.01
        30   0.946   0.944     0.943       0.930    0.928   0.926   0.925     0.922   0.920
        40   0.972   0.970     0.968       0.961    0.959   0.958   0.954     0.952   0.950
        50   0.987   0.985     0.984       0.979    0.977   0.976   0.974     0.972   0.971
        60   0.994   0.993     0.992       0.988    0.986   0.985   0.984     0.982   0.981
       100   1.000   1.000     0.999       0.999    0.999   0.998   0.998     0.998   0.997
       150   1.000   1.000     1.000       1.000    1.000   1.000   1.000     1.000   1.000
       200   1.000   1.000     1.000       1.000    1.000   1.000   1.000     1.000   1.000
       250   1.000   1.000     1.000       1.000    1.000   1.000   1.000     1.000   1.000



      ejemplo alrededor de K = 5. Con datos de alta frecuencia no estacionales,
      la elección de K depende de la frecuencia de medición.
   • Para cada valor de K y cada valor de α, la potencia de la prueba tiende a 1
     a medida que n crece.
   • La prueba tiene una potencia muy alta aun en muestras pequeñas.
   • Si n < 40, la potencia que aparece en la tabla no es exacta, puesto que el
     verdadero nivel de significancia usado es α∗ y no α. Sin embargo, si emplea-
     mos α = 0.01 para obtener un nivel α∗ ≈ 0.05, la verdadera potencia está
     alrededor de 0.943 contra la nominal de 0.946.
   • Con valores de n mayores que 100, la prueba alcanza la máxima potencia de
     1.


2.3. Distribución asintótica del estadístico T MIN
Proposición 1. Bajo H0 y si at es un proceso de ruido blanco gaussiano,
                                       d
                           T M IN → χ2 (K), cuando n → ∞

Demostración. Bajo H0 y cuando n → ∞, se cumple que:
                      p
  i) T A − T M IN → 0
  ii) T A es el estadístico de Box-Pierce, para el cual, agregando el supuesto de
                                                                   d
      normalidad en at , Box & Pierce (1970) probaron que T A → χ2 (K). Por
                      d
      tanto T M IN → χ2 (K).
Observación 1. Para una mejor aproximación a la distribución chi-cuadrado,
se puede emplear la modificación de Ljung & Box (1978) del estadístico T M IN ,
dada por T M IN ∗ = mı́n{T A∗ , T D∗ }, donde
                                             K
                                             X               h          i2
                                                                 (0)
                     T A∗ = n(n + 2)                (n − j)−1 ρbba∇Z (j)
                                            j=−K
                                             j6=0


                                            Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                                   309

y
                                          K
                                          X                h        i2
                                                               (j)
                       T D∗ = n(n + 2)            (n − j)−1 ρbbaZ ∗
                                          j=−K
                                           j6=0


2.3.1. Tamaño de la prueba asintótica

   La tabla 5 presenta el tamaño de la prueba para la distribución asintótica
de TMIN con diferentes valores de α, K y n. Se usaron 20.000 simulaciones. El
modelo generador de los datos es Zt = 2 + Zt−1 + at , donde at ∼ N (0, 1).

      Tabla 5: Tamaño de la prueba bajo la distribución asintótica de T M IN .
                      K=5                     K = 10                     K = 15
       n      0.05    0.025    0.01    0.05    0.025     0.01     0.05    0.025    0.01
        30    0.090   0.071   0.060   0.104    0.079     0.063   0.112    0.086   0.068
        40    0.061   0.037   0.022   0.079    0.053     0.035   0.088    0.062   0.040
        50    0.055   0.030   0.015   0.069    0.044     0.025   0.081    0.054   0.032
        60    0.054   0.029   0.014   0.066    0.040     0.023   0.074    0.046   0.026
       100    0.052   0.028   0.012   0.061    0.035     0.017   0.065    0.039   0.020
       150    0.052   0.028   0.012   0.058    0.032     0.014   0.060    0.035   0.018
       200    0.053   0.027   0.011   0.054    0.029     0.013   0.060    0.034   0.016
       250    0.049   0.023   0.010   0.054    0.028     0.014   0.060    0.033   0.015
       300    0.050   0.026   0.011   0.052    0.028     0.012   0.057    0.031   0.014
       350    0.051   0.026   0.011   0.053    0.028     0.012   0.056    0.030   0.014
       400    0.051   0.027   0.012   0.052    0.027     0.012   0.054    0.028   0.012
       450    0.049   0.024   0.010   0.052    0.027     0.011   0.053    0.028   0.012
       500    0.051   0.026   0.010   0.052    0.026     0.010   0.054    0.029   0.013
      1000    0.048   0.025   0.010   0.050    0.025     0.010   0.052    0.027   0.011


    De la tabla 5 se observa que:

    • Para K = 5, los niveles verdaderos están más próximos a los nominales.

    • A medida que K crece, la convergencia de los verdaderos niveles a los nomi-
      nales es más lenta.

    • Para cada K y α, el tamaño de la prueba converge al nivel de significancia
      nominal cuando n → ∞.

2.3.2. Potencia de la prueba asintótica

    La tabla 6 presenta la potencia de la prueba asintótica para diferentes valores
de α, K y n. Se usaron 20000 simulaciones. El proceso generador de los datos es
el modelo Zt = 2 + 0.7t + at , donde at ∼ N (0, 1).
    De la tabla 6 observamos que:

    • La prueba asintótica tiene una potencia mayor que 0.9 aun en muestras
      pequeñas.

                                      Revista Colombiana de Estadística 32 (2009) 301–331

310                                                           Elkin Castaño & Jorge Martínez

                       Tabla 6: Potencia de la prueba asintótica.
                      K=5                         K = 10                   K = 15
        n     0.05    0.025     0.01      0.05     0.025    0.01   0.05     0.025    0.01
        30   0.944    0.941     0.940    0.922     0.918   0.916   0.915    0.911   0.909
        40   0.971    0.970     0.968    0.960     0.957   0.955   0.946    0.943   0.940
        50   0.985    0.983     0.982    0.977     0.974   0.972   0.969    0.966   0.964
        60   0.995    0.993     0.992    0.987     0.984   0.983   0.984    0.982   0.980
       100   1.000    1.000     1.000    0.999     0.999   0.998   0.999    0.998   0.998
       150   1.000    1.000     1.000    1.000     1.000   1.000   1.000    1.000   1.000
       200   1.000    1.000     1.000    1.000     1.000   1.000   1.000    1.000   1.000
       250   1.000    1.000     1.000    1.000     1.000   1.000   1.000    1.000   1.000



   • Se alcanza rápidamente la máxima potencia de 1, independientemente del
     valor de K.

   • Para cada valor de K y α, la potencia de la prueba tiende a 1 cuando n → ∞.


3. Estadístico de la prueba cuando at es un proceso
   gaussiano autocorrelacionado
    La prueba desarrollada en la sección anterior supone que el término de error
del modelo bajo H0 no está autocorrelacionado. Sin embargo, en muchos casos
suele existir autocorrelación que, de no ser tenida en cuenta, puede deteriorar
el comportamiento de la prueba. Para observar los efectos sobre el tamaño de la
prueba cuando la autocorrelación es ignorada, la tabla 7 presenta los tamaños de la
prueba suponiendo que bajo H0 existe una simple estructura MA(1) con parámetro
θ = 0.5 en el ruido del modelo. Para K = 5 se realizaron 20000 simulaciones con
diferentes tamaños muestrales, una distribución N (0, 1) para el término de error
y un valor de β0 = 2 para el modelo Zt = β0 + Zt−1 + (1 − θB)at .

  Tabla 7: Efectos de errores correlacionados sobre el tamaño de la prueba, K = 5.
                 n      0.05     0.025    0.01       n     0.05    0.025   0.01
                 30    0.651     0.631    0.617      250    1        1      1
                 40    0.602     0.544    0.495      300    1        1      1
                 50    0.627     0.529    0.434      350    1        1      1
                 60    0.704     0.582    0.443      400    1        1      1
                100    0.944     0.882    0.763      450    1        1      1
                150    0.998     0.992    0.971      500    1        1      1
                200         1        1    0.998     1000    1        1      1


    Los resultados anteriores muestran que, debido a la presencia de la autocorrela-
ción bajo H0 , el estadístico de la prueba tiende a tomar valores grandes, y a medida
que n crece, debido a la consistencia de la ACFM, la probabilidad de rechazar H0 ,
siendo cierta, crece hacia 1. En conclusión, si la existencia de autocorrelación no
se tiene en cuenta, la prueba rechazará H0 , siendo cierta, con probabilidad mayor
que α a medida que n crece. Como la autocorrelación se presenta frecuentemente

                                          Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                              311

en situaciones reales, a continuación se extiende la prueba al caso en el que el
término de ruido del modelo se genera por un proceso ARMA(p, q) estacionario e
invertible.
   La extensión de la prueba compara la hipótesis H0 : Zt = β0 + Zt−1 + bt con
H1 : Zt = β0 + β1 t + bt , pero a diferencia del caso anterior bt no es un proceso
de ruido blanco, sino que es el proceso ARMA, bt = [θ(B)/φ(B)]at . Si conocemos
dicho proceso, la extensión de la prueba al caso autocorrelacionado es natural. Sin
embargo, este proceso es generalmente desconocido y debe identificarse desde los
datos.
Proposición 2. (Generalización de la prueba) Para contrastar H0 : Zt = β0 +
Zt−1 + bt contra H1 : Zt = β0 + β1 t + bt , donde bt = [θB)/φ(B)]at con at un
proceso de ruido blanco, N (0, σa2 ) y φ(B), θ(B) son los polinomios autorregresivos
y de medias móviles con raíces fuera del círculo unidad y sin raíces comunes, se
puede emplear el siguiente procedimiento:

  1) Defina el estadístico T M IN = mı́n{T A, T D}, donde
                              K h
                              X           i2          K h
                                                      X          i2
                                     (0)                    (1)
                     TA = n       ρbba (j)   y TD = n    ρbba (j)
                              j=1                          j=1

              (0)       (1)
      donde ρbba (j) y ρbba (j) son los coeficientes de autocorrelación de orden j de
      la ACF de los residuales del modelo bajo H0 y H1 , respectivamente.
  2) Bajo H0 y n grande, no rechace H0 a un nivel de significancia aproximado
     α si
                   T M IN = T A y T M IN ≤ χ2 (α, K − p − q)
      y rechace H0 si

           T M IN = T D o T M IN > χ2 (α, K − p − q), con K − p − q > 0

Demostración. Por construcción T A está cercano a cero, bajo H0 . Entonces si
T M IN = T A, valores pequeños de T M IN conducirán al no rechazo de H0 . La
obtención de la distribución nula asintótica de T M IN se basa en la proposición
2. Para una mejor aproximación a la distribución chi-cuadrado se puede emplear
la modificación de Ljung-Box del estadístico T M IN .


3.1. Tamaño de la prueba asintótica para procesos MA(1) y
     AR(1)
    Las tablas 8, 9, 10 y 11 contienen los resultados de la simulación del tamaño de
la prueba para modelos MA(1) y AR(1) con parámetro θ = ±0.2, ± 0.5, ± 0.8, ± 0.95
y φ = ±0.2, ± 0.5, ± 0.8, ± 0.95, valores de α = 0.01, 0.025, 0.05, K = 5 y β0 = 2.
Para cada combinación de α con θ y φ y se realizaron 20.000 simulaciones. El ruido
es un proceso N (0, 1). El modelo generador de los datos es el modelo bajo H0 .
   De las tablas 8, 9, 10 y 11 se observa que:

                                      Revista Colombiana de Estadística 32 (2009) 301–331

312                                                                 Elkin Castaño & Jorge Martínez

           Tabla 8: Tamaño de la prueba para procesos MA(1) con θ > 0.
                θ = 0.2                   θ = 0.5                   θ = 0.8                   θ = 0.95
  n     0.05      0.025   0.01    0.05      0.025   0.01    0.05      0.025   0.01    0.05      0.025 0.01
   30   0.248     0.239   0.234   0.432     0.426   0.423   0.670     0.664   0.662   0.700     0.692 0.688
   40   0.144     0.132   0.126   0.297     0.287   0.281   0.631     0.625   0.622   0.719     0.713 0.708
   50   0.089     0.073   0.064   0.194     0.182   0.177   0.572     0.564   0.560   0.724     0.716 0.711
   60   0.064     0.044   0.034   0.131     0.115   0.107   0.507     0.498   0.493   0.738     0.731 0.727
   70   0.053     0.032   0.020   0.096     0.078   0.068   0.439     0.429   0.422   0.741     0.733 0.729
   80   0.047     0.025   0.014   0.078     0.056   0.044   0.369     0.357   0.350   0.741     0.734 0.730
  100   0.046     0.024   0.010   0.053     0.031   0.020   0.264     0.247   0.238   0.736     0.730 0.726
  150   0.048     0.023   0.009   0.051     0.025   0.010   0.114     0.093   0.080   0.713     0.706 0.701
  200   0.048     0.024   0.009   0.050     0.025   0.010   0.071     0.045   0.031   0.659     0.651 0.646
  250   0.050     0.025   0.011   0.050     0.025   0.011   0.059     0.032   0.017   0.577     0.567 0.560
  300   0.049     0.024   0.010   0.052     0.027   0.011   0.055     0.029   0.012   0.503     0.489 0.480
  350   0.047     0.023   0.009   0.051     0.027   0.010   0.054     0.028   0.011   0.431     0.414 0.405
  400   0.051     0.025   0.010   0.051     0.026   0.011   0.052     0.026   0.011   0.360     0.341 0.330
  450   0.050     0.024   0.010   0.049     0.025   0.011   0.052     0.026   0.011   0.303     0.283 0.271
  500   0.046     0.024   0.010   0.049     0.025   0.010   0.052     0.026   0.010   0.255     0.231 0.218
 1000   0.048     0.026   0.010   0.049     0.024   0.010   0.053     0.027   0.012   0.086     0.053 0.031
 5000   0.051     0.026   0.011   0.048     0.025   0.011   0.052     0.027   0.010   0.073     0.039 0.016




           Tabla 9: Tamaño de la prueba para procesos MA(1) con θ < 0.
             θ = −0.2                  θ = −0.5                  θ = −0.8                  θ = −0.95
  n     0.05   0.025 0.01         0.05   0.025 0.01         0.05   0.025 0.01         0.05    0.025 0.01
   30   0.132 0.121 0.114         0.094 0.078 0.071         0.091 0.065 0.049         0.108 0.073 0.050
   40   0.072 0.056 0.048         0.057 0.037 0.026         0.065 0.038 0.021         0.091 0.055 0.031
   50   0.052 0.032 0.021         0.048 0.027 0.013         0.059 0.032 0.015         0.085 0.049 0.024
   60   0.047 0.025 0.013         0.045 0.023 0.010         0.058 0.030 0.013         0.083 0.044 0.020
   70   0.045 0.022 0.008         0.047 0.024 0.010         0.057 0.030 0.014         0.081 0.044 0.021
   80   0.042 0.021 0.009         0.049 0.024 0.010         0.055 0.030 0.012         0.077 0.042 0.018
  100   0.046 0.022 0.009         0.046 0.022 0.010         0.057 0.029 0.012         0.078 0.042 0.019
  150   0.046 0.024 0.010         0.052 0.026 0.011         0.053 0.028 0.011         0.068 0.036 0.015
  200   0.050 0.023 0.009         0.050 0.026 0.010         0.057 0.029 0.011         0.067 0.035 0.015
  250   0.050 0.025 0.011         0.050 0.025 0.009         0.055 0.027 0.012         0.072 0.037 0.016
  300   0.049 0.024 0.010         0.051 0.025 0.010         0.055 0.027 0.011         0.070 0.036 0.014
  350   0.046 0.024 0.009         0.050 0.026 0.009         0.053 0.028 0.010         0.072 0.037 0.016
  400   0.050 0.025 0.011         0.053 0.026 0.011         0.054 0.028 0.011         0.072 0.038 0.017
  450   0.050 0.025 0.009         0.048 0.025 0.010         0.053 0.027 0.011         0.073 0.039 0.017
  500   0.048 0.024 0.010         0.052 0.025 0.010         0.054 0.028 0.011         0.076 0.040 0.018
 1000   0.047 0.024 0.010         0.049 0.024 0.009         0.052 0.025 0.010         0.078 0.042 0.019
 5000   0.050 0.026 0.011         0.050 0.025 0.011         0.053 0.027 0.010         0.070 0.037 0.015




   • Para cada α y θ > 0, a medida que n → ∞, el tamaño de la prueba converge
     al nivel de significancia nominal. La convergencia se hace más lenta a medida
     que θ → 1. Con tamaños muestrales pequeños y moderados, a mayor valor
     del parámetro θ, mayor es la distorsión del verdadero tamaño de la prueba
     con respecto al nivel de significancia nominal.

                                              Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                                             313

           Tabla 10: Tamaño de la prueba para procesos AR(1) con φ > 0.
                φ = 0.2                   φ = 0.5                   φ = 0.8                φ = 0.95
  n     0.05     0.025    0.01    0.05     0.025    0.01    0.05     0.025    0.01    0.05   0.025 0.01
   30   0.293    0.280    0.274   0.126    0.106    0.095   0.074    0.050    0.036   0.076 0.050 0.035
   40   0.273    0.261    0.255   0.088    0.067    0.055   0.058    0.036    0.019   0.062 0.037 0.019
   50   0.239    0.227    0.220   0.062    0.040    0.029   0.049    0.026    0.013   0.057 0.031 0.015
   60   0.215    0.200    0.192   0.058    0.034    0.019   0.051    0.026    0.013   0.059 0.031 0.015
   70   0.188    0.172    0.163   0.056    0.031    0.015   0.055    0.030    0.011   0.065 0.035 0.014
   80   0.161    0.146    0.137   0.050    0.027    0.012   0.050    0.027    0.012   0.060 0.032 0.013
  100   0.126    0.107    0.097   0.049    0.025    0.010   0.052    0.027    0.011   0.064 0.034 0.013
  150   0.078    0.057    0.045   0.048    0.024    0.010   0.050    0.026    0.010   0.063 0.031 0.012
  200   0.066    0.040    0.025   0.052    0.027    0.010   0.054    0.027    0.011   0.068 0.035 0.015
  250   0.057    0.032    0.017   0.052    0.027    0.011   0.055    0.028    0.012   0.069 0.036 0.015
  300   0.053    0.026    0.013   0.051    0.025    0.010   0.052    0.026    0.010   0.066 0.034 0.014
  350   0.051    0.026    0.011   0.052    0.026    0.010   0.053    0.026    0.010   0.068 0.033 0.014
  400   0.048    0.024    0.010   0.047    0.024    0.009   0.050    0.024    0.010   0.064 0.032 0.013
  450   0.051    0.024    0.009   0.051    0.025    0.010   0.054    0.027    0.011   0.068 0.035 0.014
  500   0.052    0.026    0.010   0.050    0.026    0.011   0.050    0.027    0.011   0.067 0.034 0.015
 1000   0.047    0.023    0.010   0.048    0.024    0.010   0.050    0.025    0.010   0.066 0.032 0.013
 5000   0.048    0.024    0.010   0.051    0.026    0.011   0.052    0.026    0.010   0.069 0.035 0.014


           Tabla 11: Tamaño de la prueba para procesos AR(1) con φ < 0.
             φ = −0.2                  φ = −0.5                  φ = −0.8                  φ = −0.95
  n     0.05   0.025 0.01         0.05   0.025 0.01         0.05   0.025 0.01         0.05    0.025 0.01
   30   0.461 0.455 0.452         0.340 0.333 0.331         0.181 0.168 0.161         0.138 0.114 0.101
   40   0.447 0.441 0.437         0.239 0.228 0.224         0.100 0.080 0.070         0.091 0.055 0.031
   50   0.404 0.396 0.393         0.162 0.149 0.142         0.064 0.042 0.029         0.071 0.039 0.020
   60   0.365 0.357 0.353         0.115 0.097 0.089         0.058 0.032 0.018         0.071 0.037 0.017
   70   0.326 0.316 0.311         0.089 0.069 0.056         0.060 0.032 0.013         0.074 0.040 0.017
   80   0.293 0.284 0.278         0.068 0.048 0.036         0.052 0.026 0.011         0.067 0.035 0.014
  100   0.237 0.223 0.216         0.054 0.032 0.018         0.053 0.027 0.013         0.067 0.036 0.016
  150   0.146 0.129 0.120         0.049 0.024 0.010         0.053 0.026 0.011         0.068 0.034 0.015
  200   0.106 0.086 0.072         0.051 0.027 0.011         0.054 0.028 0.011         0.070 0.036 0.014
  250   0.079 0.057 0.044         0.052 0.026 0.011         0.055 0.028 0.012         0.070 0.037 0.016
  300   0.065 0.041 0.027         0.051 0.026 0.010         0.051 0.027 0.011         0.067 0.036 0.014
  350   0.056 0.034 0.020         0.051 0.025 0.010         0.054 0.027 0.011         0.069 0.036 0.015
  400   0.050 0.027 0.014         0.047 0.024 0.009         0.049 0.025 0.010         0.065 0.034 0.013
  450   0.052 0.026 0.012         0.049 0.024 0.010         0.052 0.025 0.011         0.069 0.034 0.014
  500   0.051 0.026 0.011         0.052 0.025 0.010         0.054 0.028 0.011         0.073 0.037 0.015
 1000   0.049 0.023 0.010         0.050 0.024 0.010         0.051 0.025 0.010         0.067 0.032 0.013
 5000   0.048 0.025 0.010         0.050 0.025 0.011         0.051 0.025 0.010         0.069 0.035 0.014



   • Para cada α y θ < 0, a medida que n → ∞ el tamaño de la prueba converge
     a nivel de significancia nominal. La convergencia se hace más lenta a medida
     que θ → −1.

   • Para cada α y φ, en forma general se observa que a medida que n → ∞ el
     tamaño de la prueba converge a nivel de significancia nominal. Las mayores
     distorsiones del tamaño aparecen para valores pequeños de φ y n.


                                              Revista Colombiana de Estadística 32 (2009) 301–331

314                                                                 Elkin Castaño & Jorge Martínez

3.2. Potencia de la prueba con modelos MA(1) y AR(1)
   Las tablas 12, 13, 14 y 15 contienen los resultados de la potencia de la prueba
para modelos MA(1) y AR(1) con parámetro θ = ±0.2, ±0.5, ±0.8, ±0.95, φ =
±0.2, ±0.5, ±0.8, ±0.95, valores de α = 0.01, 0.025, 0.05, K = 5, β0 = 2 y
β1 = 0.7. Con cada combinación de α con θ y φ se realizaron 20000 simulaciones.
El modelo generador de los datos es el modelo bajo H1 .

          Tabla 12: Potencia de la prueba para procesos MA(1) con θ > 0.
                θ = 0.2                   θ = 0.5                   θ = 0.8                   θ = 0.95
  n     0.05      0.025   0.01    0.05      0.025   0.01    0.05      0.025   0.01    0.05      0.025 0.01
   30   0.798     0.791   0.788   0.910     0.905   0.903   0.942     0.937   0.934   0.942     0.936 0.933
   40   0.839     0.834   0.831   0.952     0.949   0.946   0.974     0.972   0.969   0.974     0.971 0.967
   50   0.873     0.868   0.865   0.974     0.971   0.969   0.989     0.986   0.984   0.989     0.985 0.982
   60   0.892     0.888   0.884   0.986     0.983   0.982   0.995     0.993   0.992   0.996     0.993 0.991
   70   0.914     0.908   0.906   0.992     0.990   0.989   0.998     0.997   0.996   0.998     0.997 0.996
   80   0.930     0.925   0.922   0.995     0.993   0.992   1.000     0.998   0.997   1.000     0.999 0.997
  100   0.956     0.953   0.951   0.999     0.998   0.997   1.000     1.000   1.000   1.000     1.000 1.000
  150   0.984     0.982   0.980   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000 1.000
  200   0.993     0.992   0.992   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000 1.000
  250   0.997     0.997   0.996   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000 1.000
  300   0.999     0.999   0.999   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000 1.000
  350   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000 1.000
  400   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000 1.000
  450   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000 1.000
  500   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000 1.000
 1000   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000   1.000   1.000     1.000 1.000



          Tabla 13: Potencia de la prueba para procesos MA(1) con θ < 0.
             θ = −0.2                  θ = −0.5                  θ = −0.8                  θ = −0.95
  n     0.05   0.025 0.01         0.05   0.025 0.01         0.05   0.025 0.01         0.05    0.025 0.01
   30   0.704 0.698 0.694         0.814 0.808 0.806         0.843 0.835 0.830         0.827 0.815 0.808
   40   0.740 0.733 0.729         0.882 0.877 0.873         0.917 0.911 0.907         0.909 0.900 0.895
   50   0.774 0.768 0.764         0.923 0.919 0.917         0.954 0.949 0.946         0.951 0.944 0.939
   60   0.804 0.798 0.794         0.946 0.942 0.939         0.975 0.970 0.968         0.975 0.970 0.965
   70   0.828 0.823 0.820         0.964 0.961 0.959         0.988 0.984 0.982         0.989 0.984 0.982
   80   0.847 0.842 0.839         0.976 0.974 0.972         0.994 0.991 0.989         0.995 0.991 0.988
  100   0.878 0.875 0.872         0.989 0.988 0.987         0.999 0.998 0.996         1.000 0.999 0.997
  150   0.931 0.928 0.927         0.998 0.997 0.997         1.000 1.000 1.000         1.000 1.000 1.000
  200   0.960 0.959 0.958         1.000 1.000 0.999         1.000 1.000 1.000         1.000 1.000 1.000
  250   0.974 0.974 0.973         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  300   0.984 0.983 0.982         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  350   0.990 0.989 0.989         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  400   0.995 0.994 0.994         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  450   0.996 0.996 0.995         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  500   0.998 0.998 0.997         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
 1000   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
 5000   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000


   De las tablas 12, 13, 14 y 15 se observa que:

                                              Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                                             315

          Tabla 14: Potencia de la prueba para procesos AR(1) con φ > 0.
                φ = 0.2                   φ = 0.5                   φ = 0.8                φ = 0.95
  n     0.05     0.025    0.01    0.05     0.025    0.01    0.05     0.025    0.01    0.05   0.025 0.01
   30   0.833    0.827    0.825   0.728    0.719    0.715   0.544    0.535    0.530   0.444 0.436 0.432
   40   0.908    0.905    0.903   0.826    0.819    0.815   0.619    0.611    0.607   0.462 0.454 0.451
   50   0.944    0.941    0.939   0.884    0.876    0.872   0.679    0.672    0.668   0.471 0.465 0.462
   60   0.963    0.961    0.959   0.918    0.913    0.910   0.714    0.707    0.704   0.468 0.461 0.458
   70   0.978    0.976    0.975   0.943    0.939    0.935   0.747    0.741    0.738   0.464 0.456 0.452
   80   0.987    0.985    0.984   0.962    0.958    0.956   0.772    0.767    0.764   0.458 0.451 0.447
  100   0.994    0.993    0.992   0.978    0.977    0.975   0.814    0.809    0.807   0.468 0.460 0.457
  150   0.999    0.999    0.999   0.994    0.993    0.993   0.879    0.875    0.872   0.475 0.468 0.464
  200   1.000    1.000    1.000   0.998    0.997    0.997   0.916    0.914    0.913   0.492 0.485 0.480
  250   1.000    1.000    1.000   0.999    0.999    0.999   0.942    0.941    0.940   0.507 0.501 0.497
  300   1.000    1.000    1.000   1.000    1.000    1.000   0.959    0.957    0.956   0.524 0.516 0.511
  350   1.000    1.000    1.000   1.000    1.000    1.000   0.971    0.970    0.969   0.541 0.533 0.529
  400   1.000    1.000    1.000   1.000    1.000    1.000   0.979    0.977    0.977   0.562 0.555 0.550
  450   1.000    1.000    1.000   1.000    1.000    1.000   0.985    0.984    0.984   0.577 0.569 0.565
  500   1.000    1.000    1.000   1.000    1.000    1.000   0.988    0.987    0.987   0.594 0.586 0.582
 1000   1.000    1.000    1.000   1.000    1.000    1.000   1.000    0.999    0.999   0.703 0.696 0.693
 5000   1.000    1.000    1.000   1.000    1.000    1.000   1.000    1.000    1.000   0.956 0.953 0.952


          Tabla 15: Potencia de la prueba para procesos AR(1) con φ < 0.
             φ = −0.2                  φ = −0.5                  φ = −0.8                  φ = −0.95
  n     0.05   0.025 0.01         0.05   0.025 0.01         0.05   0.025 0.01         0.05    0.025 0.01
   30   0.906 0.903 0.902         0.928 0.925 0.924         0.941 0.938 0.936         0.950 0.947 0.945
   40   0.949 0.947 0.946         0.962 0.960 0.959         0.970 0.967 0.966         0.976 0.974 0.972
   50   0.971 0.970 0.969         0.978 0.976 0.976         0.983 0.981 0.981         0.988 0.986 0.984
   60   0.983 0.982 0.981         0.990 0.988 0.987         0.994 0.992 0.991         0.995 0.994 0.993
   70   0.990 0.989 0.989         0.995 0.993 0.992         0.997 0.995 0.995         0.998 0.997 0.996
   80   0.995 0.993 0.993         0.997 0.996 0.996         0.999 0.998 0.997         1.000 0.999 0.998
  100   0.999 0.998 0.997         1.000 0.999 0.999         1.000 1.000 0.999         1.000 1.000 1.000
  150   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  200   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  250   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  300   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  350   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  400   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  450   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
  500   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
 1000   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000
 5000   1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000         1.000 1.000 1.000



   • Cuando el error es MA(1), en general la prueba alcanza potencias. La prueba
     es consistente ya que, para cada valor α y de θ, la potencia de la prueba
     converge a 1 a medida que n → ∞.

   • Con cada valor de α y de φ la potencia de la prueba también converge a 1 a
     medida que n → ∞.

   • Las potencias más bajas se presentan a medida que φ → 1.


                                              Revista Colombiana de Estadística 32 (2009) 301–331

316                                                          Elkin Castaño & Jorge Martínez

4. Comparación de la prueba T MIN ∗ con la prueba
   de Dickey y Fuller Aumentada
   Para probar la hipótesis nula de la existencia de una raíz unitaria en una serie
de tiempo, contra la hipótesis alterna de que la serie es estacionaria, Dickey &
Fuller (1979) proponen emplear el modelo general
                                                     P
                                                     X
                     ∆Zt = β0 + β1 t + γZt−1 +              δj ∆Zt−j + at
                                                      j=1

                                                                                         
donde β0 , β1 , γ y δj , j = 1, 2, . . . , P son constantes y at es ruido blanco N 0, σa2 .
Para realizar la prueba los autores proponen probar la hipótesis H0 : γ = 0 (la
serie tiene una raíz unitaria) contra H1 : γ < 1 (la serie es estacionaria) basándose
en la estimación de mínimos cuadrados de la ecuación anterior. El estadístico de
prueba es ADF = γ     b/SE(b  γ ), donde b    γ es el estimador del parámetro γ y SE(b   γ)
es su error estándar. Dichos autores mostraron que la distribución nula asintótica
del estadístico ADF no es la tradicional distribución t de Student (depende de
procesos Weiner), y que debe ser derivada por simulación. Dickey y Fuller también
mostraron que los valores críticos de la distribución dependen de la forma de la
ecuación anterior, ya que pueden considerarse tres posibilidades: sin intercepto y
sin tendencia (β0 = 0 y β1 = 0), con intercepto y sin tendencia (β0 6= 0 y β1 = 0)
y con intercepto y con tendencia (β0 6= 0 y β1 6= 0). A un nivel de significancia
aproximado α, se rechaza H0 si ADF < ADF (α, n), donde ADF (α, n) es el valor
crítico apropiado de la distribución asintótica de ADF bajo H0 .
    A continuación se presenta una comparación del tamaño y potencia de la prue-
ba asintótica T M IN ∗ con los correspondientes tamaños y potencias de la prueba
de Dickey-Fuller Aumentada (ADF ). Las figuras que se muestran a continuación
se basan en las tablas 19, 20, 21 y 22 del apéndice A1 . Las figuras 1 y 2 presentan
una comparación de la potencia de la prueba generalizada T M IN ∗ y de la prueba
ADF con diferentes valores de φ de un proceso AR(1), diferentes valores de θ de
un proceso MA(1), diferentes valores de n, α = 0.05, y K = 5. Se usaron 20000
simulaciones. Las figuras 3 y 4 comparan los tamaños de las pruebas.
    Comparando las potencias se observa que en el caso de errores AR(1) y n = 25
la prueba T M IN ∗ tiene en general mayor potencia que la prueba ADF, sobre
todo cuando φ → 1. A medida que n crece y si −1 ≤ φ ≤ 0, las potencias tienden
a igualarse y convergen a 1. Sin embargo, con valores positivos y cerca de 1, la
prueba T M IN ∗ tiene mayor potencia que la prueba ADF.
    En el caso de errores MA(1) cuando −1 ≤ θ < 0, la potencia de T M IN ∗
es mayor que la ADF y la situación se invierte si 0 ≤ θ < 1. En ambos casos
las potencias tienden a 1 cuando n crece. Se observa que, en general, la prueba
T M IN ∗ nunca obtiene potencias tan bajas como algunas de la prueba ADF.
   1 Para calcular la potencia y el tamaño de la prueba ADF cuando los errores son MA(1), se

seleccionó el máximo rezago autorregresivo utilizando k máx = b12(n/100)1/4c. Se ajustaron
todos los modelos autorregresivos hasta ese orden, en la prueba se utilizó el modelo que tuviera
el menor criterio de información de Schwartz (1978).


                                         Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                                                                                               317


                                            n=25                                                                     n=50

      1.0                                                                         1.0
                                                                      TMIN
                                                                      ADF
      0.8                                                                         0.8



      0.6                                                                         0.6



      0.4                                                                         0.4



      0.2                                                                         0.2



      0.0                                                                         0.0


              −0.95   −0.8    −0.5   −0.2     0     0.2   0.5   0.8   0.95              −0.95   −0.8   −0.5   −0.2     0     0.2   0.5   0.8   0.95




                                            n=100                                                                    n=250

      1.0                                                                         1.0
                                                                      TMIN
                                                                      ADF
      0.8                                                                         0.8



      0.6                                                                         0.6



      0.4                                                                         0.4



      0.2                                                                         0.2



      0.0                                                                         0.0


              −0.95   −0.8    −0.5   −0.2     0     0.2   0.5   0.8   0.95              −0.95   −0.8   −0.5   −0.2     0     0.2   0.5   0.8   0.95




Figura 1: Comparación de potencias: T M IN ∗ vs. ADF para α = 0.05 y error AR(1).



    Se calculó una medida general del comportamiento de la desviación de la
potencia de cada prueba con respecto a 1, definida como DesvP(PRUEBA) =
Promedio[|Potencia(PRUEBA) − 1|] donde |x| indica el valor absoluto de x y
PRUEBA = T M IN ∗ o PRUEBA = ADF según el caso. La tabla 16 presenta
estos resultados.

                             Tabla 16: Desviaciones absolutas desde la potencia 1.
                                    AR                                                         MA
             n         DesvP(T M IN ∗ ) DesvP(ADF )                               DesvP(T M IN ∗ ) DesvP(ADF )
             25            0.2380          0.4567                                     0.1806          0.1744
             50            0.1255          0.2425                                     0.0658          0.0517
            100            0.0845          0.1531                                     0.0199          0.0123
            250            0.0605          0.0831                                     0.0030          0.0001



   De la tabla 16 se observa que cuando el proceso es AR hay ventaja de la prueba
T M IN ∗ , mientras que en el caso MA la situación es muy pareja con una ligera
ventaja de la prueba ADF.

                                                                        Revista Colombiana de Estadística 32 (2009) 301–331

318                                                                                          Elkin Castaño & Jorge Martínez


                                         n=25                                                                     n=50

      1.0                                                                      1.0
                TMIN
                ADF
      0.8                                                                      0.8



      0.6                                                                      0.6



      0.4                                                                      0.4



      0.2                                                                      0.2



      0.0                                                                      0.0


            −0.95   −0.8   −0.5   −0.2     0     0.2   0.5   0.8   0.95              −0.95   −0.8   −0.5   −0.2     0     0.2   0.5   0.8   0.95




                                         n=100                                                                    n=250

      1.0                                                                      1.0



      0.8                                                                      0.8



      0.6                                                                      0.6



      0.4                                                                      0.4



      0.2                                                                      0.2



      0.0                                                                      0.0


            −0.95   −0.8   −0.5   −0.2     0     0.2   0.5   0.8   0.95              −0.95   −0.8   −0.5   −0.2     0     0.2   0.5   0.8   0.95




Figura 2: Comparación de potencias: T M IN ∗ vs. ADF para α = 0.05 y error MA(1).



    En cuanto a los tamaños de las pruebas, claramente la prueba ADF mantiene
los tamaños nominales para el caso AR, mientras que para la prueba T M IN ∗
hay distorsiones importantes sobre todo si n ≤ 50 y φ toma valores peque-
ños positivos o negativos. Cuando los errores son MA, los tamaños de las dos
pruebas presentan distorsiones mayores a medida que θ → 1, siendo más seve-
ras para la prueba ADF. Con valores negativos de θ la prueba T M IN ∗ pre-
senta menores distorsiones que la prueba ADF. La medida de comportamien-
to de la desviación del tamaño de cada prueba con respecto a 0.05 está de-
finida como DesvT(PRUEBA) = Promedio[|Tamaño(PRUEBA) − 0.05|], donde
PRUEBA= T M IN ∗ o PRUEBA=ADF según el caso. La tabla 17 presenta estos
resultados.


5. Aplicación a datos reales
   La figura 5 muestra la tasa anual de muertes por cáncer (por cada 100000 habi-
tantes) en Pensilvania entre los años 1930 y 2000, publicada por el Departamento
de Salud de Pensilvania. Los datos aparecen también en Wei (2006).

                                                                     Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                                                                                                   319


                                             n=25                                                                       n=50

       1.0                                                                           1.0
                                                                 TMIN                                                                       TMIN
                                                                 ADF                                                                        ADF
       0.8                                                       NOMINAL             0.8                                                    NOMINAL


       0.6                                                                           0.6



       0.4                                                                           0.4



       0.2                                                                           0.2



       0.0                                                                           0.0


               −0.95    −0.8   −0.5   −0.2     0     0.2   0.5    0.8   0.95               −0.95   −0.8   −0.5   −0.2     0     0.2   0.5    0.8   0.95




                                             n=100                                                                      n=250

       1.0                                                                           1.0
                                                                 TMIN                                                                       TMIN
                                                                 ADF                                                                        ADF
       0.8                                                       NOMINAL             0.8                                                    NOMINAL


       0.6                                                                           0.6



       0.4                                                                           0.4



       0.2                                                                           0.2



       0.0                                                                           0.0


               −0.95    −0.8   −0.5   −0.2     0     0.2   0.5    0.8   0.95               −0.95   −0.8   −0.5   −0.2     0     0.2   0.5    0.8   0.95




 Figura 3: Comparación de tamaños: T M IN ∗ vs. ADF para α = 0.05 y error AR(1).


                       Tabla 17: Desviaciones absolutas desde el tamaño α = 0.05.
                                     AR                                                           MA
              n         DesvT(T M IN ∗ ) DesvT(ADF )                                 DesvT(T M IN ∗ ) DesvT(ADF )
              25            0.1767          0.0072                                       0.2681          0.3059
              50            0.0801          0.0044                                       0.1586          0.2981
             100            0.0339          0.0034                                       0.1048          0.2556
             250            0.0078          0.0023                                       0.0628          0.2040



    La figura anterior muestra una tendencia en la serie de incremento en su valor.
Este incremento podría haber sido generado por un modelo de tendencia aleatoria
con una deriva o por un modelo de tendencia determinística. Wei (2006), usando
la prueba de Dickey y Fuller, concluye que la serie es consistente con un proceso de
caminata aleatoria con deriva. Sin embargo, en la gráfica se observa que en el año
1978 la serie se desvía de su nivel anterior (hay un salto hacia arriba) y en los años
1988, 1989 y 2000 la serie cae2 . Un análisis más detallado sugiere que el modelo
propuesto por Wei tiene problemas en el ajuste, pues para rezagos mayores que 12
   2 Evidencia sobre la importancia de estas observaciones se confirmó al usar el procedimiento

de Chen & Liu (1990), implementado en el paquete estadístico SCA.


                                                                           Revista Colombiana de Estadística 32 (2009) 301–331

320                                                                                             Elkin Castaño & Jorge Martínez


                                         n=25                                                                        n=50

      1.0                                                                        1.0
                TMIN                                                                        TMIN
                ADF                                                                         ADF
      0.8       NOMINAL                                                          0.8        NOMINAL


      0.6                                                                        0.6



      0.4                                                                        0.4



      0.2                                                                        0.2



      0.0                                                                        0.0


            −0.95   −0.8   −0.5   −0.2     0     0.2   0.5   0.8   0.95                 −0.95   −0.8   −0.5   −0.2     0     0.2   0.5   0.8   0.95




                                         n=100                                                                       n=250

      1.0                                                                        1.0
                TMIN                                                                        TMIN
                ADF                                                                         ADF
      0.8       NOMINAL                                                          0.8        NOMINAL


      0.6                                                                        0.6



      0.4                                                                        0.4



      0.2                                                                        0.2



      0.0                                                                        0.0


            −0.95   −0.8   −0.5   −0.2     0     0.2   0.5   0.8   0.95                 −0.95   −0.8   −0.5   −0.2     0     0.2   0.5   0.8   0.95




Figura 4: Comparación de tamaños: T M IN ∗ vs. ADF para α = 0.05 y error MA(1).




                           250



                           200



                           150



                           100

                                    1930          1940        1950        1960   1970     1980          1990           2000




       Figura 5: Tasa anual de muertes por cáncer en Pensilvania, 1930−2000.




                                                                     Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                              321

y un nivel de significancia de 0.05, la prueba de Ljung y Box rechaza la hipótesis
de que los residuales proceden de un proceso de ruido blanco. Este resultado puede
deberse a la existencia de observaciones atípicas en los años mencionados, que no
se tuvieron en cuenta en la especificación del modelo.
    Para la realización de la prueba propuesta se debe iniciar con la especificación
de los modelos bajo H0 en los cuales se debe tener en cuenta la posible influen-
cia de las observaciones mencionadas, junto con la especificación adecuada de la
componente ARMA desconocida. En este punto podría surgir una complicación
puesto que, usando los datos, la identificación de la componente ARMA bajo H0
y bajo H1 podría conducir a modelos distintos para el ruido bt . La solución a este
problema es emplear los modelos identificados para la componente bajo cada una
de las hipótesis. La diferencia de los modelos de los ruidos bajo las dos hipótesis
no invalida resultados de la proposición 3 porque esta se refiere a la distribución
asintótica del estadístico de prueba bajo la hipótesis nula. A continuación se ilustra
este procedimiento con la serie descrita anteriormente.


5.1. Especificación del modelo bajo la hipótesis H0
    Debido a la existencia de observaciones sospechosas descritas antes (posibles
cambios estructurales), el modelo bajo H0 es de la forma ∆Zt = β0 + δ1 ∆D49t +
δ2 ∆D59t + δ3 ∆D60t + δ4 ∆D71t + [θ(B)/φ(B)] at , donde las variables D49t , D59t ,
D60t y D71t son binarias con 1 en los años 1978, 1988, 1989 y 2000, respectiva-
mente, y cero en los demás años. La identificación de la componente ARMA no se
puede realizar directamente sobre la serie ∆Zt debido a la presencia de los cam-
bios estructurales. La identificación puede realizarse usando dos alternativas. La
primera es usar el periodo inicial de la serie donde no hay cambios de estructura,
es decir usando las primeras 48 observaciones (antes de 1978). Para este perio-
do se identifica un proceso AR(3) restringido de la forma bt = 1/(1 − φ3 B 3 )at .
La otra alternativa es usar el procedimiento sugerido por Castaño (1995) para la
identificación de un modelo ARIMA contaminado con observaciones atípicas. El
resultado de este procedimiento arroja de nuevo un modelo AR(3), de la forma
obtenida anteriormente. Por consiguiente, una especificación del modelo bajo H0
es de la forma

             ∆Zt =β0 + δ1 ∆D49t + δ2 ∆D59t + δ3 ∆D60t + δ4 ∆D71t
                                    
                     + 1/(1 − φ3 )B 3 at


5.2. Especificación del modelo bajo la hipótesis H1
    Bajo la hipótesis alterna, el modelo es de la forma Zt = β0 + β1 t + δ1 ∆D49t +
δ2 D59t + δ3 D60t + δ4 D71t + [θ(B)/φ(B)] at .
    Para la identificación de un modelo adecuado para la componente ARMA se
siguió el mismo procedimiento sugerido para la identificación bajo H0 , teniendo
en cuenta la introducción de la tendencia determinística. El modelo sugerido es un
AR(4) restringido de la forma bt = [1/(1 − φ1 B − φ3 B 3 − φ4 B 4 )]at . Por lo tanto,

                                      Revista Colombiana de Estadística 32 (2009) 301–331

322                                                           Elkin Castaño & Jorge Martínez

la especificación del modelo bajo H1 es de la forma
                 Zt =β0 + β1 t + δ1 D49t + δ2 D59t + δ3 D60t + δ4 D71t
                                                        
                        + 1/(1 − φ1 B − φ3 B 3 − φ4 B 4 ) at

     Para la prueba propuesta, las hipótesis que se deben contrastar son:
            H0 : ∆Zt =β0 + δ1 ∆D49t + δ2 ∆D59t + δ3 ∆D60t + δ4 ∆D71t
                                         
                         + 1/(1 − φ3 B 3 ) at
y
              H1 : Zt =β0 + β1 t + δ1 D49t + δ2 D59t + δ3 D60t + δ4 D71t
                                                          
                          + 1/(1 − φ1 B − φ3 B 3 − φ4 B 4 ) at

    Para el cálculo del estadístico T M IN ∗ se estiman los dos modelos3 . Con un
valor de K = 10 se obtiene que T A∗ = 3.8 y T D∗ = 5.5 son los valores observados
del estadístico de Ljung y Box para cada modelo. A un nivel de significancia
aproximado de 0.05, como T M IN ∗ = mı́n{T A∗ , T D∗ } = T A∗ = 3.8 y T M IN ∗ ≤
χ2 (0.05, 9) = 16.919, no se rechaza H0 , es decir, la tendencia de la tasa anual
de mortalidad por cáncer es aleatoria con deriva. La tabla 18 muestra que esta
conclusión se mantiene para todos los valores de K = 2, . . . , 16.
               Tabla 18: Cálculo de T A∗ y T D∗ para varios valores de K.
                             K    T A∗    T D∗    K    T A∗     T D∗
                             1     0.7     1.5     9    3.1      4.5
                             2     0.8     1.5    10    3.8      5.5
                             3     0.9     1.5    11    4.3      5.8
                             4     1.8     3.1    12    7.4      9.1
                             5     2.1     3.5    13   11.6     13.8
                             6     2.3     3.6    14   11.6     13.8
                             7     2.7     3.9    15   15.3     17.7
                             8     2.8     4.0    16   13.7     17.8


    Los resultados de la tabla 18 muestran que las conclusiones no se modifican
variando K puesto que T A∗ sigue siendo el mínimo y es menor que el percentil
χ2 (0.05, K − 1) para K = 2, . . . , 20.
    El uso adecuado de la prueba propuesta exige al analista la formulación adecua-
da de los modelos que se van a comparar. Esta es una diferencia con otras pruebas
cuya utilización, para usuarios inexpertos, se convierte generalmente en una “caja
negra”, en las cuales las componentes exógenas, tales como cambios estructurales,
no son tenidas en cuenta.


6. Conclusiones
   Se presenta un procedimiento que permite el contraste de hipótesis específicas
sobre el comportamiento de la tendencia frecuentemente encontrado en series de
    3 Los resultados de las estimaciones se encuentran en el Apéndice B.




                                          Revista Colombiana de Estadística 32 (2009) 301–331

Tendencia aleatoria o determinística...                                              323

tiempo. Este procedimiento tiene ventajas, en términos de su potencia y tamaño,
frente a la tradicional prueba de Dicker y Fuller.
   Cuando el término de error es ruido blanco gaussiano, la prueba T M IN ∗ posee
una alta potencia y no presenta grandes distorsiones del tamaño de la prueba, aun
en tamaños muestrales pequeños.
    Cuando el término de error es un proceso gaussiano autocorrelacionado, en
los casos analizados la prueba asintótica presenta buena potencia. Se observa que
la potencia decrece cuando la raíz del polinomio autorregresivo se acerca a uno.
Aunque este es un fenómeno que ocurre en todas las pruebas de raíces unitarias,
la prueba propuesta tiene un mejor comportamiento que la prueba de Dickey y
Fuller Aumentada. En general, a medida que n crece, la potencia de la prueba
tiende a 1.
    En cuanto al tamaño de la prueba asintótica, cuando los errores son AR(1) y
el valor φ es pequeño, positivo o negativo, existen distorsiones importantes cuando
n ≤ 50. Si los errores son MA(1), con valores positivos del parámetro θ, las dis-
torsiones se hacen cada vez mayores a medida que θ tiende a 1. Sin embargo, en
ambas situaciones se tiene que el tamaño de la prueba converge a su valor nominal
a medida que el tamaño muestral aumenta.
   De la comparación de la prueba asintótica T M IN ∗ con la prueba de Dickey y
Fuller Aumentada se concluye que la primera tiene, en general, mayor potencia,
sobre todo cuando φ → 1. En cuanto al tamaño de la prueba, los resultados
muestran que la prueba T M IN ∗ nunca alcanza distorsiones tan severas como la
prueba ADF.
   Finalmente, el uso adecuado de la prueba propuesta exige al analista la for-
mulación adecuada de los modelos que se confrontan. Esto podría interpretarse
como una desventaja, pero en realidad forma parte de la metodología de análisis
en cualquier uso de la estadística.
Apéndice A.

                 Tabla 19: Potencia de T M IN ∗ para errores AR(1).
      Tabla 20: Potencia de T M IN ∗ para errores MA(1).
                 Tabla 21: Tamaño de T M IN ∗ para errores AR(1).
      Tabla 22: Tamaño de T M IN ∗ para errores MA(1).

Apéndice B.
   A continuación se presentan las estimaciones de máxima verosimilitud bajo
normalidad de los modelos empleados en el ejemplo de la sección 5. Los valores
entre paréntesis corresponden a los valores p de las pruebas.
                 Tabla 23: Modelo con componente AR(3) bajo H0 .
                     No se detectaron observaciones atípicas
                     Número total de observaciones: 71
                     Número efectivo de observaciones: 67
                     Estadístico F : 13.141(0)
                     Error estándar de la regresión: 2.034
                     Criterio de Schwartz: 4.541
                     Jarque-Bera (normalidad): 2.497(0.287)
                 Tabla 24: Modelo con componente AR(4) bajo H1 .
                    No se detectaron observaciones atípicas
                    Número total de observaciones: 71
                    Número efectivo de observaciones: 67
                    Estadístico F : 3732.543(0)
                    Error estándar de la regresión: 1.983
                    Criterio de Schwartz: 4.628
                    Jarque-Bera (normalidad): 3.458(0.177)
Referencias
Arellano C,Pantula S G.Testing for Trend Stationarity versus Difference Stationarity.(1995).Journal of Time Series Analysis.
Box G E P,Pierce D A.Distribution of the residual autocorrelations in autoregressive-integrated moving average time series models.(1970).Journal of the American Statistical Association.
Castaño E.Identificación de un modelo ARIMA contaminado.(1995).Lecturas de Economía.
Chen C,Liu M L.Joint estimation of model parameters and outlier effects in time series.(1990).Scientific computing associates.
Choi I.Durbin-Hausman Tests for a Unit Roots.(1992).Oxford Bulletin of Economics and Statistics.
Choi I,Yu B C.A General Framework for testing I(m) contra I(m+k).(1997).Journal of Economic Theory and Econometrics.
Cleveland W S.Visualizing Data.(1993).Hobart Press.Michigan.
Cleveland W S.The Elements of Graphing Data.(1994).Hobart Press.Michigan.
Cochran J H.How Big is the Random Walk in GNP?.(1988).Journal of Political Economy.
Cochrane J H.A Critique of the Application of Unit Root Tests.(1991).Journal of Economics Dynamics and Control.
DeJong D N,Nankervis J C,Savin N E,Whiteman C H.Integration Versus Trend Stationarity in Time Series.(1992).Econometrica.
DeJong D N,Nankervis J C,Savin N E,Whiteman C H.The Powers Problems of the Unit Root Tests in Time Series with Autorregressive Errors.(1992).Journal of Econometrics.
Dickey D A,Fuller W A.Distribution of the Estimators for Autoregressive Time Series with a Unit Root.(1979).Journal of the American Statistical Association.
Elliot G,Rothenber T J,Stock J H.Efficient Tests for an Autorregressive Unit Root.(1996).Econometrica.
Flores de Frutos R,Jerez M.Testing for Invertivility in Univariate ARIMA Process.(2002).Universidad Complutense de Madrid.
Fuller W A.Introduction to Statistical Time Series.(1976).Wiley Interscience.New York.
Hall A.Testing for a Unit Root in the Presence of Moving Average Error.(1989).Biometrika.
Harvey A.Forecasting, Structural Time Series Models and the Kalman Filter.(1989).Cambridge University Press.Cambridge.
Harvey A.Trend Analysis, Mimeo.(2000).University of Cambridge.
Jones R H.Longitudinal Data with Serial Correlation: A State Space Approach.(1993).Chapman and Hall.
Kitagawa G,Gersch W.Smoothness Priors Analysis of Time Series.(1996).Springer-Verlag.Berlín.
Ljung G M.Diagnostic Testing of Univariate Time Series Models.(1986).Biometrika.
Ljung G M,Box G E P.On a Measure of Lack of Fit in Time Series Models.(1978).Biometrika.
Nelson C R,Plosser C I.Trends and random walks in macroeconomic time series.(1982).Journal of Monetary Economics.
Ng S,Perron P.Unit Roots Tests in ARMA Models with Data Dependent Methods for the Selection of Truncation Lag.(1996).Journal of the American Statistical Association.
Pankratz A.Forecasting with Univariate Box-Jenkins Models.(1983).Wiley Interscience.New York.
Phillips P,Perron P.Testing for a Unit Root in Time Series Regression.(1988).Biometrika.
Saikkonen P,Luukkonen R.Testing for a moving average unit root in autoregressive integrated moving average models.(1993).Journal of the American Statistical Association.
Sargan J D,Bhargava A.Maximum Likelihood Estimation of Regression Models with First Order Moving Average Errors When the Roots Lies on the Unit Circle.(1983).Econometrica.
SCA-Corp.The SCA Statistical System, versión VI 3a.(2001).SCA Corp.Illinois.
Schwartz G.Estimating the Dimension of a Model.(1978).The Annals of Statistics.
Schwert G W.Tests for Unit Roots: A Monte Carlo Investigation.(1989).Journal of Business and Economics Statistics.
Shephard N.Distribution of the ML Estimator of an MA(1) Model and a Local Level Model.(1993).Econometric Theory.
Shephard N,Harvey A.On the Probability of Estimating a Deterministic Component in the local Level Model.(1990).Journal of Time Series Analysis.
Tanaka K.Testing for a Moving Average Unit Root.(1990).Econometric Theory.
Tsay R S.Testing for Noninvertible Models with Applications.(1993).Journal of Business and Economic Statistics.
Wei W.Time Series Analysis Univariate and Multivariate Methods.(2006).Pearson Addison Wesley.Boston.
West M,Harrison J.Bayesian Forecasting and Dynamic Models.(1989).Springer-Verlag.New York.
Young P.Recursive Estimation and Time-Series Analysis.(1984).Springer-Verlag.Berlín.