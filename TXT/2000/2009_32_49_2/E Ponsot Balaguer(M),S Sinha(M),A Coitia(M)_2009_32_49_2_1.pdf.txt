Sobre la agrupaciÃ³n de niveles del factor explicativo en el modelo logit binario
Universidad de Los Andes
Resumen
Se discute el efecto que se produce sobre el modelo logit binario con un Ãºnico factor explicativo cuando el investigador decide agrupar algunos niveles de dicho factor. Con base en la parametrizaciÃ³n de referencia y el modelo saturado se sugiere un procedimiento que, aprovechando los cÃ³mputos de un primer ajuste logit y corrigiendo el supuesto distribucional sobre la varianza,produce estimaciones mÃ¡s eficientemente y con mayor precisiÃ³n que las que se producen si solo se decide reiterar un ajuste logit. Una vez colocado el tema en perspectiva, se desarrollan las ecuaciones que sustentan el procedimiento sugerido, apelando a la teorÃ­a asintÃ³tica. Se ilustra mediante un ejemplo la diferencia entre el procedimiento sugerido y el habitual y, con base en una extensa simulaciÃ³n, se muestran tendencias sÃ³lidas a favor del primero, en la medida en que las probabilidades de Ã©xito de la variable respuesta (Y=1),asociadas con las categorÃ­as del factor explicativo incluidas en la agrupaciÃ³n,sean mÃ¡s disÃ­miles entre sÃ­.
Palabras clave: modelo logit, agregaciÃ³n de niveles, datos agregados, tablas de contingencia, modelo lineal generalizado.
IntroducciÃ³n
El modelo logit ha sido en las Ãºltimas dÃ©cadas una herramienta de gran utilidad en el anÃ¡lisis estadÃ­stico de datos categÃ³ricos y tablas de contingencia (vÃ©ase
por ejemplo Christensen 1997, Powers & Xie 1999, Hosmer & Lemeshow 2000,
Agresti 2007, Hilbe 2009). Se desprende como un caso particular del modelo lineal
generalizado cuando los datos se suponen distribuidos de forma binomial. Bajo
este supuesto, se utiliza logit como funciÃ³n de enlace canÃ³nico entre los compo-
nentes aleatorio y sistemÃ¡tico del modelo (McCullagh & Nelder 1989, p. 30), y se
postulan factores o tratamientos explicativos, al estilo del diseÃ±o de experimentos
y el anÃ¡lisis de varianza convencionales.
    Este modelo propone que el logaritmo de la posibilidad, entendida como el
cociente entre la probabilidad de Ã©xito y la de fracaso en un ensayo de Bernoulli,
es igual a una funciÃ³n lineal en los parÃ¡metros, denominada usualmente predic-
tora lineal. Su propÃ³sito es estimar y establecer la significancia estadÃ­stica de los
factores, frente a una respuesta observada. En el proceso, operando con la inver-
sa del logaritmo de posibilidad en funciÃ³n de la predictora lineal, se predicen las
probabilidades de Ã©xito en cada combinaciÃ³n de niveles de los factores.
   En particular y a efectos de simplificar la exposiciÃ³n, este trabajo supone un
modelo logit en su formulaciÃ³n mÃ¡s simple. Esto es, una variable respuesta dico-
tÃ³mica y un solo factor explicativo. Adicionalmente, se asume que las respuestas
correspondientes a los distintos niveles del factor explicativo son binomiales inde-
pendientes.
    Es comÃºn encontrar en la literatura aplicaciones de este modelo en las mÃ¡s
diversas Ã¡reas de investigaciÃ³n. Interesa particularmente aquÃ­ la situaciÃ³n en que
el investigador cuenta con una tabla de contingencia (obtenida en un estudio pros-
pectivo o por muestreo, por ejemplo) y, luego de postular y ajustar un modelo
logit a los datos, Ã©l mismo decide agrupar algunos niveles del factor y reiterar el
anÃ¡lisis, en el sentido de ajustar nuevamente un modelo logit sobre la tabla de
contingencia resultante de la agrupaciÃ³n.
   Por ejemplo, este procedimiento es sugerido en Hosmer & Lemeshow (2000, p.
136) como estrategia para subsanar el inconveniente de respuestas con muy baja
o ninguna representaciÃ³n en la tabla de contingencia. Esta eventualidad ocasiona
problemas numÃ©ricos ya que, cuando su ajuste se lleva a cabo por medios asintÃ³-

                                      Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                     159

ticos, la estimaciÃ³n de los parÃ¡metros del modelo logit es exigente con respecto a
los tamaÃ±os de muestra.
    TambiÃ©n abundan los ejemplos en que el investigador agrega niveles del factor,
simplemente para disminuir la complejidad del anÃ¡lisis o bien por cuanto le in-
teresa a posteriori concentrarse en algunos niveles y tratar los restantes de forma
anÃ³nima. Un ejercicio que ilustra este proceder puede verse en Hilbe (2009, pp. 74
y 88). En su texto, de origen muy reciente, el autor desarrolla modelos a partir del
Registro Nacional Cardiovascular del CanadÃ¡, empleando en una primera oportu-
nidad la edad con cuatro niveles como factor explicativo, y en otra oportunidad
agrupando dicho factor hasta alcanzar solo dos niveles.
    Al reiterar el ajuste de un modelo logit sobre una segunda tabla de contingen-
cia con niveles agrupados de los factores, en general se incurre en una violaciÃ³n del
supuesto binomial original, con implicaciones importantes sobre las varianzas esti-
madas. Este es el centro de la investigaciÃ³n pautada en la tesis doctoral del primer
autor (Ponsot 2009), uno de cuyos resultados parciales es el presente trabajo.
    Consecuentemente, el propÃ³sito de este artÃ­culo es ahondar sobre dicho pro-
blema y, manteniÃ©ndose en el Ã¡mbito del modelo logit, sugerir un nuevo curso
de acciÃ³n que mejore la precisiÃ³n de los resultados. La exposiciÃ³n continÃºa con la
siguiente secciÃ³n dedicada a la formulaciÃ³n del problema. La tercera secciÃ³n se des-
tina al estudio de las varianzas, tanto cuando se supone que todas las poblaciones
son binomiales (el procedimiento habitual), como cuando no es asÃ­ (el procedimien-
to sugerido). En la cuarta secciÃ³n se presenta el procedimiento sugerido cuando el
investigador agrupa los dos Ãºltimos niveles, argumentando con base en la teorÃ­a
asintÃ³tica. En la quinta secciÃ³n se comenta la extensiÃ³n natural del procedimiento
sugerido, cuando se agrupan en general k niveles (k â‰¥ 2). La sexta secciÃ³n del tra-
bajo contiene una comparaciÃ³n entre ambos procedimientos, ilustrada mediante
un ejemplo concreto. La sÃ©ptima secciÃ³n sintetiza los resultados de una simulaciÃ³n
extensa sobre 10000 tablas de contingencia generadas seudoaleatoriamente, cuyo
cÃ³digo fuente R se reproduce en el anexo. Por Ãºltimo, la octava secciÃ³n se dedica
a las conclusiones.


2. FormulaciÃ³n del problema

                           Tabla 1: Y (0, 1) vs. A(1, . . . , a).
                                                 Y
                                A        0      1     Total
                                 1      n10    n11     n1Â·
                                 2      n20    n21     n2Â·
                                 .       .      .       .
                                 ..      ..     ..      ..
                                 a      na0    na1     naÂ·
                               Total    nÂ·0    nÂ·1     nÂ·Â·


    Sea la tabla 1 un arreglo de la variable categÃ³rica Y (respuesta binaria) versus
los niveles del factor A (nominales u ordinales), en el cual nij (i = 1, . . . , a y

                                       Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

160                         Ernesto Ponsot Balaguer, Surendra Sinha & Arnaldo GoitÃ­a

j = 0, 1) representa la frecuencia simple de apariciÃ³n del i-Ã©simo nivel del factor A
y la j-Ã©sima categorÃ­a de la variable respuesta Y , entendiendo Y = 0 como fracaso
y Y = 1 como Ã©xito.
    En presencia de una respuesta binaria, la tabla 1 queda completamente especi-
ficada con los valores ni1 y niÂ· , ya que niÂ· = ni0 + ni1 . Para simplificar la notaciÃ³n,
sea entonces yi â‰¡ ni1 el nÃºmero de Ã©xitos observado en el i-Ã©simo nivel de A, y
ti â‰¡ niÂ· el total de observaciones para dicho nivel.
    La situaciÃ³n de interÃ©s en este trabajo asume que las respuestas correspon-
dientes a los distintos niveles de A son independientes entre sÃ­. TambiÃ©n se supone
que dichas respuestas, es decir, las frecuencias observadas de los niveles del factor,
provienen de una poblaciÃ³n binomial en el nÃºmero de Ã©xitos (Y = 1), esto es,
                              Ind
                           Yi âˆ¼ Bin(ti , pi ), âˆ€ i = 1, . . . , a

donde Yi es la variable aleatoria que representa el nÃºmero de Ã©xitos en la i-Ã©sima
muestra y pi , considerada constante, es la probabilidad de Ã©xito asociada. Se su-
pondrÃ¡ ademÃ¡s en este trabajo la inexistencia de sobredispersiÃ³n.
   Entre muchos modelos que pueden formularse para el caso, es de interÃ©s parti-
cular aquÃ­ el modelo logit. Dicho modelo es la versiÃ³n del tipo anÃ¡lisis de varianza
(ANOVA) del modelo de regresiÃ³n logÃ­stica, y aun cuando se conoce desde hace
varias dÃ©cadas, en la actualidad (Hilbe 2009, p. 4) se suele presentar como un caso
particular del modelo lineal generalizado, originalmente propuesto por Nelder &
Wedderburn (1972). Su formulaciÃ³n es la siguiente:

                          logit(pi ) = x0i Î², i = 1, . . . , a                         (1)
                                                 0
    En la ecuaciÃ³n (1), Î² = Î²1 Î²2 Â· Â· Â· Î²r es un vector columna de parÃ¡metros
desconocidos, con r un nÃºmero entero fijo que representa la cantidad de dichos
parÃ¡metros que el investigador ha decidido incorporar en su diseÃ±o; x0i es el i-
Ã©simo vector fila de la matriz de diseÃ±o XaÃ—r la cual, en presencia del modelo
saturado, como es el caso, resulta en una matriz cuadrada (r = a).
    La expresiÃ³n logit(pi ) es la aplicaciÃ³n de la transformaciÃ³n logit(p) = loge [p/(1âˆ’
p)] a las probabilidades de Ã©xito poblacionales supuestas para la i-Ã©sima muestra.
Para simplificar la notaciÃ³n del modelo en tÃ©rminos matriciales y hacer compati-
bles los subÃ­ndices de los elementos de la matriz X y el vector Î², el parÃ¡metro
Î²1 se corresponde en esta formulaciÃ³n con el intercepto (usualmente denotado por
Î²0 ). Las cantidades pi /(1 âˆ’ pi ) se interpretan como las â€œposibilidadesâ€ (en inglÃ©s,
odds) del Ã©xito frente al fracaso. Consecuentemente logit(pi ) modela el logaritmo
neperiano de la posibilidad en la i-Ã©sima muestra. Claramente las pi son tambiÃ©n
objeto de estimaciÃ³n, por lo cual el ajuste del modelo se produce generalmente por
la aplicaciÃ³n del mÃ©todo de Newton-Raphson, entre otros, que implica un cÃ³mputo
iterativo hasta lograr la convergencia. Otro procedimiento de estimaciÃ³n, no ite-
rativo, se conoce en la literatura como el mÃ©todo GSK, originalmente propuesto
por Grizzle et al. (1969).
    En su acepciÃ³n mÃ¡s simple es comÃºn utilizar la parametrizaciÃ³n de referencia
para la matriz X. Sin pÃ©rdida de generalidad, sea a el nivel de referencia, entonces

                                        Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                      161

dicha parametrizaciÃ³n conduce al modelo siguiente:
          ï£®            ï£¹    ï£®                 ï£¹ï£®      ï£¹ ï£®         ï£¹
            logit(p1 )        1 1 0 Â·Â·Â· 0          Î²1     Î²1 + Î²2
          ï£¯ logit(p ) ï£º     ï£¯1 0 1 Â· Â· Â· 0ï£º ï£¯ Î² ï£º ï£¯Î² + Î² ï£º
          ï£¯         2 ï£º     ï£¯                 ï£ºï£¯ 2 ï£º ï£¯ 1         3ï£º
          ï£¯      ..    ï£º    ï£¯                 ï£ºï£¯ . ï£º ï£¯            ï£º
          ï£¯            ï£º = ï£¯ ..               ï£ºï£¯ . ï£º = ï£¯      ..  ï£º                    (2)
          ï£¯       .    ï£º    ï£¯.                ï£ºï£¯ . ï£º ï£¯         .  ï£º
          ï£¯            ï£º    ï£¯                 ï£ºï£¯      ï£º ï£¯         ï£º
          ï£°logit(paâˆ’1 )ï£»    ï£°1 0 0 Â· Â· Â· 1ï£» ï£°Î²aâˆ’1 ï£» ï£°Î²1 + Î²a ï£»
            logit(pa )        1 0 0 Â·Â·Â· 0          Î²a        Î²1

   En (2), el modelo es saturado (a = r) y por lo tanto no se cuenta con los
grados de libertad suficientes para que tenga sentido el cÃ¡lculo de los estadÃ­sticos
de devianza de Pearson. Sin embargo, aÃºn pueden estimarse sus parÃ¡metros (Î²)
y determinarse su significaciÃ³n estadÃ­stica. NÃ³tese ademÃ¡s que existe X âˆ’1 puesto
que X es no singular.
   En efecto, el cÃ¡lculo del determinante por la descomposiciÃ³n en cofactores
(Xij ), por simplicidad, pivotando la Ãºltima fila de la matriz X ya que el Ãºnico de
sus elementos diferente de cero es xa1 , resulta |X| = (âˆ’1)a+1 |I| = (âˆ’1)a+1 6= 0.
    El modelo logit ha sido profusamente estudiado y caracterizado (vÃ©anse por
ejemplo Cox 1970, McCullagh & Nelder 1989, McCulloch & Searle 2001, Collett
2002, Agresti 2007, RodrÃ­guez 2008). Sin embargo, poco se ha profundizado en
las consecuencias que acarrea la violaciÃ³n de sus supuestos. En particular, son
del interÃ©s aquÃ­ las consecuencias de la violaciÃ³n del supuesto binomial para las
poblaciones subyacentes.
    AsÃ­, supÃ³ngase que el investigador decide agrupar los niveles a y aâˆ’1, haciendo
 âˆ—
yaâˆ’1  = yaâˆ’1 + ya y tâˆ—aâˆ’1 = taâˆ’1 + ta . Claramente, la situaciÃ³n puede extenderse
a mÃ¡s de dos niveles, simplemente agregando los dos Ãºltimos, luego estos con el
anterior y asÃ­ sucesivamente. El teorema 1 establece que la suma de dos varia-
bles aleatorias independientes binomiales, con probabilidades de Ã©xito en general
distintas, no resulta en una variable aleatoria binomial.
Teorema 1. Sean X1 y X2 dos variables aleatorias independientes tales que X1 âˆ¼
Bin(n1 , p1 ) y X2 âˆ¼ Bin(n2 , p2 ) con n1 â‰¤ n2 . Entonces, la variable aleatoria Z =
X1 + X2 de distribuye como sigue:
                                           k
                                     p1
                  P[Z = k] =                     (1 âˆ’ p1 )n1 (1 âˆ’ p2 )n2 S(k)          (3)
                                   1 âˆ’ p1

donde
          ï£±             !      !              i
          ï£´
          ï£´ Xk
                    n      n      p2 (1 âˆ’ p1 )
          ï£´
          ï£´           1      2
                                                  , k = 0, . . . , n1
          ï£´
          ï£´                       p1 (1 âˆ’ p2 )
          ï£´
          ï£´       kâˆ’i       i
          ï£´
          ï£´
            i=0            !      !                i
          ï£² X  k
                        n1     n2     p2 (1 âˆ’ p1 )
   S(k) =                                              , k = n1 + 1, . . . , n2
          ï£´
          ï£´            kâˆ’i      i     p1 (1 âˆ’ p2 )
          ï£´
          ï£´ i=kâˆ’n 1        !      !                i
          ï£´
          ï£´   Xn2
          ï£´
          ï£´             n1     n2     p2 (1 âˆ’ p1 )
          ï£´
          ï£´                                            , k = n2 + 1, . . . , n1 + n2
          ï£³            kâˆ’i      i     p1 (1 âˆ’ p2 )
               i=kâˆ’n1



                                       Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

162                            Ernesto Ponsot Balaguer, Surendra Sinha & Arnaldo GoitÃ­a

DemostraciÃ³n.

                                                 0
                                                 X
        P[Z = 0] = P[X1 = 0, X2 = 0] =                 P[X1 = 0 âˆ’ i, X2 = i]
                                                 i=0
        P[Z = 1] = P[X1 = 1, X2 = 0] + P[X1 = 0, X2 = 1]
                      1
                      X
                  =         P[X1 = 1 âˆ’ i, X2 = i]
                      i=0
                 ..
                  .
       P[Z = n1 ] = P[X1 = n1 , X2 = 0] + Â· Â· Â· + P[X1 = 0, X2 = n1 ]
                    n1
                    X
                  =    P[X1 = n1 âˆ’ i, X2 = i]
                      i=0
  P[Z = n1 + 1] = P[X1 = n1 , X2 = 1] + Â· Â· Â· + P[X1 = 0, X2 = n1 + 1]
                       1 +1
                      nX
                  =           P[X1 = n1 + 1 âˆ’ i, X2 = i]
                      i=1
                 ..
                  .
       P[Z = n2 ] = P[X1 = n1 , X2 = n2 âˆ’ n1 ] + Â· Â· Â· + P[X1 = 0, X2 = n2 ]
                      n2
                      X
                  =        P[X1 = n2 âˆ’ i, X2 = i]
                      i=n2 âˆ’n1

  P[Z = n2 + 1] = P[X1 = n1 , X2 = n2 âˆ’ n1 + 1] + Â· Â· Â· + P[X1 = 1, X2 = n2 ]
                     n2
                     X
                =          P[X1 = n2 + 1 âˆ’ i, X2 = i]
                      i=n2 âˆ’n1 +1
                 ..
                  .
                                                    n2
                                                    X
 P[Z = n2 + n1 ] = P[X1 = n1 , X2 = n2 ] =                P[X1 = n1 + n2 âˆ’ i, X2 = i]
                                                   i=n2
                 ï£±Pk
                 ï£´
                 ï£²Pi=0 P[X1 = k âˆ’ i, X2 = i], k = 0, . . . , n1
                    k
      âˆ´ P[Z = k]    i=kâˆ’n1 P[X1 = k âˆ’ i, X2 = i], k = n1 + 1, . . . , n2
                 ï£´ P
                 ï£³ n2
                    i=kâˆ’n1 P[X1 = k âˆ’ i, X2 = i], k = n2 + 1, . . . , n1 + n2




Ahora bien, como X1 y X2 son independientes, para r = 0, 1, . . . , n1 y s =
0, 1, . . . , n2 , se tiene que:


                                                             
                                        n1 r                   n2 s
          P[X1 = r, X2 = s] =               p1 (1 âˆ’ p1 )n1 âˆ’r     p2 (1 âˆ’ p2 )n2 âˆ’s
                                        r                      s

                                           Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                              163

   Luego, para un k fijo, llÃ¡mese i(k) al rango correspondiente de cada sumatoria
implicada en P[Z = k]. Entonces:
X                            X  n1                          
                                           kâˆ’i        n1 âˆ’k+i n2
   P[X1 = k âˆ’ i, X2 = i] =                p (1 âˆ’ p1 )              pi2 (1 âˆ’ p2 )n2 âˆ’i
                                  kâˆ’i 1                        i
i(k)                                i(k)
                                                k
                                          p1
                               =                      (1 âˆ’ p1 )n1 (1 âˆ’ p2 )n2
                                        1 âˆ’ p1
                                                                 X  n1  n2   p2 (1 âˆ’ p1 ) i
                                                                        kâˆ’i      i   p1 (1 âˆ’ p2 )
                                                                 i(k)


       Consecuentemente,
                               k
                           p1
                 P[Z = k] =        (1 âˆ’ p1 )n1 (1 âˆ’ p2 )n2 S(k), donde:
                         1 âˆ’ p1
          ï£±           !       !              i
          ï£´
          ï£´ Xk
                   n1      n2    p2 (1 âˆ’ p1 )
          ï£´
          ï£´                                      , k = 0, . . . , n1
          ï£´
          ï£´                      p1 (1 âˆ’ p2 )
          ï£´
          ï£´       kâˆ’i       i
          ï£´
          ï£´
            i=0           !      !                i
          ï£² X  k
                      n1      n2     p2 (1 âˆ’ p1 )
   S(k) =                                             , k = n1 + 1, . . . , n2
          ï£´
          ï£´          kâˆ’i       i     p1 (1 âˆ’ p2 )
          ï£´
          ï£´ i=kâˆ’n1        !      !                i
          ï£´
          ï£´   Xn2
          ï£´
          ï£´           n1      n2     p2 (1 âˆ’ p1 )
          ï£´
          ï£´                                           , k = n2 + 1, . . . , n1 + n2
          ï£³          kâˆ’i       i     p1 (1 âˆ’ p2 )
                  i=kâˆ’n1




    El corolario 1 establece, empleando el teorema 1, que la distribuciÃ³n binomial
se obtiene cuando las probabilidades de Ã©xito son iguales.
Corolario 1. p1 = p2 = p â‡’ Z âˆ¼ Bin(n = n1 + n2 , p).

DemostraciÃ³n.
                                                k
                                          p1
                     P[Z = k] =                       (1 âˆ’ p1 )n1 (1 âˆ’ p2 )n2 S(k)
                                        1 âˆ’ p1
                                  = pk (1 âˆ’ p)nâˆ’k S(k)

       Y ya que {[p2 (1 âˆ’ p1 )]/[p1 (1 âˆ’ p2 )]}i = {[p(1 âˆ’ p)]/[p(1 âˆ’ p)]}i = 1 para i finito,
                         ï£± k 
                         ï£´    X n1  n2 
                         ï£´
                         ï£´                          , k = 0, . . . , n1
                         ï£´
                         ï£´
                         ï£´
                         ï£´           kâˆ’i        i
                         ï£´
                         ï£´    i=0
                                              
                         ï£² X     k
                                         n1       n2
             S(k) =                                     , k = n1 + 1, . . . , n2
                         ï£´
                         ï£´              kâˆ’i        i
                         ï£´
                         ï£´    i=kâˆ’n1
                                              
                         ï£´
                         ï£´      n2
                                X
                         ï£´
                         ï£´               n1       n2
                         ï£´
                         ï£³                              , k = n2 + 1, . . . , n1 + n2
                                        kâˆ’i        i
                              i=kâˆ’n1


                                             Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

164                          Ernesto Ponsot Balaguer, Surendra Sinha & Arnaldo GoitÃ­a

    Ahora, haciendo uso de propiedades combinatorias (Rohatgi & Ehsanes 2001,
Feller 1968), se tiene:

 a) Para k = 0, . . . , n1
                              k 
                              X                                           
                                  n1   n2                     n1 + n2          n
                     S(k) =                           =                     =
                                      kâˆ’i         i              k             k
                              i=0


 b) Para k = n1 + 1, . . . , n2

               Xk         
                       n1     n2
      S(k) =
                      kâˆ’i      i
             i=kâˆ’n1
                                                                
               n1 + n2 âˆ’ n2       n2        n1 + n2 âˆ’ n2        n2
           =                            +                                + Â·Â·Â·
                    n1         k âˆ’ n1          n1 âˆ’ 1      k âˆ’ (n1 âˆ’ 1)
                                             
               n1 + n2 âˆ’ n2    n2       n1 + n2       n
           +                         =            =
                    0           k          k          k

  c) Para k = n2 + 1, . . . , n1 + n2
                Xn2         
                         n1    n2
      S(k) =
                        kâˆ’i     i
              i=kâˆ’n1
                                                                
                n1 + n2 âˆ’ n2      n2        n1 + n2 âˆ’ n2        n2
            =                           +                                + Â·Â·Â·
                      n1        k âˆ’ n1         n1 âˆ’ 1      k âˆ’ (n1 âˆ’ 1)
                                             
                n1 + n2 âˆ’ n2    n2      n1 + n2       n
            +                        =            =
                    k âˆ’ n2      n2         k          k

                                                          
                                  k         nâˆ’k           n k
               âˆ´ P [Z = k] = p (1 âˆ’ p)            S(k) =     p (1 âˆ’ p)nâˆ’k
                                                          k

Corolario 2. E[Z] = n1 p1 + n2 p2 y V[Z] = n1 p1 (1 âˆ’ p1 ) + n2 p2 (1 âˆ’ p2 ).

DemostraciÃ³n. Por una parte,

                E[Z] = E[X1 + X2 ] = E[X1 ] + E[X2 ] = n1 p1 + n2 p2

y dado que X1 y X2 son independientes, entonces:

       V[Z] = V[X1 + X2 ] = V[X1 ] + V[X2 ] = n1 p1 (1 âˆ’ p1 ) + n2 p2 (1 âˆ’ p2 )

    La ecuaciÃ³n (3) es una generalizaciÃ³n de la suma de ensayos de Poisson (Feller
1968, p. 218), es decir, ensayos independientes de Bernoulli con probabilidades de
Ã©xito en general diferentes. Se trata de una realizaciÃ³n particular de la distribuciÃ³n
de probabilidades conocida en la literatura como Poisson-Binomial (Wang 1993, p.
298), y ha sido estudiada desde varios puntos de vista a partir de la apariciÃ³n de los

                                        Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                    165

trabajos de Neyman (1939). No obstante, al no tener una forma analÃ­tica simple,
ha recibido atenciÃ³n casi exclusivamente por la vÃ­a de las aproximaciones numÃ©-
ricas (Sprott 1958, Hodges & Le Cam 1960, Ollero & Ramos 1991, Weba 1999,
Roos 1999, Neammanee 2005). En particular, la estimaciÃ³n de sus parÃ¡metros no
presenta problemas desde el punto de vista numÃ©rico, menos aÃºn hoy en dÃ­a con
la gran capacidad computacional disponible. Sin embargo, su tratamiento analÃ­-
tico, por ejemplo, como factor en la funciÃ³n de verosimilitud, es de complejidad
considerable.
    Claramente, establecidos los supuestos de un primer modelo logit sobre la tabla
1, un segundo modelo logit sobre una nueva tabla que agrupe los niveles a âˆ’ 1 y a,
en el caso en que paâˆ’1 6= pa , violenta el supuesto binomial original en la muestra
correspondiente al Ãºltimo de los niveles de la variable respuesta, es decir, aquel
que surge de la agrupaciÃ³n. AdemÃ¡s, puede descartarse su pertenencia a la familia
exponencial, ya que la conformaciÃ³n de la densidad de probabilidades depende del
recorrido de la variable aleatoria como se aprecia en (3).
    Este obstÃ¡culo es de consideraciÃ³n puesto que el modelo logit, en el contexto
del modelo lineal generalizado, supone una funciÃ³n de enlace canÃ³nico deducida a
partir de la pertenencia de la distribuciÃ³n de la muestra a la familia exponencial.
Una alternativa serÃ­a entonces proceder con base en la funciÃ³n de cuasiverosimi-
litud (Wedderburn 1974) en lugar de la funciÃ³n de verosimilitud. Sin embargo,
tampoco es posible encontrar una relaciÃ³n funcional entre la media y la varian-
za exclusivamente para la distribuciÃ³n en (3), con lo cual queda descartada esta
posibilidad (McCullagh & Nelder 1989, p. 337).
   Procurando mantener el problema en el Ã¡mbito del modelo lineal generalizado
y modelo logit, este trabajo persigue entonces estudiar las dos aristas siguientes:

  1. CuÃ¡l es el efecto de la agregaciÃ³n de niveles sobre las estimaciones y las
     pruebas de hipÃ³tesis y, para el caso en que tal efecto resulte importante,
     cÃ³mo pueden mejorarse los resultados en el sentido de la disminuciÃ³n en
     la longitud de los intervalos de confianza estimados o, equivalentemente,
     aumentando la precisiÃ³n de los estimadores.

  2. CÃ³mo puede aprovecharse la informaciÃ³n obtenida a partir de un primer
     modelo logit en el ajuste de un segundo modelo con niveles agregados del
     factor.

   Para ello se adoptan argumentos de naturaleza asintÃ³tica, basados en el teore-
ma del LÃ­mite Central (TLC) (Lehmann 1999, p. 73) y el mÃ©todo delta (Lehmann
1999, p. 86).


3. Estudio de las varianzas
    Como se dijo, el modelo logit supone una distribuciÃ³n binomial en el nÃºmero
de Ã©xitos de la variable respuesta en cada nivel del factor explicativo. Ello implica
la suposiciÃ³n V[Yi ] = ti pi (1 âˆ’ pi ) para todo i = 1, . . . , a. Sin embargo, cuando el

                                      Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

166                           Ernesto Ponsot Balaguer, Surendra Sinha & Arnaldo GoitÃ­a

investigador agrupa dos niveles cualesquiera, por ejemplo a âˆ’ 1 y a, formando una
                             âˆ—
nueva variable aleatoria Yaâˆ’1    = Yaâˆ’1 + Ya , y nuevamente ejecuta el procedimiento
                                                                                 âˆ—
de ajuste del modelo logit, implÃ­citamente supone la varianza como VBin [Yaâˆ’1       ]=
 âˆ—     âˆ—         âˆ—             âˆ—                    âˆ—           âˆ—     âˆ—
taâˆ’1 paâˆ’1 (1 âˆ’ paâˆ’1 ), donde taâˆ’1 = taâˆ’1 + ta y paâˆ’1 = E[Yaâˆ’1 ]/taâˆ’1 = (taâˆ’1 paâˆ’1 +
ta pa )/(taâˆ’1 + ta ).
    Ahora bien, como se prueba en el corolario 2, una expresiÃ³n adecuada para la
                   âˆ—
varianza es V[Yaâˆ’1    ] = taâˆ’1 paâˆ’1 (1 âˆ’ paâˆ’1 ) + ta pa (1 âˆ’ pa ). El teorema 2 muestra
que ambas expresiones de la varianza no son equivalentes y de hecho, para valores
                                                   âˆ—           âˆ—
dados de los parÃ¡metros, se tiene que VBin [Yaâˆ’1      ] â‰¥ V[Yaâˆ’1   ].
                      âˆ—
Teorema 2. Con Yaâˆ’1      = Yaâˆ’1 + Ya , para valores dados de taâˆ’1 , ta , paâˆ’1 , pa ,
        âˆ—          âˆ—
VBin [Yaâˆ’1 ] â‰¥ V[Yaâˆ’1 ].

DemostraciÃ³n.
        âˆ—
VBin [Yaâˆ’1 ] = tâˆ—aâˆ’1 pâˆ—aâˆ’1 (1 âˆ’ pâˆ—aâˆ’1 )
                                                                         
                                taâˆ’1 paâˆ’1 + ta pa         taâˆ’1 paâˆ’1 + ta pa
             = (taâˆ’1 + ta )                          1âˆ’
                                   taâˆ’1 + ta                 taâˆ’1 + ta
                 2                         2
               t     paâˆ’1 (1 âˆ’ paâˆ’1 ) + ta pa (1 âˆ’ pa ) + taâˆ’1 ta [paâˆ’1 + pa âˆ’ 2paâˆ’1 pa ]
             = aâˆ’1
                                                taâˆ’1 + ta
               taâˆ’1 V[Yaâˆ’1 ] + ta V[Ya ] + taâˆ’1 ta [paâˆ’1 + pa âˆ’ 2paâˆ’1 pa ]
             =
                                          taâˆ’1 + ta

  Sea âˆ†V el incremento en varianza entre ambos supuestos, definido como âˆ†V =
        âˆ—          âˆ—
VBin [Yaâˆ’1 ] âˆ’ V[Yaâˆ’1 ]. Entonces:
        taâˆ’1 V[Yaâˆ’1 ] + ta V[Ya ] + taâˆ’1 ta [paâˆ’1 + pa âˆ’ 2paâˆ’1 pa ]
 âˆ†V =                                                                âˆ’ V[Yaâˆ’1 ] âˆ’ V[Ya ]
                                 taâˆ’1 + ta
        taâˆ’1 ta [paâˆ’1 + pa âˆ’ 2paâˆ’1 pa ] âˆ’ ta V[Yaâˆ’1 ] âˆ’ taâˆ’1 V[Ya ]
      =
                                 taâˆ’1 + ta
        taâˆ’1 ta [paâˆ’1 + pa âˆ’ 2paâˆ’1 pa ] âˆ’ ta taâˆ’1 paâˆ’1 + ta taâˆ’1 p2aâˆ’1 âˆ’ taâˆ’1 ta pa + taâˆ’1 ta p2a
      =
                                               taâˆ’1 + ta
        âˆ’2taâˆ’1 ta paâˆ’1 pa + ta taâˆ’1 p2aâˆ’1 + taâˆ’1 ta p2a
      =
                          taâˆ’1 + ta
          taâˆ’1 ta
      =            (paâˆ’1 âˆ’ pa )2                                                               (4)
        taâˆ’1 + ta

                              âˆ—          âˆ—
  Claramente âˆ†V â‰¥ 0 â‡’ VBin [Yaâˆ’1 ] â‰¥ V[Yaâˆ’1 ]. En particular, si paâˆ’1 = pa â‡’
        âˆ—          âˆ—
VBin [Yaâˆ’1 ] = V[Yaâˆ’1 ].

   La figura 1 ilustra el comportamiento de ambas varianzas cuando se fijan los
parÃ¡metros taâˆ’1 , ta , paâˆ’1 , evaluando la cantidad pa en los niveles 0.3, 0.5, 0.8.
    Una discusiÃ³n interesante sobre el tema, partiendo de una sucesiÃ³n de ensayos
de Poisson, puede consultarse en Nedelman & Wallenius (1986) y en las referencias
citadas allÃ­. Ahora bien, del examen de la ecuaciÃ³n (4) se desprenden dos hechos
importantes:

                                          Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                     167




      Figura 1: ComparaciÃ³n de VBin [Yaâˆ’1
                                      âˆ—
                                          ] y V[Yaâˆ’1
                                                 âˆ—
                                                     ] con taâˆ’1 = 20, ta = 50.


  1. âˆ†V es directamente proporcional al cuadrado de la diferencia entre paâˆ’1 y
     pa , siempre positivo o nulo (llÃ¡mese âˆ†p = |paâˆ’1 âˆ’ pa |). Por consiguiente, sin
     importar cuÃ¡les sean los valores de paâˆ’1 y pa que originan âˆ†p, mientras mÃ¡s
     distantes estÃ©n entre sÃ­, tanto mayor serÃ¡ la diferencia entre ambas varianzas.
  2. âˆ†V es tambiÃ©n directamente proporcional a la funciÃ³n:
                              T (taâˆ’1 , ta ) = taâˆ’1 ta /(taâˆ’1 + ta )
      estrictamente positiva y creciente. Por lo tanto, la diferencia entre ambas
      varianzas se incrementarÃ¡ en la medida en que aumenten simultÃ¡neamente
      taâˆ’1 y ta , o cualquiera de ellos, manteniÃ©ndose constante el otro. AdemÃ¡s, sin
      pÃ©rdida de generalidad, supÃ³ngase que taâˆ’1 â‰¤ ta . En tal caso T es mÃ¡xima
      cuando taâˆ’1 = ta = t y âˆ†V = t(âˆ†p)2 /2.
    AsÃ­, es clara la existencia de un problema cuando se agrupan niveles y se insiste
en el modelo logit sin variar el supuesto binomial, especialmente en lo relacionado
con la estimaciÃ³n de las varianzas y, en consecuencia, de los errores estÃ¡ndares
utilizados para las pruebas de hipÃ³tesis sobre los parÃ¡metros del modelo.

                                       Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

168                            Ernesto Ponsot Balaguer, Surendra Sinha & Arnaldo GoitÃ­a

4. El procedimiento sugerido
    La estimaciÃ³n mÃ¡ximo-verosÃ­mil de los parÃ¡metros en el modelo logit (1) se
lleva a cabo, bajo el supuesto binomial, mediante por ejemplo la aplicaciÃ³n del mÃ©-
todo de Newton-Raphson al sistema de ecuaciones de las primeras derivadas par-
ciales del logaritmo de la funciÃ³n de verosimilitud, respecto a los Î²j (j = 1, . . . , r),
igualadas a cero. Las probabilidades de Ã©xito poblacionales en la verosimilitud se
                                                  0         0
sustituyen, despejando del modelo, como pi = exi Î² /(1 + exi Î² ) para i = 1, . . . , a. En
el procedimiento se itera hasta tanto la diferencia entre dos estimaciones sucesivas
de Î² sea despreciable.
     La Ãºltima iteraciÃ³n del mÃ©todo produce las estimaciones mÃ¡ximo-verosÃ­miles
tanto de pi como de Î², cuyos estimadores se denotan respectivamente por pbi y
b McCullagh & Nelder (1989, p. 119) demuestran que, asintÃ³ticamente, es decir,
Î².
cuando los yi son suficientemente grandes,           b
                                     h i el vector Î² obtenido por este mecanismo
                                                                           
es un estimador insesgado de Î² y V Î²b = (X 0 W X)âˆ’1 , donde W = diag ti pi (1 âˆ’
    
pi ) . Este resultado es vÃ¡lido para cualesquiera matriz de diseÃ±o XaÃ—r y vector
columna de parÃ¡metros Î²r . En particular, es vÃ¡lido tambiÃ©n para el caso del modelo
saturado en el cual a = r.
    Luego, en presencia del modelo saturado (2) que postula la equivalencia en-
tre logit(pi ) y la funciÃ³n predictora lineal x0i Î² (en tÃ©rminos matriciales XÎ²),
sustituyendo
  h    i       los parÃ¡metros por sus estimadores se tiene que, asintÃ³ticamente,
      b
V X Î² = X(X 0 W X)âˆ’1 X 0 = XX âˆ’1 W âˆ’1 (X 0 )âˆ’1 X 0 = W âˆ’1 . Por consiguiente
y como consecuencia del TLC, asÃ­ como de las propiedades de los estimadores
mÃ¡ximo-verosÃ­miles, se tiene que:
                                                               âˆ’1 
                        pi ) = x0i Î²b âˆ¼ AN x0i Î², ti pi (1 âˆ’ pi )
                  logit(b                                                     (5)

   NÃ³tese que tanto en la ecuaciÃ³n (5) como en las que siguen se ha decidido
emplear la notaciÃ³n â€œANâ€, frecuente en la literatura estadÃ­stica, como abreviatura
de la frase â€œasintÃ³ticamente normalâ€. Ahora bien, empleando el mÃ©todo delta a
partir de la ecuaciÃ³n (5) se tiene:

                              0 b
                           e xi Î²                    
                                            âˆ’1    0b
                  pbi =             0 b
                                        = g     x i Î²
                       1 + e xi Î²
                          0          0           0       0             0
      d g âˆ’1 (x0i Î²)   e xi Î² 1 + e xi Î² âˆ’ e xi Î² e xi Î²             e xi Î²
                     =                    0 2
                                                             =             0 2
                                                                                  = pi (1 âˆ’ pi )
        d (x0i Î²)                 1 + e xi Î²                       1 + e xi Î²
                                          0                      2                   !
                                       e xi Î²         pi (1 âˆ’ pi )        pi (1 âˆ’ pi )
              â‡’ pbi âˆ¼ AN pi =                 0 ;                     =                            (6)
                                    1 + exi Î² ti pi (1 âˆ’ pi )                  ti

ya que la funciÃ³n g âˆ’1 (Â·) es no nula y diferenciable.
    Entonces, la ecuaciÃ³n (6) implica que el investigador conoce la distribuciÃ³n
asintÃ³tica del estimador de las probabilidades de Ã©xito para el modelo (2). En

                                             Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                           169

particular, cumplido el procedimiento de ajuste,
                                             .h  el investigador
                                                        i        tiene la estimaciÃ³n
                                         0 b        0 b
mediante el modelo logit de pi , pbi = exi Î² 1 + exi Î² y la varianza asintÃ³tica del
             pi ] = pi (1 âˆ’ pi )/ti .
estimador V [b
    Ahora bien, siguiendo la notaciÃ³n definida en la secciÃ³n anterior, cuando se
agrupan los niveles a âˆ’ 1 y a, el estimador mÃ¡ximo-verosÃ­mil de la nueva probabi-
lidad de Ã©xito pâˆ—aâˆ’1 es
                            \
                           E[Y  âˆ—       \         [
                               aâˆ’1 ]   E[Yaâˆ’1 ] + E[Ya ]   taâˆ’1 pbaâˆ’1 + ta pba
               pbâˆ— aâˆ’1 =     âˆ—       =                   =                                  (7)
                            taâˆ’1          taâˆ’1 + ta           taâˆ’1 + ta

   Considerando el corolario 2, claramente pbâˆ— aâˆ’1 es un estimador insesgado de
 âˆ—
paâˆ’1 . El teorema 3 demuestra cÃ³mo se distribuye este nuevo estimador cuando
taâˆ’1 y ta son suficientemente grandes.
Teorema 3. Si los pbi se distribuyen independientes como en (6) para i = a âˆ’ 1 e
i = a, entonces:
                   taâˆ’1 pbaâˆ’1 + ta pba
         pbâˆ— aâˆ’1 =
                      taâˆ’1 + ta
                                                                                   
                          taâˆ’1 paâˆ’1 + ta pa taâˆ’1 paâˆ’1 (1 âˆ’ paâˆ’1 ) + ta pa (1 âˆ’ pa )
                 âˆ¼ AN                      ;
                             taâˆ’1 + ta                   (taâˆ’1 + ta )2

DemostraciÃ³n. Claramente, en el lÃ­mite, pbâˆ— aâˆ’1 es la suma ponderada de dos
funciones lineales de variables aleatorias independientes asintÃ³ticamente normales.
Luego, su distribuciÃ³n asintÃ³tica tambiÃ©n es normal. Ahora bien, por un lado se
tiene que:
                h      i t         paâˆ’1 ] + ta E[b
                             aâˆ’1 E[b             pa ]   taâˆ’1 paâˆ’1 + ta pa
              E pbâˆ— aâˆ’1 =                             =
                                   taâˆ’1 + ta               taâˆ’1 + ta
y por el otro:
      h      i t2 V[b paâˆ’1 ] + t2a V[b
                                     pa ]   taâˆ’1 paâˆ’1 (1 âˆ’ paâˆ’1 ) + ta pa (1 âˆ’ pa )
    V pbâˆ— aâˆ’1 = aâˆ’1                       =
                    (taâˆ’1 + ta )2                        (taâˆ’1 + ta )2

    El teorema
              4, empleando nuevamente el mÃ©todo delta, identifica la distribuciÃ³n
          bâˆ—
de logit p aâˆ’1 requerida.

Teorema 4. Si pbâˆ— aâˆ’1 se distribuye como en el teorema 3, entonces:
                                                 âˆ— 
                      logit pbâˆ— aâˆ’1 âˆ¼ AN Âµâˆ—aâˆ’1 , Ïƒ 2 aâˆ’1

donde:
                                               
                              taâˆ’1 paâˆ’1 + ta pa
          Âµâˆ—aâˆ’1 = logit                           , y
                                 taâˆ’1 + ta
         âˆ—                          taâˆ’1 paâˆ’1 (1 âˆ’ paâˆ’1 ) + ta pa (1 âˆ’ pa )
      Ïƒ 2 aâˆ’1 =                                               taâˆ’1 ta                 2
                    taâˆ’1 paâˆ’1 (1 âˆ’ paâˆ’1 ) + ta pa (1 âˆ’ pa ) + taâˆ’1                 2
                                                                   +ta (paâˆ’1 âˆ’ pa )



                                            Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

170                         Ernesto Ponsot Balaguer, Surendra Sinha & Arnaldo GoitÃ­a

DemostraciÃ³n. Claramente la funciÃ³n logit es no nula y diferenciable, luego el
mÃ©todo delta garantiza la normalidad asintÃ³tica con la esperanza seÃ±alada. Resta
probar la expresiÃ³n de la varianza asintÃ³tica, como sigue:
                                            
         âˆ—                   d logit(pâˆ—aâˆ’1 ) 2
      Ïƒ 2 aâˆ’1 = V[pbâˆ— aâˆ’1 ]
                                 d pâˆ—aâˆ’1
                                                                               2
                 [taâˆ’1 paâˆ’1 (1 âˆ’ paâˆ’1 ) + ta pa (1 âˆ’ pa )]             1
               =
                               (taâˆ’1 + ta )2                 pâˆ—aâˆ’1 (1 âˆ’ pâˆ—aâˆ’1 )
                         âˆ—                      âˆ—
                     V[Yaâˆ’1 ]              V[Yaâˆ’1 ]
               =                2 =                   
                           âˆ—
                  VBin [Yaâˆ’1 ]              âˆ— ] + âˆ†V 2
                                       V[Yaâˆ’1
                                taâˆ’1 paâˆ’1 (1 âˆ’ paâˆ’1 ) + ta pa (1 âˆ’ pa )
               =                                                                   
                                                               taâˆ’1 ta
                  taâˆ’1 paâˆ’1 (1 âˆ’ paâˆ’1 ) + ta pa (1 âˆ’ pa ) + taâˆ’1                   2 2
                                                                  +ta (paâˆ’1 âˆ’ pa )


    Para efectos de las pruebas de hipÃ³tesis e intervalos de confianza deseados, los
parÃ¡metros distribucionales se sustituyen por sus estimadores. AsÃ­, el parÃ¡metro
poblacional pi se sustituye por su estimador pbi y el vector de parÃ¡metros Î² en la
predictora lineal, por su estimador Î². b Ambos calculados a partir de la muestra
observada por el mÃ©todo de Newton-Raphson, como se seÃ±alÃ³ al inicio de esta sec-
ciÃ³n. Consecuentemente, el procedimiento propuesto en la situaciÃ³n de agregaciÃ³n
de niveles del factor es el siguiente:

  1. Ajustar un modelo logit (llÃ¡mese M ) sobre los datos como se disponen en la
     tabla 1. Preservar del cÃ³mputo el vector de estimaciones de los pi y la matriz
     estimada W .
  2. Calcular la estimaciÃ³n puntual de pâˆ—aâˆ’1 como en (7).
                                                             
                    pi ), i = 1, . . . , a âˆ’ 2 y logit pbâˆ— aâˆ’1 formando el vector
  3. Calcular logit(b

                                              pâˆ— )(aâˆ’1)Ã—1
                                        logit(b

  4. Estimar la nueva matriz asintÃ³tica de varianzas y covarianzas para la situa-
     ciÃ³n del modelo saturado como:
               ï£®                  âˆ’1                                           ï£¹
                  t1 pb1 (1 âˆ’ pb1 )    Â·Â·Â·               0                  0
               ï£¯            ..         ..                 ..                ..   ï£º
               ï£¯             .             .               .                 .   ï£º
          Î£=ï£¯  ï£¯                                                   âˆ’1          ï£º
                                                                                 ï£º
               ï£°            0          Â· Â· Â· taâˆ’2 pbaâˆ’2 (1 âˆ’ pbaâˆ’2 )        0 ï£»
                                                                               âˆ—
                            0          Â·Â·Â·               0               d
                                                                        (Ïƒ 2)
                                                                                aâˆ’1

                  âˆ—
             d
      donde (Ïƒ 2)
                  aâˆ’1 es la varianza obtenida en el teorema 4, estimada a partir de la
      muestra, sustituyendo pi por pbi . La matriz Î£ se conforma con la matriz W âˆ’1
      del ajuste logit original. Se trata de la matriz de varianzas y covarianzas del
      vector columna cuyas componentes son los logit(b   pi ), i = 1, . . . , a âˆ’ 2 [como se
      puede apreciar en la ecuaciÃ³n (5)], sustituyendo sus dos Ãºltimos elementos en

                                       Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                    171

      la diagonal por la varianza adecuada cuando se agregan los correspondientes
      dos Ãºltimos niveles del factor. Î£ resulta diagonal pues las respuestas para los
      nuevos aâˆ’1 niveles no han perdido su condiciÃ³n de independencia asintÃ³tica.
                                             âˆ—
  5. Construir la nueva matriz de diseÃ±o X(aâˆ’1)Ã—r   âˆ— segÃºn el nuevo vector de

     parÃ¡metros deseado Î²râˆ— Ã—1 . Para el modelo saturado en (2), râˆ— = a âˆ’ 1.
                         âˆ—


  6. Ajustar una regresiÃ³n de mÃ­nimos cuadrados generalizados (Christensen 2002,
     pp. 34 y 88) con un nuevo modelo (llÃ¡mese M âˆ— ) formulado como sigue:

                        Y = logit(pbâˆ— ) = X âˆ— Î² âˆ— + ,  âˆ¼ AN(0, Î£)                  (8)

    Ahora bien, en la situaciÃ³n estudiada, considerando la parametrizaciÃ³n de re-
ferencia, el modelo saturado y en consecuencia la existencia de la matriz (X âˆ— )âˆ’1 ,
los cÃ³mputos se simplifican notablemente como sigue:

                               Î²bâˆ— = (X âˆ— )âˆ’1 Y
                             h i                h      i0
                              bâˆ— = (X âˆ— )âˆ’1 Î£ (X âˆ— )âˆ’1
                            V Î²

    Adicionalmente, el procedimiento sugerido presenta una ventaja computacional
frente al procedimiento habitual: como se ha mencionado, al ajustar un modelo
logit en general se recurre al mÃ©todo de Newton-Raphson. Este mÃ©todo implica
una serie de iteraciones hasta alcanzar la convergencia en la estimaciÃ³n de los
parÃ¡metros. En cada iteraciÃ³n es necesario invertir la matriz X 0 W X (si el modelo
es no saturado) o bien la matriz W (si el modelo es saturado). Luego, al ejecutar
el procedimiento de ajuste del modelo logit en dos ocasiones, se duplica el esfuerzo
computacional dedicado a la inversiÃ³n de matrices. Por otra parte, siguiendo el
procedimiento sugerido, es necesario dedicar tiempo de cÃ³mputo a la inversiÃ³n de
matrices una sola vez, pues el segundo ajuste surge aprovechando los resultados
obtenidos en la primera oportunidad, sin necesidad de iterar nuevamente.


5. ExtensiÃ³n al caso cuando se agrupa un nÃºmero
   cualquiera k de niveles (1 < k < a)
    Para efectos de simplificar la exposiciÃ³n, el procedimiento sugerido considera la
agrupaciÃ³n de los dos Ãºltimos niveles del factor explicativo. No obstante, es sencillo
observar que dicho procedimiento puede extenderse al caso cuando el investigador
decide agrupar k (1 < k < a) niveles. Evidentemente, sigue en pie la violaciÃ³n
del supuesto distribucional, cuando al menos dos de las probabilidades de Ã©xito
involucradas en la agrupaciÃ³n son distintas entre sÃ­. Por otra parte, nÃ³tese que la
posiciÃ³n que ocupan en la tabla los distintos niveles del factor es irrelevante (pues
para el caso pueden ser reacomodados). Entonces, sin pÃ©rdida de generalidad, sean
los Ãºltimos niveles a âˆ’ k + 1, a âˆ’ k + 2, . . . , a aquellos que el investigador decide
                                                    âˆ—
agrupar, formando la nueva variable aleatoria Yaâˆ’k+1      = Yaâˆ’k+1 +Yaâˆ’k+2 +Â· Â· Â·+Ya .

                                      Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

172                                          Ernesto Ponsot Balaguer, Surendra Sinha & Arnaldo GoitÃ­a

    Para simplificar los recorridos, sea Î½ = a âˆ’ k + 1. El teorema 5 establece la
diferencia entre las varianzas binomial (VBin [YÎ½âˆ— ]) y correcta (V[YÎ½âˆ— ]) para este
caso mÃ¡s general.
                                                                                                       Pa
Teorema 5. Sean VBin [YÎ½âˆ— ] = tâˆ—Î½ pâˆ—Î½ (1 âˆ’ pâˆ—Î½ ) y V[YÎ½âˆ— ] =                                                i=Î½ ti pi (1 âˆ’ pi ), donde:


                                                                                                    a
                                                                                                    X
                                     a
                                                                                                             ti p i
                                     X                                        E[YÎ½âˆ— ]
                             tâˆ—Î½ =             ti          y            pâˆ—Î½ =         = i=Î½a
                                                                                tâˆ—Î½      X
                                        i=Î½
                                                                                                              ti
                                                                                                       i=Î½


Entonces:
                                                                              aâˆ’1
                                                                              X          a
                                                                                         X
                                                                                                  ti tj (pi âˆ’ pj )2
                                                                              i=Î½ j=i+1
                       âˆ†VÎ½ = VBin [YÎ½âˆ— ] âˆ’ V[YÎ½âˆ— ] =                                             a                                            (9)
                                                                                                 X
                                                                                                       ti
                                                                                                 i=Î½




DemostraciÃ³n.
                                    ï£« a          ï£¶ï£«      a         ï£¶
                                      X                 X
                              a
                                   !ï£¬     ti p i ï£· ï£¬        ti p i ï£·  a
                             X      ï£¬ i=Î½        ï£·ï£¬                ï£· X
                 âˆ†VÎ½ =           ti ï£¬
                                    ï£¬ X a
                                                 ï£· ï£¬1 âˆ’
                                                 ï£·ï£¬
                                                        i=Î½
                                                          a
                                                                   ï£·âˆ’
                                                                   ï£·     ti pi (1 âˆ’ pi )
                                    ï£­            ï£¸ï£­      X         ï£¸ i=Î½
                             i=Î½
                                           ti                ti
                                                     i=Î½                            i=Î½


luego

      a
                 !             a
                                                 !     a                a
                                                                                       !          a
                                                                                                             !        a
                                                                                                                                          !
      X                        X                       X                X                         X                   X
            ti       âˆ†VÎ½ =              ti p i                 ti âˆ’           ti p i       âˆ’            ti                  ti pi (1 âˆ’ pi )
      i=Î½                      i=Î½                     i=Î½              i=Î½                       i=Î½                 i=Î½
                               a
                                             !       a
                                                                    !         a
                                                                                                !2
                               X                     X                        X
                        =               ti                 ti p2i       âˆ’              ti p i
                               i=Î½                   i=Î½                      i=Î½
                                                        ï£«                               ï£¶
                          a
                          X             a
                                        X    a
                                             X            a
                                                          X           a
                                                                      X        a
                                                                               X
                                                        ï£¬                               ï£·
                        =   (ti pi )2 +   ti   tj p2j âˆ’ ï£­ (ti pi )2 +   ti p i   tj p j ï£¸
                             i=Î½                      i=Î½       j=Î½                        i=Î½                     i=Î½          j=Î½
                                                              j6=i                                                              j6=i
                             a
                             X          a
                                        X                    a
                                                             X               a
                                                                             X                   a X
                                                                                                 X a
                        =          ti            tj p2j âˆ’           ti p i          tj p j =                   ti tj pj (pj âˆ’ pi )
                             i=Î½        j=Î½                  i=Î½             j=Î½                  i=Î½ j=Î½
                                        j6=i                                 j6=i                     j6=i



                                                               Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                              173

       = tÎ½ tÎ½+1 pÎ½+1 (pÎ½+1 âˆ’ pÎ½ ) + tÎ½ tÎ½+2 pÎ½+2 (pÎ½+2 âˆ’ pÎ½ ) + Â· Â· Â· + tÎ½ ta pa (pa âˆ’ pÎ½ )
       + tÎ½+1 tÎ½ pÎ½ (pÎ½ âˆ’ pÎ½+1 ) + tÎ½+1 tÎ½+2 pÎ½+2 (pÎ½+2 âˆ’ pÎ½+1 ) + Â· Â· Â·
                                 + tÎ½+1 ta pa (pa âˆ’ pÎ½+1 )
      + tÎ½+2 tÎ½ pÎ½ (pÎ½ âˆ’ pÎ½+2 ) + tÎ½+2 tÎ½+1 pÎ½+1 (pÎ½+1 âˆ’ pÎ½+2 ) + Â· Â· Â·
                                  + tÎ½+2 ta pa (pa âˆ’ pÎ½+2 )
    ..
     .
      + ta tÎ½ pÎ½ (pÎ½ âˆ’ pa ) + ta tÎ½+1 pÎ½+1 (pÎ½+1 âˆ’ pa ) + Â· Â· Â· + ta taâˆ’1 paâˆ’1 (paâˆ’1 âˆ’ pa )
       = tÎ½ tÎ½+1 [pÎ½+1 (pÎ½+1 âˆ’ pÎ½ ) + pÎ½ (pÎ½ âˆ’ pÎ½+1 )] + tÎ½ tÎ½+2 [pÎ½+2 (pÎ½+2 âˆ’ pÎ½ )
       + pÎ½ (pÎ½ âˆ’ pÎ½+2 )] + Â· Â· Â· + taâˆ’1 ta [pa (pa âˆ’ paâˆ’1 ) + paâˆ’1 (paâˆ’1 âˆ’ pa )]
           aâˆ’1
           X     a
                 X
       =               ti tj (pi âˆ’ pj )2
           i=Î½ j=i+1
                   aâˆ’1
                   X      a
                          X
                                ti tj (pi âˆ’ pj )2
                   i=Î½ j=i+1
       âˆ´ âˆ†VÎ½ =                 a
                               X
                                     ti
                               i=Î½


    AsÃ­, en general tambiÃ©n se sostiene que VBin [YÎ½âˆ— ] â‰¥ V[YÎ½âˆ— ], ya que (9) es una
cantidad no negativa. La extensiÃ³n de los teoremas 3 y 4 es inmediata:
                           ï£«                        ï£¶
          Xa                 Xa
               ti pbi      ï£¬      ti p i            ï£·
                           ï£¬               V[Y âˆ—
                                                 ]  ï£·                          
                           ï£¬                        ï£·         bâˆ— Î½ âˆ¼ AN Âµâˆ—Î½ , Ïƒ 2 âˆ—
  pbâˆ— Î½ = i=Î½a        âˆ¼ AN ï£¬ i=Î½a        ;    Î½
                                                 !  ï£·
                                                   2ï£· y logit p
           X               ï£¬ X             Xa                                     Î½
                ti         ï£­       ti               ï£¸
                                              ti
             i=Î½                     i=Î½        i=Î½

con:
                                ï£« a          ï£¶
                                  X
                                ï£¬     ti p i ï£·
                                ï£¬ i=Î½        ï£·                  V[YÎ½âˆ— ]
                     ÂµÎ½ = logit ï£¬
                      âˆ—
                                ï£¬ X a
                                             ï£· y (Ïƒ 2 )âˆ— =
                                             ï£·         Î½
                                ï£­            ï£¸             (V[YÎ½âˆ— ] + âˆ†VÎ½ )2
                                       ti
                                          i=Î½


   Consecuentemente, el procedimiento sugerido se extiende de la forma siguiente:

   1. Ajustar un modelo logit sobre los datos originales, preservando el vector de
      estimaciones de los pi y la matriz W .

   2. Calcular pbâˆ— Î½ .
                                                                                      
   3. Calcular logit pbi , i = 1, . . . , aâˆ’k y logit pbâˆ— Î½ formando el vector logit pbâˆ— (Î½Ã—1) .


                                                Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

174                        Ernesto Ponsot Balaguer, Surendra Sinha & Arnaldo GoitÃ­a

  4. Estimar la nueva matriz asintÃ³tica de covarianzas como:
                ï£®                  âˆ’1                                             ï£¹
                   t1 pb1 (1 âˆ’ pb1 )    Â·Â·Â·               0                   0
                ï£¯            .          .                  ..                  .. ï£º
                ï£¯            ..           ..                .                   . ï£º
          Î£Î½ = ï£¯ï£¯                                                   âˆ’1            ï£º
                                                                                    ï£º
                ï£°            0          Â· Â· Â· taâˆ’k pbaâˆ’k (1 âˆ’ pbaâˆ’k )         0 ï£»
                                                                                  âˆ—
                            0             Â·Â·Â·                    0           d
                                                                            (Ïƒ 2)
                                                                                 Î½

                                             âˆ—
  5. Construir la nueva matriz de diseÃ±o XÎ½Ã—r   âˆ— segÃºn el nuevo vector de parÃ¡-
                      âˆ—
     metros deseado Î²râˆ— Ã—1 . Para el modelo saturado se tendrÃ¡ que râˆ— = a âˆ’ k + 1.

  6. Ajustar una regresiÃ³n de mÃ­nimos cuadrados
                                                  generalizados con un nuevo
     modelo formulado como: Y = logit pbâˆ— = X âˆ— Î² âˆ— + , con  âˆ¼ AN(0, Î£Î½ ).

                     h i la parametrizaciÃ³n
   Y como antes, empleando                  de referencia y el modelo satura-
                                    âˆ— âˆ’1 0
    bâˆ—    âˆ— âˆ’1        bâˆ—     âˆ— âˆ’1
do, Î² = (X ) Y y V Î² = (X ) Î£Î½ (X )           .


6. Ejemplo
    En la tabla 2 se presenta una situaciÃ³n en que el interÃ©s se centra en estudiar la
relaciÃ³n entre una variable respuesta Y y un factor explicativo A con tres niveles.
Se muestran allÃ­ las frecuencias observadas para cada nivel.

                           Tabla 2: Y (0, 1) vs. A(1, 2, 3).
                                               Y
                                 A         0         1   Total
                                  1      189       161    350
                                  2      300        50    350
                                  3       32       318    350
                                Total    521       529   1050


    El modelo logit saturado empleando la parametrizaciÃ³n con Î²3 como nivel de
referencia, se muestra en la ecuaciÃ³n (10).
                          ï£®          ï£¹ ï£®                ï£¹ï£® ï£¹
                           logit(p1 )     1          1 0 Î²1
                          ï£°logit(p2 )ï£» = ï£°1          0 1ï£» ï£°Î²2 ï£»                         (10)
                           logit(p3 )     1          0 0 Î²3

   La tabla 3 contiene las estimaciones de los parÃ¡metros de la predictora lineal
con las pruebas Ï‡2 de Wald para H0 : Î²i = 0, i = 1, 2, 3 e intervalos de confianza
(IC) del 95 % construidos para Î²i .
   Las probabilidades predichas y sus intervalos de confianza siguiendo a Agresti
(2007, p. 109) se muestran en la tabla 4.
   Ahora bien, supÃ³ngase que se agrupan los niveles 2 y 3 del factor A en la tabla
2 y se repite el procedimiento para el modelo saturado. En este caso, el nuevo

                                        Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                             175

              Tabla 3: Modelo original. Î²bi y prueba de Wald (H0 : Î²i = 0).
                               EstimaciÃ³n de Î²i                              IC del 95 %
     i              Î²bi     SE          Ï‡2    p-Valo r       ConclusiÃ³n      Li        Ls
     1           2.296     0.185     153.3    < 0.0001       Rechazar       1.933     2.660
     2          âˆ’2.457     0.214     131.5    < 0.0001       Rechazar      âˆ’2.877   âˆ’2.037
     3          âˆ’4.088     0.240     289.5    < 0.0001       Rechazar      âˆ’4.559   âˆ’3.617
     SE: Error EstÃ¡ndar    Li: LÃ­mite inferior   Ls: LÃ­mite superior


           Tabla 4: Modelo original. Probabilidades predichas e IC del 95 %.
                                 i        pbi      Li        Ls
                                 1      0.4600   0.4084    0.5125
                                 2      0.1429   0.1100    0.1836
                                 3      0.9086   0.8736    0.9346


modelo es:                                               
                                     logit(pâˆ—1 )    1     1 Î²1âˆ—
                                                 =                                            (11)
                                     logit(pâˆ—2 )    1     0 Î²2âˆ—
    Las nuevas estimaciones utilizando el proceso habitual de ajuste, esto es, vol-
viendo a ajustar un modelo logit sobre la tabla de contingencia resultante, se
muestran en la tabla 5. Las probabilidades predichas por el modelo, sin atenciÃ³n
a los niveles de significaciÃ³n de los parÃ¡metros, se reproducen en la tabla 6.
                                          câˆ— y prueba de Wald (H0 : Î²iâˆ— = 0).
         Tabla 5: Procedimiento habitual. Î² i

                                EstimaciÃ³n de Î²iâˆ—                        IC del 95 %
          i      câˆ—
                 Î²         SE        Ï‡2   p-Valor       ConclusiÃ³n       Li        Ls
                    i
          1    0.103      0.076   1.850     0.174       No rechazar    âˆ’0.045     0.251
          2   âˆ’0.263      0.131   4.023     0.045       Rechazar       âˆ’0.521   âˆ’0.006



Tabla 6: Procedimiento habitual. Probabilidades predichas e IC del 95 % sin considerar
         la significaciÃ³n de los parÃ¡metros del modelo.
                                 i        c
                                          pâˆ— i     Li        Ls
                                 1      0.4600   0.4084    0.5125
                                 2      0.5257   0.4887    0.5625


    Como es de esperarse, en esta oportunidad el nuevo vector de parÃ¡metros Î² âˆ—
resulta estimado de forma diferente
                                     a la anterior. Por su parte, el nuevo vector
de probabilidades predichas pbâˆ— , sin poner atenciÃ³n a los niveles de significaciÃ³n
de los parÃ¡metros,
                    resulta igual al anterior en la primera componente pbâˆ— 1 =
pb1 = 0.460 , y diferente, pero tal como se supone deberÃ­a ocurrir, en la segunda
componente. Esto es:
                      t2 pb2 + t3 pb3   350 Ã— 0.1429 + 350 Ã— 0.9086
              pbâˆ— 2 =                 =                             = 0.526
                          t2 + t3                 2 Ã— 350
    Sin embargo, con Î± = 0.05, en la tabla 5 se sugiere la inexistencia de evidencia
suficiente para rechazar la hipÃ³tesis de nulidad de Î²1âˆ— , ya que el IC contiene al cero.

                                            Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

176                         Ernesto Ponsot Balaguer, Surendra Sinha & Arnaldo GoitÃ­a

Esto tiene implicaciones importantes para el anÃ¡lisis: al no poderse concluir que Î²1âˆ—
es significativamente diferente de 0, el modelo (11) pierde vigencia y las probabili-
dades predichas en la tabla 6, en estricto sentido estadÃ­stico, no deben considerarse
vÃ¡lidas. Las predicciones correctas son entonces notablemente diferentes:
                                      c     c                c
                                     e Î² 1 +Î² 2           eÎ² 2
                                       âˆ—     âˆ—                âˆ—

                      pbâˆ— 1 =                       =                = 0.4346                (12)
                                1 + eÎ²câˆ— 1 +Î²câˆ— 2       1 + eÎ²câˆ— 2
                                      c
                                     eÎ² 1           e0
                                       âˆ—

                      pbâˆ— 2 =                =           = 0.5                               (13)
                                1 + eÎ²câˆ— 1        1 + e0

   Finalmente, la tabla 7 contiene las estimaciones del modelo logit en (11) y los
IC del 95 %, y la tabla 8 las probabilidades predichas, ahora ajustando los datos
segÃºn el procedimiento sugerido en este trabajo.

                                        câˆ— y prueba de Wald (H0 : Î²iâˆ— = 0).
       Tabla 7: Procedimiento sugerido. Î² i

                           EstimaciÃ³n de Î²iâˆ—                               IC del 95 %
        i      câˆ—
               Î²        SE       Ï‡2   p-Valor            ConclusiÃ³n       Li         Ls
                  i
        1    0.103    0.0486   4.49     0.034            Rechazar        0.0077     0.1982
        2   âˆ’0.263    0.1177   5.00     0.025            Rechazar       âˆ’0.4941   âˆ’0.0325



      Tabla 8: Procedimiento sugerido. Probabilidades predichas e IC del 95 %.
                                 i        c
                                          pâˆ— i        Li        Ls
                                 1      0.4600      0.4084    0.5125
                                 2      0.5257      0.5019    0.5494


    NÃ³tese que, tal como se esperaba, las estimaciones puntuales del procedimiento
habitual y del procedimiento sugerido son en esencia las mismas. No obstante,
las varianzas estimadas son diferentes en ambos procedimientos. Las varianzas
estimadas por el procedimiento sugerido son menores (y por tanto preferibles) que
las estimadas mediante el procedimiento habitual, tanto en lo que se refiere a los
estimadores de los parÃ¡metros de la predictora lineal como en cuanto a la segunda
componente del vector de probabilidades.
    Adicionalmente, ahora se produce un cambio en la conclusiÃ³n sobre la significa-
ciÃ³n de Î²1âˆ— . Mientras que por el procedimiento habitual las estimaciones estadÃ­sti-
camente vÃ¡lidas, ecuaciones (12) y (13), lucen considerablemente por debajo de lo
que se supondrÃ­a, mediante el procedimiento sugerido sÃ­ resultan estadÃ­sticamente
vÃ¡lidas las predicciones de la tabla 8, que se aproximan de mejor manera a lo que
cabrÃ­a esperar con los datos disponibles.
    Por Ãºltimo, la tabla 9 sintetiza los resultados obtenidos para efectos de su com-
paraciÃ³n con base en la varianza estimada. La comparaciÃ³n de los IC en tÃ©rminos
absolutos carece de sentido sin considerar las estimaciones puntuales correspon-
dientes, de manera que, para poder comparar las diferencias en las longitudes de
los IC, se utiliza la razÃ³n entre las longitudes del primero y el segundo (obtenidos
por el procedimiento habitual y sugerido, respectivamente), esto es, el cociente

                                             Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                           177

entre las longitudes de los intervalos del 95 % de confianza, obtenidos por ambos
mÃ©todos.
           Tabla 9: Habitual vs. sugerido. RazÃ³n de la longitud de los IC.
                          câˆ—
                          Î²                                          c
                                                                     p âˆ—
                              i                                          i
                                           h)                                         h)
       i   L(ICh )    L(ICs )     RÎ² = L(IC
                                       L(IC )
                                                      L(ICh )    L(ICs )     Rp = L(IC
                                                                                  L(IC )
                                                s                                       s
       1    0.2960     0.1905          1.5538         0.1041     0.1041        1.0000
       2    0.5150     0.4616          1.1157         0.0738     0.0475        1.5537
       L(Â·): Longitud. R: RazÃ³n.
       SubÃ­ndices, h: Procedimiento habitual, s: Procedimiento sugerido.


    De la tabla 9 se deduce que para Î²  câˆ— , el IC calculado por el procedimiento
                                          1
                                                                   câˆ— , el primero
habitual es 1.5538 veces el calculado por el mÃ©todo sugerido. Para Î² 2
es 1.1157 veces el segundo. Esto significa una mejora sustancial en la precisiÃ³n
de las estimaciones empleando el procedimiento sugerido, como cabrÃ­a esperar
luego del ajuste hacia la baja en el supuesto sobre la varianza de las muestras
involucradas. En efecto, en este ejemplo particular, sea s2h la estimaciÃ³n de la
varianza calculada mediante el procedimiento habitual y âˆ†V d la estimaciÃ³n de su
diferencia respecto a la varianza correcta (teorema 2). Entonces:
            s2h = tâˆ—2 pbâˆ— 2 (1 âˆ’ pbâˆ— 2 ) = 700 Ã— 0.5257 Ã— (1 âˆ’ 0.5257) = 174, 54
                                   2                                 2
                      p2 âˆ’ pb3 )
           d = t2 t3 (b            350 Ã— (0.1429 âˆ’ 0.9086)
           âˆ†V                    =                         = 102, 60
                    t2 + t3                   2
          d estima una disminuciÃ³n en la varianza al ajustar el modelo segÃºn el
    AsÃ­, âˆ†V
procedimiento sugerido del 100Ã—(174.54âˆ’102.60)/174.54 = 41.22 %, que se refleja
en una disminuciÃ³n de 100 Ã— (0.2960 âˆ’ 0.1905)/0.2960 = 35.64 % en la longitud del
IC para Î² câˆ— y en una disminuciÃ³n de 100 Ã— (0.5150 âˆ’ 0.4616)/0.5150 = 10.37 % en
            1
la longitud del IC para Î² câˆ— .
                             2
    NÃ³tese, ademÃ¡s, que tal mejora no afecta la predicciÃ³n de pbâˆ— 1 , pero sÃ­ lo hace
en la de pbâˆ— 2 . De hecho, el efecto relativo en la disminuciÃ³n de la longitud del IC
para pbâˆ— 2 es esencialmente el mismo que opera sobre Î²   câˆ— , en total acuerdo con lo
                                                           1
esperado, puesto que en el modelo se postula una relaciÃ³n exclusiva entre estos
dos parÃ¡metros (logit(pâˆ—2 ) = Î²1âˆ— ).


7. ComparaciÃ³n de ambos procedimientos mediante
   simulaciÃ³n
    La simulaciÃ³n cuyos resultados se comentan a continuaciÃ³n, ha sido diseÃ±ada
para estudiar el efecto de la agregaciÃ³n de los niveles a âˆ’ 1 y a del factor ex-
plicativo, mediante la generaciÃ³n seudoaleatoria de un nÃºmero grande de tablas
de contingencia, como la tabla 1, y su posterior anÃ¡lisis sobre medidas-resumen
de desempeÃ±o. Para hacer mÃ¡s simple el experimento, se sigue la estructura del
ejemplo de la secciÃ³n anterior, con solo tres niveles del factor, agrupando los dos
Ãºltimos (2 y 3).

                                           Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

178                        Ernesto Ponsot Balaguer, Surendra Sinha & Arnaldo GoitÃ­a

7.1. DiseÃ±o del experimento de simulaciÃ³n
    A la luz del examen de las varianzas presentado en la secciÃ³n 3, con el pro-
pÃ³sito de amplificar el impacto de la diferencia entre ambos procedimientos, el
experimento supone t1 = t2 = t3 = t = 350. Como en la situaciÃ³n no lu-
ce de interÃ©s la comparaciÃ³n del efecto de ambos procedimientos sobre el pri-
mer nivel del factor, para este se genera seudoaleatoriamente p1 a partir de una
distribuciÃ³n uniforme en (0, 1). Con los valores de t y p1 se genera la muestra
Y1 âˆ¼ Bin(t, p1 ). Para los restantes niveles del factor (objeto de comparaciÃ³n) se
generan las muestras Y2 âˆ¼ Bin(t, p2 ) y Y3 âˆ¼ Bin(t, p3 ), para las combinaciones
âˆ†p = |p2 âˆ’ p3 | = 0.0, 0.2, 0.4, 0.6, 0.8, obtenidas manteniendo constante el valor de
p2 = 0.1 y variando el valor de p3 = 0.1, 0.3, 0.5, 0.7, 0.9.
    Para cada uno de los 5 valores a experimentar de âˆ†p, se generan 2000 tablas de
contingencia constituidas por binomiales independientes, dentro de cada tabla y
entre tablas. El experimento prosigue ajustando un primer modelo logit contando
los tres niveles del factor, un segundo modelo logit ajustado a la tabla resultante
de agrupar los niveles 2 y 3 del factor, y un tercer ajuste de dicha tabla, mediante
el procedimiento sugerido. El nivel de significaciÃ³n para las pruebas se establece
en Î± = 0.05.
   Las medidas de desempeÃ±o que se emplean como resultado de la simulaciÃ³n se
exponen a continuaciÃ³n:

 a) En primer lugar, se utilizan las diferencias en las estimaciones puntuales de
    Î²1âˆ— , Î²2âˆ— , pâˆ—1 , pâˆ—2 , obtenidas mediante los procedimientos habitual y sugerido, sin
    tomar en cuenta la significaciÃ³n de los parÃ¡metros de la predictora lineal.

 b) Para la comparaciÃ³n de las diferencias en las longitudes de los IC, calculados
    mediante los procedimientos habitual y sugerido, se utiliza el promedio de la
    razÃ³n entre las longitudes del primero y el segundo. Estas razones se calculan
    para los IC que acompaÃ±an a las estimaciones de los parÃ¡metros Î²1âˆ— , Î²2âˆ— , pâˆ—1 , pâˆ—2 .

  c) Finalmente, se estudian las frecuencias absolutas de ocurrencia del cambio
     en la conclusiÃ³n del anÃ¡lisis de varianza (aceptaciÃ³n a rechazo, o viceversa)
     para las pruebas de hipÃ³tesis sobre los parÃ¡metros H0 : Î²1âˆ— = 0 y H0 : Î²2âˆ— =
     0, cuando se los contrasta por el procedimiento habitual, y cuando se los
     contrasta por el procedimiento sugerido.


7.2. Resultados del experimento de simulaciÃ³n
 a) Cuando no se toma en cuenta la significaciÃ³n de los parÃ¡metros de la pre-
    dictora lineal, en cuanto a las estimaciones puntuales, redondeando al tercer
    decimal, en todos los casos estas coinciden por ambos mÃ©todos.
      AsÃ­, en cada una de las 10000 tablas de contingencia generadas, los estima-
      dores Î²     câˆ— , pbâˆ— y pbâˆ— se calculan esencialmente de igual forma cuando se
             câˆ— , Î²
               1    2     1     2
      les estima por el procedimiento habitual o por el procedimiento sugerido.

                                      Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                             179

 b) En cuanto a las longitudes de los IC para cada estimador, la tabla 10 presenta
    los resultados de las razones promedio obtenidas.

        Tabla 10: RazÃ³n de la longitud de los IC para los estimadores.

      NÃ³tese en la tabla 10 que a mayor âˆ†p, tanto mayor es la razÃ³n promedio de
      las longitudes de los IC estimados por ambos mÃ©todos. Por ejemplo, la lon-
      gitud del IC correspondiente a Î² câˆ— estimado por el procedimiento habitual,
                                          1
      es en promedio 1.68 veces la del IC estimado por el mÃ©todo sugerido, cuando
      âˆ†p = |p2 âˆ’ p3 | = 0.8. Por otro lado, es claro que cuando las probabilidades
      de Ã©xito de las muestras agrupadas estÃ¡n cercanas, ambos mÃ©todos estiman
      en promedio esencialmente los mismos IC para todos los parÃ¡metros. Este
      hecho debÃ­a verificarse en virtud de los postulados del teorema 2. TambiÃ©n
      resulta que el comportamiento relativo de los IC es muy similar para Î²     câˆ—
                                                                                    1
      y pb 2 , en total concordancia con lo esperado, tal y como se mencionÃ³ en la
          âˆ—

      secciÃ³n anterior. Por Ãºltimo, es apreciable que los IC correspondientes a pc
                                                                                 âˆ—1 ,
      en promedio no muestran diferencias al ser estimados por ambos mÃ©todos,
      mientras que las razones promedio de las longitudes de los IC correspondien-
      tes a los Î² câˆ— , aunque tambiÃ©n muestran un comportamiento creciente con
                    2
      âˆ†p, lo hacen en proporciÃ³n considerablemente menor que para Î²    câˆ— .
                                                                          1

  c) Finalmente, la tabla 11 muestra las frecuencias absolutas de ocurrencia de
     las conclusiones sobre los parÃ¡metros del modelo. Para Î²1âˆ— y âˆ†p por debajo
     de 0.8, ambos procedimientos conducen al rechazo de la hipÃ³tesis de nulidad
     en todas las muestras. Para âˆ†p = 0.8, la situaciÃ³n es contraria, es decir, en la
     mayorÃ­a de las muestras no hay evidencia suficiente para rechazar la hipÃ³tesis
     de nulidad. No obstante, mientras que utilizando el procedimiento habitual
     se rechaza la hipÃ³tesis nula en 3 de las 2000 muestras (0, 15 %), empleando
     el procedimiento sugerido esto ocurre en 109 de las 2000 muestras (5.46 %).

        Tabla 11: Frecuencias en las conclusiones sobre los parÃ¡metros.

      Al disminuir la regiÃ³n de aceptaciÃ³n de la hipÃ³tesis nula, mejorando la preci-
      siÃ³n en la estimaciÃ³n del parÃ¡metro y la potencia de la prueba de la hipÃ³tesis
      de nulidad, el procedimiento sugerido favorece la investigaciÃ³n particular que
      se estÃ© realizando. La calidad de las conclusiones sobre las posibilidades y
      sobre las probabilidades mejora siempre que sea estadÃ­sticamente vÃ¡lido el
      rechazo de la hipÃ³tesis de nulidad de los parÃ¡metros.
      Para Î²2âˆ— la situaciÃ³n es variada. Aunque se observa para todos los valores
      de âˆ†p una alta proporciÃ³n de rechazo a la hipÃ³tesis de nulidad del parÃ¡me-
      tro, leve pero sostenidamente a medida que aumenta âˆ†p, el procedimiento
      sugerido favorece cada vez mÃ¡s el rechazo de tal hipÃ³tesis, cuando se lo com-
      para con el procedimiento habitual. Sin embargo, para âˆ†p = 0.8, esto es, la
      mÃ¡xima diferencia entre las probabilidades de Ã©xito estudiadas por el experi-
      mento, el procedimiento sugerido conduce a cambiar la conclusiÃ³n en apenas
      1732 âˆ’ 1698 = 34 oportunidades mÃ¡s que el procedimiento habitual, es decir,
      cerca de tres veces menos que lo ocurrido para Î²1âˆ— (109 âˆ’ 3 = 106).

   En el anexo se incluye el cÃ³digo fuente R (R Development Core Team 2007)
programado para realizar la simulaciÃ³n.


8. Conclusiones
   Es clara la existencia de un problema en el ajuste del modelo logit con niveles
agrupados del factor. Se sugiere en este trabajo un procedimiento que, aprove-
chando la disminuciÃ³n en la varianza cuando se postula el modelo distribucional
correcto en lugar del modelo binomial, conduce a la reducciÃ³n de los errores es-
tÃ¡ndares de las estimaciones en un porcentaje apreciable.
    Al disminuir el error estÃ¡ndar estimado, disminuye la regiÃ³n de aceptaciÃ³n de
la hipÃ³tesis de nulidad de los parÃ¡metros de la predictora lineal, mejorando las
estimaciones y la potencia de la prueba de dicha hipÃ³tesis de nulidad. Consecuen-
temente, el procedimiento sugerido resulta preferible al habitual.
    Desde el punto de vista computacional, el procedimiento sugerido resulta mÃ¡s
eficiente que el habitual puesto que, aprovechando los cÃ³mputos obtenidos en un
primer ajuste del modelo logit, produce nuevas estimaciones mediante regresiÃ³n,
sin requerir mÃ¡s iteraciones.
    Mediante simulaciÃ³n se ha corroborado que diferencias relativamente leves en
las probabilidades de Ã©xito de las muestras involucradas en la agregaciÃ³n, en pro-
medio no conducen a concluir que la aplicaciÃ³n del procedimiento sugerido sea
diferente frente a la aplicaciÃ³n del habitual. Esto muestra clara evidencia sobre
la robustez del modelo logit, sus habituales procedimientos de ajuste y prueba de
hipÃ³tesis. Por otra parte, a medida que dicha diferencia en las probabilidades de
Ã©xito se profundiza (para los valores estudiados, esto es âˆ†p > 0.6), resulta cada vez
mejor apoyarse en el procedimiento sugerido. Consecuentemente, el investigador
debe tener especial cuidado cuando agrupa niveles del factor, cuyas proporciones
muestrales son notoriamente disÃ­miles.

                                    Revista Colombiana de EstadÃ­stica 32 (2009) 157â€“187

Sobre la agrupaciÃ³n de niveles en el modelo logit                                    181

    En este trabajo se ilustrÃ³ la situaciÃ³n considerando un solo factor, la parame-
trizaciÃ³n de referencia y el modelo saturado. La investigaciÃ³n continuarÃ¡ en varias
direcciones: asumiendo la presencia de dos o mÃ¡s factores, postulando el modelo
no saturado para su anÃ¡lisis, estudiando el efecto sobre los residuos y las medidas
de bondad del ajuste, entre otras.


Agradecimientos
   Los autores agradecen al Consejo de Desarrollo CientÃ­fico, HumanÃ­stico y Tec-
nolÃ³gico (CDCHT) de la Universidad de Los Andes el apoyo financiero brindado
para la realizaciÃ³n de este trabajo. Asimismo, agradecen los valiosos comentarios
de los Ã¡rbitros anÃ³nimos, los cuales sin duda contribuyeron a mejorar tanto el
fondo como la forma del presente trabajo.
Referencias
Agresti, A. (2007), An Introduction to Categorical Data Analysis, 2 edn, John Wiley & Sons, Inc., New Jersey, United States.
Christensen, R. (1997), Log-Linear Models and Logistic Regression, 2 edn,Springer-Verlag, New York, United States.
Christensen, R. (2002), Plane Answers to Complex Questions. The Theory of Linear Models, 3 edn, Springer-Verlag, New York, United States.
Collett, D. (2002), Modelling binary data, 2 edn, Chapman & Hall/CRC, Boca Raton, United States.
Cox, D. R. (1970), Analysis of Binary Data, 1 edn, Methuen and Co Ltd., London,England.
Feller, W. (1968), An Introduction to Probability Theory and Its Applications,Vol. 1, 3 edn, John Wiley & Sons. Inc., New York, United States.
Grizzle, J. E., Starmer, C. F. & Koch, G. G. (1969), â€˜Analysis of Categorical Data by Linear Modelsâ€™, Biometrics 25(3), 489â€“504.
Hilbe, J. M. (2009), Logistic Regression Models, 1 edn, Chapman & Hall, Florida,United States.
Hodges, J. L. & Le Cam, L. (1960), â€˜The Poisson Approximation to the Poisson Binomial Distributionâ€™, The Annals of Mathematical Statistics 31(3), 737â€“740.
Hosmer, D. W. & Lemeshow, S. (2000), Applied Logistic Regression, 2 edn, John Wiley & Sons, New York, United States.
Lehmann, E. L. (1999), Elements of Large-Sample Theory, 1 edn, Springer-Verlag,New York, United States.
McCullagh, P. & Nelder, J. (1989), Generalized Linear Models, 2 edn, Chapman & Hall, London, England.
McCulloch, C. E. & Searle, S. R. (2001), Generalized, Linear, and Mixed Models,1 edn, John Wiley & Sons, Inc., New York, United States.
Neammanee, K. (2005), â€˜A refinement of Normal approximation to Poisson Binomialâ€™, International Journal of Mathematics and Mathematical Sciences (5), 717â€“728.
Nedelman, J. & Wallenius, T. (1986), â€˜Bernoulli Trials, Poisson Trials, Surprising Variances, and Jensenâ€™s Inequalityâ€™, The American Statistician 40(4), 286â€“289.
Nelder, J. A. & Wedderburn, R. W. M. (1972), â€˜Generalized Linear Modelsâ€™, Journal of the Royal Statistical Society. Serie A (135), 370â€“384.
Neyman, J. (1939), â€˜On a new class of contagious distributions, applicable in entomology and bacteriologyâ€™, The Annals of Mathematical Statistics 10(1), 35â€“57.
Ollero, H. J. & Ramos, R. H. M. (1991), â€˜La distribuciÃ³n hipergeomÃ©trica como binomial de poissonâ€™, Trabajos de EstadÃ­stica 6(1), 35â€“43.
Ponsot, E. (2009), Estudio de la agrupaciÃ³n de niveles en el modelo logit, tesis de doctorado, Instituto de EstadÃ­stica Aplicada y ComputaciÃ³n, Facultad de Ciencias EconÃ³micas y Sociales, Universidad de Los Andes, MÃ©rida, Venezuela.
Powers, D. A. & Xie, Y. (1999), Statistical Methods for Categorical Data Analysis,1 edn, Academic Press, United States.
R Development Core Team (2007), â€˜R: A language and environment for statistical computingâ€™, Vienna, Austria.*http://www.R-project.org
RodrÃ­guez, G. (2008), â€˜Lectures notes about generalized linear modelsâ€™, New Jersey,United States.*http://data.princeton.edu/wws509/notes
Rohatgi, V. & Ehsanes, A. (2001), An Introduction to Probability and Statistics,2 edn, John Wiley & Sons, Inc., New York, United States.
Roos, B. (1999), â€˜Asymptotics and Sharp Bounds in the Poisson Approximation to the Poisson-Binomial Distributionâ€™, Bernoulli 5(6), 1021â€“1034.
Sprott, D. A. (1958), â€˜The Method of Maximum Likelihood Applied to the Poisson Binomial Distributionâ€™, Biometrics 14(1), 97â€“106.
Wang, Y. H. (1993), â€˜On the Number of Successes in Independent Trialsâ€™, Statistica Sinica 3, 295â€“312.
Weba, M. (1999), â€˜Bounds for the Total Variation Distance between the Binomial and the Poisson Distribution in case of Medium-Sized Success Probabilitiesâ€™,Journal of Applied Probability (36), 497â€“104.
Wedderburn, R. W. M. (1974), â€˜Quasi-Likelihood Functions, Generalized Linear Models, and the Gauss-Newton Methodâ€™, Biometrika 61(3), 439â€“447.