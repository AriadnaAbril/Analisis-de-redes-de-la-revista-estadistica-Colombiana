O princı́pio da equivariância: conceitos e aplicações
Universidade Federal do Ceará;Universidade de São Paulo
Resumo
Neste trabalho apresentamos uma revisão do princı́pio da estimação equivariante e algumas de suas aplicações na famı́lia de localização-escala e em modelos lineares. Consideramos também o estimador não viciado de variância uniformemente mı́nima em modelos lineares. Vários exemplos são apresentados para ilustrar o uso destes métodos.
Palavras chave: Estimação equivariante, famı́lia de localização-escala, função de perda, modelos lineares, estimador não viciado de variância uniformemente mı́nima.
Introdução
Inicialmente, considere um modelo estatı́stico (X , A, P) em que X é o espaço
amostral associado a um experimento, X (vetor aleatório), A é uma σ-álgebra
de subconjuntos de X e P é uma famı́lia de medidas de probabilidades, P, no
espaço mensurável (X , A) (fixado). Em geral, assume-se que P = {Pθ ; θ ∈ Ω}
é indexada por um parâmetro (ou vetor de parâmetros) θ ∈ Ω, e que existe uma
correspondência biunı́voca entre Ω e P (identificabilidade), com Ω denominado
de espaço paramétrico. O objetivo da inferência estatı́stica consiste em pesquisar
sobre a distribuição geradora, isto é, “descobrir” qual distribuição Pθ0 ∈ P gera
os dados em questão, ou equivalentemente estimar o valor de θ.
     Considere h : Ω → R uma função mensurável, X um vetor aleatório, cujo va-
lor em θ tem-se interesse em estimar e δ(X) : X → R um estimador e d = δ(x)
representando uma estimativa de h(θ). Um critério bastante utilizado para a
escolha de estimadores ótimos é tomar um estimador δ(X) que minimiza o risco
R(θ, δ) := Eθ [L(θ, δ)], ∀θ ∈ Ω, com L(θ, .) denotando uma função de perda apropri-
ada. Dada a impossibilidade de se obter tal estimador (Lehmann & Casella 1998,
pág. 5), é comum restringir a classe de estimadores, e determinar, dentro desta
classe, um estimador que minimiza o risco uniformemente em θ. Desta forma, por
exemplo, pode-se obter o ENVVUM (classe dos estimadores não viciados), BLUE
(classe dos estimadores lineares), entre outros.
     Neste trabalho, temos por objetivo apresentar a classe de estimadores equivari-
antes, com ênfase nos modelos de localização-escala e lineares, além de considerar
a estimação não viciada de variância uniformemente mı́nima (NVVUM), nesta
última classe de modelos. Na Seção 2, fornecemos alguns conceitos e definições
requeridas no desenvolvimento do artigo. Na Seção 3, é discutida a estimação
equivariante no modelo de escala, enquanto que na Seção 4 é analisado é o mo-
delo de localização-escala tanto de forma marginal como conjunta. Na Seção 5,
apresentamos alguns resultados básicos sobre a estimação equivariante e NVVUM
para modelos lineares.


2      Estrutura matemática do princı́pio da
       equivariância
Considere X : X → R uma variável aleatória cuja respectiva distribuição pertence
a famı́lia indexada por θ
                              P = {Pθ ; θ ∈ Ω}                                   (1)
e C uma classe de funções bijetivas g : X → X .

Definição 1.

    i) Considere g ∈ C e X uma variável aletória com distribuição Pθ ∈ P. Se
       ∀θ ∈ Ω, a distribuição de X ∗ := g(X), Pθ∗ ∈ P, diz-se que o modelo (1) é
       invariante sob a transformação g.


                                     Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                   197


 ii) Se i) vale ∀ g ∈ C, diz-se que o modelo (1) é invariante sobre a classe de
     transformações C.

     Considere C uma classe de transformações sob a qual o modelo (1) é invariante.
Perceba que C não é necessariamente um grupo de transformações (fechada por
composição e inversão). Definindo G(C) := {g; g = g1±1 ◦ · · · ◦ gm±1
                                                                         ; gi ∈ C, i =
1, . . . , m} com g ◦ h representando a composição das funções g e h, em que os
elementos gi ∈ C não são necessariamente distintos, tem-se que o modelo (1) é
invariante sob G(C), com G(C) sendo o grupo (gerado por C).
     Considere g ∈ G(C), então g(X) ∼ Pθ∗ ∈ P. Pode-se mostrar que
θ∗ := g(θ) : Ω → Ω é uma transformação bijetiva e que G := {g; g ∈ G} é
um grupo de transformações. Para demonstrar a primeira assertiva, considere
∀g ∈ G que Xi ∼ Pθi ∈ P e g(Xi ) ∼ Pθi∗ ∈ P (i = 1, 2) tal que Pθ1∗ (A) = Pθ2∗ (A),
∀A ∈ B(R) ⇔ Pθ1 (g −1 (A)) = Pθ2 (g −1 (A)), ∀A ∈ B(R) ⇔ θ1 = θ2 e o resul-
tado segue. Para provar a segunda assertiva, mostre que (g1 ◦ g2 ) = (g1 ) ◦ (g2 ) e
             −1
(g −1 ) = g , ∀g1 , g2 , g ∈ G e use o fato de que G é um grupo.
     Adicionalmente, segue diretamente da definição de g(θ) que

                               Pθ [g(X) ∈ A] = Pθ∗ [Y ∈ A]                                 (2)
                                 Eθ [ψ(g(X))] = Eθ∗ [ψ(Y )]                                (3)

para qualquer função ψ, Pθ∗ integrável.

    Considere o problema de estimar h(θ) no modelo (1) que é assumido ser inva-
riante sob as transformações X ∗ = g(X) e θ∗ = g(θ), g ∈ G. Iremos supor também
que ∀g ∈ G, h(θ∗ ) dependa de θ somente através de h(θ), ou seja

                                      h(θ∗ ) = g ∗ (h(θ))                                  (4)

Desta forma pode-se relacionar a estimativa d de h(θ) com a estimativa d∗ de h(θ∗ )
da seguinte forma
                                    d∗ = g ∗ (d)                               (5)
implicando que o problema de estimar h(θ) em termos de (X, θ, d) ou h(θ∗ ) em
termos de (X ∗ , θ∗ , d∗ ) representam a mesma situação fı́sica apenas expressa em
um novo sistema de coordenadas. A forma da função a ser estimada tem um papel
fundamental nas considerações que serão discutidas adiante.
Exemplo 1. Duas amostras da famı́lia de localização.
   Considere X = (X1 , . . . , Xm )> e Y = (Y1 , . . . , Yn )> , dois vetores aleatórios
com respectiva densidade conjunta

       f (x − ξ, y − η) = f (x1 − ξ, . . . , xm − ξ, y1 − η, . . . , yn − η),   ξ, η ∈ R   (6)

Este modelo permanece invariante sob as transformações

                  g(X, Y) = (X + a, Y + b), g(ξ, η) = (ξ + a, η + b)                       (7)


                                         Revista Colombiana de Estadı́stica 29 (2006) 195–220

198                                                      Juvêncio Nobre & Caio Azevedo


para quaisquer escalares a e b. Considere que o interesse é estimar h(ξ, η) = ∆ :=
η − ξ. Denotando as variáveis e os parâmetros transformados por X∗ = X +
a, Y∗ = Y + b, η ∗ = η + b e ξ ∗ = ξ + a então, tem-se que as transformações
em (7) levam ∆ em ∆∗ = η ∗ − ξ ∗ = ∆ + (b − a). Portanto, dada uma estimativa
de ∆, digamos d, obtida via modelo (6), tem-se que a estimativa de ∆∗ , digamos
d∗ , no modelo transformado pode ser expressa como d∗ = d + (b − a) = g ∗ (d).
     Suponha agora que o interesse é estimar h(ξ, η) = λ := ξ 2 + η 2 . Considerando
as transformações em (7), tem-se que λ é transformado em λ∗ = (ξ+a)2 +(η+b)2 =
λ+φ(ξ, η, a, b) ou seja, λ∗ não depende de (η, ξ) somente através de λ. Neste caso o
problema de estimar λ, via modelo original, e estimar λ∗ , via modelo transformado,
não representam a mesma situação.

    Sob a veracidade de (4), tem-se que os problemas de estimar h(θ) em termos
de (X, θ, d) ou h(θ∗ ) em termos de (X ∗ , θ∗ , d∗ ) são equivalentes; então é razoável
que a função de perda seja tal que L(θ, d) = L(θ∗ , d∗ ), ou seja, que a função de
perda seja invariante sob a transformação g [uma caracterização de funções de
perda invariantes é dada em Staudte (1971)]. Tal observação conduz à seguinte
definição:
Definição 2. Se o modelo estatı́stico (1) é invariante sob g, a função de perda L
satisfaz
                            L(g(θ), g ∗ (d)) = L(θ, d)                             (8)
e h(θ) satisfaz (4), então o problema de estimar h(θ) com função de perda L é dito
ser invariante sobre g.

   Em um problema invariante, se δ é um estimador de h(θ), então existem dois
caminhos naturais de se estimar h(θ∗ ) (o estimando no modelo transformado),
apresentados a seguir.

1. Princı́pio da equivariância funcional
   Se δ(X) é o estimador de h(θ), então o estimador de φ(h(θ)) é dado por φ(δ(X)).
Fazendo φ = g ∗ , tem-se que g ∗ (δ(X)) é o estimador de g ∗ (h(θ)), quando δ(X) for
usado para estimar h(θ).

2. Princı́pio da invariância formal
    Invariância sob as transformações g, g e g ∗ no problema de estimação de h(θ)
significa essencialmente dizer que os problemas de estimar h(θ) em termos de
X, θ e d∗ , e o de estimar g ∗ (θ) em termos de X∗ , θ∗ e d∗ são formalmente o
mesmo e, por conseguinte, devem ser tratados da mesma forma. Isto significa que
δ(X∗ ) = δ(g(X)) deve ser usado para estimar g ∗ (h(θ)) = h(θ∗ ).
    É desejável que os dois princı́pios nos levem ao mesmo estimador, ou seja, que
                               δ(g(X)) = g ∗ (δ(X)).                                   (9)
Definição 3. Em um problema de estimação invariante, um estimador δ(X) é
dito ser equivariante se ele satisfaz (9), ∀g ∈ G.


                                       Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                 199


    Os princı́pios de equivariância funcional e invariância formal têm sido discuti-
dos por alguns autores, utilizando diferentes denominações. Por exemplo, Casella
& Berger (2002, p. 297) denotam por Princı́pio de medida equivariante ao
invés de Princı́pio da equivariância funcional. Algumas outras denominações
podem ser encontradas em Lehmann & Casella (1998, p. 233). Além disso, al-
guns autores destacam a diferença entre equivariância, em que as estimativas dos
parâmetros se modificam em um determinado sentido quando os dados são trans-
formados, e invariância, na qual as estimativas ficam imutáveis sob transformações.
Para detalhes, veja Schervish (1995, p. 344), Borovkov (1998, p. 166), Lehmann
& Casella (1998, p. 150) e Casella & Berger (2002, p. 296), por exemplo.
Exemplo 2. Famı́lia de localização.
  Considere X = (X1 , . . . , Xn )> um vetor aleatório com densidade dada por
                       f (x − ξ) = f (x1 − ξ, . . . , xn − ξ),   ξ∈R
O modelo acima é invariante sob as seguintes transformações
                     X∗ = X + a e ξ ∗ = g ∗ (ξ) = ξ + a,         ∀a ∈ R
o problema de estimação de ξ é invariante sobre as transformações acima se consi-
deramos funções de perda da forma L(ξ + a, d + a) = L(ξ, d), ∀a ∈ R, e isto ocorre
se e somente se L(ξ, d) = ρ(d − ξ) (Lehmann & Casella 1998, p. 149). Neste caso,
um estimador δ(X) é equivariante (por localização) se e somente se
                δ(g(X)) = δ(X + a) = δ(X) + a = g ∗ (δ(X)), ∀a ∈ R                      (10)
Exemplo 3. Continuação do exemplo 1.
   No exemplo 1, tı́nhamos h(ξ, η) = ∆ = η−ξ e g ∗ (d) = d+(b−a). Considerando
uma função de perda invariante sobre as transformações (7), então tem-se um
problema de estimação (de ∆) invariante. Neste caso, um estimador δ(X, Y) é
equivariante se e somente se
                         δ(X + a, Y + b) = δ(X, Y) + (b − a).                           (11)
Se δ1 (X) e δ2 (Y) são estimadores equivariantes por localização (da forma (10)) de ξ
e η, respectivamente, então δ(X, Y) = δ2 (Y) − δ1 (X) é um estimador equivariante
de ∆.

    A seguir são obtidas algumas propriedades dos estimadores equivariantes.
Teorema 1. Considere δ(X) um estimador equivariante em um problema inva-
riante sob a transformação g, então a função de risco satisfaz
                         R(g(θ), δ(g(X))) = R(θ, δ),        ∀θ ∈ Ω.                     (12)

Demonstração. Por definição e lembrando (3), segue que
          R(g(θ), δ) = Eg(θ) [L(g(θ), δ(X))] = Eθ [L(g(θ), δ(g(X)))]
                      = Eθ [L(g(θ), g ∗ (δ(X)))] = Eθ [L((θ), δ(X))] := R(θ, δ)


                                         Revista Colombiana de Estadı́stica 29 (2006) 195–220

200                                                       Juvêncio Nobre & Caio Azevedo


Definição 4. Um grupo de transformações G de Ω é dito ser transitivo se ∀θ1 , θ2 ∈
Ω, ∃g ∈ G tal que g(θ1 ) = θ2 .

   O corolário seguinte é útil para generalizar o teorema 1.4 (Lehmann & Casella
1998, p. 150) para o problema de estimação equivariante por localização.
Corolário 1. Sob as suposições do teorema 1 e considerando G transitiva sob o
espaço paramétrico Ω, então tem-se que a função de risco de qualquer estimador
equivariante é constante.

Demonstração. Pelo teorema 1, tem-se que R(g(θ1 ), δ(g(X))) = R(θ1 , δ),
∀θ1 ∈ Ω. Sob a suposição de transitividade de G, temos que ∀θ1 , θ2 ∈ Ω, ∃g 12 ∈ G;
g 12 (θ1 ) = θ2 , portanto

             R(θ2 , δ) = R(g 12 (θ1 ), δ(g12 (X))) = R(θ1 , δ),   ∀θ1 , θ2 ∈ Ω        (13)


      Quando o risco de qualquer estimador equivariante é constante, e supondo que
exista um estimador equivariante com risco finito, o melhor estimador equivariante
δ ∗ , no sentido de minimizar o risco, denominado EERM (EERM-Estimador Equi-
variante de Risco Mı́nimo), é obtido minimizando tal constante. Uma forma de
se obter δ ∗ é encontrar uma função da amostra X, digamos (T, W )> , em que T
é uma estatı́stica suficiente e W é uma estatı́stica ancilar, ambas para θ. Desta
forma, podemos obter δ ∗ minimizando em δ a seguinte esperança condicional

                                Eθ [L(θ, δ(X)) | W = w]                               (14)
uma vez que

              R(θ, δ) := Eθ [L(θ, δ(X))] = Eθ [Eθ [L(θ, δ(X)) | W = w]]
                        Z
                      =      Eθ [L(θ, δ(X)) | W = w]d P(w)
                           k
                        ZR
                      ≥      min Eθ [L(θ, δ(X)) | W = w]d P(w)
                           Rk   δ

                      = min Eθ [L(θ, δ(X)) | W = w]
                           δ
                      = min Eθ [L(θ, δ(T, w)) | W = w]                                (15)
                           δ

em que k representa a dimensão da estatı́stica ancilar W .
Exemplo 4. Continuação do exemplo 1.
    Neste exemplo, tem-se que θ = (ξ, η)> e g(θ) = (ξ + a, η + b). Esse grupo G é
claramente transitivo sob Ω = R2 , dado que ∀(ξ, η) e (ξ ∗ , η ∗ ) ∈ R2 , ∃a, b ∈ R tais
que ξ ∗ = ξ + a e η ∗ = η + b. Por conseguinte o EERM pode ser obtido através de
(15), por exemplo.

   Algumas propriedades adicionais, tanto no contexto clássico quanto no
Bayesiano, dos estimadores equivariantes, podem ser encontradas em Zacks (1971),
Schervish (1995) e Borovkov (1998), por exemplo.


                                       Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                  201


3     Modelos de escala
     Nesta seção, vamos aplicar os princı́pios desenvolvidos na seção anterior para
o modelo de escala. Considere que X = (X1 , . . . , Xn )> pertence à famı́lia de
escala, ou seja, que sua densidade é da forma
                 1 x        1  x1         xn 
                  n
                    f    := n f       ,...,       , τ ∈ (0, ∞) := R++              (16)
                τ     τ      τ      τ         τ
em que f é uma função conhecida e τ é dito ser um parâmetro de escala. O
modelo (16) é invariante sob as transformações

                              X∗ = bX,         τ ∗ = bτ,       ∀b > 0                    (17)

    Suponha que o interesse seja estimar h(τ ) = τ r , r ∈ N. Perceba que (4) é
satisfeita uma vez que (17) induz as transformações

                          h(τ ) → br τ r = br h(τ )        e    d∗ = br d

a função de perda é invariante sob estas transformações se

                              L(bτ, br d) = L(τ, d),           ∀b > 0                    (18)

e isto ocorre se e somente se
                                                 
                                                  d
                                     L(τ, d) = φ r                                       (19)
                                                 τ

Para mostrar que (18) implica (19) basta fazer b = τ −1 , já o recı́proco não é difı́cil
de verificar.
Exemplo 5. Funções de perda invariantes por escala.
  Exemplos de função de perda que satisfazem (19) são
                                         2
               (d − τ )2          d                                |d − τ r |    d
     L(τ, d) =           =           −1         e   L(τ, d) =                 = r −1     (20)
                  τ 2r            τr                                  τr        τ

    porém, a perda quadrática não é da forma (19).
    A seguinte definição segue diretamente de (9).
Definição 5. Um estimador δ de h(τ ) = τ r é dito ser equivariante sob as trans-
formações (17), ou equivariante por escala se

                   δ(g(X)) = δ(bX) = br δ(X) = g ∗ (δ(X)),              ∀b > 0           (21)

Exemplo 6. Estimadores equivariantes por escala.
   A maioria dos estimadores usuais de τ (parâmetro de escala) são equivariantes
por escala, por exemplo, o desvio padrão, o desvio médio, a amplitude e o estimador
de MV.


                                          Revista Colombiana de Estadı́stica 29 (2006) 195–220

202                                                          Juvêncio Nobre & Caio Azevedo


    Como o grupo G de transformações τ ∗ = bτ , b > 0, é transitivo sobre Ω = R++
então, pelo Corolário 1, tem-se que o risco de qualquer estimador equivariante por
escala é constante. A seguir, caracterizamos os estimadores equivariantes por
escala.
Teorema 2. Seja X um vetor aleatório com densidade (16) e seja δ0 (X) um
estimador equivariante por escala de δ r . Então, se
                                      Xi
                             Zi :=            (i = 1, . . . , n)                      (22)
                                     |Xn |

  com Z = (Z1 , . . . , Zn )> , então uma condição necessária e suficiente para que
um estimador δ satisfaça (21) é que exista uma função w(z) tal que
                                               δ0 (x)
                                     δ(x) =                                           (23)
                                               w(z)

Demonstração. Uma condição necessária e suficiente para que δ satisfaça (21)
é que seja escrito na forma
                                        δ0 (x)
                                δ(x) =                                        (24)
                                         u(x)
com u(x) sendo uma função invariante por escala, ou seja,
                        u(bx) = u(x),        ∀x ∈ Rn     e    ∀b > 0                  (25)
se δ0 (x) e u são dados como acima, então tem-se que ∀x ∈ Rn e ∀b > 0:
                                  δ0 (bx)      δ0 (x)
                        δ(bx) =           = br        = br δ(x)
                                  u(bx)        u(x)
satisfazendo (21). Supondo que δ é um estimador equivariante por escala, seja
u(x) = δ0 (x)/δ(x), então a função u é invariante por escala. Por conseguinte, uma
condição necessária e suficiente para δ seja um estimador equivariante é que ele
seja escrito da forma (24). Para terminar a demonstração, vamos mostrar agora
que a função u é invariante por escala se e somente se u for função de z.
    Fazendo b = |xn |−1 em (25) tem-se que u(x) = u(z1 , . . . , zn ) = w(z), ∀x ∈ Rn ,
implicando-nos que ∀b > 0, u(bx) = w(bz) = u(bz1 , . . . , bzn ) = u(x1 , . . . , xn ) =
u(x), o que prova o teorema.

    Perceba que as componentes de Z no teorema (2) só estão definidas se Xn 6= 0,
ou seja, estão bem definidas q.c.[P]. Além do mais, tem-se que w(Z) é uma
estatı́stica ancilar para a famı́lia (16) ou, equivalentemente, para τ , pois w(Z)
é uma função invariante por escala.
Teorema 3. Seja X um vetor aleatório com densidade (16) e seja Z o vetor
aleatório cujo componentes são dados em (22). Suponha que a função de perda é
da forma (19) e que existe um estimador equivariante por escala, δ0 , de τ r com
risco finito. Assuma que ∀Z, existe uma função w(Z) = w∗ (Z) que minimiza
                              Eτ =1 [φ (δ0 (X)/w(Z)) | Z]                             (26)


                                      Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                  203


Então, um EERM por escala δ ∗ de τ r existe e é dado por

                                                  δ0 (X)
                                      δ ∗ (X) =                                          (27)
                                                  w∗ (Z)

Demonstração. Seja δ0 um estimador equivariante por escala de τ r , então pelo
teorema 2 tem-se que uma caracterização dos estimadores equivariantes por escala
é
                                          δ0 (X)
                                δ(X) =
                                           w(Z)
Dada a invariância do problema de estimação de τ r e a transitividade de G, tem-se
que o risco de δ(X) independe de τ . Por conseguinte

    R(τ r , δ) = Eτ [L(τ r , δ)] = Eτ [φ (δ0 (X)/(w(Z)τ r ))] = Eτ =1 [φ (δ0 (X)/w(Z))]
               = Eτ =1 [ Eτ =1 [φ (δ0 (X)/w(Z)) | Z]]
                 Z
               =      Eτ =1 [φ (δ0 (X)/w(Z)) | Z]d P1 (z)
                    n
                 ZR
               ≥      min Eτ =1 [φ (δ0 (X)/w(Z)) | Z]d P1 (z)
                  Rn   z

              = min Eτ =1 [φ (δ0 (X)/w(Z)) | Z] = Eτ =1 [φ (δ0 (X)/w∗ (Z)) | Z]
                  z

implicando que o EERM por escala de τ r é dado por (27).

    Por hipótese, tem-se que δ0 (X) tem risco finito, ou seja,

                R(τ r , δ0 ) = Eτ [φ(δ(X)/τ r )] = E1 [φ(δ(X))] < ∞,

implicando que Eτ =1 [φ (δ0 (X) | w(Z))] < ∞. Portanto, o procedimento anterior é
válido.

Corolário 2. Sob as suposições do Teorema 3, e supondo que ρ(ν) = φ(eν ) é
convexa e não monótona, então existe um EERM por escala para τ r e ele é único
se ρ é estritamente convexa.

Demonstração. Veja Lehmann & Casella (1998, p. 169).

Corolário 3. Sob as suposições do Teorema 3, se considerarmos
                                  
                                   d      (d − τ r )2
                               φ       =                                                 (28)
                                   τr        τ 2r

então
                                          δ0 (X)E1 [δ0 (X) | Z]
                              δ ∗ (X) =                                                  (29)
                                              E1 [δ02 (X) | Z]

Demonstração. Basta mostrar que se X é uma variável aleatória positiva com
Eθ [X 2 ] < ∞, então o valor de c que minimiza E[(X/c − 1)2 ] é c = E[X 2 ]/E[X].


                                          Revista Colombiana de Estadı́stica 29 (2006) 195–220

204                                                     Juvêncio Nobre & Caio Azevedo


Corolário 4. Sob as suposições do Teorema 3, se consideramos
                                
                                  d     |d − τ r |
                            φ      r
                                      =            ,                                 (30)
                                 τ         τr
então δ ∗ (X) é dado por (27), com w∗ (Z) sendo qualquer mediana-escalar da
distribuição condicional de δ0 (X) dado Z com τ = 1, isto é, w∗ (Z) satisfaz

                 E [X11(X ≥ w∗ (Z)) | Z] = E [X11(X < w∗ (Z)) | Z]                   (31)

em que 11(x ∈ A) representa a função indicadora de x no conjunto A.

Demonstração. Basta mostrar que se X é uma variável positiva integrável, então
o conjunto de valores de c que minimizam E|X − c|/|c| são os valores de c que
satisfazem
                      Z c           Z ∞
                          xd P(x) =     xd P(x).
                          0              c

Exemplo 7. EERM por escala quando n = 1.
     Suponha que n = 1 e que X > 0 q.c. Perceba que X r satisfaz (21) e que neste
caso Z = 1. Portanto, tem-se que todos os estimadores equivariantes por escala de
τ r são da forma X r /w, com w = w(1) sendo uma constante arbitrária. Supondo
que X r tem risco finito, então, pelo teorema 3 tem-se que o EERM por escala de
τ r é dado por X r /w∗ , em que w∗ é qualquer constante que minimiza

                          E1 [φ(X r /w)] := Eτ =1 [φ(X r /w)]                        (32)

Em particular, se a função de perda é dada por (28), tem-se que o EERM por
escala de τ r é dado por
                                    X r E1 [X r ]
                                                                         (33)
                                     E1 [X 2r ]
Quando utilizamos (30) o EERM por escala de τ r é dado por X r /w∗ com wr
representando qualquer mediana-escalar da distribuição de X r para τ = 1.
Exemplo 8. Distribuição U (0, τ ).
     Considere que X1 , . . . , Xn são variáveis aleatórias i.i.d. com distribuição
U (0, τ ), τ > 0 e que o interesse é estimar τ . Um estimador equivariante por
escala para τ é X(n) = max1≤i≤n Xi . Além disso tem-se que X(n) é uma es-
tatı́stica suficiente e completa para τ . Dado que Z = (X1 /Xn , . . . , Xn−1 /Xn , 1)
é uma estatı́stica ancilar, então, pelo teorema de Basu, tem-se que X(n) e Z são
independentes. Considerando a função de perda (28), tem-se que o EERM por
escala para τ é dado por
                                  X(n) E1 [X(n) ]   n+2
                         δ(X) =            2 ]    =     X(n)
                                   E1 [X(n)         n+1

que não coincide com o ENVVUM de τ , dado por [(n + 1)/n]X(n) , que é um
estimador equivariante por escala.


                                      Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                   205


Exemplo 9. Estimador equivariante para a variância duma distribuição normal
com média conhecida.
                              a.a.
    Considere X1 , . . . , Xn ∼ N (0, σ 2 ) e admita que o interesse é estimar σ 2 . Um
                                                           Xn
estimador equivariante por escala para σ 2 é δ0 (X) =         Xi2 que também é uma
                                                                i=1
estatı́stica suficiente e completa. Então, pelo teorema de Basu (vide, por exemplo,
Lehmann & Casella 1998, p. 42), conclui-se que δ0 (X) e Z são independentes, pois
Z é uma estatı́stica ancilar. Desta forma, considerando a função de perda (28),
temos que um ERRM por escala de σ 2 é
                                            δ0 (X)E1 [δ0 (X)]
                                    δ(X) =                                                (34)
                                                E1 [δ02 (X)]
                                                     n
                                               1 X 2
                                          =              X                                (35)
                                            n + 2 i=1 i

pois E1 [δ0 (X)] = n e E1 [δ02 (X)] = n(n + 2). Neste caso, o ENVVUM de σ 2 é dado
    Xn
por      Xi2 /n.
     i=1

Teorema 4. Sob as suposições do Teorema 3 com função de perda (28), o EERM
por escala para τ é dado por
                              R ∞ −(n+2)
                                 τ       f (x1 /τ, . . . , xn /τ )dτ
                     δ (X) = R0∞ −(n+3)
                      ∗
                                                                            (36)
                               0
                                 τ       f (x1 /τ, . . . , xn /τ )dτ
e, nesta forma, é chamado de estimador de Pitman de τ .

Demonstração. Veja Schervish (1995, p. 352).

  Lehmann & Casella (1998, p. 170) mostram a expressão do estimador de Pit-
man para τ r .
Exemplo 10. Distribuição exp(λ−1 ).
  Considere que X1 , . . . , Xn são variáveis aleatórias i.i.d. tais que
                             f (x, λ) = λ−1 e−x/λ 11R+ (x),   ∀λ > 0
Neste caso, o estimador de Pitman de λ é dado por
                               R∞             Pn
                       ∗         0 (1/λn+2 )e− i=1 Xi /λ dλ
                      δ (X) = R ∞             Pn
                                 0
                                   (1/λn+3 )e− i=1 Xi /λ dλ
                 Pn
Chamando α = i=1 Xi /λ, tem-se
            R∞     Pn                Pn                   n      R ∞ n −α
             0  (α/ i=1 Xi )n+2 e−α ( i=1 Xi /α2 )dα X               α e dα
   ∗
  δ (X) = R ∞      Pn        n+3  −α
                                     Pn        2
                                                     =       Xi R ∞0 n+1 −α
             0 (α/   i=1 Xi )    e ( i=1 Xi /α )dα       i=1     0 α    e dα
               n
               X                            n
                          Γ(n + 1)     1 X
           =         Xi            =           Xi
               i=1
                          Γ(n + 2)   n + 1 i=1


                                           Revista Colombiana de Estadı́stica 29 (2006) 195–220

206                                                    Juvêncio Nobre & Caio Azevedo


que não coincide com o ENVVUM, que é dado por X, que também é um estimador
equivariante por escala; porém, o EERM possui risco uniformemente menor do que
o ENVVUM para a função de perda (28).

  Na próxima seção consideraremos o processo de estimação equivariante nos
modelos de localização-escala.


4     Modelos de localização-escala
Nesta seção estudaremos o processo de construção dos estimadores equivariantes
dos parâmetros de localização-escala considerando ambos os parâmetros desco-
nhecidos. Salientamos que estaremos focados em apenas um dos parâmetros por
vez.
   Primeiramente, vamos introduzir a famı́lia de localização-escala. Consideramos
que a densidade do vetor aleatório X = (X1 , . . . , Xn )> é
                                                       
                              1     x1 − ξ       xn − ξ
                                f          ,...,                                    (37)
                             τn       τ            τ

em que o vetor de parâmetros θ = (ξ, τ )> é desconhecido. Este problema perma-
nece invariante sob as transformações,

         X∗i = a + bXi ,   ξ ∗ = a + bξ,   τ ∗ = bτ,   i = 1, . . . , n   (b > 0)   (38)

    Nas próximas duas seções apresentaremos o procedimento para a obtenção dos
estimadores dos parâmetros de escala e de localização, respectivamente. Note que
este grupo de transformações é transitivo, o que, com a escolha duma função de
perda adequada, torna o risco constante com relação ao parâmetro de interesse.


4.1    Parâmetro de interesse é o de escala
      Na Seção 3, os estimadores equivariantes por escala foram caracterizados como
a razão entre em estimador equivariante por escala (função dum vetor aleatório
pertencente à famı́lia de escala) e uma função dum vetor de estatı́sticas ancilares
para τ . O desenvolvimento no presente caso é basicamente uma extensão daquele
primeiro. Sob o grupo de transformações definido em (38), um estimador de τ r
será equivariante por escala se,

                                δ(a + bX) = br δ(X)                                 (39)

    Sendo assim, temos que a classe dos estimadores equivariantes por escala pode
ser descrita como
                                          δ0 (Y)
                                 δ(X) =
                                          w(Z)

                                     Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                       207


em que δ0 um estimador equivariante por escala como em (39), i = 1, . . . , n − 1,
Y = (Y1 , . . . , Yn−1 )> , Yi = Xi − Xn , Z = (Z1 , . . . , Zn−1 )>
                              Yi                                            Yn−1
                  Zi =                ,   i = 1, . . . , n − 2,   Zn−1 =                      (40)
                            |Yn−1 |                                        |Yn−1 |
Além disso, a densidade de Y possui estrutura da famı́lia de escala e Z é uma
estatı́stica ancilar para θ (Lehmann & Casella 1998, p. 168).
    Segue então, do teorema 3, que o EERM para τ r é dado por
                                                       δ0 (Y)
                                            δ(X) =                                            (41)
                                                       w∗ (z)
em que w∗ (z) é um número que minimiza (o risco)

                                   Eτ =1 [φ (δ0 (Y)/w(z)) | Z = z]                            (42)

Exemplo 11. EERM para a variância duma distribuição normal com média des-
conhecida.
    Considere X1 , P. . . , Xn uma amostra aleatória duma distribuição N (ξ, τ 2 ). Te-
                        n
mos que T = (X, i=1 (Xi − X)2 )> é uma estatı́stica suficiente e completa para θ
          Pn Logo, pelo teorema de Basu, T e Z são independentes e, portanto,
e Z é ancilar.
δ0 (X) = i=1 (Xi − X)2 e Z também o são. Além disso, δ0 é um estimador equi-
variante por escala [(39), com r = 2]. Portanto, considerando a função de perda
φ(d/τ 2 ) = [(d − τ 2 )2 ]/τ 4 , temos que,
                                                      n−1
                                                             n−1 
           ∗       E1 [δ02 (X)|Z]      E1 [δ02 (X)]    2 +1    2    4
          w (z) =                   =               =                 =n+1
                   E1 [δ0 (X)|Z]        E1 [δ(X)]         n−1
                   Pn
pois δ0 (X)τ =1 = i=1 (Xi − X)2 ∼ χ2n−1 . Portanto, o EERM de τ será
                                                      n
                                                 1 X
                                   δ(X) =                (Xi − X)2
                                               n + 1 i=1

Exemplo 12. Distribuição uniforme
                                                                                        
     Sejam X1 , . . . , Xn uma amostra aleatória duma distribuição U ξ − τ2 , ξ + τ2
e considere o problema de estimar τ com função de perda igual à do exemplo
11 [com r = 1]. Temos que T = (X(1) , X(n) )> é suficiente e completa e, pelo
teorema de Basu, é independente de Z (Lehmann & Casella 1998). Além disso,
δ0 = X(n) −X(1) é um estimador equivariante por escala [sob (38)] para τ e também,
é independente de Z. Como [X(n) −X(1) ] ∼ β(n−1, 2) se ξ = 0 e τ = 1, temos que,
                                            n(n−1)
                        ∗     E1 δ02 (X)    (n+2)(n+1)     n
                      w (Z) =             =    n−1     =
                              E1 [δ0 (X)]      n+1
                                                         n + 2
Dessa forma, o EERM de τ será
                                               n+2
                                   δ ∗ (X) =       (X(n) − X(1) )
                                                n


                                               Revista Colombiana de Estadı́stica 29 (2006) 195–220

208                                                            Juvêncio Nobre & Caio Azevedo


4.2    Parâmetro de interesse é o de localização
     Tal como na seção anterior, o desenvolvimento aqui apresentado constitui, es-
sencialmente, uma extensão daquele apresentado na Seção 1, cap. 3 de Lehmann
& Casella (1998). As transformações definidas em (38), relacionadas aos espaços
amostral e paramétrico, permanecem as mesmas. Contudo, a transformação rela-
cionada ao estimador deve ser

                                    δ(a + bX) = a + b δ(X)                                 (43)

Uma função de perda é invariante sob essas transformações se e somente se for da
forma                                              
                                                d−ξ
                               L(ξ, τ, d) = ρ                                    (44)
                                                 τ
Pela transitividade do grupo de transformações (38), a função de risco será cons-
tante [Seção 2].
   Para um valor fixo de τ , seja

                                            1  x1           xn 
                                    gτ =      f    , . . . ,
                                           τn   τ            τ

   de tal modo que (37) se torne

                                    gτ (x1 − ξ, . . . , xn − ξ)                            (45)

   O lema 4.1 fornece um modo de obter EERM de ξ em certas situações.

Lema 1. Suponha que para a famı́lia de localização (45) e função de perda (44),
exista um EERM, digamos δ ∗ , considerando τ conhecido e que

 i) δ ∗ não é função de τ , e

 ii) δ ∗ satisfaz (43).

   Então δ ∗ é o EERM de ξ satisfazendo (43).

Demonstração. Como δ ∗ minimiza o risco, qualquer outro estimador terá risco
maior ou igual a ele. Como isso vale ∀ τ , então o resultado segue.

Exemplo 13. EERM para a média da distribuição normal.
    Sejam X1 , . . . , Xn uma amostra aleatória duma distribuição N (ξ, τ 2 ) com am-
bos os parâmetros desconhecidos. Lehmann & Casella (1998) encontram δ ∗ = X
como EERM de ξ com a variância conhecida, para qualquer função de perda (44)
(convexa e par; note que, no caso considerado por esses autores, τ é uma constante
conhecida). Além disso, δ ∗ satisfaz as suposições do Lema 1, pois não é função de
τ e δ ∗ (a + bX) = a + bX = a + bδ ∗ (X). Logo δ ∗ é EERM de ξ também neste caso.


                                            Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                 209


Exemplo 14. Parâmetro de localização da distribuição uniforme.
                                                                    
    Seja X1 , . . . , Xn uma amostra aleatória de U ξ − τ2 , ξ + τ2 com ambos os
parâmetros desconhecidos e considere uma função de perda da forma L(ξ, τ, d) =
[(d − ξ)2 ]/(τ 2 ). Lehmann & Casella (1998) demonstram que δ ∗ = (X(1) + X(n) )/2
é o EERM de ξ quando τ é conhecido. Pelas mesmas justificativas apresentadas
no exemplo 14, temos que δ ∗ é o EERM de ξ também neste caso.

    Entretanto, alguns estimadores não satisfazem as condições do lema 1, como
aqueles apresentados em Lehmann & Casella (1998, p. 153 e 155). Sendo assim,
é necessário o desenvolvimento de alguns EERM que não dependam das referidas
suposições.

Teorema 5. Seja δ0 qualquer estimador de ξ satisfazendo (43) e δ1 qualquer
estimador de τ tomando valores positivos e satisfazendo

                          δ1 (a + bx) = b δ1 (x),    ∀ b > 0,   ∀a                      (46)

    Então, δ satisfaz (43) se e somente se for da forma

                                δ(x) = δ0 (x) − w(z)δ1 (x)                              (47)

em que z é dado por (40).

Demonstração. Primeiramente, pelo lema 1.6 (Lehmann & Casella 1998, p. 150),
temos que δ satisfaz (43) se e somente se for da forma,

                                δ(x) = δ0 (x) − u(x)δ1 (x)                              (48)

em que
                              u(a + bx) = u(x) , ∀ b > 0 e ∀a                           (49)

   Suficiência. Considere que δ(x) = δ0 (x) − u(x)δ1 (x) e u(a + bx) = u(x).
Dessa forma, temos que

                   δ(a + bx) = δ0 (a + bx) − u(a + bx)δ1 (a + bx)
                              = a + b δ0 (x) − b u(x)δ1 (x)
                              = a + b [δ(x) − u(x)δ1 (x)] = a + b δ(x)

    Necessidade. Considere que δ(a + bX) = a + bδ(X) e defina u(x) = (δ(x) −
δ0 (x))/(δ1 (x)). Portanto,

                         δ(a + bx) − δ0 (a + bx)   a + bδ(x) − a − bδ0 (x)
           u(a + bx) =                           =
                                 δ1 (a + bx)               bδ1 (x)
                         δ(x) − δ0 (x)
                       =                 = u(x)
                             δ1 (x)


                                         Revista Colombiana de Estadı́stica 29 (2006) 195–220

210                                                                Juvêncio Nobre & Caio Azevedo


   Logo, (48) e (49) são válidos. O fato de (48) ser válido se e somente se u
depender de x através de z decorre do lema 1.7 (Lehmann & Casella 1998, p.
151)e do teorema 2.
   Por outro lado, um argumento semelhante ao teorema 1.10 (Lehmann & Casella
1998, p. 151) mostra que o EERM de ξ é,

                                δ(X) = δ0 (X) − w∗ (z)δ1 (X)                                (50)

em que w∗ (z) é um número que minimiza

      Eξ=0,τ =1 [ρ (δ0 (X) − w∗ (z)δ1 (X)) | z] = E0,1 [ρ (δ0 (X) − w∗ (z)δ1 (X)) | z]

    Em particular, se
                                                             2
                                           d−ξ           (d − ξ)
                                   ρ                 =                                      (51)
                                            τ               τ2
não é difı́cil ver que
                                            E0,1 [δ1 (X)δ0 (X)|Z]
                               w∗ (z) =                                                     (52)
                                               E0,1 [δ12 (X)|Z]
Exemplo 15. Exponencial deslocada Sejam X1 , . . . , Xn uma amostra aleatória
duma distribuição E(ξ, τ ) cuja densidade é dada por

                    fXi (xi ) = τ −1 e−(x−ξ) 11[ξ,∞) (x),          ξ ∈ R,   τ >0

com ambos os parâmetros desconhecidos. Considere δ0 (X) = X(1) e δ1 (X) =
Pn                                    >
  i=1 Xi − X(1) . Como δ = (δ0 , δ1 )      é uma estatı́stica suficiente e completa
para θ, ela é independente de Z pelo teorema de Basu e, além do mais, é possı́vel
demonstrar que são independentes entre si (Lehmann & Casella   Pn1998, p. 43). Por
                                                                                 
outro lado, δ0 (a + bX) = a + bX(1) = a + bδ0 e δ1 (a + bX) = b i=1 Xi − X(1) =
bδ1 (X). Sendo assim, o teorema 5 pode ser aplicado, o que, unido à função de
perda (51) e com o fato de que δ0 (X)τ =1 ∼ E(0, 1/n) e δ1 (X)τ =1 ∼ Γ(n − 1, 1)
(Lehmann & Casella 1998), leva a
                                                                               1   Γ(n)
      ∗    E0,1 [δ0 (X)δ1 (X) | Z]   E0,1 [δ0 (X)] E0,1 [δ1 (X)]   n Γ(n−1) 1
   w (z) =                         =                             = Γ(n+1) = 2
              E0,1 [δ12 (X) | Z]            E0,1 [δ12 (X)]                  n
                                                                                Γ(n−1)


    Logo, o EERM de ξ é
                                                         m
                                                 1 X            
                            δ ∗ (X) = X(1) −      2
                                                       Xi − X(1)
                                                 n i=1


4.3       Estimação simultânea
Nas subseções anteriores, mostramos como encontrar EERM para os parâmetros
do modelo de localização-escala de forma marginal. Nesta subseção, apresenta-
mos os resultados obtidos por Prabakaran & Chandrasekar (1994), que estimam


                                            Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                 211


de forma conjunta os parâmetros (ξ, τ r )> no modelo de localização-escala (37).
Inicialmente, são dadas algumas definições e conceitos necessários para o desen-
volvimento desta subseção.
    Considere o grupo de transformações
                                        X∗ = a + bX                                     (53)
                                    ∗
que induzem à transformação θ = (ξ ∗ , τ ∗ )> = (a + bξ, bτ )> , sob a qual o modelo
(37) permanece invariante. Se d = (d1 , d2 )> é uma estimativa de (ξ, τ r )> obtida no
modelo original, então podemos relacionar a mesma com a estimativa de (ξ ∗ , τ ∗r )>
obtida no modelo transformado, da forma g(d) = d∗ = (a + b d1 , br d2 )> , que é
uma função apenas de d. Pode-se mostrar (Prabakaran & Chandrasekar 1994)
que uma função de perda é invariante sobre as transformações acima se e somente
se                                                     
                                             d1 − ξ d2
                              L(θ, d) = ρ           , r                            (54)
                                                τ    τ
e que o grupo G é transitivo sobre Ω = R × R+ . Portanto, o risco de qual-
quer estimador equivariante, calculado sob funções de perda da forma (54), não
depende de θ.
Definição 6. Um estimador (δ1 , δ2 )> de (ξ, τ r )> é dito ser equivariante por
localização-escala se δ1 e δ2 são estimadores marginalmente equivariantes por
localização-escala, respectivamente, para ξ e τ r , ou seja, se δ1 satisfaz (43) e δ2
satisfaz (39).
Definição 7. Uma função vetorial u(x) = (u1 (x), u2 (x))> é dita ser invariante
para o problema de localização-escala se
                 u(a + bx) = (bu1 (x), u2 (x))> ,       ∀a ∈ R       e   ∀b > 0         (55)

   A seguir, mostramos alguns resultados importantes acerca da caracterização
dos estimadores equivariantes por localização-escala de (ξ, τ r )> .
Lema 2. Um estimador (δ1 (x), δ2 (x))> é equivariante por localização-escala para
(ξ, τ r ) se e somente se, para todo estimador equivariante (δ01 (x), δ02 (x))> , existir
uma função invariante por localização-escala u tal que
                                  δ1 (x) = δ01 (x) − u1 (x)                             (56)
                                  δ2 (x) = δ02 (x)/u2 (x)                               (57)

    O seguinte lema fornece uma caracterização das funções invariantes por loca-
lização-escala.
Lema 3. Uma função u(x) = (u1 (x), u2 (x))> é invariante para o problema de
localização-escala se e somente se
                              u1 (x) = g(x)w1 (z1 , . . . , zn−1 )                      (58)
                              u2 (x) = w2 (z1 , . . . , zn−1 )                          (59)
para alguma função positiva g tal que g(a + bx) = bg(x) e zi = (xi − xn )/g(x)
(i = 1, . . . , n − 1).


                                         Revista Colombiana de Estadı́stica 29 (2006) 195–220

212                                                        Juvêncio Nobre & Caio Azevedo


   Perceba que se fizermos g(x) = |xn−1 − xn |, obtemos a mesma caracterização
obtida nas Seções 4.1 e 4.2 de forma marginal. Pode-se observar também que g,
como definida acima, é um estimador equivariante por escala de τ .
Teorema 6. Seja (δ01 (x), δ02 (x))> um estimador equivariante de (ξ, τ r )> . Então
uma condição necessária e suficiente para que (δ1 (x), δ2 (x))> seja um estimador
equivariante por localização-escala é que ele seja da forma

                        δ1 (x) = δ01 (x) − g(x)w1 (z1 , . . . , zn−1 )                 (60)
                        δ2 (x) = δ02 (x)/w1 (z1 , . . . , zn−1 )                       (61)

para algumas funções w1 e w2 .

Demonstração. É uma consequência imediata dos lemas 2 e 3.

   Considere D a classe de todos os estimadores equivariantes para (ξ, τ r )> que
tenham risco finito. Em particular, quando a função de perda é da forma
                          2                                        2
                    d1 − ξ             d1 − ξ    d2                d2
   L(θ, d) = a11              + 2a12                − 1   + a 22      − 1    (62)
                       τ                  τ      τr                τr

então um estimador δ ∗ ∈ D que minimiza risco sobre esta função de perda é
denominado QA -EERM (Prabakaran & Chandrasekar 1994), com A = (aij )1≤i,j≤2
representando uma matriz 2 × 2 simétrica positiva definida. A função de perda
(62) é dita ser quadrática, conforme definido em Zacks (1971, p. 102).
Teorema 7. Considere X um vetor aleatório com densidade (37). Se
                                     
 i) L(ξ, τ, d1 , d2 ) = ρ d1τ−ξ , τd2r ;

 ii) existir um estimador equivariante δ 0 = (δ01 , δ02 )> com risco finito;
iii) para cada z = (z1 , . . . , zn−1 )> , existir uma função vetorial w∗ (z) que mini-
     mize E[ρ(δ01 (X) − g(X)w1 (z), δ02 (X)/w2 (z))/z], com o operador esperança
     sendo calculado quando θ = (0, 1)> .
      Então um EERM δ ∗ = (δ1∗ , δ2∗ )> existe e é dado por

                                δ1∗ (X) = δ01 (X) − g(X)w1∗ (z)                        (63)
                                δ2∗ (X) = δ02 (X)/w2∗ (z)                              (64)

Demonstração. Analóga à demonstração do teorema 3.

     A abordagem acima é bem geral e fornece uma estimação simultânea de ξ e
τ r . Escolhendo a função de perda de forma apropriada, pode-se obter os mesmos
EERM para ξ e τ r obtidos (de forma marginal) nas subseções anteriores. Para
isto, basta escolher de forma conveniente a matriz A.
     Considerando que a função de perda seja dada por (62), Prabakaran & Chan-
drasekar (1994, eq. 3.6 e 3.7) obtêm expressões explı́citas dos EERM de (ξ, τ r )>


                                        Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                 213


que dependem da particular escolha da matriz A. Os autores mostram também
que quando o interesse é estimar θ = (ξ, τ )> , o EERM por localização-escala é
independente da escolha da matriz A é e dado por δ ∗ (X) = (δ1∗ (X), δ2∗ (X))> com
                                               E[δ01 (X)δ02 (X) | Z]
                    δ1∗ (X) = δ01 (X) − δ02 (X)        2 (X)|Z]                         (65)
                                                   E[δ02
                              δ02 (X)E[δ02 (X)|Z]
                    δ2∗ (X) =        2 (X)|Z]                                           (66)
                                  E[δ02
que coincidem com os EERM marginais de ξ e τ , dados por (50) e (41), sob as
funções de perda quadráticas (51) e (28), respectivamente.
    Além disso, Prabakaran & Chandrasekar (1994) concluem que sob funções de
perda quadráticas, os EERM de (ξ, τ r )> , r > 1, não coincidem com os EERM
de ξ e τ r obtidos de forma marginal, e que esta diferença pode ser atribuı́da
ao fato de que θ = (ξ, τ )> é o parâmetro natural enquanto que (ξ, τ r )> é uma
função paramétrica de θ. Entre outras propriedades, Prabakaran & Chandrasekar
(1994) caracterizam o QA -EERM (caracterização semelhante à do ENVVUM) de
θ e mostram que se ele existe, então é único q.c. (tais propriedades podem ser
aplicadas nos resultados obtidos nas subseções anteriores quando se tem interesse
em estimar marginalmente ξ ou τ sob funções de perda quadráticas das formas
(51) e (28)).
                                                                       a.a.
Exemplo 16. Distribuição E(ξ, τ ). Suponha que X1 , . . . , Xn ∼ E(ξ, τ ) e que se
tem interesse em estimar obter o EERM de θ = (ξ, τ )> , considerando a função de
perda (62). Como foi discutido anteriormente, tem-se que o EERM por localização-
escala de θ é independente da particular escolha da matriz A e é dado por δ ∗ (X) =
(δ1∗ (X), δ2∗ (X))> , com δ1∗ (X) = X(1) sendo
                                           P o EERM marginal por localização de ξ
sob a função de perda (51) e δ2∗ (X) = ni=1 (X(i) − X(1) ) sendo o EERM marginal
por escala de τ sob a função de perda (28), como foi mostrado anteriormente.
Dado que o EERM por localização-escala existe, conclui-se também que ele é
único quase-certamente [P].


5     Aplicação em modelos lineares e ENVVUM
Os modelos de regressão constituem uma das mais importantes ferramentas de
análise estatı́stica. Nesta seção, apresentaremos alguns resultados de estimação
equivariante e não-viciada de variância uniformemente mı́nima, aplicados à classe
de modelos de regressão normais lineares. Existe uma vasta literatura sobre esses
modelos, entre as quais destacamos Scheffé (1959), Seber (1977), Searle (1987),
entre outros.
    Antes de abordan propriamente os processos de estimação, vamos definir o
chamado Modelo Linear Geral (normal) (Searle 1987), qual seja,
                              Xi ∼ N (ξi , σ 2 ),i = 1, . . . , n                (67)
                                                    Q
em que os Xi são independentes e ξ1 , . . . , ξn ∈ Ω que é um sub-espaço linear de
dimensão s de En (s < n).


                                         Revista Colombiana de Estadı́stica 29 (2006) 195–220

214                                                            Juvêncio Nobre & Caio Azevedo


   Para evitar problemas de não-identificabilidade (Searle 1987) e para facilitar
o processo de obtençao de estatı́sticas suficientes e completas para a estimação
NVVUM (Lehmann & Casella 1998), é conveniente reduzir este modelo à forma
canônica através da transformação ortogonal
                                             Y = XC                                          (68)
que leva a
                                         η = E(Y) = ξC
em que η = (η1 , . . . , ηn )> e ξ = (ξ1 , . . . , ξn )> . Note que a transformação (68) é 1
a 1 e, além disso, o Jacobiano é igual a 1. Segue daı́, devido às propriedades da
distribuição normal multivariada (Mardia et al. 1979), que Y ∼ N (η, σ 2 In ), pois
                         Cov(Y) = σ 2 CIC> = σ 2 CC> = σ 2 In
notando que C é ortogonal, com In representando a matriz identidade de ordem
n. Denotando por c>      i Qa i-ésima coluna de C, é desejável escolher ci de tal modo
que c1 , . . . , cs gerem Ω [para garantir a identificabilidade]. Então,
                    Y
               ξ∈       ⇐⇒ ξ for ortogonal às n − s colunas restantes de C
                 Ω

Como η = ξC = [ξ 1 C1        ξ2 C2 ] = [ξ1 C1 0], segue que,
                                Y
                            ξ∈       ⇐⇒ ηs+1 = · · · = ηn = 0
                                  Ω

Em termos dos Y , temos que,
                          (
                                      N (ηi , σ 2 ), i = 1, . . . , s;
                           Yi =
                                      N (0, σ 2 ), i = s + 1, . . . , n.
                           Q
Note que, ξ varia em         Ω e η1 , . . . , ηs varia irrestritamente sobre Es com
ηs+1 = . . . = ηn = 0.
                                                               Pn
    Nesta representação T = (Y1 , . . . , Ys , S 2 )> , S 2 = j=s+1 Yj2 , é uma estatı́stica
suficiente e completa para (η1 , . . . , ηs , σ 2 )> (Lehmann & Casella 1998). O teorema
a seguir apresenta um modo de obter os EERM e ENVVUM dos parâmetros de
interesse.
Teorema 8.
                          Ps                                             2
     Os ENVVUM de
  i) P                      i=1 λi ηi (λ são constantes conhecidas) e σ   são
       s           2
          λ Y
       i=1 i i e S   /(n − 2), respectivamente.
 ii) Sob as transformações
               Yi∗ = Yi + ai (i = 1, . . . , s)            Yi∗ = Yi (i = s + 1, . . . , n)
                                                                      Xn
                ηi∗ = ηi + ai (i = 1, . . . , s)           d∗ = d +       ai λi
                                                                       i=1
                                                   Ps
                  de perda L(η, d) = ρ(d − i=1 λi ηP
      com funçãoP                                i ), em que ρ é convexa e par, o
      ENVVUM si=1 λi Yi também é o EERM de si=1 λi ηi .


                                            Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                     215


iii) Sob a função de perda (d − σ 2 )2 /σ 4 , o EERM de σ 2 é S 2 /(n − s + 2).

Demonstração.

   1. Basta observar que os estimadores propostos são não-viesados e, além disso,
      funções de estatı́sticas suficientes e completas, no caso (Y1 , . . . , Ys , S 2 )> .
   2. Note que o grupo de transformações é transitivo e a função de perda é inva-
                          P e portanto, o risco é constante. Por outro lado, note,
      riante por localização
      denotanto δ(Y) = si=1 λi Yi , que

         δ(Y1 + a1 , Y2 + a2 , . . . , Ys + as , Ys+1 , . . . , Yn ) =
                           X s                      Xs               Xs                s
                                                                                       X
                                  λi (Yi + ai ) =         λi Yi +       λi ai = δ(Y) +   λi ai
                               i=1                    i=1           i=1                i=1

      Ou seja, o ENVVUM também é equivariante por localização. Pelo teo-
      rema de Rao-Blackwell (Lehmann & Casella 1998), temos que, para qualquer
                                                    menor ou igual ao de qualquer
      função de perda convexa, o risco de δ(Y) é P
                                                     s
      outro estimador. Logo, δ(Y) é o EEMR de i=1 λi ηi .
   3. Segue essencialmente do exemplo 11.

      É conveniente expressar os estimadores desenvolvidos em termos das variáveis
originais X ao invés de Y (lembre-se de que a transformação é 1 a 1). Para tal,
vamos introduzir o seguinte conceito.
                         Q
      Tome ξ ∈                        os estimadores de mı́nimos quadrados destes são
                           Ω , então P                                        Q
(ξb1 , . . . , ξbn ) que minimizam ni=1 (Xi − ξi )2 , sujeito à condição ξ ∈ Ω .
                                                            Pn             Pn
Teorema 9. Sob o modelo (67), o EN V V U M de i=1 γi ξi é i=1 γi ξbi , ∀γi ∈ R
conhecido.

Demonstração. Pelo teorema 8 e a completividade de T é suficiente mostrar
P                                                                                Pn      que
  n      b
  i=1 γi ξi é uma função linear de Y1 , . . . , Ys e que é não-viesado para  i=1 γi ξi .
   Note que
                        n
                        X                     n
                                              X
                              (Xi − ξi )2 =         (Yi − E(Yi ))2
                        i=1                   i=1
                                              s
                                              X                      n
                                                                     X
                                         =          (Yi − ηi )2 +           Yi2              (69)
                                              i=1                   i=s+1

O lado direito de (69) é minimizado por ηbi = Yi , i = 1, . . . , s, enquanto que o lado
esquerdo, por ξb1 , . . . , ξbn . Assim, temos que (η = ξC)

         ξC ⇒ (Y1 . . . YS 0 . . . 0) = (ξb1 . . . ξbn )C ⇒ b
    ηb = b                                                  ξ = (Y1 . . . YS 0 . . . 0)C−1   (70)

   Como E(b ξ) = ηC−1 = ξCC−1 = ξ, ou seja, é um estimador não-viesado, e de
(70), vemos que são funções lineares do vetor Y.


                                          Revista Colombiana de Estadı́stica 29 (2006) 195–220

216                                                              Juvêncio Nobre & Caio Azevedo


   Agora, vamos reinterpretar as considerações sobre equivariância em termos
das variáveis originais. Antes, precisamos definir o grupo de transformações que
deixam o problema invariante. As transformações conduzidas nos Y (teorema 8)
em termos das variáveis X1 , . . . , Xn , tornam-se

                                                                                     Y
              X∗ = X + b                                 b = (b1 , . . . , bn )> ∈
                                                                                     Ω
                              Y                                     n
                                                                    X
               ξ∗ = ξ + b ∈                             d∗ = d +          bi γi             (71)
                                  Ω                                 i=1


   Podemos então estender o teorema 8 para o seguinte corolário.
                                             Pn                     Pn
Corolário 5. Sob as transformações
                       Pn              (71), i=1 γi ξbi é o EERM de i=1 γi ξi com
função de perda ρ(d − i=1 γi ξi ) convexa e par.
                                                  Ps
Demonstração. Notando que de (70) ξbj =           i=1 cij Yi , j = 1, . . . , n, então
Pn      b    Ps    ∗           ∗
                                   Pn
 j=1 γj ξj =  i=1 ci Yi , com ci =  j=1 γj cij e o resultado segue do teorema 8(i).



   Para obter o ENNVUM e o EERM de σ 2 em termos do vetor X, é necessário
apenas expressar S 2 em função desse vetor. Note que, da minimização de (69),
temos
                        Xn                 Xn
                            (Xi − ξbi )2 =     Yi2 = S 2                     (72)
                            i=1                       i=s+1

   Logo, o ENNVUM e o EERM de σ 2 são, respectivamente teorema 8 (iii),
                        Pn          b 2                Pn           b 2
                          i=1 (Xi − ξi )                  i=1 (Xi − ξi )
                                                  e
                              n−s                          n−s+2

   Vamos agora ilustrar os resultados apresentados.

Exemplo 17. Anova com 1 fator.
   Suponha que Xij ∼ N (ξi , σ 2 ), i = 1, . . . , s; j = 1, . . . , ni e que sejam inde-
pendentes. Do corolário 5 temos que, para encontrar os ENVVUM ou EERM de
combinações lineares de ξ, basta encontrar os estimadores de mı́nimos quadrados.
Estes, por sua vez, são os valores bξ que minimizam,
             s X ni                s
                                       ( n                                    )
           X                      X     X i
                               2                        2                   2
                    (Xij − ξi ) =           (Xij − Xi. ) + ni (Xi. − ξi )
           i=1 j=1                     i=1     j=1

que resulta em
                                                      ni
                                                  1 X
                                      ξbi = Xi. =        Xij
                                                  ni j=1


                                             Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                       217


    Além disso, de (72), temos que o ENVVUM de σ 2 é
                                                  Xs X ni
                                         1
                         b 2 = Ps
                         σ                                (Xij − Xi. )2
                                      i=1 n i − s i=1 j=1

Exemplo 18. Anova com 2 fatores.
   Considere Xijk ∼ N (ξij , σ 2 ), i = 1, . . . , I; j = 1, . . . , J; k = 1, . . . , m. Uma
reparametrização usual para este modelo é

                                    ξij = µ + αi + βj + γij

com as seguintes restrições de identificabilidade
                         I
                         X            J
                                      X            I
                                                   X             J
                                                                 X
                               αi =         βj =         γij =         γij = 0                (73)
                         i=1          j=1          i=1           j=1


    Usando as restrições (73) temos que (o ponto representa a média calculada no
ı́ndice de interesse)

                          ξ.. = µ,      ξi. = µ + αi ,      ξ.j = µ + βj

    Então,

              µ = ξ.. , αi = ξi. − ξ.. , βj = ξ.j − ξ.. , γij = ξij − µ − αi − βj

ou ainda, γij = (ξij − ξ.. ) − [(ξi. − ξ.. ) + (ξ.j − ξ.. )]. Note que αi é o efeito médio do
nı́vel i do primeiro fator, βj é o efeito médio do nı́vel j do segundo fator e γij é a
diferença entre o efeito conjunto dos dois fatores e a soma dos efeitos dos fatores
separados de cada um (chamado de interação).
    Os ENVVUM desses parâmetros (efeitos) seguen-se imediatamente do teo-
rema 8 e do exemplo 17. Essencialmente, os ENVVUM são obtidos calculando-se
os estimadores de mı́nimos quadrados do vetor ξ, que neste caso são (denotando
pelo ponto a média calculada num determinado ı́ndice),

 µ
 b = X... ,    α
               bi = Xi.. − X... ,      βbj = X.j. − X... ,        γij = Xij. − Xi.. − X.j. + X...
                                                                  b

    Análogamente, o ENVVUM de σ 2 é

                                    XXX     m     J   I
                              1
                                             (Xijk − Xij. )2
                          IJ(m − 1)  j=1 i=1k=1


    Note ainda que, do corolário 5, os EMQ (estimadores de mı́nimos quadrados) de
b
ξ são também os EERM, sob uma perda convexa, par e invariante por localização.

   Estes resultados podem ser generalizados para experimentos fatoriais, ou seja,
experimentos que envolvem um número geral de fatores.


                                             Revista Colombiana de Estadı́stica 29 (2006) 195–220

218                                                     Juvêncio Nobre & Caio Azevedo


   Podemos ainda considerar situações em que restrigimos o interesse em estima-
dores não-viciados e funções de perda quadrática mas, por outro lado, desconside-
rando a normalidade e a independência.
   Suponha que consideramos de (67) somente suposições a respeito dos dois pri-
meiros momentos,
                              Y
         E(Xi ) = ξi , ξ ∈       , Var(Xi ) = σ 2 , Cov(Xi , Xj ) = 0, i 6= j    (74)
                             Ω

sem considerar as suposições de independência ou normalidade.

Teorema 10 (Gauss). Para os estimadores de Mínimos Quadrados
                              Pn     b
                          Pn i= γi ξi do teorema 9 é ENVVUM, entre todos os
    Sob as suposições (74),
estimadores lineares, de i=1 γi ξi .

Demonstração.
     Pn            Este estimador também é não-viesado, nas referidas
                                                                    Pn      condições.
Seja i=1 ci Xi qualquer outro estimador linear não-viesado de i=1 γi ξi . Como
Pn       b
  i=1 γi ξi é o ENVVUM no caso normal e a variância de funções lineares dos
Xi ndependemo somente    nPdo primeiroo      e segundo momentos, segue que
     Pn         b            n      b            Pn       b
Var      i=1 γi ξi ≤ Var     i=1 ci ξi . Então,   i=1 γi ξi é o ENNVUM entre to-
dos os estimadores lineares não-viesados.
                                                                  P
Corolário 6. Sob as suposições (74) e com perda quadrática, ni=1 γi ξbi é o EERM
com respeitoPnas trasnformações (71) entre todos os estimadores equivariantes li-
neares de i=1 γi ξi .

Demonstração. Este resultado segue do lema 1.23 (Lehmann & Casella 1998,
                    Pn
p. 157), dado que i=1 γi ξbi é o ENVVUM (entre os estimadores lineares) e além
disso é equivariante.

     Para finalizar, gostarı́amos de salientar que os resultados apresentados nesta
seção podem ser estendidos para Modelos Lineares Mistos, como no teorema 4.14,
Lehmann & Casella (1998, p. 185); veja também Harville (1976).


6     Conclusões e comentários adicionais
Verificamos que, em sua essência, os estimadores equivariantes podem ser cons-
truı́dos a partir dum estimador equivariante qualquer e duma estatı́stica ancilar.
Além disso, se este estimador equivariante escolhido for função duma estatı́stica
suficiente e completa, ele será independente da estatı́stica ancilar em questão e
isso facilita a obtenção do EERM.
    Desde que se restrinja aos estimadores lineares, a estimação NVVUM, no con-
texto de modelos lineares, não fica comprometida sem a suposição de normalidade
e, além disso, estes estimadores podem ser obtidos em várias situações, inclusive
para os efeitos aleatórios em modelos mistos (Harville 1976).


                                      Revista Colombiana de Estadı́stica 29 (2006) 195–220

O princı́pio da equivariância: conceitos e aplicações                                 219


    Além das situações apresentadas neste trabalho, famı́lia de localização-escala e
alguns modelos lineares, podemos citar Zacks (1971), Schervish (1995) e Lehmann
& Casella (1998) que discutem estimação equivariante no contexto bayesiano;
Borovkov (1998) e Lehmann & Romano (2005) definem os testes de hipóteses
invariantes e apresenta algumas propriedades destes testes; (Khuri et al. 1998)
fazem uso da teoria de testes invariantes para definir testes invariantes uniforme-
mente mais poderosos em modelos mistos, tanto para as componentes de variância,
como para os efeitos fixos (dado a inexistência de testes UMP na maioria das si-
tuações nessa classe de modelos); e Alexander & Chandrasekar (1999) que, dentro
do contexto de Análise de Sobrevivência (amostra com censura), discutem o pro-
blema de estimação equivariante dos parâmetros do modelo exponencial.


Agradecimentos
Este trabalho foi apresentado na disciplina MAE 5834 - Estatı́stica Avançada I
(2004) no IME-USP. Os autores gostariam de agradecer à Profa. Dra. Silvia
Ferrari (IME/USP) que revisou paciente e cuidadosamente todo o manuscrito e
nos concedeu imprescindı́veis sugestões e ao colega de doutorado Raydonal Ospina
por sugerir a submissão do referido trabalho e aos dois árbitros pelas valiosas
sugestões para a melhoria do nosso trabalho. Gostariamos também de agradecer
ao CNPq pelo suporte financeiro ao curso de Doutorado.
Referencias
Alexander T L,Chandrasekar B.Equivariant Estimation for the ParaMeters of an Exponential Model Based on Censored Sampling.(1999).Biometrical.
Borovkov A A.Mathematics Statistics.(1998).Gordon and Breach Science Publishes.Moscow.
Casella G,Berger R L.Statistical Inference.(2002).Duxbury Advanced Series.New York.
Harville D A.Extension of the Gauss-Markov Theorem to Include the Estimation of Random Effects.(1976).The Annals of Statistics.
Khuri A I,Mathew T,Sinha B K.Statistical Tests for Mixed Linear Models.(1998).John Wiley & Sons.New York.
Lehmann E L,Casella G.Theory of Point Estimation.(1998).Springer-Verlag.New York.
Lehmann E L,Romano J P.Testing Statistical Hypothesis.(2005).Springer-Verlag.New York.
Mardia K V,Kent J T,Bibby J M.Multivariate Analysis.(1979).Academic Press.London.
Prabakaran T,Chandrasekar B.Simultaneous Equivariant Estimation for Location-Scales Models.(1994).Journal of Statistical Planning and Inference.
Scheffé H.The Analysis of Variance.(1959).Wiley.New York.
Schervish M J.Theory of Statistics.(1995).Springer-Verlag.New York.
Searle S R.Linear Models for Unbalaced Data.(1987).Wiley, New York.
Seber G A F.Linear Regression Analysis.(1977).Wiley.New York.
Staudte R G.A Characterization of Invariant Loss Functions.(1971).The Annals of Mathematical Statistics.
Zacks S.The Theory of Statistical Inference.(1971).John Wiley.New York.