Una introducción a los diseños óptimos
Universidad Nacional de Colombia;Centro de Investigación en Matemáticas
Resumen
Introducimos varios conceptos utilizados en la teoría de diseños de experimentos óptimos. Definimos criterios de optimalidad utilizados en esta área y exploramos sus propiedades. Se listan algunos resultados importantes para encontrar diseños óptimos para modelos lineales y no lineales, entre ellos teoremas de equivalencia. Finalmente se presentan algunos ejemplos típicos donde se aplica la teoría vista anteriormente.
Palabras clave: función de información, matriz de información, criterios de optimalidad, teoremas de equivalencia, modelos de regresión no lineal.
1.     Introducción
    En muchas áreas de investigación interesa explicar una variable respuesta, Y ,
a través de k−variables explicativas, xT = [x1 , x2 , . . . , xk ], mediante un modelo de
la forma:
siendo η(x, θ) una función lineal o no lineal en el vector de parámetros desconocido
θ ∈ Rm ; y el término de error se asume que tiene media cero y varianza constante
σ 2 . Una vez se especifica el modelo, la siguiente etapa consiste en determinar en
qué condiciones experimentales, niveles de los xj ’s, se debe medir la respuesta para
obtener una mejoría en la calidad de la inferencia estadística a un menor costo.
Esto se logra construyendo un diseño donde la elección de los niveles de los xj ’s
y la frecuencia de medición de la respuesta están regidas por algún criterio de
optimalidad (con significado estadístico). Hay varios ejemplos prácticos que han
hecho uso de los diseños óptimos (véase Atkinson (1996)) y existe un gran número
de contribuciones sobre este tema; por ejemplo, entre otros autores, Smith (1918)
encontró diseños para los modelos polinomiales, Kiefer (1959) introdujo explíci-
tamente la noción de diseño óptimo y sus propiedades; y posteriormente realizó
muchos trabajos en el área (véase Brown et al. (1985)). También, recientemente
en los libros de Atkinson & Donev, A. N. (1992) y Pukelsheim (1993), los auto-
res hicieron un tratamiento estadístico y formal, respectivamente, de los diseños
óptimos.
   Este trabajo tiene como objetivo presentar los conceptos básicos de los diseños
óptimos y, en forma general, los criterios de optimalidad, tanto en modelos lineales
como no lineales, dando mayor énfasis y extensión a los primeros, ya que son
una alternativa de solución para los modelos no lineales, por ejemplo los diseños
óptimos locales mencionados en la sección 3.1.
    Este artículo se divide en cuatro secciones. En la siguiente sección se darán los
aspectos sobresalientes de los diseños óptimos para el modelo lineal, se definen los
criterios de optimalidad en general y se mencionan varios resultados, principalmen-
te teoremas de equivalencia para determinar optimalidad. En la tercera sección
se estudia el caso no lineal y se definen algunos de los criterios de optimalidad
usados en la literatura. En la última sección se construyen diseños óptimos para
dos posibles escenarios: cuando el experimentador conoce de antemano los puntos
de soporte del diseño, caso usual en diseños de experimentos (véase la sección 4.1);
y cuando no se conocen ni los puntos de soporte ni los pesos del diseño (véase la
sección 4.3).



2.    Diseños óptimos para modelos lineales
   Para los modelos lineales se considera que la relación entre las N −observaciones
Yi y xi está dada por:

                    Y (xi ) = θT f (xi ) + ,   xi ∈ Rk ,   θ ∈ Rm

donde f = [f1 , . . . , fm ]T es un vector de m−funciones continuas linealmente in-
dependientes definidas en un conjunto compacto χ, rango de regresión, χ ⊆ Rk ,
θ ∈ Rm es un vector de m−parámetros desconocidos,  es una variable alea-
toria con media cero y varianza constante σ 2 y se asume incorrelación en las
N −observaciones.

                                        Revista Colombiana de Estadística 30 (2007) 37–51

Una introducción a los diseños óptimos                                                 39

   Aunado al modelo anterior, se define un diseño aproximado,
                                                
                                    x   . . . xn
                             ξ= 1
                                    w1 . . . wn
con wi = ξ(xi ), como una medida de probabilidad definida en B, conjunto de Borel
de χ que incluye los conjuntos unitarios; tal que ξ tiene soporte finito. El soporte
de ξ es Supp(ξ) = [x1 , . . . , xn ], n: número de puntos de soporte de ξ, y las obser-
vaciones Y (x) se hacen en x1 , . . . , xn con frecuencias (o pesos) aproximadamente
proporcionales a w1 , . . . , wn .
   Para cada diseño ξ se define la matriz de momentos:
                              Z                      n
                                                     X
                  M (ξ) ≡        f (x)f T (x)dξ(x) =   f (xi )f T (xi )wi
                            χ                      i=1

    La forma de cuantificar la información suministrada por la matriz de momen-
tos depende de los criterios de optimalidad, definidos como aquellos que maxi-
mizan algún funcional real (con un significado estadístico) de la matriz de mo-
mentos sobre Ξ; clase de todos los diseños aproximados definidos en B. Es-
tos criterios de optimalidad se presentan a continuación, siguiendo el enfoque de
Pukelsheim (1993), quien introduce la matriz de información CK , función puente
que da cuenta de la “información” contenida en combinaciones lineales de θ; CK
es una función del conjunto de las matrices definidas no negativas de orden m,
N N D(m), en el conjunto de las matrices simétricas de orden q, Sim(q). Con-
cluyendo con la noción de función de información φ. La matriz de información
intuitivamente mide la información que aporta el sistema de parámetros K T Θ,
mientras que la función de información la cuantifica por medio de un número real.
   En las observaciones 1 y 2 se presenta lo anterior esquemáticamente, y en la
observación 3 se da la formulación del problema de diseño.

Observación 1. Se considera el caso general, cuando el investigador está intere-
sado en la estimación de q−combinaciones lineales de θ. Es decir, la estimación
del subsistema K T θ, donde K ∈ Rm×q es conocida y r(K) = q.

      Sea ξ un diseño factible para K T θ, es decir, C(K) ⊆ C(M (ξ)), C(A) es el
      espacio generado por las columnas de la matriz A. Se define la matriz de
      información como la función:
                                CK : N N D(m) → Sim(q)
      tal que: CK (M (ξ)) = (K T M − K)−1 , A− denota una inversa generalizada de
      A.
      Por notación, A ≥ 0 si y sólo si A ∈ N N D(m); A ≥ B si y sólo si A − B ≥ 0.
      La matriz de información es homogéneamente positiva (CK (δA) = δCK (A),
      A ≥ 0, δ > 0), superaditiva (CK (A + B) ≥ CK (A) + CK (B), A, B ≥ 0),
      Rango(CK ) ⊆ N N D(q), cóncava (CK ((1 − α)A + αB) ≥ (1 − α)CK (A) +
      αCK (B), A, B ∈ N N D(m), 0 < α < 1) e isotónica (A ≥ B ⇒ CK (A) ≥
      CK (B)).

                                         Revista Colombiana de Estadística 30 (2007) 37–51

40                                           Víctor Ignacio López & Rogelio Ramos

     Si K = Im , interesa estimar θ, y M (ξ) es no singular, entonces CI (M (ξ)) =
     M (ξ). Es decir, la matriz de información coincide con la matriz de momentos;
     por esta razón en la literatura M también se llama matriz de información.

Observación 2. Cuantificación de la información suministrada para cada diseño,
ya sea por la matriz de momentos o la matriz de información, es definida a partir
de una función de valor real φ.
    Sea φ un funcional de valor real, φ : N N D(q) → R. φ es una función de
información si es: homogéneamente positiva (φ(δC) = δφ(C), δ > 0, C ≥ 0),
superaditiva: φ(C + D) ≥ φ(C) + φ(D), no negativa: (φ(C) ≥ 0, C ≥ 0) y
semicontinua superiormente (los conjuntos de nivel {φ ≥ α} = {C ∈ N N D(q) :
φ(C) ≥ α} son cerrados para todo α ∈ R).
    Para lo que sigue φ, denotará una función de información.

Observación 3. Formulación del problema de diseño.

     El problema de diseño para el sistema parametral K T θ consiste en encontrar
     un diseño ξ ∗ que sea factible y que maximice, sobre todos los diseños ξ
     factibles para K T θ, la función de información:

                         φ(CK (M (ξ))) = φ((K T M (ξ)− K)−1 )

     Por las propiedades de φ y CK , principalmente la semicontinuidad superior
     y la compacidad de χ, el máximo anterior se alcanza para algún diseño ξ.
     c−optimalidad. Si K = c, c ∈ Rm×1 entonces el criterio asociado se deno-
     mina c−optimalidad; se puede mostrar que la única función de información
     es la identidad: φ(δ) = δ y el problema de diseño se reduce a encontrar un
     diseño ξ ∗ que sea factible para cT θ y maximice la función de información:

                     φ(Cc (M (ξ))) = Cc (M (ξ)) = (cT M (ξ)− c)−1

     observe que el lado derecho representa el inverso de la varianza asociada al
     estimador óptimo para cT θ; luego los diseños c−óptimos son aquellos que
                                 b
     minimizan la varianza de cT θ.

  A continuación se exhibe una clase de funciones de información, denominada
matriz de medias (matrix means), la cual contiene los criterios de optimalidad de
mayor popularidad.
  Sea C ∈ N N D(q), para C > 0:
                           
                           
                            λmax (C),        p = ∞;
                           h
                                      i1/p
                            1      p
                  φp (C) =    q tr(C )      , p 6= 0, p 6= ±∞;
                                                                              (2)
                           (det(C))1/q ,
                                             p =  0;
                           
                           
                           
                             λmin (C),        p = −∞.




                                     Revista Colombiana de Estadística 30 (2007) 37–51

Una introducción a los diseños óptimos                                                 41

Observación 4. Anotaciones sobre los criterios φp −óptimos.

     φp es función de información para p ∈ [−∞, 1].

     Si un diseño ξ maximiza el criterio anterior, se dice que el diseño es φp −óptimo
     (p ∈ [−∞, 1]).

     Si C = CK (M (ξ)) = (K T M (ξ)− K)−1 y p ∈ {0, −1, −∞} se tienen los crite-
     rios de optimalidad más populares, versión generalizada, que dependen de la
     maximización del respectivo funcional evaluado en la matriz información (o
     en algunos casos evaluado en la matriz de diseño); ellos son, respectivamente,

        • D−optimalidad, criterio del determinante, equivale a minimizar el vo-
          lumen del elipsoide asociado a la estimación del sistema K T θ, cuando
          los errores son normales.
        • A−optimalidad, criterio promedio, recíproco del promedio de las va-
          rianzas asociado a las q−combinaciones lineales de θ, y
        • E−optimalidad, criterio del valor propio, minimización del valor propio
          más pequeño.

    El problema de optimización planteado en la observación 3 es muy complejo;
en la práctica se hace uso de teoremas de equivalencia para verificar si un diseño
dado es φ−óptimo (Pukelsheim 1993, Atkinson & Donev, A. N. 1992). El primer
teorema de equivalencia lo demostraron Kiefer & Wolfowitz (1960); allí estable-
cieron la equivalencia entre D−optimalidad y G−optimalidad − ξ es un diseño
G−óptimo si minimiza: ∀ξ ∈ Ξ,
                            (
                              supx∈χ d(x, M (ξ)), C(M (ξ)) ⊇ χ;
                 d(M (ξ)) =
                              ∞,                  en otro caso.

siendo, d(x, M (ξ)) = f T (x)M (ξ)− f (x). Es decir, si ξ minimiza la varianza más
grande posible sobre χ, rango de regresión.

Teorema 1. Teorema de Equivalencia de Kiefer-Wolfowitz.
Sea χ ⊆ Rk con m−vectores linealmente independientes. Un diseño ξ con matriz
de momentos M (ξ), definida positiva, es D−óptimo si y sólo si ξ es G−óptimo si
y sólo si f T (x)M (ξ)−1 f (x) ≤ m, ∀x ∈ χ si y sólo si d(M (ξ)) = m.
                                                              1
En caso de optimalidad, f T (xi )M −1 f (xi ) = m, ξ(xi ) ≤ m   , ∀xi ∈ Supp(ξ).

    Por lo popular de los criterios φp (p ∈ [−∞, 1]), se enuncia el siguiente teorema
de equivalencia, da condiciones necesarias y suficientes para garantizar que un
diseño dado es φp −óptimo.

Teorema 2. Sea φp , p ∈ (−∞, 1], M un subconjunto convexo y compacto de
N N D(m) y M (ξ) ∈ M, con ξ factible para K T θ y matriz de información C =
CK (M (ξ)). Entonces:

                                         Revista Colombiana de Estadística 30 (2007) 37–51

42                                              Víctor Ignacio López & Rogelio Ramos

       ξ es φp −óptimo para K T θ en M sií: ∃G ∈ M − tal que:
       Tr(AGKC p+1 K T GT ) ≤ Tr(C p ),     ∀A ∈ M      (desigualdad de normalidad).

       En caso de optimalidad, la igualdad se obtiene si en vez de A se coloca M u
                   f ∈ M φp −óptima para K T θ en M.
       otra matriz M
       Si 0 < M (ξ) ∈ M, entonces ξ es φp −óptimo para θ en M sií: Tr(AM p−1 ) ≤
       Tr(M p ), ∀A ∈ M.
    Para p = 0 y M > 0, la condición requerida se traduce en: Tr(AM −1 ) ≤
m, ∀A ∈ M, pero M es generado por las matrices de rango uno: A = f (x)f T (x);
es suficiente verificar la condición para A, y el lado izquierdo de la desigualdad es:
     Tr(AM −1 ) = Tr(f (x)f T (x)M −1 ) = Tr(f T (x)M −1 f (x)) = f T (x)M −1 f (x)
lo cual muestra un caso particular de una de las equivalencias del Teorema 1. Existe
la versión del teorema de equivalencia para E−optimalidad (p = −∞) (véase
Pukelsheim 1993). Para p = −1 (A−optimalidad), M > 0 y C = (K T M −1 K)−1 ,
la condición a verificar será:
             f T (x)M −1 KK T M −1 f (x) − Tr(K T M −1 K) ≤ 0,      ∀x ∈ χ            (3)


3.     Diseños óptimos para los modelos no lineales
     Los modelos no lineales se pueden representar por:
                                  Y (x) = η(x, θ) +                                  (4)
donde, como en el modelo lineal, las variables explicativas xT = [x1 , x2 , . . . , xk ]
varían en un espacio de diseño compacto, χ ⊆ Rk , dotado de una σ−álgebra, B,
(Borelianos en χ, agregándole los conjuntos unitarios), θ ∈ Θ ⊆ Rm , los errores
con media cero y varianza constante y η(x, θ) es una función no lineal en θ.
   En el modelo 4, dado un diseño ξ definido en B, se sabe que el estimador de
mínimos cuadrados para θ, bajo ciertas condiciones de regularidad, es asintótica-
mente insesgado y su matriz de varianzas−covarianzas asintótica es la inversa de
la matriz:
                                               Z
                                           
             M (ξ, θ) = Eξ g(x, θ)g T (x, θ) =   g(x, θ)g T (x, θ) dξ(x)
                                                  χ

donde:   g(x, θ) = ∂η(x,θ)
                        Lo cual motiva el análisis de M (ξ, θ). En la literatura
                     ∂θ .
a M se le conoce como matriz de información, y juega el papel de la matriz de
momentos del modelo lineal, si se considerara el modelo linealizado.
    La dependencia de M de θ hace que la búsqueda de diseños óptimos dependa
de este parámetro. En forma análoga al caso lineal, se cuantifica la magnitud
de la información suministrada por M (ξ, θ) a partir de funcionales de ésta, y
consecuentemente la maximización de alguna función de información φ, de valor
real. Para la construcción de los diseños óptimos existen varios enfoques; en este
trabajo se exploran los siguientes:

                                        Revista Colombiana de Estadística 30 (2007) 37–51

Una introducción a los diseños óptimos                                                 43

3.1.     Diseños óptimos locales
    Introducidos por Chernoff (1953), son los primeros diseños que aparecieron
para el caso no lineal. Consisten en dar inicialmente un valor a priori para θ, θ0 ,
que esté cercano al valor verdadero del parámetro, luego utilizar la aproximación
lineal de Taylor para η(x, θ) alrededor de θ0 y construir diseños óptimos para el
modelo linealizado: Y ∗ (x) = β T g(x, θ0 ) + ∗ . Los diseños resultantes son diseños
óptimos locales. Varios autores han construido diseños con este enfoque; véase por
ejemplo: Ford et al. (1992), Dette et al. (2004), Dette et al. (2005), entre otros.
La construcción de diseños D−óptimos locales y A−óptimos locales se explora en
los ejemplos de la sección 4.3.


3.2.     Diseños óptimos promediados por una distribución
         a priori π−enfoque Bayesiano
    Este criterio hace uso del conocimiento que se tiene acerca de θ por una dis-
tribución a priori π, resultando un criterio de optimalidad denominado Bayesiano.
En particular, un diseño ξ es D−óptimo Bayesiano (con respecto a la distribución
a priori π), para abreviar Dπ −óptimo, si maximiza:
                                           Z
                                      
                      Eθ log |M (ξ, θ)| =     log |M (ξ, θ)|dπ(θ)
                                             Θ


    En general, un diseño es φ−óptimo Bayesiano con respecto a la distribución a
priori π, abreviado por φπ −óptimo, si maximiza: Eθ φ(M (ξ)) (Dette et al. 2003).
Ejemplos de este tipo de diseños se muestran en la sección 4.3.
   Para Dπ optimalidad, se obtiene la siguiente equivalencia, generalización del
teorema de Kiefer y Wolfowitz:

          ξ es Dπ − óptimo sií E[g T (x, θ)M −1 (ξ, θ)g(x, θ)] ≤ m,     ∀x ∈ χ        (5)

La respectiva equivalencia se obtiene para Aπ −optimalidad al calcular la esperan-
za, con respecto a θ, de la expresión 3:

  ξ es Aπ − óptimo sií
       E[g T (x, θ)M −1 (ξ)KK T M −1 g(x, θ) − Tr(K T M −1 (ξ)K)] ≤ 0,      ∀x ∈ χ    (6)

donde K, M −1 , son funciones que dependen de θ.


4.     Ejemplos
    En esta sección se presentan varios ejemplos de modelos (lineales y no linea-
les) donde el interés está en encontrar diseños óptimos, ya sea que se conozcan
los puntos de soporte o no. Inicialmente se considera el caso lineal, criterios φp
optimales y por último el caso no lineal.

                                         Revista Colombiana de Estadística 30 (2007) 37–51

44                                                   Víctor Ignacio López & Rogelio Ramos

4.1.    Ejemplo 1. Determinación de los pesos óptimos para
        un diseño dado
    Este ejemplo muestra los resultados reportados por Pukelsheim & Torsney
(1991) cuando los puntos de soporte del diseño son conocidos, y luego se da una
aplicación.
    Por conveniencia se reescribe el modelo lineal de la siguiente forma:
                  E[Yij ] = xTi θ,   j = 1, 2, . . . , ni ,   i = 1, 2, . . . , l       (7)
con observaciones Yij incorrelacionadas, varianza constante σ 2 , y los l vectores de
regresión {x1 , x2 , . . . , xl } linealmente independientes y conocidos.
    El objetivo es encontrar un diseño experimental ξ que indique, en forma óptima,
el número de réplicas ni que se harán en el vector de regresión xi , con el fin de esti-
mar K T θ. En términos generales, hallar un vector de pesos wT = [w1 , w2 , . . . , wl ]
que maximice la función de información:
                                     φp [CK (M (w))]
donde M (w), la matriz de momentos asociada al modelo (7), es expresada como:
                                     l
                                     X
                           M (w) =         xi xTi wi = X T ∆w X
                                     i=1

  T
                         
X = x1       x2    · · · xl y ∆w = diag(w), con la siguiente inversa generalizada
para M :
                       M (w)− = X T (XX T )−1 ∆−    T −1
                                               w (XX )   X
V = (XX T )−1 XK, entonces la matriz de información es:
                              CK (M (w)) = (V T ∆−
                                                 wV )
                                                     −1


∆−w inversa generalizada para ∆w , si todos los pesos de w no son positivos.
   En el siguiente resultado se obtiene una expresión cerrada para los pesos
A−óptimos (p = −1) y una forma de encontrarlos recursivamente para los otros
valores de p.
Teorema 3. Sea p ∈ (−∞, 1], el vector de pesos w es φp −óptimo para K T θ si y
sólo si:                    √
                              bii
                   wi = Pl p , para i = 1, . . . , l                       (8)
                           j=1    bjj
donde b11 , . . . , bll son los elementos de la diagonal de la matriz definida no negativa
l × l: B = V C p+1 V T , con C = CK (M (w)).
Observación 5. Si p = −1, A−optimalidad, y el sistema de interés es el vector
                                                                   1             −1
de parámetros θ, entonces la función objetivo: φ−1 (M (w)) = m        Tr(M −1 (w))    ,
el inverso del promedio de las varianzas de los estimadores de mínimos cuadrados
θb1 , . . . , θbm , estandarizados relativo a su tamaño muestral N y a la varianza del
modelo σ 2 .



                                           Revista Colombiana de Estadística 30 (2007) 37–51

Una introducción a los diseños óptimos                                                     45

Aplicación: Modelo de análisis de varianza de un factor con tres niveles:
                     Yij = µi + ij ,   j = 1, 2, . . . ,   ni ,   i = 1, 2, 3
En este caso, según el modelo (7), θT = [µ1 , µ2 , µ3 ], xT1 = [1, 0, 0], xT2 = [0, 1, 0],
xT3 = [0, 0, 1]. El interés está en conocer el número de réplicas en cada nivel del
factor con el fin de estimar en forma óptima: C1.− Los tres efectos promedio, y
C2.− El contraste: µ3 − µ1 y µ2 . Aplicando el teorema 3 se obtienen los pesos
φp −óptimos para p = −1, 0, ver tabla 1. Note que:
       Para el caso C1 los diseños óptimos coinciden para los dos criterios conside-
       rados.
       En ambos casos, el diseño A−óptimo requiere la misma proporción de ob-
       servaciones en cada uno de los tres niveles del factor. Difiere con respecto
       al criterio D−óptimo ya que en el caso C2, el diseño D−óptimo requiere
       alrededor de la mitad de las observaciones para el segundo nivel, y el resto
       se reparte igualmente para los otros dos niveles.

           Tabla 1: Resultados para los pesos óptimos diseño de un factor.
                                              p       criterio                 w
                                                                         ˆ            ˜
    Caso 1. Estimación de µ                  -1    A-optimalidad          1/3 1/3  1/3˜
                                                                         ˆ
                                              0    D-optimalidad          1/3 1/3 1/3
                                                                         ˆ            ˜
    Caso 2. Estimación de µ3 − µ1 y µ2       -1    A-optimalidad
                                                                      ˆ 1/3 1/3 1/3 ˜
                                              0    D-optimalidad       0.251 0.498 0.251



4.2.      Ejemplo 2. Diseños óptimos para modelos
         polinomiales
   Considere inicialmente el modelo polinomial de grado 2 en el intervalo [−1, 1],
                             Y (x) = f T (x)θ + 
                                           
donde f T (x) = 1 x x2 y θT = θ0 θ1 θ2 , x ∈ [−1, 1].
   En el caso D−óptimo, se verificará a continuación que el diseño
                                                 
                                   −1    0     1
                            ξ=
                                   1/3 1/3 1/3
es un diseño D−óptimo para estimar θ (tomando K = I).
   En efecto, bastará con mostrar que el diseño ξ verifica las condiciones del
teorema 1. Primero note que su matriz de momentos es:

   En la figura 1 se muestra que esta función tiene todos sus valores por debajo
de m = 3, y en los puntos de soporte alcanza su máximo, luego ξ es D−óptimo
para estimar el vector de parámetros θ.
                          Figura 1: Gráfico de la función d(x, ξ).
    Suponga que el interés del investigador está en estimar la diferencia entre el
             la potencia
coeficiente de          cuadrática y la lineal. En este caso el sistema de interés
es: K T θ = 0 −1 1 θ.
    En la tabla 2 aparecen los resultados que se obtuvieron con los criterios D
y A optimalidad para los casos C1 y C2, y con los mismos puntos de soporte.
Observe que los diseños dados por ambos criterios, para estimar θ2 − θ1 , reparten
en forma equitativa el número de observaciones en los puntos x = −1 y en x = 0 y
ninguna observación para x = 1. Se presentan diferencias en los diseños óptimos
para la estimación del vector de parámetros; para A−optimalidad el 50% de las
observaciones se deberán tomar en x = 0, y el resto se reparte equitativamente
en los otros dos puntos, mientras que con D−optimalidad el mismo número de
observaciones se deberá tomar en los tres puntos.
   En la literatura (Pukelsheim 1993) existe la solución para el caso general, poli-
nomios de grado d, para los diseños D−óptimos en el intervalo [−1, 1]; los autores
usan como argumento el teorema 1, y muestran que los diseños D−óptimos tienen

                                             Revista Colombiana de Estadística 30 (2007) 37–51

Una introducción a los diseños óptimos                                                      47

igual peso 1/(d + 1) en los puntos de soporte que son solución a la ecuación:

                                      (1 − x2 )Ṗd (x) = 0

donde Ṗd (x) es la derivada del polinomio de Legendre de grado d.

        Tabla 2: Resultados para los pesos óptimos para el modelo cuadrático.
                                             p     Criterio                    w
                                                                   ˆ                    ˜
         Caso 1. Estimación de θ            -1     A-optimalidad       0.25   0.50 0.25˜
                                                                       ˆ
                                             0     D-optimalidad        1/3 1/3 1/3
                                                                        ˆ            ˜
         Caso 2. Estimación de θ2 − θ1      -1     A-optimalidad
                                                                        ˆ0.5 0.5 0.0˜
                                             0     D-optimalidad          0.5 0.5 0.0




4.3.     Ejemplo 3. Modelos no lineales
   Como ilustración se consideran dos modelos no lineales (Atkinson & Donev, A.
N. 1992), y se construyen diseños óptimos locales y usando un enfoque Bayesiano.

  1. El modelo de decaimiento exponencial está dado por:

                                   η(x, θ) = exp(−θx),         x>0

       Si θ0 es una buena asignación para θ, suR matriz de información, la cual es un
       escalar, es: M (ξ, θ0 ) = M (x0 , θ0 ) = x>0 f 2 (x, θ0 ) dξ(x), donde f (x, θ0 ) =
        d
       dθ η(x, θ)|θ=θ0 = −x exp(−θ0 x).
       El modelo linealizado consta de un parámetro, y el diseño D−óptimo local
       concentra toda su masa en un punto. Se verá a continuación que el punto es:
       x0 = 1/θ0 . Sea ξ0 el diseño que tiene como punto de soporte a x0 , entonces:

                                   M (ξ0 , θ0 ) = x20 exp(−2θ0 x0 )                         (9)

       No es difícil mostrar que el máximo de la ecuación (9) se alcanza en
       x0 = 1/θ0 , y

         d(x, ξ0 ) = f T (x, θ0 )M −1 (ξ0 , θ0 )f (x, θ0 ) =
                                                   f 2 (x, θ0 )
                                              R                  = (xθ0 )2 exp(−2(xθ0 − 1))
                                                  f 2 (x)dξ0 (x)

       observe que d(x, ξ0 ) ≤ 1, ∀x > 0 y d(x, ξ0 ) = 1 en x = 1/θ0 , luego el diseño
       que concentra su masa en 1/θ0 es D−óptimo local. Este diseño no permite
       realizar pruebas de bondad de ajuste para el modelo en cuestión. El diseño
       depende de la especificación de θ0 , y puede llegar a ser ineficiente si θ0 está
       muy lejos del valor verdadero θ. Otra forma de hallar un diseño óptimo es a
       partir de un enfoque Bayesiano, donde se incorpora el conocimiento acerca
       de θ por medio de una distribución a priori. Como ilustración se consideran
       6 distribuciones a priori discretas, uniformes en 5 puntos, y se hallaron los

                                             Revista Colombiana de Estadística 30 (2007) 37–51

48                                                  Víctor Ignacio López & Rogelio Ramos

       respectivos diseños Dπ −óptimos para estimar θ, con las diferentes a prioris;
       ver tabla 3. Lo anterior se hizo numéricamente con ayuda de algoritmos
       computacionales programados en el lenguaje R (R Development Core Team
       2006) usando la equivalencia 5. Los diseños Dπ −óptimos obtenidos están
       formados por tres puntos de soporte, observándose variación en las distintas
       a prioris consideradas, tanto en los puntos de soporte como en sus pesos.
       Atkinson & Donev, A. N. (1992, pág. 230) muestran cómo los puntos de
       soporte del diseño aumentan a medida que la distribución a priori que ellos
       consideran es más dispersa.

Tabla 3: Ejemplo de decaimiento exponencial con diferentes distribuciones a prio-
         ris uniformes para θ.
           Puntos de la a priori j                x                        w∗
         ˆ                         ˜   ˆ                    ˜    ˆ                      ˜
        ˆ 0.09  0.49 1 4.9 9 ˜          0.156
                                        ˆ      1.503 10.998˜     ˆ0.438   0.403   0.158˜
        ˆ0.10 0.50 1 5.0 10˜            ˆ0.143 1.517 9.812˜      ˆ0.432   0.420   0.148˜
        ˆ0.11 0.51 1 5.1 11˜            ˆ0.132 1.536 8.812˜      ˆ0.428   0.437   0.135˜
        ˆ0.12 0.52 1 5.2 12˜            ˆ0.123 1.558 7.952˜      ˆ0.424   0.455   0.121˜
        ˆ0.14 0.54 1 5.4 14˜            ˆ0.107 1.617 6.547˜      ˆ0.418   0.496   0.085˜
          0.15 0.55 1 5.5 15             0.101 1.649 5.965        0.416   0.521   0.063



     2. Modelo de compartimientos.

       Los modelos de compartimientos son de gran utilidad en farmacocinética,
       utilizados, entre otras aplicaciones, para modelar el nivel de concentración
       de un medicamento en la sangre de un individuo a lo largo del tiempo. Se
       considera el siguiente modelo:

                         θ1
          η(x, θ) =           {exp(−θ2 x) − exp(−θ1 x)},        x ≥ 0,    θ1 > θ2 > 0       (10)
                      θ1 − θ2

       Asociado al trabajo biológico es de interés, además de estimar el vector de
       parámetros θ, estimar tres cantidades que ayudan al estudio de la cinética
       del medicamento en un individuo. Estas cantidades son:
                                                        R∞
         a) El área bajo la curva (AUC): g1 (θ) =         0   η(x, θ)dθ = θ12 .
                                                                          −log θ2
         b) Tiempo para la concentración máxima: g2 (θ) = xmax = log θθ11 −θ 2
                                                                                  .
         c) La concentración máxima: g3 (θ) = η(xmax , θ).

       La construcción de diseños óptimos para la estimación de estas funciones
       simultáneamente, se hará por medio de diseños A−óptimos locales (véase
       (2), con p = −1), y diseños A−óptimos promediados por una distribución a
       priori uniforme. La j−ésima columna Kj , de K es el gradiente de función
       no lineal gj (θ), evaluada en θ0 . Así se asegura que el diseño óptimo será
       aquel que minimice el promedio de las varianzas del respectivo estimador
       linealizado, es decir, aquel que minimiza:

                                            Revista Colombiana de Estadística 30 (2007) 37–51

Una introducción a los diseños óptimos                                                  49


                      3
                   1X                     1X
                         var(gj (θb0 )) ≈            b ∝ K T M −1 (ξ)K
                                             var(KjT β)
                   3 j=1                  3

     En el caso de estudio, las primeras dos columnas de K están dadas por:
                                                h                         i
           K1T (θ0 ) = 0 −1/θ20 2 ,                    10 −xmax
                                        K2 (θ0 ) = 1/θθ10 −θ20
                                                                xmax −1/θ20
                                                                 θ10 −θ20

     en forma análoga
                        se halla la tercera columna de K. Como ilustración, se
     tomó θ0T = 0.7 0.2 , y en la tabla 4 se presentan los diseños A−óptimos
     locales obtenidos para la estimación de las tres características de interés
     simultáneamente. También se consideró una a priori uniforme discreta para
     los siguientes cinco valores del vector de parámetros θ:

           Θ = {(0.70, 0.20), (0.65, 0.15), (0.75, 0.25), (0.65, 0.25), (0.75, 0.15)}

     es decir, π(θ) = 1/5, ∀θ ∈ Θ, y en la tabla 4 se reporta el diseño A−óptimo
     Bayesiano obtenido. Ambos diseños A−óptimo local y A−óptimo promedia-
     do por la a priori π, presentan pocas diferencias. Además en ambos casos se
     verificó que el diseño hallado satisfacía las equivalencias dadas por (3) y (6),
     respectivamente.

Tabla 4: Diseños A−óptimos locales y promediados por la a priori π para el
         modelo 10.
                      Criterio                        Tiempo x      Pesos del diseño
                                                   ˆ            ˜   ˆ              ˜
     A−optimalidad local                            1.313  6.602˜
                                                   ˆ                ˆ0.276 0.724˜
     A−optimalidad promediado por la a priori π     1.456 7.145       0.269 0.731




5.    Anotaciones finales
    En este trabajo se presentó una motivación inicial para el estudio de los diseños
óptimos en ambos casos lineal y no lineal. Se dio el enfoque matemático de cada
uno de los criterios de optimalidad usados en la práctica y se terminó presentando
algunos ejemplos típicos. Hay gran diversidad de bibliografía en torno a este tema,
donde el estudio en esta área es factible e interesante.
    En la mayoría de los artículos citados, los autores asumen que el modelo bajo
consideración es conocido, y el valor de los parámetros es desconocido. Con este
supuesto, usan criterios de optimalidad que son eficientes para la estimación de los
parámetros del modelo fijo. Sin embargo, existen aplicaciones donde la forma de
la función de regresión no es conocida en forma exacta, es decir, el experimentador
debe decidir, entre un conjunto de clases de funciones competitivas, cuáles de estas
describen los datos en una forma más adecuada. Como lo afirman Biedermann
et al. (2005), el problema de diseño para discriminar entre modelos no lineales
competitivos ha encontrado muy poco interés en la literatura que aquellos proble-
mas de estimación de parámetros. En el caso de discriminación de modelos, lineal y no lineal, se pueden revisar los trabajos de: Atkinson & Cox (1974), Atkinson &
Fedorov (1975), Pukelsheim & Rosenberger (1993), Biswas & Chaudhuri (2002) y
Biedermann et al. (2005). Por lo anterior, está como trabajo futuro ahondar en el
estudio de diseños óptimos que sean eficientes para discriminar entre modelos no
lineales anidados, además de que permitan estimar en forma simultánea funciones
de los parámetros.
Agradecimientos
Agradecemos los comentarios hechos por los dos árbitros, lo que hizo que este trabajo se mejorara considerablemente. El presente trabajo se realizó cuando el primer autor estaba haciendo su doctorado en Ciencias con Orientación en Probabilidad y Estadística en el Centro de Investigación en Matemáticas (CIMAT), México. Parte de este trabajo fue apoyado por CIMAT, Secretaría de Relaciones Exteriores de México (SRE) y la Universidad Nacional de Colombia, sede Medellín.
Referencias
Atkinson A C.The Uselfulness of Optimum Experimental Designs.(1996).Journal of the Royal Statistical Society.
Atkinson A C,Cox D R.Planning Experiments for Discriminating Between Models.(1974).Journal of the Royal Statistical Society.
Atkinson A C,Donev A N.Optimum Experimental Designs.(1992).Oxford Science Publications.New York.
Atkinson A C,Fedorov V V.Optimal Design: Experiments for Discriminating Between Several Models.(1975).Biometriks.
Biedermann S,Dette H,Pepelyshev A.Optimal Discrimination Designs for Exponential Regression Models.(2005)..
Biswas A,Chaudhuri P.An Efficient Design for Model Discrimination on Parameter Estimation in Linear Models.(2002).Biometriks.
Brown L D,I O,Sacks J,Wynn H P.Jack Karl Kiefer Collected Papers III, Design of Experiments.(1985).Springer-Verlag.New York.
Chernoff H.Locally Optimal Designs for Estimating Parameters.(1953).The Annals of Mathematical Statistics.
Dette H,Haines L M,Imhof L A.Maximin and Bayesian Optimal Designs for Regression Models.(2003)..
Dette H,Melas V B,Pepelyshev A.Optimal Designs for a Class of Nonlinear Regression Models.(2004).The Annals of Statistics.
Dette H,Melas V B,Wong W K.Optimal Design for Goodness-of Fit of the Michaelis-Menten Enzyme Kinetic Function.(2005).Journal of the American Statistical Association.
Ford I,Tornsney B,Wu C F J.The Use of a Canonical Form in the Construction of Locally Optimal Designs for Nonlinear Problems.(1992).Journal of the Royal Statistical Society.
Kiefer J.Optimum Experimental Designs.(1959).Journal Royal Statistical Society.
Kiefer J,Wolfowitz J.The Equivalence of Two Extremum Problems.(1960).Canadian Journal of Mathematics.
Pukelsheim F.Optimal Design of Experiments.(1993).John Wiley & Sons.New York.
Pukelsheim F,Rosenberger J L.Experimental Designs for Model Discrimination.(1993).Journal of the American Statistical Association.
Pukelsheim F,Torsney B.Optimal Weights for Experimental Designs on Linearly Independent Support Points.(1991).The Annals of Statistics.
R Development Core Team.R: A Language and Environment for Statistical Computing.(2006).R Foundation for Statistical Computing.Austria.
Smith K.On the Standard Deviations of Adjusted and Interpolates Values of an Observed Polynomial Functions and its Constants and the Guidance They Give Towards a Proper Choice of the Distribution of Observations.(1918).Biometrika.