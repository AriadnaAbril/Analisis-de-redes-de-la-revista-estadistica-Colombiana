Una introducci√≥n a los dise√±os √≥ptimos
Universidad Nacional de Colombia;Centro de Investigaci√≥n en Matem√°ticas
Resumen
Introducimos varios conceptos utilizados en la teor√≠a de dise√±os de experimentos √≥ptimos. Definimos criterios de optimalidad utilizados en esta √°rea y exploramos sus propiedades. Se listan algunos resultados importantes para encontrar dise√±os √≥ptimos para modelos lineales y no lineales, entre ellos teoremas de equivalencia. Finalmente se presentan algunos ejemplos t√≠picos donde se aplica la teor√≠a vista anteriormente.
Palabras clave: funci√≥n de informaci√≥n, matriz de informaci√≥n, criterios de optimalidad, teoremas de equivalencia, modelos de regresi√≥n no lineal.
1.     Introducci√≥n
    En muchas √°reas de investigaci√≥n interesa explicar una variable respuesta, Y ,
a trav√©s de k‚àívariables explicativas, xT = [x1 , x2 , . . . , xk ], mediante un modelo de
la forma:
siendo Œ∑(x, Œ∏) una funci√≥n lineal o no lineal en el vector de par√°metros desconocido
Œ∏ ‚àà Rm ; y el t√©rmino de error se asume que tiene media cero y varianza constante
œÉ 2 . Una vez se especifica el modelo, la siguiente etapa consiste en determinar en
qu√© condiciones experimentales, niveles de los xj ‚Äôs, se debe medir la respuesta para
obtener una mejor√≠a en la calidad de la inferencia estad√≠stica a un menor costo.
Esto se logra construyendo un dise√±o donde la elecci√≥n de los niveles de los xj ‚Äôs
y la frecuencia de medici√≥n de la respuesta est√°n regidas por alg√∫n criterio de
optimalidad (con significado estad√≠stico). Hay varios ejemplos pr√°cticos que han
hecho uso de los dise√±os √≥ptimos (v√©ase Atkinson (1996)) y existe un gran n√∫mero
de contribuciones sobre este tema; por ejemplo, entre otros autores, Smith (1918)
encontr√≥ dise√±os para los modelos polinomiales, Kiefer (1959) introdujo expl√≠ci-
tamente la noci√≥n de dise√±o √≥ptimo y sus propiedades; y posteriormente realiz√≥
muchos trabajos en el √°rea (v√©ase Brown et al. (1985)). Tambi√©n, recientemente
en los libros de Atkinson & Donev, A. N. (1992) y Pukelsheim (1993), los auto-
res hicieron un tratamiento estad√≠stico y formal, respectivamente, de los dise√±os
√≥ptimos.
   Este trabajo tiene como objetivo presentar los conceptos b√°sicos de los dise√±os
√≥ptimos y, en forma general, los criterios de optimalidad, tanto en modelos lineales
como no lineales, dando mayor √©nfasis y extensi√≥n a los primeros, ya que son
una alternativa de soluci√≥n para los modelos no lineales, por ejemplo los dise√±os
√≥ptimos locales mencionados en la secci√≥n 3.1.
    Este art√≠culo se divide en cuatro secciones. En la siguiente secci√≥n se dar√°n los
aspectos sobresalientes de los dise√±os √≥ptimos para el modelo lineal, se definen los
criterios de optimalidad en general y se mencionan varios resultados, principalmen-
te teoremas de equivalencia para determinar optimalidad. En la tercera secci√≥n
se estudia el caso no lineal y se definen algunos de los criterios de optimalidad
usados en la literatura. En la √∫ltima secci√≥n se construyen dise√±os √≥ptimos para
dos posibles escenarios: cuando el experimentador conoce de antemano los puntos
de soporte del dise√±o, caso usual en dise√±os de experimentos (v√©ase la secci√≥n 4.1);
y cuando no se conocen ni los puntos de soporte ni los pesos del dise√±o (v√©ase la
secci√≥n 4.3).



2.    Dise√±os √≥ptimos para modelos lineales
   Para los modelos lineales se considera que la relaci√≥n entre las N ‚àíobservaciones
Yi y xi est√° dada por:

                    Y (xi ) = Œ∏T f (xi ) + ,   xi ‚àà Rk ,   Œ∏ ‚àà Rm

donde f = [f1 , . . . , fm ]T es un vector de m‚àífunciones continuas linealmente in-
dependientes definidas en un conjunto compacto œá, rango de regresi√≥n, œá ‚äÜ Rk ,
Œ∏ ‚àà Rm es un vector de m‚àípar√°metros desconocidos,  es una variable alea-
toria con media cero y varianza constante œÉ 2 y se asume incorrelaci√≥n en las
N ‚àíobservaciones.

                                        Revista Colombiana de Estad√≠stica 30 (2007) 37‚Äì51

Una introducci√≥n a los dise√±os √≥ptimos                                                 39

   Aunado al modelo anterior, se define un dise√±o aproximado,
                                                
                                    x   . . . xn
                             Œæ= 1
                                    w1 . . . wn
con wi = Œæ(xi ), como una medida de probabilidad definida en B, conjunto de Borel
de œá que incluye los conjuntos unitarios; tal que Œæ tiene soporte finito. El soporte
de Œæ es Supp(Œæ) = [x1 , . . . , xn ], n: n√∫mero de puntos de soporte de Œæ, y las obser-
vaciones Y (x) se hacen en x1 , . . . , xn con frecuencias (o pesos) aproximadamente
proporcionales a w1 , . . . , wn .
   Para cada dise√±o Œæ se define la matriz de momentos:
                              Z                      n
                                                     X
                  M (Œæ) ‚â°        f (x)f T (x)dŒæ(x) =   f (xi )f T (xi )wi
                            œá                      i=1

    La forma de cuantificar la informaci√≥n suministrada por la matriz de momen-
tos depende de los criterios de optimalidad, definidos como aquellos que maxi-
mizan alg√∫n funcional real (con un significado estad√≠stico) de la matriz de mo-
mentos sobre Œû; clase de todos los dise√±os aproximados definidos en B. Es-
tos criterios de optimalidad se presentan a continuaci√≥n, siguiendo el enfoque de
Pukelsheim (1993), quien introduce la matriz de informaci√≥n CK , funci√≥n puente
que da cuenta de la ‚Äúinformaci√≥n‚Äù contenida en combinaciones lineales de Œ∏; CK
es una funci√≥n del conjunto de las matrices definidas no negativas de orden m,
N N D(m), en el conjunto de las matrices sim√©tricas de orden q, Sim(q). Con-
cluyendo con la noci√≥n de funci√≥n de informaci√≥n œÜ. La matriz de informaci√≥n
intuitivamente mide la informaci√≥n que aporta el sistema de par√°metros K T Œò,
mientras que la funci√≥n de informaci√≥n la cuantifica por medio de un n√∫mero real.
   En las observaciones 1 y 2 se presenta lo anterior esquem√°ticamente, y en la
observaci√≥n 3 se da la formulaci√≥n del problema de dise√±o.

Observaci√≥n 1. Se considera el caso general, cuando el investigador est√° intere-
sado en la estimaci√≥n de q‚àícombinaciones lineales de Œ∏. Es decir, la estimaci√≥n
del subsistema K T Œ∏, donde K ‚àà Rm√óq es conocida y r(K) = q.

      Sea Œæ un dise√±o factible para K T Œ∏, es decir, C(K) ‚äÜ C(M (Œæ)), C(A) es el
      espacio generado por las columnas de la matriz A. Se define la matriz de
      informaci√≥n como la funci√≥n:
                                CK : N N D(m) ‚Üí Sim(q)
      tal que: CK (M (Œæ)) = (K T M ‚àí K)‚àí1 , A‚àí denota una inversa generalizada de
      A.
      Por notaci√≥n, A ‚â• 0 si y s√≥lo si A ‚àà N N D(m); A ‚â• B si y s√≥lo si A ‚àí B ‚â• 0.
      La matriz de informaci√≥n es homog√©neamente positiva (CK (Œ¥A) = Œ¥CK (A),
      A ‚â• 0, Œ¥ > 0), superaditiva (CK (A + B) ‚â• CK (A) + CK (B), A, B ‚â• 0),
      Rango(CK ) ‚äÜ N N D(q), c√≥ncava (CK ((1 ‚àí Œ±)A + Œ±B) ‚â• (1 ‚àí Œ±)CK (A) +
      Œ±CK (B), A, B ‚àà N N D(m), 0 < Œ± < 1) e isot√≥nica (A ‚â• B ‚áí CK (A) ‚â•
      CK (B)).

                                         Revista Colombiana de Estad√≠stica 30 (2007) 37‚Äì51

40                                           V√≠ctor Ignacio L√≥pez & Rogelio Ramos

     Si K = Im , interesa estimar Œ∏, y M (Œæ) es no singular, entonces CI (M (Œæ)) =
     M (Œæ). Es decir, la matriz de informaci√≥n coincide con la matriz de momentos;
     por esta raz√≥n en la literatura M tambi√©n se llama matriz de informaci√≥n.

Observaci√≥n 2. Cuantificaci√≥n de la informaci√≥n suministrada para cada dise√±o,
ya sea por la matriz de momentos o la matriz de informaci√≥n, es definida a partir
de una funci√≥n de valor real œÜ.
    Sea œÜ un funcional de valor real, œÜ : N N D(q) ‚Üí R. œÜ es una funci√≥n de
informaci√≥n si es: homog√©neamente positiva (œÜ(Œ¥C) = Œ¥œÜ(C), Œ¥ > 0, C ‚â• 0),
superaditiva: œÜ(C + D) ‚â• œÜ(C) + œÜ(D), no negativa: (œÜ(C) ‚â• 0, C ‚â• 0) y
semicontinua superiormente (los conjuntos de nivel {œÜ ‚â• Œ±} = {C ‚àà N N D(q) :
œÜ(C) ‚â• Œ±} son cerrados para todo Œ± ‚àà R).
    Para lo que sigue œÜ, denotar√° una funci√≥n de informaci√≥n.

Observaci√≥n 3. Formulaci√≥n del problema de dise√±o.

     El problema de dise√±o para el sistema parametral K T Œ∏ consiste en encontrar
     un dise√±o Œæ ‚àó que sea factible y que maximice, sobre todos los dise√±os Œæ
     factibles para K T Œ∏, la funci√≥n de informaci√≥n:

                         œÜ(CK (M (Œæ))) = œÜ((K T M (Œæ)‚àí K)‚àí1 )

     Por las propiedades de œÜ y CK , principalmente la semicontinuidad superior
     y la compacidad de œá, el m√°ximo anterior se alcanza para alg√∫n dise√±o Œæ.
     c‚àíoptimalidad. Si K = c, c ‚àà Rm√ó1 entonces el criterio asociado se deno-
     mina c‚àíoptimalidad; se puede mostrar que la √∫nica funci√≥n de informaci√≥n
     es la identidad: œÜ(Œ¥) = Œ¥ y el problema de dise√±o se reduce a encontrar un
     dise√±o Œæ ‚àó que sea factible para cT Œ∏ y maximice la funci√≥n de informaci√≥n:

                     œÜ(Cc (M (Œæ))) = Cc (M (Œæ)) = (cT M (Œæ)‚àí c)‚àí1

     observe que el lado derecho representa el inverso de la varianza asociada al
     estimador √≥ptimo para cT Œ∏; luego los dise√±os c‚àí√≥ptimos son aquellos que
                                 b
     minimizan la varianza de cT Œ∏.

  A continuaci√≥n se exhibe una clase de funciones de informaci√≥n, denominada
matriz de medias (matrix means), la cual contiene los criterios de optimalidad de
mayor popularidad.
  Sea C ‚àà N N D(q), para C > 0:
                           Ô£±
                           Ô£¥
                           Ô£¥ Œªmax (C),        p = ‚àû;
                           Ô£¥h
                           Ô£¥           i1/p
                           Ô£≤ 1      p
                  œÜp (C) =    q tr(C )      , p 6= 0, p 6= ¬±‚àû;
                                                                              (2)
                           Ô£¥(det(C))1/q ,
                           Ô£¥                  p =  0;
                           Ô£¥
                           Ô£¥
                           Ô£≥
                             Œªmin (C),        p = ‚àí‚àû.




                                     Revista Colombiana de Estad√≠stica 30 (2007) 37‚Äì51

Una introducci√≥n a los dise√±os √≥ptimos                                                 41

Observaci√≥n 4. Anotaciones sobre los criterios œÜp ‚àí√≥ptimos.

     œÜp es funci√≥n de informaci√≥n para p ‚àà [‚àí‚àû, 1].

     Si un dise√±o Œæ maximiza el criterio anterior, se dice que el dise√±o es œÜp ‚àí√≥ptimo
     (p ‚àà [‚àí‚àû, 1]).

     Si C = CK (M (Œæ)) = (K T M (Œæ)‚àí K)‚àí1 y p ‚àà {0, ‚àí1, ‚àí‚àû} se tienen los crite-
     rios de optimalidad m√°s populares, versi√≥n generalizada, que dependen de la
     maximizaci√≥n del respectivo funcional evaluado en la matriz informaci√≥n (o
     en algunos casos evaluado en la matriz de dise√±o); ellos son, respectivamente,

        ‚Ä¢ D‚àíoptimalidad, criterio del determinante, equivale a minimizar el vo-
          lumen del elipsoide asociado a la estimaci√≥n del sistema K T Œ∏, cuando
          los errores son normales.
        ‚Ä¢ A‚àíoptimalidad, criterio promedio, rec√≠proco del promedio de las va-
          rianzas asociado a las q‚àícombinaciones lineales de Œ∏, y
        ‚Ä¢ E‚àíoptimalidad, criterio del valor propio, minimizaci√≥n del valor propio
          m√°s peque√±o.

    El problema de optimizaci√≥n planteado en la observaci√≥n 3 es muy complejo;
en la pr√°ctica se hace uso de teoremas de equivalencia para verificar si un dise√±o
dado es œÜ‚àí√≥ptimo (Pukelsheim 1993, Atkinson & Donev, A. N. 1992). El primer
teorema de equivalencia lo demostraron Kiefer & Wolfowitz (1960); all√≠ estable-
cieron la equivalencia entre D‚àíoptimalidad y G‚àíoptimalidad ‚àí Œæ es un dise√±o
G‚àí√≥ptimo si minimiza: ‚àÄŒæ ‚àà Œû,
                            (
                              supx‚ààœá d(x, M (Œæ)), C(M (Œæ)) ‚äá œá;
                 d(M (Œæ)) =
                              ‚àû,                  en otro caso.

siendo, d(x, M (Œæ)) = f T (x)M (Œæ)‚àí f (x). Es decir, si Œæ minimiza la varianza m√°s
grande posible sobre œá, rango de regresi√≥n.

Teorema 1. Teorema de Equivalencia de Kiefer-Wolfowitz.
Sea œá ‚äÜ Rk con m‚àívectores linealmente independientes. Un dise√±o Œæ con matriz
de momentos M (Œæ), definida positiva, es D‚àí√≥ptimo si y s√≥lo si Œæ es G‚àí√≥ptimo si
y s√≥lo si f T (x)M (Œæ)‚àí1 f (x) ‚â§ m, ‚àÄx ‚àà œá si y s√≥lo si d(M (Œæ)) = m.
                                                              1
En caso de optimalidad, f T (xi )M ‚àí1 f (xi ) = m, Œæ(xi ) ‚â§ m   , ‚àÄxi ‚àà Supp(Œæ).

    Por lo popular de los criterios œÜp (p ‚àà [‚àí‚àû, 1]), se enuncia el siguiente teorema
de equivalencia, da condiciones necesarias y suficientes para garantizar que un
dise√±o dado es œÜp ‚àí√≥ptimo.

Teorema 2. Sea œÜp , p ‚àà (‚àí‚àû, 1], M un subconjunto convexo y compacto de
N N D(m) y M (Œæ) ‚àà M, con Œæ factible para K T Œ∏ y matriz de informaci√≥n C =
CK (M (Œæ)). Entonces:

                                         Revista Colombiana de Estad√≠stica 30 (2007) 37‚Äì51

42                                              V√≠ctor Ignacio L√≥pez & Rogelio Ramos

       Œæ es œÜp ‚àí√≥ptimo para K T Œ∏ en M si√≠: ‚àÉG ‚àà M ‚àí tal que:
       Tr(AGKC p+1 K T GT ) ‚â§ Tr(C p ),     ‚àÄA ‚àà M      (desigualdad de normalidad).

       En caso de optimalidad, la igualdad se obtiene si en vez de A se coloca M u
                   f ‚àà M œÜp ‚àí√≥ptima para K T Œ∏ en M.
       otra matriz M
       Si 0 < M (Œæ) ‚àà M, entonces Œæ es œÜp ‚àí√≥ptimo para Œ∏ en M si√≠: Tr(AM p‚àí1 ) ‚â§
       Tr(M p ), ‚àÄA ‚àà M.
    Para p = 0 y M > 0, la condici√≥n requerida se traduce en: Tr(AM ‚àí1 ) ‚â§
m, ‚àÄA ‚àà M, pero M es generado por las matrices de rango uno: A = f (x)f T (x);
es suficiente verificar la condici√≥n para A, y el lado izquierdo de la desigualdad es:
     Tr(AM ‚àí1 ) = Tr(f (x)f T (x)M ‚àí1 ) = Tr(f T (x)M ‚àí1 f (x)) = f T (x)M ‚àí1 f (x)
lo cual muestra un caso particular de una de las equivalencias del Teorema 1. Existe
la versi√≥n del teorema de equivalencia para E‚àíoptimalidad (p = ‚àí‚àû) (v√©ase
Pukelsheim 1993). Para p = ‚àí1 (A‚àíoptimalidad), M > 0 y C = (K T M ‚àí1 K)‚àí1 ,
la condici√≥n a verificar ser√°:
             f T (x)M ‚àí1 KK T M ‚àí1 f (x) ‚àí Tr(K T M ‚àí1 K) ‚â§ 0,      ‚àÄx ‚àà œá            (3)


3.     Dise√±os √≥ptimos para los modelos no lineales
     Los modelos no lineales se pueden representar por:
                                  Y (x) = Œ∑(x, Œ∏) +                                  (4)
donde, como en el modelo lineal, las variables explicativas xT = [x1 , x2 , . . . , xk ]
var√≠an en un espacio de dise√±o compacto, œá ‚äÜ Rk , dotado de una œÉ‚àí√°lgebra, B,
(Borelianos en œá, agreg√°ndole los conjuntos unitarios), Œ∏ ‚àà Œò ‚äÜ Rm , los errores
con media cero y varianza constante y Œ∑(x, Œ∏) es una funci√≥n no lineal en Œ∏.
   En el modelo 4, dado un dise√±o Œæ definido en B, se sabe que el estimador de
m√≠nimos cuadrados para Œ∏, bajo ciertas condiciones de regularidad, es asint√≥tica-
mente insesgado y su matriz de varianzas‚àícovarianzas asint√≥tica es la inversa de
la matriz:
                                               Z
                                           
             M (Œæ, Œ∏) = EŒæ g(x, Œ∏)g T (x, Œ∏) =   g(x, Œ∏)g T (x, Œ∏) dŒæ(x)
                                                  œá

donde:   g(x, Œ∏) = ‚àÇŒ∑(x,Œ∏)
                        Lo cual motiva el an√°lisis de M (Œæ, Œ∏). En la literatura
                     ‚àÇŒ∏ .
a M se le conoce como matriz de informaci√≥n, y juega el papel de la matriz de
momentos del modelo lineal, si se considerara el modelo linealizado.
    La dependencia de M de Œ∏ hace que la b√∫squeda de dise√±os √≥ptimos dependa
de este par√°metro. En forma an√°loga al caso lineal, se cuantifica la magnitud
de la informaci√≥n suministrada por M (Œæ, Œ∏) a partir de funcionales de √©sta, y
consecuentemente la maximizaci√≥n de alguna funci√≥n de informaci√≥n œÜ, de valor
real. Para la construcci√≥n de los dise√±os √≥ptimos existen varios enfoques; en este
trabajo se exploran los siguientes:

                                        Revista Colombiana de Estad√≠stica 30 (2007) 37‚Äì51

Una introducci√≥n a los dise√±os √≥ptimos                                                 43

3.1.     Dise√±os √≥ptimos locales
    Introducidos por Chernoff (1953), son los primeros dise√±os que aparecieron
para el caso no lineal. Consisten en dar inicialmente un valor a priori para Œ∏, Œ∏0 ,
que est√© cercano al valor verdadero del par√°metro, luego utilizar la aproximaci√≥n
lineal de Taylor para Œ∑(x, Œ∏) alrededor de Œ∏0 y construir dise√±os √≥ptimos para el
modelo linealizado: Y ‚àó (x) = Œ≤ T g(x, Œ∏0 ) + ‚àó . Los dise√±os resultantes son dise√±os
√≥ptimos locales. Varios autores han construido dise√±os con este enfoque; v√©ase por
ejemplo: Ford et al. (1992), Dette et al. (2004), Dette et al. (2005), entre otros.
La construcci√≥n de dise√±os D‚àí√≥ptimos locales y A‚àí√≥ptimos locales se explora en
los ejemplos de la secci√≥n 4.3.


3.2.     Dise√±os √≥ptimos promediados por una distribuci√≥n
         a priori œÄ‚àíenfoque Bayesiano
    Este criterio hace uso del conocimiento que se tiene acerca de Œ∏ por una dis-
tribuci√≥n a priori œÄ, resultando un criterio de optimalidad denominado Bayesiano.
En particular, un dise√±o Œæ es D‚àí√≥ptimo Bayesiano (con respecto a la distribuci√≥n
a priori œÄ), para abreviar DœÄ ‚àí√≥ptimo, si maximiza:
                                           Z
                                      
                      EŒ∏ log |M (Œæ, Œ∏)| =     log |M (Œæ, Œ∏)|dœÄ(Œ∏)
                                             Œò


    En general, un dise√±o es œÜ‚àí√≥ptimo Bayesiano con respecto a la distribuci√≥n a
priori œÄ, abreviado por œÜœÄ ‚àí√≥ptimo, si maximiza: EŒ∏ œÜ(M (Œæ)) (Dette et al. 2003).
Ejemplos de este tipo de dise√±os se muestran en la secci√≥n 4.3.
   Para DœÄ optimalidad, se obtiene la siguiente equivalencia, generalizaci√≥n del
teorema de Kiefer y Wolfowitz:

          Œæ es DœÄ ‚àí √≥ptimo si√≠ E[g T (x, Œ∏)M ‚àí1 (Œæ, Œ∏)g(x, Œ∏)] ‚â§ m,     ‚àÄx ‚àà œá        (5)

La respectiva equivalencia se obtiene para AœÄ ‚àíoptimalidad al calcular la esperan-
za, con respecto a Œ∏, de la expresi√≥n 3:

  Œæ es AœÄ ‚àí √≥ptimo si√≠
       E[g T (x, Œ∏)M ‚àí1 (Œæ)KK T M ‚àí1 g(x, Œ∏) ‚àí Tr(K T M ‚àí1 (Œæ)K)] ‚â§ 0,      ‚àÄx ‚àà œá    (6)

donde K, M ‚àí1 , son funciones que dependen de Œ∏.


4.     Ejemplos
    En esta secci√≥n se presentan varios ejemplos de modelos (lineales y no linea-
les) donde el inter√©s est√° en encontrar dise√±os √≥ptimos, ya sea que se conozcan
los puntos de soporte o no. Inicialmente se considera el caso lineal, criterios œÜp
optimales y por √∫ltimo el caso no lineal.

                                         Revista Colombiana de Estad√≠stica 30 (2007) 37‚Äì51

44                                                   V√≠ctor Ignacio L√≥pez & Rogelio Ramos

4.1.    Ejemplo 1. Determinaci√≥n de los pesos √≥ptimos para
        un dise√±o dado
    Este ejemplo muestra los resultados reportados por Pukelsheim & Torsney
(1991) cuando los puntos de soporte del dise√±o son conocidos, y luego se da una
aplicaci√≥n.
    Por conveniencia se reescribe el modelo lineal de la siguiente forma:
                  E[Yij ] = xTi Œ∏,   j = 1, 2, . . . , ni ,   i = 1, 2, . . . , l       (7)
con observaciones Yij incorrelacionadas, varianza constante œÉ 2 , y los l vectores de
regresi√≥n {x1 , x2 , . . . , xl } linealmente independientes y conocidos.
    El objetivo es encontrar un dise√±o experimental Œæ que indique, en forma √≥ptima,
el n√∫mero de r√©plicas ni que se har√°n en el vector de regresi√≥n xi , con el fin de esti-
mar K T Œ∏. En t√©rminos generales, hallar un vector de pesos wT = [w1 , w2 , . . . , wl ]
que maximice la funci√≥n de informaci√≥n:
                                     œÜp [CK (M (w))]
donde M (w), la matriz de momentos asociada al modelo (7), es expresada como:
                                     l
                                     X
                           M (w) =         xi xTi wi = X T ‚àÜw X
                                     i=1

  T
                         
X = x1       x2    ¬∑ ¬∑ ¬∑ xl y ‚àÜw = diag(w), con la siguiente inversa generalizada
para M :
                       M (w)‚àí = X T (XX T )‚àí1 ‚àÜ‚àí    T ‚àí1
                                               w (XX )   X
V = (XX T )‚àí1 XK, entonces la matriz de informaci√≥n es:
                              CK (M (w)) = (V T ‚àÜ‚àí
                                                 wV )
                                                     ‚àí1


‚àÜ‚àíw inversa generalizada para ‚àÜw , si todos los pesos de w no son positivos.
   En el siguiente resultado se obtiene una expresi√≥n cerrada para los pesos
A‚àí√≥ptimos (p = ‚àí1) y una forma de encontrarlos recursivamente para los otros
valores de p.
Teorema 3. Sea p ‚àà (‚àí‚àû, 1], el vector de pesos w es œÜp ‚àí√≥ptimo para K T Œ∏ si y
s√≥lo si:                    ‚àö
                              bii
                   wi = Pl p , para i = 1, . . . , l                       (8)
                           j=1    bjj
donde b11 , . . . , bll son los elementos de la diagonal de la matriz definida no negativa
l √ó l: B = V C p+1 V T , con C = CK (M (w)).
Observaci√≥n 5. Si p = ‚àí1, A‚àíoptimalidad, y el sistema de inter√©s es el vector
                                                                   1             ‚àí1
de par√°metros Œ∏, entonces la funci√≥n objetivo: œÜ‚àí1 (M (w)) = m        Tr(M ‚àí1 (w))    ,
el inverso del promedio de las varianzas de los estimadores de m√≠nimos cuadrados
Œ∏b1 , . . . , Œ∏bm , estandarizados relativo a su tama√±o muestral N y a la varianza del
modelo œÉ 2 .



                                           Revista Colombiana de Estad√≠stica 30 (2007) 37‚Äì51

Una introducci√≥n a los dise√±os √≥ptimos                                                     45

Aplicaci√≥n: Modelo de an√°lisis de varianza de un factor con tres niveles:
                     Yij = ¬µi + ij ,   j = 1, 2, . . . ,   ni ,   i = 1, 2, 3
En este caso, seg√∫n el modelo (7), Œ∏T = [¬µ1 , ¬µ2 , ¬µ3 ], xT1 = [1, 0, 0], xT2 = [0, 1, 0],
xT3 = [0, 0, 1]. El inter√©s est√° en conocer el n√∫mero de r√©plicas en cada nivel del
factor con el fin de estimar en forma √≥ptima: C1.‚àí Los tres efectos promedio, y
C2.‚àí El contraste: ¬µ3 ‚àí ¬µ1 y ¬µ2 . Aplicando el teorema 3 se obtienen los pesos
œÜp ‚àí√≥ptimos para p = ‚àí1, 0, ver tabla 1. Note que:
       Para el caso C1 los dise√±os √≥ptimos coinciden para los dos criterios conside-
       rados.
       En ambos casos, el dise√±o A‚àí√≥ptimo requiere la misma proporci√≥n de ob-
       servaciones en cada uno de los tres niveles del factor. Difiere con respecto
       al criterio D‚àí√≥ptimo ya que en el caso C2, el dise√±o D‚àí√≥ptimo requiere
       alrededor de la mitad de las observaciones para el segundo nivel, y el resto
       se reparte igualmente para los otros dos niveles.

           Tabla 1: Resultados para los pesos √≥ptimos dise√±o de un factor.
                                              p       criterio                 w
                                                                         ÀÜ            Àú
    Caso 1. Estimaci√≥n de ¬µ                  -1    A-optimalidad          1/3 1/3  1/3Àú
                                                                         ÀÜ
                                              0    D-optimalidad          1/3 1/3 1/3
                                                                         ÀÜ            Àú
    Caso 2. Estimaci√≥n de ¬µ3 ‚àí ¬µ1 y ¬µ2       -1    A-optimalidad
                                                                      ÀÜ 1/3 1/3 1/3 Àú
                                              0    D-optimalidad       0.251 0.498 0.251



4.2.      Ejemplo 2. Dise√±os √≥ptimos para modelos
         polinomiales
   Considere inicialmente el modelo polinomial de grado 2 en el intervalo [‚àí1, 1],
                             Y (x) = f T (x)Œ∏ + 
                                           
donde f T (x) = 1 x x2 y Œ∏T = Œ∏0 Œ∏1 Œ∏2 , x ‚àà [‚àí1, 1].
   En el caso D‚àí√≥ptimo, se verificar√° a continuaci√≥n que el dise√±o
                                                 
                                   ‚àí1    0     1
                            Œæ=
                                   1/3 1/3 1/3
es un dise√±o D‚àí√≥ptimo para estimar Œ∏ (tomando K = I).
   En efecto, bastar√° con mostrar que el dise√±o Œæ verifica las condiciones del
teorema 1. Primero note que su matriz de momentos es:

   En la figura 1 se muestra que esta funci√≥n tiene todos sus valores por debajo
de m = 3, y en los puntos de soporte alcanza su m√°ximo, luego Œæ es D‚àí√≥ptimo
para estimar el vector de par√°metros Œ∏.
                          Figura 1: Gr√°fico de la funci√≥n d(x, Œæ).
    Suponga que el inter√©s del investigador est√° en estimar la diferencia entre el
             la potencia
coeficiente de          cuadr√°tica y la lineal. En este caso el sistema de inter√©s
es: K T Œ∏ = 0 ‚àí1 1 Œ∏.
    En la tabla 2 aparecen los resultados que se obtuvieron con los criterios D
y A optimalidad para los casos C1 y C2, y con los mismos puntos de soporte.
Observe que los dise√±os dados por ambos criterios, para estimar Œ∏2 ‚àí Œ∏1 , reparten
en forma equitativa el n√∫mero de observaciones en los puntos x = ‚àí1 y en x = 0 y
ninguna observaci√≥n para x = 1. Se presentan diferencias en los dise√±os √≥ptimos
para la estimaci√≥n del vector de par√°metros; para A‚àíoptimalidad el 50% de las
observaciones se deber√°n tomar en x = 0, y el resto se reparte equitativamente
en los otros dos puntos, mientras que con D‚àíoptimalidad el mismo n√∫mero de
observaciones se deber√° tomar en los tres puntos.
   En la literatura (Pukelsheim 1993) existe la soluci√≥n para el caso general, poli-
nomios de grado d, para los dise√±os D‚àí√≥ptimos en el intervalo [‚àí1, 1]; los autores
usan como argumento el teorema 1, y muestran que los dise√±os D‚àí√≥ptimos tienen

                                             Revista Colombiana de Estad√≠stica 30 (2007) 37‚Äì51

Una introducci√≥n a los dise√±os √≥ptimos                                                      47

igual peso 1/(d + 1) en los puntos de soporte que son soluci√≥n a la ecuaci√≥n:

                                      (1 ‚àí x2 )PÃád (x) = 0

donde PÃád (x) es la derivada del polinomio de Legendre de grado d.

        Tabla 2: Resultados para los pesos √≥ptimos para el modelo cuadr√°tico.
                                             p     Criterio                    w
                                                                   ÀÜ                    Àú
         Caso 1. Estimaci√≥n de Œ∏            -1     A-optimalidad       0.25   0.50 0.25Àú
                                                                       ÀÜ
                                             0     D-optimalidad        1/3 1/3 1/3
                                                                        ÀÜ            Àú
         Caso 2. Estimaci√≥n de Œ∏2 ‚àí Œ∏1      -1     A-optimalidad
                                                                        ÀÜ0.5 0.5 0.0Àú
                                             0     D-optimalidad          0.5 0.5 0.0




4.3.     Ejemplo 3. Modelos no lineales
   Como ilustraci√≥n se consideran dos modelos no lineales (Atkinson & Donev, A.
N. 1992), y se construyen dise√±os √≥ptimos locales y usando un enfoque Bayesiano.

  1. El modelo de decaimiento exponencial est√° dado por:

                                   Œ∑(x, Œ∏) = exp(‚àíŒ∏x),         x>0

       Si Œ∏0 es una buena asignaci√≥n para Œ∏, suR matriz de informaci√≥n, la cual es un
       escalar, es: M (Œæ, Œ∏0 ) = M (x0 , Œ∏0 ) = x>0 f 2 (x, Œ∏0 ) dŒæ(x), donde f (x, Œ∏0 ) =
        d
       dŒ∏ Œ∑(x, Œ∏)|Œ∏=Œ∏0 = ‚àíx exp(‚àíŒ∏0 x).
       El modelo linealizado consta de un par√°metro, y el dise√±o D‚àí√≥ptimo local
       concentra toda su masa en un punto. Se ver√° a continuaci√≥n que el punto es:
       x0 = 1/Œ∏0 . Sea Œæ0 el dise√±o que tiene como punto de soporte a x0 , entonces:

                                   M (Œæ0 , Œ∏0 ) = x20 exp(‚àí2Œ∏0 x0 )                         (9)

       No es dif√≠cil mostrar que el m√°ximo de la ecuaci√≥n (9) se alcanza en
       x0 = 1/Œ∏0 , y

         d(x, Œæ0 ) = f T (x, Œ∏0 )M ‚àí1 (Œæ0 , Œ∏0 )f (x, Œ∏0 ) =
                                                   f 2 (x, Œ∏0 )
                                              R                  = (xŒ∏0 )2 exp(‚àí2(xŒ∏0 ‚àí 1))
                                                  f 2 (x)dŒæ0 (x)

       observe que d(x, Œæ0 ) ‚â§ 1, ‚àÄx > 0 y d(x, Œæ0 ) = 1 en x = 1/Œ∏0 , luego el dise√±o
       que concentra su masa en 1/Œ∏0 es D‚àí√≥ptimo local. Este dise√±o no permite
       realizar pruebas de bondad de ajuste para el modelo en cuesti√≥n. El dise√±o
       depende de la especificaci√≥n de Œ∏0 , y puede llegar a ser ineficiente si Œ∏0 est√°
       muy lejos del valor verdadero Œ∏. Otra forma de hallar un dise√±o √≥ptimo es a
       partir de un enfoque Bayesiano, donde se incorpora el conocimiento acerca
       de Œ∏ por medio de una distribuci√≥n a priori. Como ilustraci√≥n se consideran
       6 distribuciones a priori discretas, uniformes en 5 puntos, y se hallaron los

                                             Revista Colombiana de Estad√≠stica 30 (2007) 37‚Äì51

48                                                  V√≠ctor Ignacio L√≥pez & Rogelio Ramos

       respectivos dise√±os DœÄ ‚àí√≥ptimos para estimar Œ∏, con las diferentes a prioris;
       ver tabla 3. Lo anterior se hizo num√©ricamente con ayuda de algoritmos
       computacionales programados en el lenguaje R (R Development Core Team
       2006) usando la equivalencia 5. Los dise√±os DœÄ ‚àí√≥ptimos obtenidos est√°n
       formados por tres puntos de soporte, observ√°ndose variaci√≥n en las distintas
       a prioris consideradas, tanto en los puntos de soporte como en sus pesos.
       Atkinson & Donev, A. N. (1992, p√°g. 230) muestran c√≥mo los puntos de
       soporte del dise√±o aumentan a medida que la distribuci√≥n a priori que ellos
       consideran es m√°s dispersa.

Tabla 3: Ejemplo de decaimiento exponencial con diferentes distribuciones a prio-
         ris uniformes para Œ∏.
           Puntos de la a priori j                x                        w‚àó
         ÀÜ                         Àú   ÀÜ                    Àú    ÀÜ                      Àú
        ÀÜ 0.09  0.49 1 4.9 9 Àú          0.156
                                        ÀÜ      1.503 10.998Àú     ÀÜ0.438   0.403   0.158Àú
        ÀÜ0.10 0.50 1 5.0 10Àú            ÀÜ0.143 1.517 9.812Àú      ÀÜ0.432   0.420   0.148Àú
        ÀÜ0.11 0.51 1 5.1 11Àú            ÀÜ0.132 1.536 8.812Àú      ÀÜ0.428   0.437   0.135Àú
        ÀÜ0.12 0.52 1 5.2 12Àú            ÀÜ0.123 1.558 7.952Àú      ÀÜ0.424   0.455   0.121Àú
        ÀÜ0.14 0.54 1 5.4 14Àú            ÀÜ0.107 1.617 6.547Àú      ÀÜ0.418   0.496   0.085Àú
          0.15 0.55 1 5.5 15             0.101 1.649 5.965        0.416   0.521   0.063



     2. Modelo de compartimientos.

       Los modelos de compartimientos son de gran utilidad en farmacocin√©tica,
       utilizados, entre otras aplicaciones, para modelar el nivel de concentraci√≥n
       de un medicamento en la sangre de un individuo a lo largo del tiempo. Se
       considera el siguiente modelo:

                         Œ∏1
          Œ∑(x, Œ∏) =           {exp(‚àíŒ∏2 x) ‚àí exp(‚àíŒ∏1 x)},        x ‚â• 0,    Œ∏1 > Œ∏2 > 0       (10)
                      Œ∏1 ‚àí Œ∏2

       Asociado al trabajo biol√≥gico es de inter√©s, adem√°s de estimar el vector de
       par√°metros Œ∏, estimar tres cantidades que ayudan al estudio de la cin√©tica
       del medicamento en un individuo. Estas cantidades son:
                                                        R‚àû
         a) El √°rea bajo la curva (AUC): g1 (Œ∏) =         0   Œ∑(x, Œ∏)dŒ∏ = Œ∏12 .
                                                                          ‚àílog Œ∏2
         b) Tiempo para la concentraci√≥n m√°xima: g2 (Œ∏) = xmax = log Œ∏Œ∏11 ‚àíŒ∏ 2
                                                                                  .
         c) La concentraci√≥n m√°xima: g3 (Œ∏) = Œ∑(xmax , Œ∏).

       La construcci√≥n de dise√±os √≥ptimos para la estimaci√≥n de estas funciones
       simult√°neamente, se har√° por medio de dise√±os A‚àí√≥ptimos locales (v√©ase
       (2), con p = ‚àí1), y dise√±os A‚àí√≥ptimos promediados por una distribuci√≥n a
       priori uniforme. La j‚àí√©sima columna Kj , de K es el gradiente de funci√≥n
       no lineal gj (Œ∏), evaluada en Œ∏0 . As√≠ se asegura que el dise√±o √≥ptimo ser√°
       aquel que minimice el promedio de las varianzas del respectivo estimador
       linealizado, es decir, aquel que minimiza:

                                            Revista Colombiana de Estad√≠stica 30 (2007) 37‚Äì51

Una introducci√≥n a los dise√±os √≥ptimos                                                  49


                      3
                   1X                     1X
                         var(gj (Œ∏b0 )) ‚âà            b ‚àù K T M ‚àí1 (Œæ)K
                                             var(KjT Œ≤)
                   3 j=1                  3

     En el caso de estudio, las primeras dos columnas de K est√°n dadas por:
                                                h                         i
           K1T (Œ∏0 ) = 0 ‚àí1/Œ∏20 2 ,                    10 ‚àíxmax
                                        K2 (Œ∏0 ) = 1/Œ∏Œ∏10 ‚àíŒ∏20
                                                                xmax ‚àí1/Œ∏20
                                                                 Œ∏10 ‚àíŒ∏20

     en forma an√°loga
                        se halla la tercera columna de K. Como ilustraci√≥n, se
     tom√≥ Œ∏0T = 0.7 0.2 , y en la tabla 4 se presentan los dise√±os A‚àí√≥ptimos
     locales obtenidos para la estimaci√≥n de las tres caracter√≠sticas de inter√©s
     simult√°neamente. Tambi√©n se consider√≥ una a priori uniforme discreta para
     los siguientes cinco valores del vector de par√°metros Œ∏:

           Œò = {(0.70, 0.20), (0.65, 0.15), (0.75, 0.25), (0.65, 0.25), (0.75, 0.15)}

     es decir, œÄ(Œ∏) = 1/5, ‚àÄŒ∏ ‚àà Œò, y en la tabla 4 se reporta el dise√±o A‚àí√≥ptimo
     Bayesiano obtenido. Ambos dise√±os A‚àí√≥ptimo local y A‚àí√≥ptimo promedia-
     do por la a priori œÄ, presentan pocas diferencias. Adem√°s en ambos casos se
     verific√≥ que el dise√±o hallado satisfac√≠a las equivalencias dadas por (3) y (6),
     respectivamente.

Tabla 4: Dise√±os A‚àí√≥ptimos locales y promediados por la a priori œÄ para el
         modelo 10.
                      Criterio                        Tiempo x      Pesos del dise√±o
                                                   ÀÜ            Àú   ÀÜ              Àú
     A‚àíoptimalidad local                            1.313  6.602Àú
                                                   ÀÜ                ÀÜ0.276 0.724Àú
     A‚àíoptimalidad promediado por la a priori œÄ     1.456 7.145       0.269 0.731




5.    Anotaciones finales
    En este trabajo se present√≥ una motivaci√≥n inicial para el estudio de los dise√±os
√≥ptimos en ambos casos lineal y no lineal. Se dio el enfoque matem√°tico de cada
uno de los criterios de optimalidad usados en la pr√°ctica y se termin√≥ presentando
algunos ejemplos t√≠picos. Hay gran diversidad de bibliograf√≠a en torno a este tema,
donde el estudio en esta √°rea es factible e interesante.
    En la mayor√≠a de los art√≠culos citados, los autores asumen que el modelo bajo
consideraci√≥n es conocido, y el valor de los par√°metros es desconocido. Con este
supuesto, usan criterios de optimalidad que son eficientes para la estimaci√≥n de los
par√°metros del modelo fijo. Sin embargo, existen aplicaciones donde la forma de
la funci√≥n de regresi√≥n no es conocida en forma exacta, es decir, el experimentador
debe decidir, entre un conjunto de clases de funciones competitivas, cu√°les de estas
describen los datos en una forma m√°s adecuada. Como lo afirman Biedermann
et al. (2005), el problema de dise√±o para discriminar entre modelos no lineales
competitivos ha encontrado muy poco inter√©s en la literatura que aquellos proble-
mas de estimaci√≥n de par√°metros. En el caso de discriminaci√≥n de modelos, lineal y no lineal, se pueden revisar los trabajos de: Atkinson & Cox (1974), Atkinson &
Fedorov (1975), Pukelsheim & Rosenberger (1993), Biswas & Chaudhuri (2002) y
Biedermann et al. (2005). Por lo anterior, est√° como trabajo futuro ahondar en el
estudio de dise√±os √≥ptimos que sean eficientes para discriminar entre modelos no
lineales anidados, adem√°s de que permitan estimar en forma simult√°nea funciones
de los par√°metros.
Agradecimientos
Agradecemos los comentarios hechos por los dos √°rbitros, lo que hizo que este trabajo se mejorara considerablemente. El presente trabajo se realiz√≥ cuando el primer autor estaba haciendo su doctorado en Ciencias con Orientaci√≥n en Probabilidad y Estad√≠stica en el Centro de Investigaci√≥n en Matem√°ticas (CIMAT), M√©xico. Parte de este trabajo fue apoyado por CIMAT, Secretar√≠a de Relaciones Exteriores de M√©xico (SRE) y la Universidad Nacional de Colombia, sede Medell√≠n.
Referencias
Atkinson A C.The Uselfulness of Optimum Experimental Designs.(1996).Journal of the Royal Statistical Society.
Atkinson A C,Cox D R.Planning Experiments for Discriminating Between Models.(1974).Journal of the Royal Statistical Society.
Atkinson A C,Donev A N.Optimum Experimental Designs.(1992).Oxford Science Publications.New York.
Atkinson A C,Fedorov V V.Optimal Design: Experiments for Discriminating Between Several Models.(1975).Biometriks.
Biedermann S,Dette H,Pepelyshev A.Optimal Discrimination Designs for Exponential Regression Models.(2005)..
Biswas A,Chaudhuri P.An Efficient Design for Model Discrimination on Parameter Estimation in Linear Models.(2002).Biometriks.
Brown L D,I O,Sacks J,Wynn H P.Jack Karl Kiefer Collected Papers III, Design of Experiments.(1985).Springer-Verlag.New York.
Chernoff H.Locally Optimal Designs for Estimating Parameters.(1953).The Annals of Mathematical Statistics.
Dette H,Haines L M,Imhof L A.Maximin and Bayesian Optimal Designs for Regression Models.(2003)..
Dette H,Melas V B,Pepelyshev A.Optimal Designs for a Class of Nonlinear Regression Models.(2004).The Annals of Statistics.
Dette H,Melas V B,Wong W K.Optimal Design for Goodness-of Fit of the Michaelis-Menten Enzyme Kinetic Function.(2005).Journal of the American Statistical Association.
Ford I,Tornsney B,Wu C F J.The Use of a Canonical Form in the Construction of Locally Optimal Designs for Nonlinear Problems.(1992).Journal of the Royal Statistical Society.
Kiefer J.Optimum Experimental Designs.(1959).Journal Royal Statistical Society.
Kiefer J,Wolfowitz J.The Equivalence of Two Extremum Problems.(1960).Canadian Journal of Mathematics.
Pukelsheim F.Optimal Design of Experiments.(1993).John Wiley & Sons.New York.
Pukelsheim F,Rosenberger J L.Experimental Designs for Model Discrimination.(1993).Journal of the American Statistical Association.
Pukelsheim F,Torsney B.Optimal Weights for Experimental Designs on Linearly Independent Support Points.(1991).The Annals of Statistics.
R Development Core Team.R: A Language and Environment for Statistical Computing.(2006).R Foundation for Statistical Computing.Austria.
Smith K.On the Standard Deviations of Adjusted and Interpolates Values of an Observed Polynomial Functions and its Constants and the Guidance They Give Towards a Proper Choice of the Distribution of Observations.(1918).Biometrika.