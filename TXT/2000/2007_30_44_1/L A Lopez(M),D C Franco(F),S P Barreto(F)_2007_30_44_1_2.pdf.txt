Sobre la construcción del mejor predictor lineal insesgado (BLUP) y restricciones asociadas
Universidad Nacional de Colombia;Universidad de la Sabana;Titularizadora Colombiana S. A
Resumen
A través del modelo lineal clásico de Gauss-Markov, se caracteriza el modelo de efectos mixtos, se aplica la técnica de multiplicadores de Lagrange para obtener los mejores predictores lineales (BLUP) y se ilustran los resultados de Searle (1997), donde se encuentra que las sumas de los BLUP, cuando se evalúan sobre los efectos aleatorios (exceptuando las interacciones provenientes únicamente de efectos aleatorios), son iguales a cero, encontrándose con esto una analogía entre la reparametrización Σ-restricción que se hace sobre los modelos de efectos fijos y la forma general de la restricción que se hace sobre los modelos de efectos mixtos. Se lleva a cabo una ilustración en modelos cruzados con los resultados expuestos en Gaona (2000), donde se evaluó la ganancia de peso en novillos de ganado criollo sanmartiniano; adicionalmente para modelos jerárquicos se ilustra con los resultados presentados en Harville & Fenech (1985), correspondientes a mediciones de las ganancias en peso de un grupo de ovejos machos. Se observa de los resultados que en el modelo usual de análisis de varianza para modelos mixtos, ciertas sumas de los predictores lineales insesgados (BLUP), asociados a los efectos aleatorios, son iguales a cero si se tiene un modelo con una sola variable respuesta. Sin embargo, esta propiedad se pierde cuando se tienen evaluaciones diferentes en la misma unidad experimental, las cuales van a estar correlacionadas. Un caso diferente resulta en estudios longitudinales como se muestra empíricamente en la sección 5.3.
Palabras clave: modelos de efectos mixtos, multiplicadores de Lagrange, diseño cruzado, modelos lineales jerárquicos.
Introducción
Los modelos de efectos mixtos fueron ampliamente estudiados por Fisher hacia 1918, quien los denominó modelos de componentes de varianza. Estos modelos fueron de gran utilidad en los estudios de genética cuantitativa y mejoramiento animal; sin embargo, su aplicación en diferentes campos de la investigación científica se ha venido generalizando en las últimas décadas, en las cuales se han implementado nuevos desarrollos metodológicos que han contribuido a su estudio y aplicación.
    En los estudios de modelos mixtos es fundamental que se tengan en cuenta los
siguientes aspectos:

     1. Estimación de efectos fijos.

     2. Estimación de efectos aleatorios.

     3. Estimación de los predictores lineales.

    Este último aspecto no ha sido ampliamente difundido a pesar de que tie-
ne diversas aplicaciones, principalmente en mejoramiento animal y programas de
inseminación artificial, cuando se desean evaluar los méritos genéticos de los re-
productores.
   Según Hartley & Rao (1967) y Barroso & Bussab (1998), el modelo mixto
puede ser escrito en forma general como:

                        y = Xβ + Z1 U1 + Z2 U2 + · · · + Zc Uc + e                        (1)
donde:
        y es el vector de observaciones de orden n × 1,

                                           Revista Colombiana de Estadística 30 (2007) 13–36

Construcción del mejor predictor lineal insesgado (BLUP) y restricciones asociadas 15

       X una matriz conocida de tamaño n × p,
       β un vector de constantes desconocidas de dimensión p × 1,
       Zi una matriz conocida de tamaño n × qi , con i = 1, 2, . . . , c,
       Ui un vector de variables aleatorias de dimensión qi × 1, y
       e un vector de variables aleatorias de orden n × 1.

   Para el modelo (1) se asume que U1 , U2 , . . . , Uc se distribuyen de manera inde-
pendiente e idénticamente como:

                                          Ui ∼ N (0; σi2 Iqi )                                (2)
                                           e ∼ N (0; Rσ02 )                                   (3)

donde:

       Zi Zit y R son matrices que se asumen conocidas, y
       σ02 , σ12 , . . . , σc2 son constantes desconocidas no negativas a las cuales se les
       conoce como los componentes de varianza.


2.     Notación
     El modelo (1) se puede escribir en forma matricial como:

                    y(n×1) = X(n×p) β(p×1) + Z(n×q) U(q×1) + e(n×1)                           (4)

donde:

       Z = (Z1 , Z2 , . . . , Zc ); Zi será una matriz conocida de tamaño n × qi para
       i = 1, 2, . . . , c,
       U = (U1t , U2t , . . . , Uct )t un vector no observable
                                                     P         de variables aleatorias desco-
       nocidas de dimensión q × 1, con q = ci=1 qi .

   En el modelo (4) se asume que si U0 = e, entonces U = (U0t , U1t , . . . , Uct )t y
además se satisface:

 i) E(Ui ) = 0          (
                            σi2 Iqi , si i = i0 ;
 ii) Cov(Ui , Ui0 ) =
                            0,        si i 6= i0 .
      Para i, i0 = 0, 1, . . . , t.
                V ar(y) = V ar(Xβ + ZU + e)
                                                                                              (5)
                        = ZV ar(U )Z t + V ar(e) + ZCov(U, e) = ZDZ t + R

      donde:

                                                 Revista Colombiana de Estadística 30 (2007) 13–36

16                 Luis Alberto López, Diana Carolina Franco & Sandra Patricia Barreto

            D = ⊕ci=1 σi2 Iqi , con ⊕ el operador que representa la suma directa de
            matrices,
            R = σ02 IN .

iii) De esta forma (5) se puede reescribir como:

                               V ar(y) = Z(⊕ci=1 σi2 Iqi )Z t + R
                                         Xc
                                       =    Zi Zit σi2 + R                              (6)
                                           i=1
                                         =V

iv)

                           Cov(y, U t ) = E[(y − E(y))(U − E(U ))t ]
                                                                                        (7)
                                        = ZD = C


3.       Sobre la obtención del mejor predictor lineal
         insesgado BLUP
    Cuando en el modelo (1) se tiene interés en la estimación de funciones lineales
de la forma K t β + M t U a través de una función lineal de las observaciones Lt y,
conocida como el predictor lineal, se busca que la varianza del error de predicción
sea mínima. La estimación de esta función se obtiene asumiendo inicialmente
que K t β va a ser una función lineal paramétrica estimable. Para obtener estas
estimaciones existen diferentes métodos, como se puede ver en Henderson (1982).
      Al minimizar la varianza del error de predicción se tiene:
                                  
     min V ar(K t β + M t U − Lt y) =
     β,U
                                                                            
         min V ar(M t U ) + V ar(Lt y) − Cov(M t U, Lt y) − Cov(Lt y, M t U ) =
         β,U
                                                                               
                                min M t DM + Lt V L − M t DZ t Lt − Lt ZDM        (8)
                                  β,U


      Si el predictor es insesgado, se satisface que:

                                 E[K t β̂ + M t Ũ] = K t β

y
                                E[Lt y] = Lt E[y] = Lt Xβ
igualando los valores esperados se tiene que:

                                        Lt Xβ = K t β

siempre que Lt X − K t = 0.

                                           Revista Colombiana de Estadística 30 (2007) 13–36

Construcción del mejor predictor lineal insesgado (BLUP) y restricciones asociadas 17

    Se busca entonces minimizar la varianza del error del predictor sujeta a la
restricción Lt X − K t = 0, lo cual en el presente trabajo se hace a través de la
minimización de una función de Lagrange. Los resultados que se muestran al
minimizar esta ecuación se obtienen siguiendo a Henderson (1982, 1984).

                  F = M t DM + Lt V L − 2Lt ZDM + λt (X t L − K)

En la función anterior, al derivar e igualar a cero, se obtiene el siguiente sistema
de ecuaciones:
                           ∂F
                               = 2V L − 2ZDM + λX = 0
                           ∂Lt
                           ∂F
                               = X tL − K = 0
                           ∂λt
matricialmente:                                         
                                   V     X        L      ZDM
                                                  1   =                                    (9)
                                   Xt    0        2λ      K
con V = ZDZ t + R y haciendo θ = 21 λ, el sistema (9) es equivalente a:
                                                         
                          ZDZ t + R            X     L    ZDM
                                                       =                                  (10)
                            Xt                 0     θ     K

operando con la primera ecuación se tiene:

                            (ZDZ t + R)L + Xθ = ZDM

entonces,

                         ZDZ t L + RL + Xθ − ZDM = 0
                               RL + ZD[Z t L − M ] + Xθ = 0

finalmente,
                                    RL + ZS + Xθ = 0                                      (11)
              t
con S = D[Z L − M ] y como D es no singular, entonces se satisface que:

                                        D−1 S = Z t L − M

de lo anterior se tiene que:
                                        M = Z t L − D−1 S                                 (12)

   Teniendo en cuenta (9), (11) y (12), entonces:
                                            
                         R       Z     X     L    0
                        Z t −D−1 0  S  = M 
                        Xt       0      0    θ    K

   De (11) se sigue que:
                                    RL = −(ZS + Xθ)

                                              Revista Colombiana de Estadística 30 (2007) 13–36

18              Luis Alberto López, Diana Carolina Franco & Sandra Patricia Barreto

Además, por ser R una matriz no singular, entonces se tiene que:

                                   L = −R−1 (ZS + Xθ)                                  (13)

Si ahora se reemplaza (13) en (12), se tiene que:

                        M = Z t [−R−1 (ZS + Xθ)] − D−1 S
                        M = −[Z t R−1 ZS + Z t R−1 Xθ + D−1 S]
                        M = −[(Z t R−1 Z + D−1 )S + Z t R−1 Xθ]

reemplazando L obtenido en (13) con la condición X t L = K, se tiene el sistema:
                 t −1                t −1
                                             
                  Z R Z + D−1 Z     |  R{z X}           
                |       {z
                        c11
                                 }
                                        c12   S        −M
                
                       t −1           t −1 
                                                   =
                     X
                     | R {z Z}      | R{z X} θ
                                    X                   −K
                
                             c21                  c22

La solución al sistema anterior está dada por:
                                                     −1          
                               S    c             c12           −M
                                 = 11
                               θ    c21           c22           −K

de (11) se tiene que:
                                 RL = −ZS − Xθ                                         (14)
                                               −1     
                                     c11 c12        −M
                         RL = − Z X
                                        c21 c22       −K
                                                                  −1        
                                             c11           c12           M
                          L = R−1 Z        X
                                                c21          c22           K

   De esta forma se obtiene finalmente la función lineal de predicción, la cual está
dada por:
                                              −1  t 
                                   c11 c12         Z
                   Lt y = M t K t                        R−1 y                  (15)
                                      c21 c22        Xt
o de otra manera:
                                                       " #
                                    t
                                             t
                                                       Ũ
                                                         t
                                   Ly= M            K
                                                        β̂
                                   Lt y = M t Ũ + K t β̂                              (16)

    Las estimaciones para los vectores U y β se obtienen a partir de la solución del
siguiente sistema de ecuaciones:
                 t −1                       " # "
                  X R X          X t R−1 Z              X t R−1 y
                                                                  #
                                                 β̂
                                                   =                          (17)
                  Z t R−1 X Z t R−1 Z + D−1 Ũ          Z t R−1 y


                                           Revista Colombiana de Estadística 30 (2007) 13–36

Construcción del mejor predictor lineal insesgado (BLUP) y restricciones asociadas 19

conocidas como las soluciones de las ecuaciones normales de Henderson, según
Searle (1987) y McCulloch & Searle (2001). Estas ecuaciones proveen los mejores
predictores lineales insesgados (BLUP).
    Del sistema de ecuaciones (17), se encuentran las soluciones explícitas para Ũ
y β̂. Desarrollando la segunda de estas ecuaciones se tiene:

                     Z t R−1 X β̂ + [Z t R−1 Z + D−1 ]Ũ = Z t R−1 y

                   Ũ = [Z t R−1 Z + D−1 ]−1 [Z t R−1 y − Z t R−1 X β̂]
                                                                                     (18)
                   Ũ = [Z t R−1 Z + D−1 ]−1 Z t R−1 (y − X β̂)
reemplazando este resultado en la primera ecuación de (17) se tiene:

       X t R−1 X β̂ + X t R−1 Z[Z t R−1 Z + D−1 ]−1 Z t R−1 (Y − X β̂) = X t R−1 y

reagrupando términos en la ecuación anterior, se tiene:

                                   X t BX β̂ = X t By

donde:
                    B = R−1 − R−1 Z[Z t R−1 Z + D−1 ]−1 Z t R−1
y
                                V −1 = [ZDZ t + R]−1
utilizando el complemento de Schurb, puede ser escrito como:

                       R−1 − R−1 Z[Z t R−1 Z + D−1 ]−1 Z t R−1

de aquí,
                                        B = V −1
y
                                X t V −1 X β̂ = X t V −1 y
que es la ecuación de mínimos cuadrados generalizados para β.
    Por otro lado, Ũ es el BLUP(U ) y usando la identidad:

                        [D−1 + Z t R−1 Z]−1 Z t R−1 = DZ t V −1

entonces:
                         BLUP(U ) = Ũ = DZ t V −1 [y − X β̂]
con:
                               β̂ = [X t V −1 X]− X t V −1 y
o de otra manera (ver Henderson (1984) y Searle (1987)):

                              BLUP(U ) = Ũ = DZ t P y                               (19)

                                         Revista Colombiana de Estadística 30 (2007) 13–36

20               Luis Alberto López, Diana Carolina Franco & Sandra Patricia Barreto

   A Ũ se le conoce como el mejor predictor para U , con D = V ar(U ), Z, X y y
como se definieron al principio de esta sección; además:

                        P = V −1 − V −1 X(X t V −1 X)− X t V −1

puesto que:
                                         PX = 0
siendo
                               V = V ar(y) = ZDZ t + R
como se definió en la sección anterior.


4.       Una restricción general sobre el BLUP(U )
    En Searle (1997) se presenta una forma general de la restricción que proviene
del hecho P X = 0. En un artículo de referencia se demuestra que esto se obtiene
siempre y cuando existan unos vectores λ y τ , tales que:

                                       ZDλ = Xτ

   Entonces, una restricción sobre los Ũ está dada por (ver Henderson (1984) y
Searle (1987)):
                       λt Ũ = λt DZ t P t y = (P Xτ )t y = 0              (20)
siendo:

            λt Ũ = λt [DZ t V −1 (y − X β̂)]
                 = λt DZ t V −1 (y − X(X t V −1 X)− X t V −1 X t y)
                 = λt DZ t V −1 y − λt DZ t V −1 X(X t V −1 X)− X t V −1 X t y
                 = (Xτ )t [V −1 − X(X t V −1 X)− X t V −1 X t ]y
                 = (Xτ )t P t y
                 = (P Xτ )t y = 0

de donde: λt Ũ = 0, lo cual se satisface en los modelos de efectos mixtos jerárquicos
o cruzados con estructura balanceada o desbalanceada y en presencia de celdas
vacías, pero no en modelos mixtos en los cuales están involucrados datos de tipo
longitudinal, como se muestra empíricamente en la sección 5.3.
   En Searle (1997) se demuestra que los resultados numéricos visualizados por
McLean et al. (1991) son evidentemente ciertos en datos no correlacionados.


5.       Ilustración de los resultados
    En esta sección se lleva a cabo una ilustración de los resultados expuestos
previamente, la cual se hace con dos ejemplos numéricos aplicados a problemas
reales de mejoramiento animal.

                                          Revista Colombiana de Estadística 30 (2007) 13–36

Construcción del mejor predictor lineal insesgado (BLUP) y restricciones asociadas 21

5.1.     Aplicación con un modelo de efectos cruzados
    En este caso se considera la información presentada en Gaona (2000), la cual
fue recopilada entre 1990 y 1996 en el marco del Proyecto de Evaluación Genética
bajo el plan de Modernización de la Ganadería y contiene registros del peso al
nacimiento de ganado criollo sanmartiniano, el sexo de la cría (hembra o macho),
un intervalo del número de partos de la madre de la cría, la época de nacimiento
del animal (invierno o verano), la edad del animal y el código del padre de la cría.
    De acuerdo con las variables citadas, el modelo de interés tiene la siguiente
estructura:

             yijkln = µ + αi + βj + ck + γl + αγil + αβjl + cγkl + eijkln

donde:

       y(207×1) es el vector que tiene información referente a los pesos al nacimiento
       de la cría,

       µ es la media general,

       αi representa el efecto del i-ésimo sexo,

       βj representa el efecto de la j-ésima época,

       ck representa el efecto del k-ésimo número de partos,

       γl es el efecto del l-ésimo padre,

       eijkln es la componente aleatoria de error.

    De esta manera, los factores sexo, época y número de partos corresponden a
efectos fijos y el factor padre es aleatorio con media cero y varianza dada por σγ2 .
Es claro que las interacciones de los efectos fijos con el factor padre van a ser
aleatorias.
   En términos matriciales, el modelo anterior puede ser escrito como:

          y = 1µ + X0 α + X1 β + X2 C + Z1 γ + Z2 αγ + Z3 βγ + Z4 Cγ + e

Las dimensiones de las matrices asociadas con este modelo son las siguientes:
   X0(207×2) , X1(207×2) , X2(207×5) , Z1(207×20) , Z2(207×40) , Z3(207×40) , Z4(207×69) .
    Se considera la información en un arreglo, en el cual cada yijkl corresponde
al peso del animal observado en la celda correspondiente al i-ésimo sexo, j-ésima
época, k-ésimo parto y l-ésimo padre; donde i, j = 1, 2, k = 1, 2, 3, 4, 5 y l =
1, 2, . . . , 20. El arreglo de la información se muestra en la tabla (2).

                                         Revista Colombiana de Estadística 30 (2007) 13–36

22                      Luis Alberto López, Diana Carolina Franco & Sandra Patricia Barreto

     Los componentes de varianza, del vector ũ0 de tamaño 1 × 169, a estimar son:
 γ1            γ2         γ3         γ4          γ5         γ6        γ7         γ8       γ9            γ10
 γ11           γ12        γ13        γ14         γ15        γ16       γ17        γ18      γ19           γ20
 αγ1,1         αγ1,2      αγ1,3      αγ1,4       αγ1,5      αγ1,6     αγ1,7      αγ1,8    αγ1,9         αγ1,10
 αγ1,11        αγ1,12     αγ1,13     αγ1,14      αγ1,15     αγ1,16    αγ1,17     αγ1,18   αγ1,19        αγ1,20
 αγ2,1         αγ2,2      αγ2,3      αγ2,4       αγ2,5      αγ2,6     αγ2,7      αγ2,8    αγ2,9         αγ2,10
 αγ2,11        αγ2,12     αγ2,13     αγ2,14      αγ2,15     αγ2,16    αγ2,17     αγ2,18   αγ2,19        αγ2,20
 βγ1,1         βγ1,2      βγ1,3      βγ1,4       βγ1,5      βγ1,6     βγ1,7      βγ1,8    βγ1,9         βγ1,10
 βγ1,11        βγ1,12     βγ1,13     βγ1,14      βγ1,15     βγ1,16    βγ1,17     βγ1,18   βγ1,19        βγ1,20
 βγ2,1         βγ2,2      βγ2,3      βγ2,4       βγ2,5      βγ2,6     βγ2,7      βγ2,8    βγ2,9         βγ2,10
 βγ2,11        βγ2,12     βγ2,13     βγ2,14      βγ2,15     βγ2,16    βγ2,17     βγ2,18   βγ2,19        βγ2,20
 Cγ1,5         Cγ1,7      Cγ1,8      Cγ1,9       Cγ1,12     Cγ1,15    Cγ1,16     Cγ1,17   Cγ1,18
 Cγ2,1         Cγ2,3      Cγ2,4      Cγ2,5       Cγ2,9      Cγ2,10    Cγ2,11     Cγ2,12   Cγ2,15        Cγ2,16
 Cγ2,17        Cγ2,18     Cγ2,19     Cγ2,20
 Cγ3,1         Cγ3,2      Cγ3,3      Cγ3,4       Cγ3,5      Cγ3,6     Cγ3,7      Cγ3,8    Cγ3,9         Cγ3,11
 Cγ3,12        Cγ3,13     Cγ3,14     Cγ3,15      Cγ3,16     Cγ3,17    Cγ3,18     Cγ3,19   Cγ3,20
 Cγ4,1         Cγ4,2      Cγ4,4      Cγ4,5       Cγ4,6      Cγ4,7     Cγ4,8      Cγ4,9    Cγ4,12        Cγ4,13
 Cγ4,14        Cγ4,15     Cγ4,17     Cγ4,18      Cγ4,19     Cγ4,20
 Cγ5,1         Cγ5,2      Cγ5,3      Cγ5,5       Cγ5,6      Cγ5,8     Cγ5,9      Cγ5,12   Cγ5,13        Cγ5,14
 Cγ5,19


         P padre es aleatorio y, como se puede comprobar, la suma de las esti-
  El factor
maciones 20l=1 γ̂l es cero.

               e1 = −0.684
               γ                e2 = −0.129
                                γ                  e
                                                   γ3 = −0.389       e4 = −0.764
                                                                     γ                e
                                                                                      γ5 =     0.161
               e6 =
               γ        0.946   e7 =
                                γ        0.255     e
                                                   γ8 =     0.657    e9 =
                                                                     γ        0.232   e10 =
                                                                                      γ        0.959
           e11 =
           γ            0.049   e
                                γ12 =    1.124    e13 =
                                                  γ         0.400    e
                                                                     γ14 = −0.853     e15 = −0.101
                                                                                      γ
           e16 =
           γ            0.029   e
                                γ17 = −1.052      e18 = −0.178
                                                  γ                  e
                                                                     γ19 = −0.192     e20 = −0.472
                                                                                      γ

    La interacción aleatoria padre*sexo proviene de una combinación
                                                              P20    de un efecto
                                                                    ˆ il es igual a
fijo y uno aleatorio, por lo tanto la suma de las estimaciones l=1 αγ
cero, para i = 1, 2.
     Para i = 1, las estimaciones de αγil son:
     f 1,1 = −0.116
     αγ                    f 1,2 =
                           αγ           0.000     f 1,3 =
                                                  αγ         0.157     f 1,4 = −0.228
                                                                       αγ                     f 1,5 =
                                                                                              αγ         0.021
     f 1,6 =
     αγ         0.276      f 1,7 = −0.106
                           αγ                     f 1,8 =
                                                  αγ         0.099     f 1,9 = −0.073
                                                                       αγ                 f 1,10 =
                                                                                          αγ             0.357
  f 1,11 =
  αγ            0.063     f 1,12 = −0.205
                          αγ                     f 1,13 =
                                                 αγ          0.063    f 1,14 =
                                                                      αγ          0.114   f 1,15 = −0.156
                                                                                          αγ
  f 1,16 =
  αγ            0.092     f 1,17 =
                          αγ            0.080    f 1,18 = −0.173
                                                 αγ                   f 1,19 = −0.180
                                                                      αγ                  f 1,20 = −0.085
                                                                                          αγ

     Para i = 2, las estimaciones de αγil son:
     f 2,1 = −0.109
     αγ                    f 2,2 = −0.042
                           αγ                     f 2,3 = −0.284
                                                  αγ                   f 2,4 = −0.022
                                                                       αγ                     f 2,5 =
                                                                                              αγ         0.032
     f 2,6 =
     αγ         0.035      f 2,7 =
                           αγ           0.190     f 2,8 =
                                                  αγ         0.116     f 2,9 =
                                                                       αγ         0.149   f 2,10 = −0.042
                                                                                          αγ
  f 2,11 = −0.046
  αγ                      f 2,12 =
                          αγ            0.574    f 2,13 =
                                                 αγ          0.069    f 2,14 = −0.395
                                                                      αγ                  f 2,15 =
                                                                                          αγ             0.123
  f 2,16 = −0.083
  αγ                      f 2,17 = −0.425
                          αγ                     f 2,18 =
                                                 αγ          0.114    f 2,19 =
                                                                      αγ          0.117   f 2,20 = −0.070
                                                                                          αγ

    La interacción aleatoria padre*época proviene de una combinación
                                                              P20 ˆ de un efecto
fijo y uno aleatorio, por lo tanto la suma de las estimaciones l=1 βγ jl es igual a
cero, para j = 1, 2.

                                                    Revista Colombiana de Estadística 30 (2007) 13–36

Construcción del mejor predictor lineal insesgado (BLUP) y restricciones asociadas 23

   Para j = 1, las estimaciones de βγjl son:
   f                     f                    f                     f                      f
   βγ 1,1 = −0.093       βγ 1,2 =   0.064     βγ 1,3 = −0.016       βγ 1,4 = −0.043        βγ 1,5 = −0.002
   f                     f                    f                     f                     f
   βγ 1,6 =   0.199      βγ 1,7 =   0.124     βγ 1,8 =   0.152      βγ 1,9 =    0.003     βγ 1,10 = −0.050
  f                     f                    f                     f                      f
  βγ 1,11 = −0.064      βγ 1,12 =   0.111    βγ 1,13 =   0.052     βγ 1,14 = −0.076       βγ 1,15 =    0.013
  f                     f                    f                     f                      f
  βγ 1,16 =   0.000     βγ 1,17 = −0.115     βγ 1,18 = −0.069      βγ 1,19 = −0.080       βγ 1,20 = −0.110


   Para j = 2, las estimaciones de βγjl son:
   f                     f                    f                     f                      f
   βγ 2,1 =   0.004      βγ 2,2 = −0.081      βγ 2,3 = −0.034       βγ 2,4 = −0.057        βγ 2,5 =    0.023
   f                     f                    f                     f                     f
   βγ 2,6 = −0.076       βγ 2,7 = −0.091      βγ 2,8 = −0.067       βγ 2,9 =    0.027     βγ 2,10 =    0.175
  f                     f                    f                     f                      f
  βγ 2,11 =   0.071     βγ 2,12 =   0.035    βγ 2,13 = −0.000      βγ 2,14 = −0.034       βγ 2,15 = −0.026
  f                     f                    f                     f                      f
  βγ 2,16 =   0.003     βγ 2,17 = −0.022     βγ 2,18 =   0.046     βγ 2,19 =    0.055     βγ 2,20 =    0.048

    La interacción aleatoria padre*partos proviene de una combinación
                                                              P20     de un efecto
                                                                    ˆ kl es igual a
fijo y uno aleatorio, por lo tanto la suma de las estimaciones l=1 Cγ
cero, para k = 1, 2, 3, 4, 5.
   Para k = 1, las estimaciones de Cγkl son:
   f 1,5 = −0.040
   Cγ                    f 1,7 = −0.506
                         Cγ                   f 1,8 = −0.118
                                              Cγ                     f 1,9 = −0.177
                                                                     Cγ                     f 1,12 = 0.243
                                                                                            Cγ
  f                     f                    f                      f
  Cγ 1,15 =   0.132     Cγ 1,16 = −0.006     Cγ 1,17 =    0.200     Cγ 1,18 =     0.272

   Para k = 2, las estimaciones de Cγkl son:
  f 2,1 = −0.029
  Cγ                    f 2,3 = −0.063
                        Cγ                   f 2,4 =
                                             Cγ          0.046      f 2,5 = −0.040
                                                                    Cγ                      f 2,9 = −0.235
                                                                                            Cγ
 f                     f                    f                      f                       f
 Cγ 2,10 =    0.510    Cγ 2,11 =    0.218   Cγ 2,12 = −0.163       Cγ 2,15 = −0.040        Cγ 2,16 =    0.282
 f                     f                    f                      f
 Cγ 2,17 = −0.495      Cγ 2,18 = −0.183     Cγ 2,19 =    0.209     Cγ 2,20 = −0.017


   Para k = 3, las estimaciones de Cγkl son:
  f                     f                    f                      f                       f
  Cγ 3,1 = −0.090       Cγ 3,2 =    0.308    Cγ 3,3 = −0.243        Cγ 3,4 = −0.158         Cγ 3,5 = −0.294
  f                     f                    f                      f                      f
  Cγ 3,6 =    0.505     Cγ 3,7 =    0.087    Cγ 3,8 =    0.193      Cγ 3,9 =     0.204     Cγ 3,11 = −0.192
 f                     f                    f                      f                       f
 Cγ 3,12 =    0.418    Cγ 3,13 =    0.129   Cγ 3,14 = −0.069       Cγ 3,15 = −0.122        Cγ 3,16 = −0.260
 f                     f                    f                      f
 Cγ 3,17 = −0.255      Cγ 3,18 = −0.263     Cγ 3,19 =    0.356     Cγ 3,20 = −0.254


   Para k = 4, las estimaciones de Cγkl son:
   f                   f                    f                      f                       f
   Cγ 4,1 = 0.035      Cγ 4,2 = −0.127      Cγ 4,4 = −0.294        Cγ 4,5 =     0.081      Cγ 4,6 = −0.090
   f                   f                    f                     f                       f
   Cγ 4,7 = 0.554      Cγ 4,8 = −0.071      Cγ 4,9 =     0.045    Cγ 4,12 = −0.047        Cγ 4,13 =    0.201
  f                    f                    f                     f                       f
  Cγ 4,14 = 0.123      Cγ 4,15 = −0.024     Cγ 4,17 = −0.010      Cγ 4,18 =     0.080     Cγ 4,19 = −0.477
  f
  Cγ 4,20 = 0.020


   Para k = 5, las estimaciones de Cγkl son:
   f 5,1 = −0.280
   Cγ                    f 5,2 = −0.250
                         Cγ                   f 5,3 = 0.100
                                              Cγ                  f 5,5 =
                                                                  Cγ            0.379     f 5,6 =
                                                                                          Cγ           0.087
   f                     f                   f                    f                       f
   Cγ 5,8 =    0.344     Cγ 5,9 =   0.287    Cγ 5,12 = 0.146      Cγ 5,13 = −0.117        Cγ 5,14 = −0.507
  f
  Cγ 5,19 = −0.189




                                                 Revista Colombiana de Estadística 30 (2007) 13–36

24                 Luis Alberto López, Diana Carolina Franco & Sandra Patricia Barreto

5.2.     Aplicación con un diseño jerárquico
   Se considera la información presentada en Harville & Fenech (1985), recopilada
en el Departamento de Ciencia Animal de la Universidad de California, la cual
contiene los pesos al nacer de 62 ovejos machos que provienen de 5 familias de
poblaciones distintas, dos familias de control y tres familias de selección. Cada
ovejo tiene una madre diferente y la edad de la progenitora fue clasificada en 3
categorías: de 1 a 2 años, de 2 a 3 años y mayor de 3 años.
    Teniendo en cuenta las variables citadas, el modelo apropiado tiene la siguiente
estructura:
                        yijkd = µ + δi + πj + Sk(j) + eijkd
con i = 1, 2, 3, j = 1, 3, 4, 5, k = 1, 2, . . . , nj , d = 1, . . . , nijk , nijk ≥ 0, donde yijkd
corresponde al peso del d-ésimo ovejo, proveniente del k-ésimo padre dentro de
la j-ésima familia, cuya madre pertenece a la i-ésima categoría de edad; µ es la
media general y eijkd es la componente aleatoria de error.
    En este caso, el factor correspondiente a la edad de la madre (δ1 , δ2 , δ3 ) y el
factor que hace alusión a la familia (π1 , π2 , π3 , π4 , π5 ) son de efectos fijos, mientras
que el factor que se refiere a los padres dentro de las familias (S1(1) , S2(1) , . . . , S8(5) )
es de efectos aleatorios independientemente distribuido N (0, σS2 ).
    Adicionalmente, los errores aleatorios e1111 , . . . , e35819 tienen distribución
N (0, σ 2 ), siendo independientes uno de otro y de los efectos de los padres den-
tro de las familias.
     En términos matriciales, el modelo anterior puede escribirse como:

                              y = 1µ + X0 δ + X1 π + Z1 S + e

En el cual las dimensiones de los vectores y las matrices son respectivamente:
y(62×1) , 1(62×1) , X0(62×3) , δ(3×1) , X1(62×5) , π(5×1) , Z1(62×23) , S(23×1) , e(62×1) .
     En la tabla 1 se presenta el arreglo con la información empleada en el análisis.
                                            0  los componentes de varianza
    Teniendo el modelo que se expuso previamente,
                                             S̃
estimados en este caso están dados por S̃ = 00 , donde:
                                             S̃
                                
               S̃1(1)      −3.391                                     
                                                     S̃1(4)        0.291
              S̃2(1)   1.980 
              S̃                                S̃2(4)   0.011 
              3(1)   −0.584                     S̃                
              S̃4(1)   1.562                    3(4)   −0.111 
                                                S̃1(5)   −1.243 
              S̃1(2)   −1.560                                     
                                                S̃2(5)   0.121 
              S̃          0.665                                   
      S̃ 0 =  2(2)  =                  S̃ 00 =  S̃3(5)  =  −0.905 
              S̃3(2)   0.819                    S̃       −0.133 
              S̃                                4(5)              
              4(2)   −0.020                     S̃5(5)   −1.267 
              S̃1(3)   0.373                                      
                                                S̃6(5)   1.063 
              S̃2(3)   −0.148                                     
                       0.824                     S̃7(5)        0.703
                 S̃3(3)
                                                                S̃8(5)            1.302
                 S̃4(3)          −0.372

                               P23
     Se puede verificar que       i=1 S̃k(j) = 0.


                                             Revista Colombiana de Estadística 30 (2007) 13–36

Construcción del mejor predictor lineal insesgado (BLUP) y restricciones asociadas 25

                    Tabla 1: Peso de nacimiento de ovejos machos

 Familia Padre   Edad    Peso Familia Padre   Edad    Peso Familia Padre   Edad    Peso
                 madre                        madre                        madre
   1        1      1      6.2    3      2       1     11.0    4        3     3       9.9
   1        2      1      1.3    3      2       2     10.1    5        1     1      11.7
   1        3      1      9.5    3      2       2     11.7    5        1     1      12.6
   1        3      1     10.1    3      2       3      8.5    5        2     1       9.0
   1        3      1     11.4    3      2       3      8.8    5        2     3      11.0
   1        3      2     11.8    3      2       3      9.9    5        3     3       9.0
   1        3      3     12.9    3      2       3     10.9    5        3     3      12.0
   1        3      3     13.1    3      2       3     11.0    5        4     3       9.9
   1        4      1     10.4    3      2       3     13.9    5        5     2      13.5
   1        4      2      8.5    3      3       1     11.6    5        6     2      10.9
   2        1      3     13.5    3      3       3     13.0    5        6     3       5.9
   2        2      2     10.1    3      4       2     12.0    5        7     2      10.0
   2        2      3     11.0    4      1       1      9.2    5        7     2      12.7
   2        2      3     14.0    4      1       1     10.6    5        7     3      13.2
   2        2      3     15.5    4      1       1     10.6    5        7     3      13.3
   2        3      1     12.0    4      1       3      7.7    5        8     1      10.7
   2        4      1     11.5    4      1       3     10.0    5        8     1      11.0
   2        4      3     10.8    4      1       3     11.2    5        8     1      12.5
   3        1      2      9.0    4      2       1     10.2    5        8     3       9.0
   3        1      3      9.5    4      2       1     10.9    5        8     3      10.2
   3        1      3     12.6    4      3       1     11.7



5.3.     Aplicación con datos de tipo longitudinal
    Finalmente, se ilustra de modo empírico que la restricción sobre los BLUP dada
por λt Ũ = 0 no se satisface en modelos mixtos en los cuales están involucrados
datos de tipo longitudinal. La demostración de este resultado empírico no es
trivial por la naturaleza de la matriz P . Se considera nuevamente la información
empleada en el modelo de efectos cruzados de la sección 5.1. Los datos se muestran
en las tablas 2, 3 y 4.
    El modelo de efectos aleatorios con estructura longitudinal con relación al tiem-
po se representa en forma matricial como: y = ZφA + Zq B + E, donde:

       y(t×n) es la matriz que tiene información referente a los pesos al nacimiento,
       al destete y final de la cría (t = 3), con n el número de unidades experimen-
       tales.
       Z(t×r) es la matriz de especificación del modelo intraunidades experimenta-
       les.
       φ(r×f ) es la matriz de coeficientes polinomiales desconocidos.
       A(f ×n) es la matriz de especificación del modelo entre unidades experimen-
       tales.
       Zq(t×q) es la matriz de especificación de efectos aleatorios.
       B(q×n) es la matriz que contiene los efectos aleatorios.

        E(t×n) es la matriz que contiene los errores asociados a cada unidad experi-
        mental.

      La matriz P en modelos con medidas repetidas está dada por:

                              P = V −1 [I − X(X t V −1 X)−1 X t V −1 ]

cuya forma general es:

para i 6= j; i, j = 1, . . . , n con Σi no estructurada y V = Diag(Σ1 , Σ2 , . . . , Σn ).
   En la obtención del BLUP se usó una matriz no estructurada, pero puede
trabajarse con otras estructuras, las cuales pueden estudiarse en Andreoni (1989)
y Jennrich & Schluchter (1986).
   Con los programas que se muestran en el apéndice, se obtuvieron los diferentes
BLUP, asociados a los efectos aleatorios y, como se muestra en los resultados, esto
no satisface las restricciones impuestas por Searle (1997) y visualizadas empírica-
mente por McLean et al. (1991). La razón está por demostrarse.
   Se exponen a continuación los arreglos con la información longitudinal y los
resultados obtenidos.
P20El factor padre es aleatorio; se puede comprobar que la suma de las estimaciones
 l=1 γ̂l no es cero.

     La interacción aleatoria padre*sexo proviene de una combinación
                                                              P20     de un efecto
                                                                    ˆ il no es igual
fijo y uno aleatorio; sin embargo, la suma de las estimaciones l=1 αγ
a cero, para i = 1, 2.
     Para i = 1, las estimaciones de αγil son:

             Tabla 2: Peso promedio al nacimiento de novillos por celda

                  Tabla 3: Peso promedio al destete de novillos por celda
                   Tabla 4: Peso promedio final de novillos por celda

      Para i = 2, las estimaciones de αγil son:
     La interacción aleatoria padre*época proviene de una combinación
                                                              P20 ˆ de un efecto
fijo y uno aleatorio; sin embargo, la suma de las estimaciones l=1 βγ jl no es igual
a cero, para j = 1, 2.

      Para j = 1, las estimaciones de βγjl son:
      Para j = 2, las estimaciones de βγjl son:
     La interacción aleatoria padre*partos proviene de una combinación
                                                              P20 ˆ de un efecto
fijo y uno aleatorio; sin embargo, la suma de las estimaciones l=1 Cγ kl no es igual
a cero, para k = 1, 2, 3, 4, 5.

      Para k = 1, las estimaciones de Cγkl son:
      Para k = 2, las estimaciones de Cγkl son:
      Para k = 3, las estimaciones de Cγkl son:
     Para k = 4, las estimaciones de Cγkl son:

     La interacción aleatoria padre*tiempo proviene de una combinación
                                                              P20 ˆ de un efecto
fijo y uno aleatorio; sin embargo, la suma de las estimaciones l=1 λγ hl no es igual
a cero, para h = 1, 2, 3.
     Para h = 1 (peso al nacimiento), las estimaciones de λγhl son:

     Para h = 2 (peso al destete), las estimaciones de λγhl son:

     Para h = 3 (peso final), las estimaciones de λγhl son:

6.       Conclusiones
    Cuando se lleva a cabo el análisis de varianza en modelos de efectos mixtos bajo
normalidad, ciertas sumas asociadas al BLUP que involucran los efectos aleatorios
o la interacción de estos con los efectos fijos, son iguales a cero (equivalente al
concepto Σ-restricción). Sin embargo, cuando existe algún tipo de correlación
serial, esta propiedad se pierde, haciendo que la propuesta de Searle (1997) solo
sea válida en modelos mixtos sin estructura de correlación.

Agradecimientos
    Este trabajo hace parte del Grupo de Investigación de Estadística Aplicada,
dentro del marco del proyecto Metodología estadística con modelos lineales gene-
ralizados.
    Agradecemos las sugerencias y comentarios hechos por los evaluadores de este
artículo.
Referencias
Andreoni S.Modelos de efeitos aleatórios para análise de dados longitudinais nâo balanceados em relaçâo ao tempo.(1989).IME-USP.
Barroso L P,Bussab W D.Best Linear Unbiased Predictors in the Mixed Models with Incomplete Data.(1998).Commun Statist.
Gaona B L.Aplicación de medidas repetidas para la predicción de efectos aleatorios en evaluación genética animal.(2000).Universidad Nacional de Colombia.
Hartley H O,Rao C R.Maximun Likelihood Estimation for the Mixed Analysis of Variance Models.(1967).Biometriks.
Harville D A,Fenech A P.Confidence Intervals for Variance Ratio or for Heredability in an Unbalanced Mixed Linear Models.(1985).Biometrics.
Henderson C R.Statistical Methods in Animal Breeding.(1982).Guelph University.Canada.
Henderson C R.Estimation of Linear Models in Animal Breeding.(1984).Guelph University.Canada.
Jennrich R,Schluchter M.Unbalanced Measures Models with Structured Covariance Matrix.(1986).Biometrics.
McCulloch C E,Searle S R.Generalized Linear and Mixed Models.(2001).John Wiley & Sons.New York.
McLean R A,Sander W L,Stroup W W.A Unified Approach to Mixed Linear Models.(1991).The American Statistician.
Searle S R.Linear Models for Unbalanced Data.(1987).John Wiley & Sons.New York.
Searle S R.Built in Restrictions on Best Linear Unbiased Predictors (BLUP) of Random Effects in Mixed Models.(1997).The American Statistician.