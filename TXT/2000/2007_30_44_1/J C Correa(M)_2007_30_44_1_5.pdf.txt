Estimación por intervalo del parámetro de la distribución de Poisson con una sola observación
Universidad Nacional de Colombia
Resumen
La estimación del parámetro de la distribución de Poisson, digamos es un problema importante en el trabajo estadístico aplicado. En muchas ocasiones solo disponemos de un único dato para construir un intervalo de confianza. Se muestra cuándo se pueden construir intervalos de confianza basados en el teorema central del límite, el método exacto y la razón de verosimilitud cuando se tiene una sola observación. Se ilustra este caso construyendo un intervalo para la tasa de suicidios en Colombia.
Palabras clave: estimación, intervalo de confianza, tamaño de muestra pequeño, teorema central del límite, razón de verosimilitud.
Introducción
La distribución de Poisson juega un papel de fundamental importancia en el trabajo aplicado para modelar problemas de conteo en muchas áreas.
Asumamos que X1 es una observación de una distribución de Poisson con función de masa dada por:
                                             λx exp (−λ)
                             PX (X = x) =
                                                  x!
para λ > 0 y x = 0, 1, 2, . . ., la media de la distribución es λ y su varianza σ 2 = λ.
   Sea Y1 , Y2 , . . . , YN una muestra aleatoria de tamaño n, el estimador de máxima
verosimilitud para λ es λ    b = Y = 1/N PN Yi , donde PN Yi es suficiente minimal
                                            i=1             i=1
para λ.
    Para poder usar el teorema del límite central (TLC) debemos tener una muestra
aleatoria de tamaño N , grande, de una población con varianza σ 2 < ∞ y media
µY . Entonces
                               Y − µY
                                   √     −→ N (0, 1)
                                σ/ N
cuando N → ∞.
   En el caso de X1 , aparentemente solo tenemos una única observación, pero si
representamos X1 como
                                        N
                                        X
                                 X1 =      Yi
                                            i=1

donde las Yi ’s son i.i.d. (independientes e idénticamente distribuidas), y si N
es grande, entonces podríamos aplicar el TLC. Esta descomposición es posible
y justificada por el teorema de Skorohod (Billingsley 1986). En el caso Poisson
Y1 ∼ P oisson(λ∗ = λ/N ).
   El intervalo de confianza para λ∗ basado en el TLC es:
                                   s               s    
                                      b∗
                                      λ               b∗
                                                      λ
                        λb∗ − zα/2       b∗ + zα/2
                                         ,λ              
                                      N               N

donde λ b∗ = Y y zα/2 es el percentil α/2 superior de la normal estándar. Ya que
el interés no es λ∗ sino λ, lo único que debemos hacer es multiplicar por N ambos
límites del intervalo anterior. Con esto llegamos a que el intervalo de confianza
basado en el TLC para λ con una sola observación es
                                      p           p 
                              λ          b λ
                               b − zα/2 λ,          b
                                           b + zα/2 λ

donde λb = X1 . Note que el resultado final no depende de N y depende exclusiva-
mente del valor del estadístico suficiente. Esto es claro en el caso donde alguien
decide observar un conteo por unidad de tiempo en minutos en lugar de horas: una
observación de una hora equivale a 60 observaciones de un minuto. No se tiene
más información al hacerlo por minutos.
   Uno de los problemas que se enfrenta con aproximaciones de este tipo es saber
cuándo N es lo suficientemente grande. Para ello recurrimos al teorema de Berry-
Esséen (Serfling 1980, p. 33; Lehmann 1999, p. 78): Si Y1 , . . . , YN son variables

                                        Revista Colombiana de Estadística 30 (2007) 69–75

Estimación del parámetro de la distribución de Poisson con una sola observación       71

aleatorias i.i.d. con media µ y varianza σ 2 > 0 y tercer momento central finito, y
si GN (t) = P (SN ≤ t), donde

                                           Y −µ
                                    SN =     √
                                           σ/ N
entonces
                                                          3
                                          C |Y1 − µ|
                   sup |GN (t) − Φ(t)| ≤ √           ,             ∀N
                    t                      N    σ3
Φ(z) es la función de distribución acumulada de una variable aleatoria normal es-
tándar. La determinación de la constante óptima C ha sido motivo de una intensa
investigación; se sabe que existe la constante pero no se conoce, y se ha logrado
reducir hasta C = 0.7975 (Lehmann 1999). Serfling (1980) en la presentación de
este resultado tiene C = 33/4.
   En el caso de la distribución Poisson√tenemos que µ = σ 2 = E(Y1 − λ)3 = λ.
Por lo tanto la cota se reduce a 0.7975/ N λ.

Tabla 1: Tamaños muestrales mínimos para estimar el parámetro de la Poisson usando
         el teorema de Berry-Essén.

    La tabla 1 puede leerse así: si permitimos un error máximo en la aproximación
a la normal de 0.1 (diferencia entre la distribución acumulada real y la normal
estándar acumulada), dado un λ específico, por ejemplo 1.0, la muestra mínima
en este caso es 64. Si la diferencia máxima permitida la rebajamos a 0.05, el
tamaño muestral mínimo se incrementa a 255. De la tabla 1 se observa que para
valores muy grandes de λ solo es necesaria una observación, lo cual nos garantiza

que la aproximación usando la distribución normal para la media muestral es lo
suficientemente buena.



2.     Otros intervalos

2.1.    Método exacto
   Un intervalo de confianza exacto para λ, en el caso de una sola observación, se
obtiene resolviendo las siguientes ecuaciones para λL y λU :

                                          X1
                                          X       i
                                             (λL )                   α
                           exp (−λL )                       =1−
                                          i=0
                                                  i!                 2

y
                                           X1
                                           X       i
                                              (λU )              α
                             exp (−λU )                      =
                                            i=0
                                                       i!        2

Observe que la solución existe sin importar que X1 sea discreta, ya que λL y λU
toman valores en (0, ∞).


2.2.    Intervalos basados en la razón de verosimilitud relativa
    Kalbfleish (1985) presenta la metodología para construir intervalos de verosimi-
litud. Si L(µ) es una función de verosimilitud, se define la función de verosimilitud
relativa como
                                            L(λ)
                                   R(λ) =       
                                            L λ
                                              b

El conjunto de valores de λ para los cuales R(λ) ≥ p es llamado el intervalo de
p100% de verosimilitud para λ. Los intervalos del 14.7% y del 3.6% de verosi-
militud corresponden a intervalos de confianza aproximadamente de niveles del
95% y del 99%, respectivamente.
    Lo que se debe hacer entonces es hallar las raíces que nos dan los límites del
intervalo. Para el caso del parámetro de la Poisson λ, tenemos que un intervalo
de confianza del 95% se halla encontrando el par de raíces tal que
                                         X1            
                        L(λ)         λ                    b ≥ 0.147
               R(λ) =       =                  exp − λ − λ
                        L λ
                          b          X1

      b = X1 . Esto se resuelve numéricamente. Las raíces existen dada la log-
donde λ
concavidad de la función de verosimilitud, asumiendo que el estadístico suficiente
sea mayor que cero.

2.3.    Método basado en la máxima verosimilitud
    Se sabe que si θb es el estimador máximo verosímil para θ (el cual puede
ser un vector),
               bajo ciertas condiciones suaves (Serfling 1980), entonces θb ∼
N θ, I (θ) , con I(θ) siendo la matriz de información de Fisher. Entonces, en el
       −1

caso Poisson
                                   √             √ !
                                    X              X
                          X − zα/2 √ , X + zα/2 √
                                     n             n

en el caso de una observación se tiene
                                  p             p 
                         X1 − zα/2 X1 , X1 + zα/2 X1

                                                                       b = X1 .
Este método produce el mismo resultado que el basado en el TLC, ya que λ



3.     Resultados de simulación
    Se realizó una simulación para comparar tanto la longitud de los intervalos
como el nivel de confianza real (el porcentaje de veces que el intervalo cubre el
parámetro) alcanzado por los tres métodos considerados cuando la muestra es de
tamaño uno. El nivel de confianza nominal o teórico fue del 95%. La tabla 2
presenta algunos estadísticos de la distribución de la amplitud de los intervalos
como son el percentil 5%, la mediana, la amplitud media y el percentil 95%.
Esto nos da una idea de la dispersión de las amplitudes. La última columna
hace referencia al nivel real de confianza logrado. Para diferentes valores de λ se
generaron 1000 muestras de tamaño uno. A cada muestra se le aplicó cada uno de
los métodos para construir los intervalos.
    Los tres métodos producen intervalos con niveles reales cercanos al nivel no-
minal; sin embargo, el método exacto tiende a producir intervalos con amplitudes
mayores que los otros dos métodos, los cuales producen resultados bastante simi-
lares.



4.     Ilustración
    El número de suicidios en Colombia fue 1786 casos en el año 2005 (Sarmiento
2007). Asumiendo que el número de suicidios en un año puede distribuirse Pois-
son, y dado que solo tenemos un dato, aplicamos el método anterior el cual nos
lleva a concluir que el número esperado de suicidios está en el intervalo (1703.16,
1868.83) a un nivel de confianza del 95%. Este intervalo se construyó utilizando
el método basado en la máxima verosimilitud. Si la población a mitad de año era
de 45795000 habitantes, entonces la tasa de suicidios por cada 100000 habitantes
puede estimarse entre 3.7191 y 4.0808 con una confianza del 95%.

5.    Conclusiones
   Bajo ciertas condiciones es posible construir intervalos de confianza a partir de
muestras de tamaño uno, lo cual es ilustrativo en los cursos básicos de estadística
donde una inquietud general por parte de los estudiantes es determinar un n mí-
nimo. El resultado es además útil para epidemiólogos y demógrafos, para quienes


Tabla 2: Longitud y nivel de confianza real de los tres tipos de intervalos: TLC, exacto
         y razón de verosimilitud al 95% de confianza nominal.

no es inusual obtener al final de un período una única cifra sobre las ocurrencias
de eventos de interés.
    Una diferencia que cabe anotar entre el resultado del teorema de Berry-Essen y
los resultados obtenidos en la simulación es que el teorema de Berry-Essen presenta
una cota uniforme para la diferencia entre la distribución de la media muestral y
la distribución normal, mientras que en el caso tradicional la construcción del
intervalo es más importante que la aproximación de las distribuciones en las colas.

Agradecimientos
Al profesor Francisco Díaz, quien leyó cuidadosamente este documento y sugirió correcciones que resultaron en una mejora sustancial.

Referencias
Billingsley, P. (1986), Probability and Measure, 2nd edn, John Wiley & Sons, New York.
Kalbfleish, J. G. (1985), Probability and Statistical Inference, Vol. 2, 2nd edn, Springer-Verlag, New York.
Lehmann, E. L. (1999), Elements of Large-Sample Theory, Springer-Verlag, New York.
Sarmiento, L. (2007), Jóvenes: ¿Por qué se suicidan?, Web, Red de Prensa No Alineados http://www.voltairenet.org/image/article139303.html#article139303
Serfling, R. J. (1980), Approximation Theorems of Mathematical Statistics, John Wiley, New York.