CRITERIOS SOBRE EL USO DE LA DISTRIBUCIÓN NORMAL PARA APROXIMAR LA DISTRIBUCIÓN BINOMIAL
Universidad Nacional de Colombia
Resumen. Las dos reglas empı́ricas más conocidas para aceptar la aproximación normal de la distribución binomial carecen de regularidad en el control del margen de error cometido al utilizar la aproximación normal. Se propone un criterio y algunas fórmulas para controlarlo cerca de algunos valores escogidos para el error máximo.
Abstract. The two most popular “rules of thumb” for the approximation of the binomial distribution by the normal distribution lack of regularity in the control of the maximal error. A criterion and some formulas for selected values of maximal errors are proposed to solve this lack of regularity.
Palabras Claves Distribución binomial, Aproximación normal,
Introducción
Tradicionalmente se ha considerado de manera empı́rica que los parámetros n y p deben satisfacer np ≥ 5 y n(1 − p) ≥ 5 como condición para que la aproximación normal pueda ser utilizada en el marco de aplicación del teorema del lı́mite central en el caso de la distribución binomial. Una segunda condición conocida establece más estrictamente que np(1 − p) ≥ 9, Siegel y Castellan (1995).
Schader y Schmid (1989), hacen notar que con las condiciones anteriores, la máxima diferencia en valor absoluto entre la función de distribución binomial exacta y la aproximación normal, presenta variaciones cercanamente lineales en función de p. De esto se deduce que la aplicación de cualquiera de ellas no permite controlar el error de aproximación de manera uniforme. En efecto, si p = 0.5, para cumplir la condición np(1−p) ≥ 9, n debe ser mayor o igual a 36. En este caso el valor absoluto del error es inferior a 0.00075384; mientras que si p = 0.01, según la misma condición n ≥ 909, y el error llega a ser 0.02113783. Con errores un poco más grandes, se observa un comportamiento similar al utilizar la primera condición.
El objetivo de este artículo es presentar propuestas para los valores del parámetro n en función de p de tal manera que la magnitud del error de aproximación sea controlada cerca de valores δ prefijados. El trabajo fue realizado durante el desarrollo del curso de estadı́stica no paramétrica en el segundo semestre de 1998, con el grupo de estudiantes cuya participación motivó un curso diferente y creativo.
Procedimiento
Para algunos valores prefijados (δ = 0.01, 0.005, 0.002) y para p variando desde 0.01 hasta 0.5 con incrementos de 0.01, se calculó el mı́nimo valor del parámetro n de tal manera que la máxima diferencia en valor absoluto entre la función de distribución binomial exacta con parámetros n y p y la función de distribución normal aproximada, fuera menor que δ.
Para cada uno de los márgenes de error trabajados se buscó también identificar un modelo que permitiera estimar para cada p, el valor de n necesario para mantener el máximo error de aproximación dentro del margen establecido.
donde Fnp (k) representa la función de distribución binomial con parámetros n y p, calculada en el punto k y Φ(x) representa la función de distribución normal estándar calculada en el punto x.
La tabla 1 muestra los principales resultados obtenidos. En ella aparecen los tamaños de muestra para una distribución binomial que se requieren si se necesita que la aproximación normal (con corrección de Yates) arroje máximo un error inferior al indicado. También se presentan los valores de np(1 − p). Ellos permiten examinar los valores de p que satisfacen la segunda condición mencionada antes.
Se puede observar que si el margen de error de aproximación debe ser 0.01, el criterio np(1 − p) > 9 exige un valor de n demasiado grande si p ≥ 0.27 y uno insuficiente si p < 0.27 y esta insuficiencia crece cuando p se acerca a 0.01. Si p > 0.5 la situación es simétrica y por lo tanto la regla np(1 − p) > 9 mantiene el error por debajo de 0.01 solo si 0.27 ≤ p ≤ 0.73. Cuando el margen de error es 0.005 puede verse que la misma regla solo funciona si 0.38 ≤ p ≤ 0.62. Y para un error igual a 0.002 el intervalo de utilidad de la regla en cuestión es solo para 0.45 < p < 0.55.
Si no se aplica la corrección de Yates, los tamaños requeridos para controlar el error máximo son todavı́a mayores.
La solución al problema de controlar el margen de error que aparece en la Tabla 1, se facilita en la práctica con los modelos descritos a continuación.
En la tabla 2 se muestran los coeficientes de modelos de regresión cuadrática en donde se tomó np(1 − p) como variable dependiente y p como variable independiente. Las ecuaciones obtenidas permiten estimar el valor de n mínimo para controlar el error de aproximación con precisión suficiente. El coeficiente de determinación encontrado fue superior a 0.999 en los tres casos.
Tabla 2. Coeficientes de modelos de regresión cuadrática para np(1 − p) en función de p para cada margen de error.
A partir de los modelos encontrados, se puede calcular n con las siguientes
ecuaciones:
Es posible encontrar algunas simplificaciones a los modelos encontrados sin sacrificar grandemente las estimaciones de n. Por ejemplo, para la primera ecuación (error = 0.01), se encontró que aproxima bastante bien el valor de n, siempre que los resultados no den menores que 4.
Conclusiones
Si el propósito es controlar la máxima diferencia entre la función de distribución binomial exacta y la aproximación normal con corrección de Yates, las reglas recomendadas tradicionalmente para el valor mínimo del parámetro n presentan inexactidutes importantes, generadas por la falta de regularidad en el control del error máximo. Para los valores de p cercanos a 0.5, las reglas, particularmente np(1 − p) > 9, sobreestiman el valor de n necesario. Pero si p toma valores extremos (cerca de la unidad o de cero), el valor de n calculado a partir de ellas es insuficiente. El caso es más crı́tico con la primera regla enunciada al comienzo, siendo precisamente la más conocida y aplicada. Las propuestas presentadas ofrecen un control uniforme del margen de error de aproximación en el sentido de poder afirmar que si se calcula n con las fórmulas encontradas, el error será cercano al indicado para cada una.
Referencias
Schader, Martin, Schmid, Friedrich, Two rules of thumb for the approximation of the binomial distribution by the normal distribution. The American Statistician 43 (1989), (23–24), no. 1.
Siegel, Sidney, Castellan, J., Estadı́stica no paramétrica aplicada a las ciencias de la conducta. Trillas, México (1995).