UNA GENERALIZACIÓN DE LA ESTADÍSTICA DFBETA
Universidad Nacional de Colombia
Resumen. En este artı́culo se presenta una generalización de la estadı́stica DFBeta con la cual se logra cuantificar el impacto que ejercen un grupo de obsevaciones seleccionadas, en la estimación vı́a mı́nimos cuadrados del modelo de regresión lineal múltiple.
Palabras claves: Modelos lineales, mı́nimos cuadrados, estadı́stica DFBeta.
Introducción
En la estimación mı́nimos cuadrados par detectar especı́ficamente la influencia que una observación seleccionada ejerce en la estimación de los parámetros del modelo de regresión lineal Y = Xβ + e. La estadı́stica DFBeta(i) presentada en Belsley y colaboradores (1980) es la más reconocida al respecto. Para la i-ésima observación el valor de la estadı́stica se obtiene a partir de la expresión:
con ci la i–ésima fila de la matriz C = (X' X)−1 X' , ei = Yi − Ŷi y hii el i–ésimo elemento en la diagonal de la matriz H = (X(X' X)−1 X') siendo este valor DFBeta(i) la diferencia entre los parámetros estimados al eliminar la i–ésima observación.
Por su importancia se logró la generalización de esta estadı́stica en modelos de regresión lineal simple que permite detectar la influencia que un grupo de observaciones ejerce en la estimación de los parámetros, Rincón y López (1997); e interesa en este artı́culo presentar una generalización que notaremos DF Beta(Y1) y que permite medir los cambios que ejercen las observaciones contenidas en el bloque Y1 sobre los parámetros asociados a un modelo de regresión lineal múltiple.
Derivación de la estadística DFBeta(Y1)
Para el modelo de regresión lineal múltiple mediante la estimación vía mínimos cuadrados se obtiene el estimador β de los parámetros β, los valores estimados de Y, los residuales e la suma de cuadrados de los residuales SCE de acuerdo con las siguientes expresiones:
Se considera el modelo expresado en, particionado como
Para medir la influencia que ejerce el bloque Y1 de dimendión k × 1, k < n, en la estimación de los parámetros vı́a mínimos cuadrados; se modifica cada una de las componentes del bloque Y1 con constantes arbitrarias γi , i = 1, 2, ..., k y se plantea el modelo siendo Y* ~ Y + γ , donde, es decir el modelo particionado se puede escribir ahora en la forma
interesa establecer las expresiones de los “nuevos” estimadores, en función de los estimadores obtenidos para el modelo. El estimador del vector, obtenido por el método de mínimos cuadrados, es dado por la siguiente expresión β* = (X' X)−1 X' Y donde se concluye que 
De la misma forma, el “nuevo” vector de predicciones se obtiene de acuerdo
con
Bajo la partición dada en esta ecuación es equivalente a
Con la misma metodologí́a se obtiene el vector de errores estimado para el
modelo según
Bajo la misma partición la ecuación se expresa como
De tal manera que el vector γ1 se hace e1 = 0 está dado por γ1 = −(I − H11 )−1 e1 término que al reemplazarse en la ecuación proporciona la expresión para calcular los valores de la estadística DFBeta(Y1) según
Nótese que DFBeta(Y1) es un vector de dimensión r × 1 el cual mide el efecto que tienen los k registros del bloque Y1 , en la estimación vía mínimos cuadrados en cada una de las componentes del vector de parámetros β, siendo β el vector de parámetros estimados en presencia de todas las observaciones y el vector de parámetros estimados despues de eliminar las observaciones contenidas en el bloque Y1.
El anterior resultado se puede resumir en el siguiente teorema.
Teorema 1. En un modelo de regresión lineal particionado como: con Y1 de dimensión k, siendo H11 = X1 (X' X)−1 X1'.
Distribución de probabilidad de la estadística DFBeta(Y1)
Para el método particionado y bajo el supuesto de normalidad de los residuales se satisface que e1 ∼ Normal (0, σ2 (I − H11 )) y se muestra, Rincón (1999) que γ1 definido satisface γ1 ∼ Normal (0, σ2 (I − H11 )−1 ) es decir que cada una de las componentes γi , i = 1, ..., k de γ1 se distribuye según
γ1 ∼ Normal (0, σ2 Hi )
donde Hi es el i-ésimo elemento de la diagonal de la matriz (I − H1 )−1 .
Conocida la distribución de γ1 obtenida y reescribiendo la estadística DFBeta(Y1) como se obtiene que
En particular denotaremos por Mj el j-ésimo elemento de la diagonal de C(I − H11 )−1 C' para cada j = 1, ..., r la dimensión de la DFBeta(Y1) resulta que DF Betaj (Y1) ∼ Normal (0, σ2 Mj )
Y finalmente se obtiene de la aplicación del estimador insesgado de σ2
De donde resulta que los valores de las estadıísticas tj definidos son iguales para cada j, cuando Y1 consta de un única observación y difieren Y1 tiene más de una observación, es decir que el bloque Y1 cuando tiene más de una observación puede ser influyente sobre alguno o algunos de los r parámetros y no influyente para los demás.
El anterior resultado se puede resumir en el siguiente teorema.
Teorema 2. Para el modelo de regresión lineal múltiple se tiene que DFBeta(Y1) ∼ Normal (0, σ2 C(I − H11 )−1 C' ) donde H11 = X1 (X' X)−1 X1' y C = (X' X)−1 X1'.
Ejemplo
Para los datos citados en Cook y Weisberg (1982) tabla 1, se presentan los siguientes resultados, procesados mediante el paquete SAS
La estimación del modelo de regresión lineal, con las 21 observaciones.
La estadística DF Beta(Y1), para el bloque Y1 compuesto por las primeras 4 observaciones.
La estimación del modelo de regresión lineal, después de eliminar el bloque Y1.
De los resultados anteriores se verifica que los valores del vector DFBeta(Y1) =(−2.548381, 0.032907, 0.129378, −0.017444) corresponden a la expresión.
Referencias
Belsley, D. et al (1980) Regression diagnostics: Identifying Influential Data and Sources of Collinearity, New York: Jhon Wiley.
Cook, R. D. and Weisberg, S. (1982), Residuals and Influence in Regression, New York: Chapman & Hall.
Rincón, Tatiana (1999), U na propuesta para caracterizar observaciones influyentes en modelos de regresión lineal múltiple Trabajo de grado (Estadística); Universidad Nacional de Colombia. Facultad de Ciencias, Departamento de Matemáticas y Estadı́stica. Sede: Bogotá.
Rincón Luis F., López Luis A. (1997) U na Generalización de la Estadística DFBeta en modelos de regresión lineal simple, En: Revista Colombiana de Estadística, No. 35.
Searle, S. R., (1971), Linear Models, New York: John Wiley & Sons.
Tukey, J., (1971), E xploratory Data Analysis, Reading, M.A: Addison Wesley.