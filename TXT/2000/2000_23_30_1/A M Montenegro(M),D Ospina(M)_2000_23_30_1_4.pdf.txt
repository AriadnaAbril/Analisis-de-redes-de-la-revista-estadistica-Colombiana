ESTIMACIÓN MÁXIMO VEROSÍMIL DE LOS TAMAÑOS DE DOMINIOS EN PROBLEMAS DE MARCOS MÚLTIPLES CUANDO SE DESCONOCE EL TAMAÑO DE LOS MARCOS
Universidad Nacional de Colombia
Resumen. 
Se estudia el problema de obtener estimaciones máximo verosı́miles del tamaño de los dominios para el caso de dos marcos traslapados cuando se desconoce el tamaño de los marcos. Se utiliza la técnica de muestreo por áreas y se obtienen estimadores insesgados de varianza mı́nima para el tamaño de cada uno de los marcos y del dominio traslapado. Se muestran propiedades de consistencia y de normalidad asintótica en el caso en el que las áreas son de igual medida.
Palabras claves: Marcos múltiples, marcos traslapados, máxima verosimilitud, estimación de parámetros.
Introducción
El muestreo en marcos múltiples puede ser definido como un conjunto de varios muestreos (simples) cuyas muestras se combinan para obtener estimaciones de parámetros en la unión de los marcos (Hardley, 1974). Los marcos no necesariamente son de la misma naturaleza. Por ejemplo en aplicaciones de tipo agrı́cola que forman la mayor parte de la aplicaciones reportadas, se usan dos tipos de marcos definidos como marco área y marco lista. En tales aplicaciones la unidad de muestreo de un marco lista es un nombre que puede corresponder a un individuo, conjunto de individuos o negocios (Hardley, 1974 y Hill 1977). La unidad reportada para este caso consiste en todas las parcelas de tierra trabajadas bajo el nombre seleccionado. Por otro lado, la unidad de muestreo del marco área es un segmento de tierra (pequeño bloque de tierra) (Bosecker, 1976). Junto con la delimitación del segmento cada unidad de tierra trabajada constituye una unidad reportada, Hill (1977). Los nombres para cada unidad de tierra trabajada son obtenidos a partir de los datos de la encuesta por cada unidad reportada. Por razones de optimización lo que usualmente se hace es tomar una muestra en el marco área que por lo general tiene una cobertura total de la población y una en el marco lista, por lo general incompleto. Se supone que es posible identificar cuándo una unidad reportada en uno de los marcos pertenece también al otro.
En general se supone que todos los marcos son fracciones traslapadas de la misma población de unidades, de tal manera que las unidades pueden ser clasificados en dominios. Por ejemplo si se tienen dos marcos digamos A y B, estos generan 3 dominios definidos de acuerdo a la notación de Hardley (1974) como Dominio a que contiene solo elementos de A, Dominio b que contiene solo elementos de B, Dominio ab que contiene elementos de A y B.
El problema de estimación en situaciones de marcos múltiples ha sido estudiado por varios autores. Hardley (1962, 1974) desarrolló los fundamentos de la teorı́a. Lund (Lund, 1968) obtuvo estimaciones del total de una caracterı́stica en el caso de dos marcos cuando se conoce el tamaño de los dominios; cuando se desconocen tales tamaños utilizó estimadores insesgados de tales tamaños a partir de la muestra y utilizando factores de peso para los dominios llega de nuevo a estimaciones del total de una caracterı́stica, mejorando en términos de eficiencia y menor complejidad las estimaciones de Hardley. Fuller y Burmeister (1972) por su parte hicieron un completo desarrollo para el caso de dos marcos, presentando estimaciones del tamaño del dominio traslapado más eficientes que las de Hardley.
El problema de estimar el tamaño de los dominios creados por la intersección de múltiples marcos muestrales ha sido estudiado por varios autores usando tres técnicas distintas. King (1960), y Bryant y King (1960) presentaron su aproximación utilizando la técnica ji–cuadrado mínimo modificado, Williams (1957) basó las estimaciones en el método de máxima verosimilitud y Cochran (1965) hizo el desarrollo a partir de la técnica de marcos múltiples. Cochran y Cooke (1967) obtuvieron la varianza de las estimaciones obtenidas de ji–cuadrado y marcos múltiples para muestras grandes. Fuller y Burmeister (1972) obtuvieron estimadores y varianzas cuando se tienen en cuenta las unidades duplicadas y desarrollaron también una forma general de la varianza del estimador máximo verosı́mil (EMV) cuando se consideran dos marcos y se usa el modelo hipergeométrico. Bryant y King (1960) analizaron el caso de tres marcos pero no compararon varianzas. Ospina (1985), Ospina (1989) desarrolló aproximaciones máximo verosı́miles en el caso de m marcos para el tamaño de los dominios haciendo una aproximación con la distribución multinomial para la función de verosimilitud de las observaciones y presentando por primera vez expresiones generales (en este caso asintóticas) para la matriz de covarianzas de los estimadores. Para el cálculo de los estimadores máximo verosı́miles Ospina utilizó la técnica de programación goemétrica subrogada basándose en un algoritmo escrito por Cooke (1983).
En la estimación máximo verosímil del tamaño de los dominios en problemas de marcos múltiples se supone que el tamaño de cada marco se conoce. En este trabajo se estudia el caso mas realista en el que se desconoce el tamaño de los marcos y se llega a estimaciones máximo verosímiles para el tamaño de los marcos y de los dominios simultáneamente. cuando se tienen dos marcos y por tanto tres posibles dominios. Se hace uso de la teoría de EMV para el caso de variables aleatorias independientes pero no idénticamente distribuidas para establecer propiedades de consistencia, normalidad y eficiencia asintótica. Como justificación para el desarrollo de este trabajo consideremos dos ejemplos posibles de utilización. Primero, supóngase para el caso de tipo agrícola que se dispone de un marco área pero se desconocen las unidades muestrales total o parcialmente y que se dispone de un marco lista probablemente completo pero muy grande (un directorio) y no se conoce el tamaño pero se tiene una información adicional que puede llevar a una estimación del tamaño. Como segundo ejemplo posible de utilización supongamos que se tienen los directorios de dos empresas telefónicas, que no se dispone del total de abonados en cada caso y se requiere estimar el número de abonados en las dos empresas simultáneamente. En general este trabajo se puede aplicar a todos los problemas de dos marcos traslapados estudiados con anterioridad, para los cuales no sea conocido de antemano su tamaño.
Preliminares
La tripla (omega, F, mu) denotará un espacio de medida en donde omega es un conjunto no vacío, F una sigma álgebra de subconjuntos de omega y mu una medida. Si omega es finito o infinito numerable F será sigma álgebra de todos los subconjuntos de omega y mu la medida de conteo. Si omega = Rq , F será sigma álgebra de los conjuntos de Borel y mu la medida de Lebesgue. Si C es una clase de subconjuntos de omega y denotaremos por a la clase. En este caso FA será la mínima sigma álgebra que contiene a la clase. En este trabajo no se hará referencia a espacios de medida más generales.
Si f es una función Borel medible definida sobre omega, entonces representa la integral de f sobre S con respecto a la medida mu. Si mu es la medida de conteo entonces la integral se reduce a la suma. Sea X una variable aleatoria que toma valores en una región S con función de probabilidad, entonces mu es la medida de conteo y.
Nota 1. La notación es equivalente a. Si se omite S en la integral, es decir, si escribe se asume que la integral se toma sobre todos los valores para los cuales está definida X.
Si X tiene función de densidad o de probabilidad , la matriz de información del parámetro theta es la matriz de tamaño pxp dada por
Nota 2. Si se tiene que la derivada parcial con respecto a tehta i del lado izquierdo de
puede ser obtenida bajo el signo integral, entonces
En este caso I(theta) es semidefinida positiva. Adicionalmente si, existen para cada i, j y pueden ser obtenidas diferenciado dos veces bajo el signo
integral en (3), entonces
Propiedades asintóticas de EMV para el caso de variables independientes no idénticamente distribuidas
En esta sección se introduce la notación utilizada y se presenta la teorı́a para estimadores máximo verosı́miles en el caso de variables aleatorias independientes no idénticamente distribuidas que se usa en la sección . Bradley y Gart (1962) y Hodley (1977) estudiaron el problema, partiendo de condiciones diferentes. En este trabajo es conveniente utilizar las condiciones de Bradley y Gart. Ellos examinaron el método de máxima verosimiltud en situaciones en donde las observaciones no provienen de la misma población, pero que están relacionadas en el sentido de que puede asumirse que tienen algunos parámetros en común, tales poblaciones fueron llamadas poblaciones asociadas.
Notación e hipótesis
Sean funciones de densidad o probabilidad (discretas o continuas) en donde X i es un vector aleatorio con valores sobre una región S i independientemente del vector de parámetros desconocidos theta. No es necesario que cada f i dependa de todos los theta 1 , ..., theta p. Sean x i1 , ..., x ini ni vectores de observaciones de los vectores. La función de verosimilitud para este caso está dada por y las ecuaciones normales para la maximización de ln phi son
Se partirá de las siguientes hipótesis:
M.1. Theta es un intervalo abierto p dimensional, finito, infinito o semi infinito
M.2. Si x i1 , ..., x ini son variables aleatorias independientes e idénticamente distribuidas con función de densidad o de probabilidad fi (Xi , theta) respecto a una medida sigma finita mu y parámetro theta, se supondrá que las distribuciones Pi (theta) de las x ij tienen soporte común. Es decir, el conjunto es independiente de theta para cada i = 1,..., n. Además se supondrá que las distribuciones Pi (theta) de las observaciones son diferentes (de otra manera theta no puede ser estimado consistentemente).
M.3. Para casi todo x i y para todo theta, las derivadas existen para r, s, t = 1, ..., p; i = 1, ..., n.
M.4. Para las fi que son densidades existen funciones Fir(xi), Firs(xi) y Hirst(xi) tales que en casi toda parte de Si con respecto a la medida de Lebesgue y todo theta. Además Fir (xi), Firs (xi) son integrables sobre Si y (r, s, t = 1, ..., p; i = 1, ..., n) con Mi constantes positivas. Para las fi, que son funciones de probabilidad, se tiene la medida de conteo y estas condiciones se traducen en que convergen uniformemente para todo theta, y
Estas hipótesis permiten intercambiar el orden de diferenciación e integración o suma. Si I (i) (theta) denota la matriz de información correspondiente a fi (xi , theta), se tiene el siguiente resultado Bradley y Gart (1962), Lehmann (1983), Apostol (1974).
Se considerará la siguiente hipótesis adicional.
M.5. Sea, en donde, entonces la matriz definida por es definida positiva con determinante finito para todo theta.
Nota 4. Nótese que las ecuaciones implican que I (i) (theta) es semidefinida positiva. Por otro lado se tiene que si cada una de las matrices de información I (i) (theta) es definida positiva entonces I (theta) también lo es. Además:
Consistencia
Los siguientes cuatro teoremas fueron demostrados por Bradley y Gart (1962) y son una generalización directa del caso variables aleatorias idénticamente distribuidas.
Teorema 5. Dada la función de verosimilitud y las hipótesis M1 a M5, supóngase que theta estimado es una solución de las ecuaciones normales de verosimiltud. Si theta 0 representa el valor verdadero de theta, y es constante cuando, entonces theta estimado es un estimador consistente de theta 0.
Teorema 6. Sea un estimador consistente de, que es solución de, entonces bajo las hipótesis M.1 a M.5 la matriz es definida negativa con probabilidad que tiende a 1 cuando.
Teorema 7. De todas las posibles soluciones de y bajo los supuestos de las condiciones M.1 a M.5, una y sólo una tiende en probabilidad al vector parámetro verdadero.
Normalidad Asintótica
Teorema 8. Bajo las hipótesis M.1 a M.5, si es el vector estimador máximo verosímil del vector de parámetros entonces tiene distribución asintótica normal multivariada con media cero y matriz de varianzas covarianzas en donde
Estimación máximo verosímil del tamaño del dominio traslapado y el tamaño de los marcos en el caso de dos marcos.
Notación e hipótesis
Sean M1 y M2 dos marcos que se combinan para dar cobertura completa a una población. Entonces pueden existir hasta tres dominios. Al primero pertenecen las unidades que están únicamente en el marco M1 ; al segundo dominio pertenececen la unidades que están únicamente en el marco M2 ; y al tercer dominio pertenecen las unidades restantes, o sea, las que están en ambos marcos. Sean dos espacios de medida en donde los son subespacios euclideanos dimensionales, con Fi las respectivas sigma álgebras de Borel y las respectivas medidas de Lebesgue. Sean C1 y C2 clases de subconjuntos de respectivamente y sean A1 y A2 subconjuntos de respectivamente tales que son finitas. Se denotará por a la clase. Es la mínima sigma álgebra que contiene a Entonces son subespacios de medida finita con la restrición de la medida de Lebesgue correspondiente.
Se supondrá que están asociados a los marcos M1 y M2 respectivamente, en el sentido de que cada unidad del marco Mi tiene asociada un punto en. Se dirá entonces que la unidad se encuentra ubicada en. Supóngase que existe una clase T1 de conjuntos disyuntos de la sigma álgebra FA1 tal que. Se usará la notación y. De manera completamente análoga se definen y. Cada elemento de FAi se llamará área.
Sea dos variables aleatorias definidas como sigue:
Para cada área, en donde ni es el número de unidades que se encontran ubicadas en el área en un momento determinado. La variable aleatoria puede tomar los valores
La probablidad de encontrar asociada exactamente una unidad en un área
ti con medida suficientemente pequeña es aproximadamente
igual a. Es decir, es suficientemente pequeña, en donde es una constante positiva.
La probabilidad de encontrar asociadas más de una unidad en un área de medida muy pequeña es despreciable comparada con la probabilidad de encontrar exáctamente una unidad en la misma área. Es decir, es pequeña.
Los números de unidades asociadas a áreas disyuntas en cualquier momento son independientes.
Las hipótesis A1 a A4 determinan que las variables tienen distribución de Poisson con parámetro. Entonces si es un área de FAi con medida se tiene que. La cantidad se denominará densidad del espacio.
Modelo de muestreo y función de verosimilitud
El propósito de este trabajo es obtener estimaciones máximo verosímiles para los tamaños N1 y N2 de los marcos M1 y M2 respectivamente y del tamaño theta del dominio traslapado. Se puede observar que si es la densidad del espacio entonces
Por tanto, si Ni se desconoce y se encuentra una estimación máximo verosímil entonces es la estimación máximo verosímil de Ni. Además.
El proceso de muestreo consiste en seleccionar aleatoriamente m1 áreas de T1 , m2 áreas de T2 y contar las unidades que se encuentren ubicadas cada una de las áreas. Se supone que existe un mecanismo para identificar cuando una unidad encontrada en un marco también pertenece al otro marco. Sean las variables aleatorias definidas como el número de unidades encontradas en cada una de las áreas, sean la medidas del áreas , y sean X1i i = 1, 2, ..m1 las variables aleatorias definidas como el número de unidades encontradas en el área t1i que pertenecen únicamente al marco 1. Bajo la hipótesis adicional de que la pertenencia de una unidad solamente al marco 1 es independiente para todas las unidades de dicho marco y de acuerdo con la ecuación (16), la probabilidad conjunta de encontrar n1i unidades en el área t1i del marco 1, de las cuales x1i pertenecen únicamente al marco 1 está dada por
P [X1i = x1i , η1i = n1i | λ1 , θ] = P [X1i = x1i | η1i = n1i , λ1 , θ] × P [η1i = n1i , | λ1 ]
La probabilidad de la izquierda se justifica teniendo en cuenta que de acuerdo a la hipótesis de independencia del suceso de pertenecer unicamente al marco 1, la variable aleatoria (X1i | η1i = n1i ) tiene distribución binomial con parámetros n1i y p1. La probabilidad del segundo paréntesis se obtiene de las hipótesis A.1 a A.4 de la sección anterior.
La función de probabilidad conjunta del vector aleatorio (X1i , η1i ), está dada por f1i (X1i , η1i | λ1 , θ) en donde X1i = 0, 1, 2, ...η1i y η1i = 0, 1, 2, ...
Si S={(x,n)|x=0,1,2,...n; n=0,1,2...} se verifica que por lo que f1i es una función de probabilidad con valores sobre la región S.
La función de verosimilitud asociada a las observaciones (x1i,n1i),                   i = 1, 2, ..m1 está dada por Φ1((x11,n11), ...(x1m1,n1m1)|λ1,θ) 
Sea η1 la variable aleatoria definida por .Entonces η1 tiene distribución de Poisson con parámetro λ1 a1, en donde
Sea (X1|η1=i=1 η1i) la variable aleatoria definida por. La variable (X1|η1=n1) tiene distribución binomial con parámetros η1 y p1 condicionada a η1 = n1
entonces la función de verosimilitud Φ1 de la ecuación se puede escribir como Φ1((x11,n11),...,(x1r1,n1r1)|λ1,θ)
Nótese que n1 es el número total de unidades encontradas en la muestra asociada al espacio ΩA1 , x1 el número total de unidades que pertenecen únicamente al marco M1 y a1 la medida del área total muestreada
Es claro que los vectores aleatorios (X1i,η1i) (i=1,...,m1) son independientes pero no idénticamente distribuidos, debido a que las áreas t1i , no necesariamente tienen la misma medida. Si la clase T1 puede ser escogida de tal manera que todas las áreas tengan la misma medida dı́gase α1 ,entonces los vectores (X1i,η1i) (i=1,...,m1) son idénticamente distribuidos con función de probabilidad dada por f1 (X1,η1 |λ1,θ)
Nota 9. Obsérvese que en este caso η1 tiene distribución de Poisson con parámetro λ1 α1, y (X1|η1) tiene distribución condicional binomial con parámetros η1 y p1.
La función de verosimilitud asociada a las observaciones (x1i,n1i), i=1,2,..m1 está dada en este caso por Ψ1 ((x11,n11 ), ...(x1m1 , n1m1 ) | λ1 , θ
Nota 10. De manera completamente análoga se hace la construcción para la muestra asociada al espacio ΩA2 , cambiando en cada expresión el 1 del primer subíndice por 2. En adelante supondremos definidos los términos f2j (j =1, ..., m2 ), Φ2, K2 , f2 , L2 y Ψ2 .
Si las dos muestras son combinadas se tiene que la función de verosimilitud asociada para las observaciones (x1i , n1i ), i = 1, 2, ...m1 , (x2j , n2j ), j = 1, 2, ...m2 en el caso de áreas de distinta medida está dada por
Φ((x11 , n11 ), ...(x1r1 , n1r1 ), (x21 , n21 ), ...(x2r2 , n2r2 ) | λ1 , λ2 , θ) = Φ1 Φ2
Para el caso de áreas de medida igual en cada espacio la función de verosimilitud está dada por
Estimación de los parámetros
El logaritmo de la función de verosimitud Φ esta dado por ln Φ = K + (n1 - x1) ln(θ) + x1 ln(λ1 A1 - θ) - λ1 a1 + (n2 - x2 ) ln(θ) + x2 ln(λ2 A2 - θ) - λ2 a2 y para el caso está dada por ln Ψ = L + (n1 - x1 ) ln(θ) + x1 ln(λ1 A1 - θ) - λ1 m1 α1 + (n2 - x2 ) ln(θ) + x2 ln(λ2 A2 - θ) - λ2 m2 α2 en donde K y L son contantes.
Teorema 11. La función ln Φ tiene un único punto crítico
Prueba. El sistema de ecuaciones normales de verosimilitud para este caso está dado por
Nota 12. Obsérvese que si 0 < x1 < n1 y 0 < x2 < n2 entonces el punto crítico obtenido satisface (θ, λ1 , λ2 ) ∈ Θ.
Teorema 13. Bajo el supuesto que 0 < x1 < n1 y 0 < x2 < n2 la matriz de las segundas derivadas parciales de la función de verosimilitud ln Φ es definida negativa para todos los valores (θ, λ1 , λ2 ) ∈ Θ, y por tanto el extremo local del teorema anterior es el único máximo local de ln Φ.
Prueba. La matriz de las segundas derivadas parciales de ln Φ esta dada por
De acuerdo con el criterio de Sylvester basta demostrar que
Supongamos que 0 < x1 < n1 y 0 < x2 < n2 Entonces se deduce directamente que D11 < 0. Por otro lado,
De acuerdo con los dos teoremas anteriores, la estimación máximo verosímil del vector de parámetros de ln Φ está dada por (θ, λ1 , λ2 ) en donde
Nótese que como 0 < x1 < n1 y 0 < x2 < n2 entonces θ̂, λ̂1 , λ̂2 ) ∈ Θ.
Análogamente, la estimación máximo verosímil del vector de parámetros de
ln Ψ está dada por (θ, λ1 , λ2) en donde
Nota 14. Para las aplicaciones prácticas deben tomarse como estimadores los
enteros mas cercanos a θ, N1 y N2
Propiedades de los estimadores
Esperanza de los estimadores
En esta sección se calculan la esperanza y la matriz de varianzas - covarianzas de los estimadores asociados a las estimaciones obtenidas en la seción anterior y se demuestra que todos los estimadores son insesgados
Si X1 y η1 son las variables aleatorias definidas, y X2 y η2 son las análogas en el espacio 2 entonces los estimadores de máxima verosimilitud que se obtienen de la sección anterior están dados para el caso de la función de verosimiltud Φ por
Nótese que para el estimador se usa el mismo símbolo que para la estimación
pero resaltado.
Lema 15. Si X1 y η1 son las variables aleatorias definidas entonces para el caso de la función de verosimiltud Φ se tiene que
E[X1] = Var[X1]
E[η1] = Var[η1] = λ1 a1
E[η1 - X1] = Var[η1 - X1]
Cov[η1 - X1 , X1] = 0
Prueba. La expresión se deduce del hecho de que η1 tiene distribución de Poisson con parámetro λ1 a1. Por otro lado la variable (X1 | η1 = n1) tiene distribución binomial con parámetros η1 y p1
De manera análoga si se tiene en cuenta que (η1 −X1 | η1 ) tiene distribución binomial con parámetros η1 y q1 = λ1 A1 se llega a la expresión.
Corolario 17.
Cov[X1 , θ] = 0
Cov[X2 , θ] = 0
Varianza de los estimadores
Teorema 18. Todos los estimadores de las expresiones son insesgados.
Teorema 19. Las varianzas de los estimadores de las expresiones están dadas por
Corolario 20.
Nota 21. La matriz de varianzas covarianzas de los estimadores para la función de verosimilitud Φ es
Las expresiones para la esperanza y la varianza de los estimadores obtenidos para la función de verosimiltud Ψ, se obtienen reemplazando en cada caso a1 por m1 α1 y a2 por m2 α2 , en este caso usamos la notación CΨ (θ, λ1 , λ2 ) y se tiene 
Nota 22. Si en las matrices de covarianzas CΨ (θ, λ1 , λ2 ) y CΦ (θ, λ1 , λ2 ) se reemplazan θ, λ1 , λ2 por θ̂, λ̂1 , λ̂2 respectivamente se obtienen estimadores insesgados para tales matrices. En particular se obtienen estimadores insesgados para las varianzas.
Normalidad asintotica de los estimadores para el caso de la función de
verosimilitud Ψ
La consistencia de los estimadores máximo verosímiles obtenidos no está garantizada debido a que en el caso de la función de verosimiltud Φ no se obtiene a partir de vectores aleatorios idénticamente distribuidos. Para el caso de la función de verosimiltud Ψ, los vectores aleatorios son idénticamente distribuidos en cada muestra. El hecho de tener dos muestras independientes no permite garantizar directamente la consistencia de los estimadores. En esta sección se demuestra la normalidad asintótica de los estimadores máximo versímiles obtenidos para la función de verosimilitud Ψ definida en la ecuación. Se demostrará que las funciones f1 y f2 satisfacen las condiciones M.1 a M.5 de la sección. La condiciones M.1 y M.2 son obvias. Para establecer la condición M.3 basta observar que 
Falta verificar las condiciones M.4 y M.5.
Teorema 23. Las funciones f1i y f2j de la función de verosimiltud Φ definida en la ecuación y las funciones f1 y f2 de la función de verosimiltud Ψ definida en la ecuación satisfacen la condición M.4. de la sección.
Prueba. Según las funciones de probabilidad f1i f2j, f1 y f2 están todas definidas en el conjunto S = {(x, n) | x = 0, 1, 2, ..n; n = 0, 1, 2...}. De (95) se sigue que se demostrará que todas las sumas de la condición M.4. son cero para f1i f2j, f1 y f2. Sea y como h es la función de probabilidad de Poisson con parámetro λa entonces se tiene que finalmente se probará que las funciones f1 y f2 satisfacen la condición M.5.
Teorema 24. Sean M = m1 + m2 . ρ1 = m1 /M, ρ2 = m2 /M , y sean I (i) (θ, λ1 , λ2 ) (i = 1, 2) las matrices definidas por
Entonces, la matriz I(θ, λ1 , λ2 ) = ρ1 I (1) (θ, λ1 , λ2 ) + ρ2 I (2) (θ, λ1 , λ2 ) es definida positiva con determinante finito para todo (θ, λ1 , λ2 ) ∈ Θ.
Nota 25. Si M → ∞, y ρ1 = m1 /M , ρ2 = m2 /M permanecen constantes, entonces, I → I0 en donde
Nota 26. Antes de establecer el teorema de normalidad asintótica para el vector de estimaciones ϕ = (θ, λ1 , λ2 ) es necesario aclarar el significado de la expresión M → ∞. Como m1 y m2 son los tamaños de muestra en cada espacio, entonces si ρ1 = m1 /M , ρ2 = m2 /M permanecen constantes y M → ∞, se tiene que m1 y m2 tiende simultáneamente a infinito. Esto implica que el número de áreas S1 de ΩA1 y el número de áreas S2 de ΩA2 deben tender ambos a infinito. Es posible tener sucesiones infinitas de áreas a1i en ΩA1 y a1j en ΩA2 , pero en este caso la medida de todas las áreas no puede ser igual, manteniendo el área total finita. Por lo tanto, cuando se requiere que M → ∞ para el caso de áreas iguales se debe suponer que S1 → ∞ y S2 → ∞ simultáneamente, en consecuencia A1 = µ(ΩA1 ) → ∞ y A2 = µ(ΩA2 ) → ∞ simultáneamente y de acuerdo con las hipótesis A.1 a A.4 de la sección N1 → ∞ y N2 → ∞ simultáneamente. Esto significa que el siguiente resultado asintótico es aplicable para muestras grandes para tamaños de marco grandes y medidas de los espacios asociados grandes.
Teorema 27. Sea ϕ = (θ, λ1 , λ2 ) el vector de estimaciones máximo verosímil del vector de parámetros ϕ = (θ, λ1 , λ2 ) obtenido para la función de verosimilitud Ψ, entonces M (ϕ̂ − ϕ) tiene asintóticamente distribución normal multivariada cuando M → ∞, mi = ρi M, i = 1, 2, con media cero y matriz de varianzas covarianzas I0−1 (θ, λ1 , λ2 ).
En el siguiente lema se exhibe explícitamente la matriz I0−1 (θ, λ1 , λ2 ).
Teorema 28. La matriz I −1 (θ, λ1 , λ2 ).está dada por
Prueba. El resultado puede verificarse efectuando el producto I · I−1
Teorema 29. Si CΨ (θ̂, λ̂1 , λ̂2 ) es la matriz de varizanza covarianza de los estimadores definida en, entonces. I −1 (θ, λ1 , λ2 ) = M · CΨ (θ̂, λ̂1 , λ̂2 )
Prueba. Se deduce de los resultados anteriores.
Para el caso de la función Φ la matriz de información se construye de la siguiente forma. Para cada función de probabilidad f1i (i = 1, ...m1 ) la matriz de información asociada al vector parámetro es
Entonces I1 (θ, λ1 , λ2 ) tiene la misma forma de la matriz I (1) ((θ, λ1 , λ2 ) de la ecuación. De la misma forma se construyen las matrices de información para cada función de probabilidad f2j (j = 1, ...m2 ) asociadas al vector parámetro. Si tales matrices se notan I2j (θ, λ1 , λ2 ) sea
Entonces I2 (θ, λ1 , λ2 ) tiene al misma forma de la matriz I (2) ((θ, λ1 , λ2 ) de la ecuación (111). Finalmente, la matriz de información asociada a todas las observaciones está dada por
I(θ, λ1 , λ2 ) = I1 (θ, λ1 , λ2 ) + I2 (θ, λ1 , λ2 )
Esta matriz tiene la misma forma de la matriz de la ecuación. Basta hacer las identificaciones ai = ρi αi y se llega la resultado, es decir, para este caso se tiene que
De manera similar al caso de la matriz CΨ se obtiene el siguiente
Teorema 30. Si CΦ (θ̂, λ̂1 , λ̂2 ) es la matriz de varizanzas covarianzas de los estimadores definida en, entonces.
I −1 (θ, λ1 , λ2 ) = CΦ (θ̂, λ̂1 , λ̂2 )
Nota 31. Obsérvese que para todos los estimadores la varianza asintótica coincide con sus varianzas. Nótese que se tiene
Teorema 32. Todos los estimadores son de varianza mínima.
Prueba. Se sigue del teorema anterior. Veáse por ejemplo (Lehmann, 1983: página 128).
Discusión
En la práctica, para la aplicación de los resultados de este trabajo, se debe verificar que la clases C1 y C2 de subconjuntos de Ω1 y Ω2 son tales que se cumplen las hipótesis A.1 a A.4, lo cual se traduce en que la densidad poblacional en cada una de las clases es aproximadamente similar. Entonces, la clase Ci está conformada por subconjuntos de Ωi para los cuales se satisfacen tales condiciones. El conjunto Ai puede corresponder a una delimitación externa, por ejemplo, una delimitación geográfica. Un primer camino de generalización de este trabajo consiste en abarcar el caso cuando las hipótesis A.1 a A.4 se cumplen localmente. En este caso se pueden proponer varias clases Cik para el espacio i en cada una de las cuales las hipótesis se satisfacen localmente. Para este caso puede admitirse una densidad λik en cada clase tal que Ni = λik µi (ΩAik). Con las respectivas identificaciones las funciones de probabilidad asociadas al
espacio 1 están dadas por
La normalidad asintótica de los estimadores para el caso de la función de verosimiltud Φ no fue demostrada en este trabajo. Todos los resultados parecen indicar que bajo algunos supuestos adicionales se puede llegar a demostrar. En los trabajos de Bradley y Gart (1962) y Hodley (1977) se proponen algunos supuestos que pueden ayudar en este y en el problema de generalización anterior.
Con respecto a las clases Ti de subconjuntos de FAi , es decir a las áreas que forman la base para el muestreo, no es necesario que sean finitas. Por otro lado, en la expresión de convergencia asintótica debe recordarse que M es el número total de áreas muestradas en los dos espacios y que se supone que ρi = mi/M permanece constante. En consecuencia, como el área total ΩAi tiene medida finita, para poder aplicar este resultado en la práctica se requiere que las clases T1 y T2 tengan cada una un número grande de elementos, y por por tanto, cada uno con medida muy pequeña comparada con la medida de el área ΩAi . Adicionalmente, este resultado implica que para seleccionar tamaños de muestra, es mejor definir desde el comienzo que las muestras sean proporcionales a dos constantes fijas. Asi, parece que una estrategia razonable para el caso de espacios del mismo tipo consiste en
tomar las muestras proporcionales a las medidas de ΩAi .
Por otro lado, para el caso de áreas iguales, se puede tomar α1 = α2 = 1, debido a que en este caso los αi solo participan como constantes de proporcionalidad en el cálculo de λ̂1 y λ̂2 , pero no participan en los estimadores para θ, N1 y N2 . Observe que si S1 y S2 representan el número total de áreas en cada espacio, entonces para cualquier valor de α1 y α2 se tiene que
En este caso la matriz de covarianzas toma la forma
La generalización del problema a mas de dos marcos puede iniciarse, reemplazando el modelo binomial condicionado por un modelo multinomial condicionado, en donde cada pi está asociado al número de elementos encontrados que pertenecen a un dominio i para cada área muestrada.
Referencias
T M Apostol.Mathematical Analysis.(1974).Addison Wesley Publishing Company.USA.
R R Bosecker,B L Ford.Multiple frame estimation with stratified overlap domain.(1976).US Deparment of Agriculture.Washington
R A Bradley,J J Gart.The asymptotic properties of ML estimators when sampling from associated populations.(1962).Biometrika.
E G Bryant,D W King.Estimation from populations identified by overlapping sampling frames.(1960).American Statistical Association.
R S Cochran.Theory and aplications of multiple frame surveys.(1965).Iowa State University.Ames.
R S Cochcran,W P Cooke.The estimation of domain size when sampling frames overlap.(1967).The American Statistical Association meeting.Washington DC.
W P Cooke.Surrogate geometric programing estimation of restricted multinomial proportions.(1983).Communications in Statistics.
W A Fuller,L F Burmeister.Estimators for samples selected from two overlapping frames.(1972).The American Statistical Asociation.Montreal.
H O Hardley.Multiple frame surveys.(1962).The American Statistical Association meeting.Mineapolis.
H O Hardley.Multiple frame metodology and selected aplications.(1974).Sankhaya: The Indian Journal of Statistics.
G H Hill.Associating a reporting unit with a list frame sampling unit in multiple frame sampling, Ohio and Wisconsin.(1977).US Deparment of Agriculture.Washington.
B Hodley.Asymptotic properties of maximum likelihood estimators for the independent not identically distributed case.(1971).The Annals of Mathematical Statistics.
D W King.Variance estimators in populations identified by multiple sampling frames.(1960).University of Wyoming.
M L Krasnov,G I Makarenko,A I Kiseliov.Cálculo Variacional.(1976)..Moscú.
E L Lehman.Theory of Point Estimation.(1983).John Wiley & Sons.New York.
R E Lund.Estimators in multiple frame surveys.(1968).The American Statistical Association.
D Ospina.Maximum Likelihood aproach on multiple frame surveys.(1985).University of Wyoming.
D Ospina.Una distribución asintótica para estimadores máximo - verosímiles de tamaños de dominios de situaciones de marcos múltiples.(1989).Revista Colombiana de Estadística.
R E Williams.Estimation of Overlapping strata boundaries.(1957).University of Wyoming.