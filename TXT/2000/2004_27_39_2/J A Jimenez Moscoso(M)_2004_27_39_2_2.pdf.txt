Un criterio para identificar datos atÄ±Ìpicos
Universidad Nacional de Colombia
Resumen
En este artÄ±Ìculo se presenta un meÌtodo para determinar las observaciones que son atÄ±Ìpicas en un modelo de regresioÌn lineal muÌltiple; estos datos se estableceran de acuerdo al cambio que ejercen sobre la suma de los cuadrados de residuales del modelo.
Palabras Claves: Modelos lineales, mÄ±Ìnimos cuadrados, formas cuadraÌticas, observaciones atÄ±Ìpicas, estadÄ±Ìstica Qk.
IntroduccioÌn
Draper & John (1981) proponen una metodologÄ±Ìa para detectar un grupo de k observaciones atÄ±Ìpicas, anaÌloga a la propuesta de Bartlett (1937), citada
en Little & Rubin (1987), para estimar los paraÌmetros del modelo de regresioÌn lineal cuando existen observaciones faltantes en la variable respuesta. En el planteamiento de Draper & John (1981) se considera el modelo de regresioÌn lineal muÌltiple:
particionado de la siguiente manera:
donde Y1 es el bloque conformado por las observaciones consideradas atÄ±Ìpicas.
Para el modelo (2) establecen las estimaciones de Î² y Î³ mediante:
donde Hij = Xi (X 0 X)âˆ’1 Xj0 es una submatriz de la matriz
    La notacioÌn de H y el nombre de matriz hat fue introducido por Tukey
(1977); por otra parte, el cambio en la suma de cuadrados de residuales lo
calculan usando la estadÄ±Ìstica:
     En resumen, el meÌtodo descrito permite detectar el grupo de observaciones
atÄ±Ìpicas en base al cambio en la suma de cuadrados de residuales, lo cual se
cuantifica con la estadÄ±Ìstica Qk , es decir, mediante este procedimiento se se-
lecciona el bloque Y1 que posee el Qk maÌs alto, como el bloque maÌs atÄ±Ìpico, y
en muchos casos quedan datos atÄ±Ìpicos dentro de un bloque y el meÌtodo no los
identifica. En este artÄ±Ìculo se muestra un criterio para identificar el bloque Y1
que contiene el grupo maÌs grande de observaciones atÄ±Ìpicas.

2.      Resultados baÌsicos del ajuste del modelo de
        regresioÌn lineal muÌltiple
    Mediante el meÌtodo de estimacioÌn mÄ±Ìnimos cuadrados ordinarios (MCO)
se obtiene para el modelo dado en (1) los siguientes estimadores:
    ObseÌrvese que la matriz H determina muchos de los resultados de las estimaciones por MCO; por ejemplo, cuando premultiplica al vector de respuestas
Y se obtienen los valores predichos de la variable dependiente, por eso en la literatura estadÄ±Ìstica en algunos casos la denominan matriz de prediccioÌn, y a
la matriz I âˆ’ H la llaman matriz residual, puesto que al anteponeÌrsele a la
variable dependiente Y se obtienen los respectivos residuales.
Propiedades de las componentes de la matriz H
En Hoaglin & Welsch (1978) se establece para la matriz H = [hij ] de tamanÌƒo
n Ã— n, las siguientes propiedades:
Si la matriz X de tamanÌƒo n Ã— r es de rango r, entonces
donde tr(H) denota la traza de la matriz H.
     Dado que hij = xi (X 0 X)âˆ’1 x0j , entonces hii estaÌ determinado por la localizacioÌn de xi en el espacio X, es decir, un valor pequenÌƒo (grande) de hii indica
que xi se encuentra cerca (lejos) de la masa de los otros puntos. AdemaÌs,
sugieren que xi es un punto influyente si hii > 2r/n.

3.      CaÌlculo de la estadÄ±Ìstica Qk
   En JimeÌnez (2001b) se establece para la estadÄ±Ìstica dada en (3), la siguiente
expresioÌn:
                Qk = SCE âˆ’ SCE âˆ— = âˆ’2Î³ 0 Ë† âˆ’ Î³ 0 (I âˆ’ H)Î³ ,                   (5)
donde SCE es obtenida en teÌrminos algebraicos como en (4) y SCE âˆ— , repre-
senta la estimacioÌn vÄ±Ìa mÄ±Ìnimos cuadrados (EM C) de SCE sin el bloque Y1 de
observaciones. AdemaÌs, muestra que si el intereÌs es minimizar la SCE âˆ— , esto
se logra haciendo:
                                     âˆ‚Qk
                                          = 0,
                                      âˆ‚Î³
lo cual equivalente a hacer:
                                 + (I âˆ’ H)b
                                b          Î³ = 0,                             (6)
       es la estimacioÌn vÄ±Ìa mÄ±Ìnimos cuadrados (EM C) de  del modelo (1).
donde b
     Al remplazar (6) en (5) se tiene:
                             b0 (I âˆ’ H)b
                        Qk = Î³           b0 Î³
                                       Î³=Î³    b0 Hb
                                            bâˆ’Î³   Î³.                          (7)

    Esta nueva expresioÌn de Qk tiene la ventaja de que estaÌ en teÌrminos de la
estimacioÌn del Î³ arbitrario, la cual para los objetivos de este trabajo es maÌs
atractiva, ya que se podraÌ establecer su distribucioÌn de probabilidad correspondiente.

4.      DistribucioÌn de probabilidad de Qk
     En JimeÌnez (2001a) al asumir la restriccioÌn Î³Ì‚ = 1 , se llega a:

donde Ik es la matriz identidad de tamanÌƒo k Ã— k, con k igual a la dimensioÌn
del bloque Y1 y Mij = Xi (X20 X2 )âˆ’1 Xj0 .

   Si se reemplaza (8) en el primer teÌrmino de la expresioÌn (7) se obtiene

    Por otra parte, si se sustituye (8) en el segundo teÌrmino de la expresioÌn (7)
y se emplean los resultados dados en JimeÌnez (2001a), se tiene que:

   Finalmente, al sustituir (9) y (10) en la ecuacioÌn (7), se obtiene que:
NoÌtese que la matriz (M âˆ’ H) es simeÌtrica; ademaÌs, es idempotente. Esto se
puede verificar de la siguiente manera:

                  (M âˆ’ H) (M âˆ’ H) =M 2 âˆ’ M H âˆ’ HM + H 2 ,

pero M 2 = M , ya que:
                                                             
           Ik     0    Ik        0     I         0        I      0
                                     = k                = k           .
            0 M22 0             M22     0      M22 M22     0    M22

   Esto se tiene, ya que para i, j = 1, 2:
                         0          0      0      0         0         0
   Mi2 M2j = [Xi (X2 X2 )âˆ’1 X2 ][X2 (X2 X2 )âˆ’1 Xj ] = Xi (X2 X2 )âˆ’1 Xj = Mij ;

por otra parte, HM = H lo cual se puede verificar como sigue:
                                                       
          H11 H12 Ik      0        H11 H12 M22        H11 H12
                               =                    =           .
          H21 H22 0 M22            H21 H22 M22        H21 H22

114                                                             JoseÌ A. JimeÌnez M.

                                        
                                        X1
   AquÄ±Ì cabe notar que cuando X =         es de rango completo, entonces:
                                        X2
                       0       0       0         0          0         0
      Hi2 M2j = [Xi (X X)âˆ’1 X2 ][X2 (X2 X2 )âˆ’1 Xj ] = Xi (X X)âˆ’1 Xj = Hij ,
para i, j = 1, 2; ademaÌs, como las matrices H y M son simeÌtricas se tiene que
H = (M H)t = HM . En consecuencia,
                           (M âˆ’ H) (M âˆ’ H) = M âˆ’ H.
Para establecer la distribucioÌn de Qk , se presentan, sin demostracioÌn, los teo-
remas 1 y 2, mencionados en Searle (1971).
Teorema 1. Si Y es un vector aleatorio de tamanÌƒo n Ã— 1, distribuido N (Âµ, V ),
donde Âµ es en si mismo un vector entonces:
   E [Y 0 AY ] = tr(AV ) + Âµ0 AÂµ   y   Var [Y 0 AY ] =2 tr(AV )2 + 4Âµ0 AV AÂµ.
                                                       0
Teorema 2. Si Y âˆ¼ N (Âµ, V ), entonces Y 0 AY âˆ¼ Ï‡2(Î½,Î») , con grados de liber-
tad Î½ = Ï(A) y paraÌmetro de no centralidad Î» = 21 Âµ0 AÂµ, si y soÌlo si AV es
idempotente.

   Puesto que, bajo el supuesto de normalidad en los residuales se tiene que
                               Y âˆ¼ N (XÎ², Ïƒ 2 In ).                            (12)

   Como la expresioÌn dada en (11) es una forma cuadraÌtica se estableceraÌ a
continuacioÌn la respectiva distribucioÌn asociada. Por el teorema 1, se tiene que
                                       h en el modelo (1).
donde r es el rango de la matriz X definida              i Cuando esta
                                                  0         0
matriz es de rango completo se tiene que tr (X2 X2 )âˆ’1 (X2 X2 ) = r.

    Utilizando el teorema 2, tambieÌn se concluye que Qk /Ïƒ 2 tiene distribucioÌn
ji-cuadrado central:
                                 Qk
                                        âˆ¼ Ï‡2(Î½) ,                           (13)
                                  Ïƒ2
                       h 0            0
                                            i
donde Î½ = k âˆ’ r + tr (X2 X2 )âˆ’1 (X2 X2 ) . AquÄ±Ì el teorema 2 es aplicable ya
      1
que 2 (M âˆ’ H)Ïƒ 2 In es una matriz idempotente.
     Ïƒ

Un criterio para identificar datos atÄ±Ìpicos                                   115


5.      MetodologÄ±Ìa para establecer datos atÄ±Ìpicos
     Dado que la estadÄ±Ìstica Qk se puede obtener de la forma cuadraÌtica:
                                           0
                                       b (I âˆ’ H)b
                                  Qk = Î³        Î³,                            (14)

al expresarla en teÌrminos del vector de respuestas Y , queda como:
                                                           
                       0  Ik       0         0  H11       H12
               Qk =Y                    Y âˆ’Y                    Y.            (15)
                           0     M22            H21       H22

                                              
                                               Y1
     Si se considera que en la particioÌn Y =     , el bloque Y1 estaÌ conformado
                                               Y2
por las observaciones atÄ±Ìpicas, dicho bloque afectaraÌ todas las EMC del modelo
dado en (1). Por otra parte, si se reescribe la expresioÌn (5), se tiene que:

                                SCE = SCE âˆ— + Qk ,

y dado que SCE âˆ— puede expresarse en forma matricial como sigue
                                        
                âˆ—    0  0          0             0
            SCE = Y                        Y = Y [In âˆ’ M ] Y ;                (16)
                        0     Inâˆ’k âˆ’ M22

usando (12), se puede establecer que las expresiones,

                  SCE                                    SCE âˆ—
                                          y                    ,              (17)
                   Ïƒ2                                     Ïƒ2
tienen distribucioÌn ji-cuadrado central. Luego, si se divide la ecuacioÌn (13) por
cualquiera de las expresiones dadas en (17), se elimina el teÌrmino Ïƒ 2 y queda
el cociente entre dos formas cuadraÌticas que se distribuyen ji-cuadrado.
    Por la teorÄ±Ìa estadÄ±Ìstica se sabe que cuando se realiza el cociente entre dos
variables aleatorias independientes con distribucioÌn ji-cuadrado y cada una se
divide por sus respectivos grados de libertad, se obtiene una nueva variable con
distribucioÌn F .
    Para llevar a cabo el cociente mencionado anteriormente se debe verificar
con cuaÌl de las distribuciones asociadas a las expresiones dadas en (17) la
distribucioÌn de probabilidad expresada en (13) es independiente; para ello, se
enuncia sin demostracioÌn el teorema 3, citado en Searle (1971).

Teorema 3. Cuando Y âˆ¼ N (Âµ, V ), las formas cuadraÌticas Y 0 AY y Y 0 BY ,
estaÌn distribuidas independientemente si y soÌlo si AV B = 0.

116                                                            JoseÌ A. JimeÌnez M.


    Veamos si las distribuciones asociadas a Qk y SCE son independientes. Si
se retoman las ecuaciones dadas en (11) y (4), se tiene por el teorema 3 que
Qk y SCE no son independientes, pues,

   (M âˆ’ H)(Ïƒ 2 In )(In âˆ’ H) = Ïƒ 2 (M âˆ’ H)(In âˆ’ H)
                              = Ïƒ 2 [M âˆ’ M H âˆ’ H + H 2 ] = Ïƒ 2 (M âˆ’ H) 6= 0;

en la uÌltima ecuacioÌn se tuvo en cuenta que H es idempotente y que M H = H.
    De manera anaÌloga, se verifica si son independientes las distribuciones de
probabilidad de Qk y SCE âˆ— ; de las ecuaciones (11) y (16) utilizando el teorema
3, se concluye que son independientes, ya que:

          (M âˆ’ H)(Ïƒ 2 In ) (In âˆ’ M ) = Ïƒ 2 (M âˆ’ H) (In âˆ’ M )
                                     = Ïƒ 2 M âˆ’ M 2 âˆ’ H + HM = 0.
                                                            


En esta uÌltima expresioÌn se utilizaron los resultados: M H = H y M 2 = M .
   La media y varianza de la SCE âˆ— se obtienen por el teorema 1, como sigue:
Como la media y la varianza de la distribucioÌn Ï‡2Î· son Î· y 2Î· respectivamente, se
            0              
deduce que Y (In âˆ’ M ) Y /Ïƒ 2 tiene distribucioÌn ji-cuadrado central. Se llega
                                1
a la misma conclusioÌn, ya que 2 (In âˆ’ M ) Ïƒ 2 In es idempotente, utilizando el
                               Ïƒ
teorema 2. AsÄ±Ì pues,
                                0
                              Y (In âˆ’ M ) Y
                                            âˆ¼ Ï‡2Î· ,                           (18)
                                   Ïƒ2
                  0            0
con Î· = nâˆ’kâˆ’tr (X2 X2 )âˆ’1 (X2 X2 ) . Cuando la matriz X es de rango completo
                                     
                0           0
se tiene que tr (X2 X2 )âˆ’1 (X2 X2 ) = r.
                                   

   Como las distribuciones de probabilidad asociadas a las expresiones (15) y
(16) son independientes, al hacer el cociente entre las relaciones (13) y (18),

Un criterio para identificar datos atÄ±Ìpicos                                     117


dividiendo cada una por sus correspondientes grados de libertad, se llega a:

     Estos resultados se pueden resumir en los siguientes teoremas.
Teorema 4. Si en un modelo de regresioÌn lineal muÌltiple particionado como:
                                        
                        Y1       X1         
                             =        Î²+ 1 ,
                        Y2       X2         2
se elimina el bloque Y1 de dimensioÌn k, entonces el cambio que se presenta en
la SCE se calcula mediante la expresioÌn:
                                            b0 [In âˆ’ H] Î³
                                          1 Î³           b
                              âˆ†(Y1 ) =            2       ,                     (19)
                                          k      S(Y1 )

       2               SCE âˆ—
donde S(Y1)
             b2 =
            =Ïƒ                  es la estimacioÌn usual de Ïƒ 2 , despueÌs de eliminar
                     nâˆ’kâˆ’r                
                                          Î³                            0         0
                                    b = 1 , con Î³
las observaciones del bloque Y1 , y Î³              b1 = âˆ’Y1 +X1 (X2 X2 )âˆ’1 X2 Y2 .
                                          b
                                           0
Teorema 5. En un modelo de regresioÌn lineal muÌltiple Y = XÎ² + , bajo el
supuesto de que  âˆ¼ N (0, Ïƒ 2 In ), se tiene que:
                                               k = dimensioÌn del bloque Y1 ,
        âˆ†(Y1 ) âˆ¼ F(k,nâˆ’râˆ’k) ,       con
                                               r = rango de la matriz X.

En este caso, se clasifica como atÄ±Ìpico al bloque Y1 de observaciones, si con un
nivel de significancia Î± se satisface que:
                                âˆ†(Y1 ) > F(k,nâˆ’râˆ’k,Î±/2) .                       (20)


6.      Ejemplo
   En la Tabla 1, se considera el conjunto de 21 observaciones (x, y), dado por
Mickey, Dunn & Clark (1967).
     Para este conjunto de datos, se presentan los siguientes resultados:

  1. La estimacioÌn del modelo de regresioÌn lineal, con las 21 observaciones.

  2. Los elementos de la diagonal de la matriz H, las estimaciones de los Î³i y
     al eliminar el i-eÌsimo dato se establecen la estadÄ±Ìstica Q1 , la distancia de
     Cook y la estadÄ±Ìstica âˆ†(i) con su p-valor correspondiente.

  3. La estimacioÌn del modelo de regresioÌn lineal, despueÌs de eliminar la ob-
     servacioÌn influyente determinada mediante distancia de Cook.

  4. La estimacioÌn del modelo de regresioÌn lineal, sin la observacioÌn que se
     considera influyente por la estadÄ±Ìstica âˆ†(i) .

  1. AnaÌlisis de varianza para el conjunto completo de datos:

   2. Compendio de estadÄ±Ìsticas:

      De los resultados anteriores se tiene que:

        a) La observacioÌn que se clasifica como influyente, usando la estadÄ±Ìstica
           propuesta por Cook, coincide con la que se detecta con el criterio
           para el elemento hii .
        b) Los otros meÌtodos detectan la misma observacioÌn como atÄ±Ìpica cuan-
           do se elimina una sola observacioÌn, pero cuando se eliminan dos
           o maÌs observaciones el procedimiento maÌs formal es el del p-valor
           asociado a la estadÄ±Ìstica âˆ†(Y1 ) .

   3. Cuando se elimina la observacioÌn 18, se obtiene:
      La distancia de Cook nos indicoÌ que la pareja (42, 57) era la que maÌs
      afectaba la EM C de los paraÌmetros, pero al eliminarla el modelo obtenido
      fue maÌs deficiente que el modelo completo. Por lo tanto, la observacioÌn
      es solamente influencial pero no es atÄ±Ìpica.
   4. Eliminando la observacioÌn 19 que detectoÌ âˆ†(i) como atÄ±Ìpica, se tiene:

El modelo que se obtiene al eliminar la pareja (17, 121) es mejor que el modelo
completo, pues el nuevo coeficiente de determinacioÌn es superior al del modelo
inicial. El valor crÄ±Ìtico de la F es tambieÌn inferior al valor crÄ±Ìtico que se deter-
minoÌ en el anaÌlisis de varianza del modelo inicial y, ademaÌs, el cuadrado medio
del error (CM E) fue menor que el CM E del modelo completo. Aunque dicha
observacioÌn es atÄ±Ìpica, no es influyente en la estimacioÌn de los paraÌmetros del
modelo.

Conclusiones
La metodologÄ±Ìa aquÄ±Ì presentada permite detectar en un grupo de observaciones la observacioÌn maÌs atÄ±Ìpica, es decir, el dato maÌs influyente sobre el cambio en la suma de cuadrados de los residuales. AdemaÌs, este procedimiento proporciona una manera de cuantificar el impacto de cada observacioÌn sobre la suma de cuadrados de los residuales, pues empleando la distribucioÌn F -central este meÌtodo permite asignarle un p-valor a cada influencia; de esta manera se obtiene un criterio maÌs exacto que el usado tradicionalmente.
BibliografÃ­a
Bartlett M S.Some examples of statistical methods of research in agriculture and applied botany.(1937).Journal of the Royal Statistical Society.
Draper N R,John J A.Influential observations and outliers in regression.(1981).Technometrics.
Hoaglin D C,Welsch R E.The hat matrix in regression and anova.(1978).The American Statistician.
JimeÌnez J A.Una generalizacioÌn de la estadÃ­stica de Cook.(2001).Revista Colombiana de EstadÄ±Ìstica.
JimeÌnez J A.Una maximizacioÌn de la estadÄ±Ìstica Qk.(2001).Revista Colombiana de EstadÃ­stica.
Little R J,Rubin D B.Statistical Analysis With Missing Data.(1987).John Wiley & Sons.
Mickey M R,Dunn O J,Clark V.Note on the use of stepwise regression in detecting outliers.(1967).Computers and Biomedical Research.
Searle S.Linear Models.(1971).John Wiley & Sons.
Tukey J W.Exploratory Data Analysis.(1977).Addison Wesley.