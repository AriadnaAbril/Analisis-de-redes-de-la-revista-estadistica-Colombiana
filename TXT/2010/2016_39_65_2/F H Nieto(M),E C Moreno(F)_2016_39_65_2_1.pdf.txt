Univariate Conditional Distributions of an Open-Loop TAR Stochastic Process. Distribuciones condicionales univariadas de un proceso estocástico TAR sin retroalimentación
Universidad Nacional de Colombia, Bogotá, Colombia. Universidad Santo Tomás, Bogotá, Colombia
Abstract
Clusters of large values are observed in sample paths of certain open-loop threshold autoregressive (TAR) stochastic processes. In order to characterize the stochastic mechanism that generates this empirical stylized fact, three types of marginal conditional distributions of the underlying stochastic process are analyzed in this paper. One allows us to find the conditional variance function that explains the aforementioned stylized fact. As a by-product, we are able to derive a sufficient condition to have asymptotic weak stationarity in an open-loop TAR stochastic process.
Key words: Conditional heteroscedasticity, Nonlinear stochastic process, Open-loop TAR model, Stationary nonlinear stochastic process.
Resumen
En trayectorias de un proceso estocástico autoregresivo de umbrales (TAR), sin retroalimentación, se observan conglomerados de valores extremos. Con el fin de caracterizar el mecanismo probabilístico que los genera, en este artículo se estudian tres tipos de distribuciones marginales condicionales del proceso subyacente. Uno de ellos permite encontrar la función de varianza condicional que explica ese hecho estilizado del proceso. Como un resultado adicional, se obtiene una condición suficiente para determinar estacionariedad débil asintótica, de un proceso TAR sin retroalimentación.
Palabras clave: heterocedasticidad condicional, modelo TAR sin retroalimentación, proceso estocástico no lineal estacionario.


1. Introduction
    In the context of nonlinear stochastic processes, Tong (1990) proposed the
open-loop threshold autoregressive (TAR) process and, among many others, Nieto
(2005, 2008) and Nieto, Zhang & Li (2013) developed a Bayesian methodology to
analyze particular cases, namely-when the threshold variable is not a covariable.
Sample paths in this kind of TAR process can exhibit clusters of (either positive
or negative) large values, which is an empirical fact that is also observed, for
example, in financial and meteorological/hydrological time series. In terms of
financial data, that stylized fact has been very well characterized by Engle’s (1982)
ARCH model and, then by the GARCH process (Bollerslev 1986) and almost
all of its extensions. The key element in these models has been the conditional
variance function of the underlying stochastic process. Along these lines, it is
important to find a conditional variance function of an open-loop TAR process in
order to determine if large-value clusters are explained by some type of conditional
probabilistic mechanism.
    The issue of characterizing univariate conditional distributions for this type
of TAR processes or, even, their univariate marginal distributions, has not in the
authors knowledge been studied until to now (see also Tong 2011). Thus, the
main goal of this paper is to obtain univariate marginal conditional distributions
for the open-loop TAR process in order to explain the presence of large-sample
clusters in a sample path. As a by-product, we provide a sufficient condition to
have asymptotic weak stationarity of the TAR process which is also considered in
this paper. The issues of weak and strict stationarity and ergodicity have been
contemplated in other cases related to the general family of TAR processes. For
example, Petruccelli & Woolford (1984) and Chen & Tsay (1991) have worked on
the so-called SETAR model class. Tong (1978), Wong & Li (2000), and Li, Ling
& Tong (2012) have undertaken research in which their threshold moving average
(TMA) equation has a stationary solution. Tong’s (2011) paper is an excellent
and comprehensive review of the literature of these issues.
    The paper is organized as follows: In Section 2 we present the basic specifi-
cation of the considered TAR process. Section 3 includes the main results of our
research, and in Section 4 we present three illustrative examples (two are real-data
examples). Section 5 concludes.


2. The Proposed Open-Loop TAR Model
   Let Z be the set of integer numbers. Following Nieto (2005) , let {Xt : t ∈ Z}
and {Zt : t ∈ Z} be stochastic processes, such that for all t ∈ Z,
                    (j)   Pkj    (j)       (j)
          Xt    = a0 +      i=1 ai Xt−i + h εt       if rj−1 < Zt ≤ rj ,           (1)

for some j = 1, . . . , l, where l denotes the number of the so-called regimes in the
sample space of variable Zt . These regimes are determined by the extended real
numbers (threshold values) r0 < r1 < · · · < rl−1 < rl , where r0 = −∞ and rl = ∞.


                                    Revista Colombiana de Estadística 39 (2016) 149–165

Univariate Conditional Distributions of a TAR Process                                        151

Let Rj = (rj−1 , rj ], j = 1, . . . , l, with the convention (rl−1 , ∞] = (rl−1 , ∞); then,
the set of regimes R1 ,. . . ,Rl is a partition of the real line R.
            (j)
    Here, ai and h(j) , i = 0, 1, . . . , kj , j = 1, . . . , l, are real numbers and they are
called nonstructural parameters. The nonnegative number kj is the autoregressive
order in regime j, j = 1, . . . , l, and l,r1 ,. . . ,rl−1 , k1 ,. . . ,kl−1 and kl are called the
structural parameters of the model.
    Additionally, {εt } is a Gaussian zero-mean white a noise process with a variance
1 such that E(Xs εt ) = 0 for s < t, Zs and the set {Xt , Xt−1 , . . .} are mutually
independent for all s > t, and {Zt } and {εt } are mutually independent. Equation
(1) describes a dynamical system without feedback with input {Zt } and output
{Xt }. To describe the stochastic behavior of {Zt }, we additionally assume that
{Zt } is a homogeneous mth order Markov chain, m ≥ 1, and, as a sequence of
random variables, it converges weakly to the distribution F .
   We shall use the symbol TAR(l; k1 , . . . , kl ) to denote this model and we will
say that {Xt } is an open-loop TAR process with {Zt } as its threshold process.
Notice that if we define, for each t ∈ Z, the random variable Jt as Jt = j, if and
only if Zt ∈ Rj , then {Jt } is an indicator process with sample space {1, · · · , l}.
Hence, the processes {Xt } and {Jt } conform a particular case of the general TAR
process, in Tong’s (1990, 2011) sense.
    This TAR model has been applied in the fields of the hydrology and meteorol-
ogy (Nieto 2005, Nieto 2008, Nieto et al. 2013), the economics (Hoyos 2006), and
finance (Moreno 2011). In a multivariate setting, Tsay (1998) among many other
authors, has also analyzed open-loop models, where variable Zt is included as a
covariable. In what follows, we refer to the above open-loop TAR process simply
as a TAR process (or model).


3. New Characteristics of the TAR Process
    In this section, our goal is to obtain the distribution of Xt for all t, conditional
on (i) a regime, Rj say, (ii) a regime Rj and the past data x̃t−1 = (xt−1 , . . . , x1 )
with t > max{kj | j = 1, . . . , l}, and (iii) x̃t−1 . That is to say, we will con-
sider three types of conditioning sets. Before finding these univariate conditional
distributions, we shall derive a sufficient condition to characterize the univariate
marginal distributions of the process {Xt }. Nieto (2008) presented the first steps
in characterizing some of these conditional distributions, as well as the univariate
marginal distributions, but the results were shown in an intuitive way without
formal analytical proofs.


3.1. Univariate Marginal Distributions and Asymptotic Weak
     Stationarity
   We assume that all the random elements considered in this paper are defined
on the same probability space (Ω, F, P ). Initially, we note that for all t ∈ Z, the
marginal cumulative distribution function (cdf) of Xt is given by


                                          Revista Colombiana de Estadística 39 (2016) 149–165

152                                                       Fabio H. Nieto & Edna C. Moreno


                                           l
                                           X
                                Ft (x) =         pt,j Ft,j (x)                        (2)
                                           j=1

for any x ∈ R, where Ft,j (x) = P (Xt ≤ x | Zt ∈ Rj ) and pt,j = P (Zt ∈ Rj ),
                                                                         Pl
j = 1, . . . , l (assuming this last probability is positive). Because j=1 pt,j = 1,
the marginal distribution of Xt is a mixture of conditional distributions, where
the conditioning events are the regimes. MomentsR for Xt can be obtained from
this marginal cdf. Indeed, if we denote µ1,j,t = xdFt,j (x) for all j = 1, . . . , l
                                    Pl
and all t, then µt = E(Xt ) = j=1 pt,j µ1,j,t (a weighted average of the regime
means at time t). A similar expression     holds for the second moment around zero.
Indeed, if we denote µ2,j,t = x2 dFt,j (x) for all j = 1, . . . , l and all t, we obtain
                                  R
                     Pl
µ2,t = E(Xt2 ) = j=1 pt,j µ2,j,t . Obviously, Var(Xt ) = µ2,t − µ2t for all t ∈ Z.
    Now, since {Zt } converges weakly to F , pt,j → pj = F (rj ) − F (rj−1 ) as
t → ∞ for all j = 1, . . . , l. Of course, if {Zt } has identical univariate marginal
distributions, as in the case of a strictly stationary process, then the cdf of Zt is
F for all t and, thus, pt,j = pj for all t and for all j = 1, . . . , l.

Proposition 1. Let C be the complex number set. If for each j = 1, . . . , l, the
                                     Pkj (j) i
roots of the polynomial φj (z) = 1 − i=1   ai z , z ∈ C, are outside of the unit
circle, then                                       !
                                               (j)
                                   x − ψj (1)a0
                     Ft,j (x) = Φ                    , x ∈ R,                 (3)
                                      h(j) σ̄j
                        P∞ (j)                          P∞   (j)
where ψj (z) = φj1(z) = i=0 ψi z i for | z |≤ 1, with i=0 | ψi |< ∞, σ̄j2 =
P∞      (j) 2
  i=0 (ψi ) , and Φ(·) denotes the standard normal cdf.

Proof . See the Appendix.

    This result was quoted by Moreno (2011) but without a formal proof, and in the
particular case where the distribution of Zt is the same for all t. It is important to
remark here that, under the assumptions of Proposition 1, the conditional cdf Ft,j
does not depend on t and that, as is noted in the proof, the Gaussian assumption
on the process {εt } is the basis for this result. Thus, let Fj = Ft,j , µ1,j,t = µ1j ,
and µ2,j,t = µ2j for all t and for all j = 1, . . . , l. Also, we can state that the
                                                                 (j)
distribution of Xt conditional on the regime Rj is N (ψj (1)a0 , [h(j) σ̄j ]2 ) for all t
                                                        (j)
and for all j = 1, . . . , l. We note that µ1j = ψj (1)a0 , and for future reference we
set σj2 = [h(j) σ̄j ]2 . Furthermore, the sequence {Xt } converges weakly to a random
                              Pl
variable with cdf FX = j=1 pj Fj . Based on this fact, the mean and the variance
function of this process converge, respectively, to a constant value, as t → ∞. As
noted above, if the univariate marginal distributions of {Zt } are identical, the cdf
of Xt is FX for all t. Notice that the limit distribution is a mixture of conditional
normal distributions where the conditioning sets are the regimes, and hence, this
distribution is potentially multimodal. Of course, if µ1j = µ1 for all j = 1, . . . , l,
the distribution is unimodal.


                                      Revista Colombiana de Estadística 39 (2016) 149–165

Univariate Conditional Distributions of a TAR Process                                      153

Proposition 2. Under the conditions in Proposition 1, the autocovariance func-
tion (ACVF) of {Xt } is given by
                                            l
                                            X
                       Cov(Xt , Xt−n ) =           pt,t−n,jk qjk (n) − µt µt−h ,           (4)
                                           j,k=1

for all t, n ∈ Z, where pt,t−n,jk = P (Zt ∈ Rj , Zt−n ∈ Rk ) and
                                                           ∞
                                                                      (j)
                                                           X
                           qjk (n) = µ1j µ1k + h(j) h(k)          (k)
                                                                 ψm   ψn+m ,               (5)
                                                           m=0

for j, k = 1, . . . , l.

Proof . See the Appendix.

    Moreno (2011) proposed an expression for this ACVF and provided a proof
for it. However, in the proof, some conditional probability measures are not well
established, there is a mistake in a probability statement, and only the case in
which the distribution of Zt is the same for all t was considered.
    Using the Chapman-Kolmogorov equations, we can show that the sequence of
two-dimensional random vectors {(Zt , Zt−n )} converges weakly to a two-dimensional
random vector with cdf Fn as t → ∞. Then, pt,t−n,jk → pn,jk = Fn (rj , rk ) −
Fn (rj , rk−1 ) − Fn (rj−1 , rk ) + Fn (rj−1 , rk−1 ) as t → ∞ and, consequently,
                      Pl                         2
Cov(Xt , Xt−n ) →       j,k=1 pn,jk qjk (n) − µ as t → ∞. Of course, if {Zt } has
identical univariate marginal distributions, the ACVF of {Xt } is given directly by
this limit form. We additionally note that E(Xt2 ) < ∞ for all t ∈ Z because of the
finiteness of the normal distribution second moment. The results obtained in the
above propositions provide us with evidence to state the following definition.
Definition 1. The TAR stochastic process {Xt } is said to be an asymptotic weak
stationary process if it satisfies the conditions given in Proposition 1.

Remarks. (1) If {Zt } has identical marginal univariate distributions, {Xt } is
weakly stationary. (2) We must be careful in trying to use this function for model
identification purposes, as in the case of linear ARMA processes. The reason is
that the usual ACVF only captures linear dependence and the process {Xt } is not
linear. (3) The usefulness of the computation of the ACVF in Proposition 2 is in
that it leads to the definition of the asymptotic weak stationarity of the process
{Xt }. (4) In future research, the analytical properties of this ACVF will be inves-
tigated, specifically for describing its mathematical properties and, in particular,
the rate of convergence towards zero (under ergodicity conditions).
    It is worth noticing that the limit form of expression (4) is an extension of the
ACVF of a linear stochastic process. Indeed, if l = 1, the only regime is the real
line R and setting h(1) = h, we obtain the limit form of the autocovariance in (4),
which is
                                     X∞
                                  h2      ψm ψn+m .
                                           m=0


                                            Revista Colombiana de Estadística 39 (2016) 149–165

154                                                     Fabio H. Nieto & Edna C. Moreno


This expression is Panalogous to the general form of the ACVF of a linear stochas-
                      ∞
tic process {Xt = i=0 ψi εt }, where the real-number sequence {ψi } is absolutely
summable and {εt } is a zero-mean white noise process with variance h2 (see
                                                                      Pk
Brockwell & Davis 1991). Obviously, in this particular case, Xt = i=1 ai Xt−i +
hεt , with k = k1 , and the roots of the polynomial φ(z) = 1 − a1 z − · · · − ak z k
are outside of the unit circle; that is, {Xt } is an AR(k) linear process. For future
reference, we put γ(n) = limt→∞ Cov(Xt , Xt−n ), for all n ∈ Z.


3.2. Univariate Conditional Distributions
    In the previous subsection, the first type of univariate conditional distribu-
tion emerged; namely when the conditioning set is the event Zt ∈ Rj (in the
σ-algebra F) for some j = 1, . . . , l. We have referred to this fact by stating that
the conditioning is “on the regime”Rj . As was seen there, under the conditions
in Proposition 1, the conditional distribution of Xt given the regime Rj is normal
with mean µ1j and variance σj2 for all t and for all j = 1, . . . , l. Also notice that,
under this scenario, the conditional variance function of the process {Xt } is given
by V ar(Xt | Rj ) = σj2 if at time t the observation zt ∈ Rj . This is a step function
that essentially depends on the variable-Z values.
     The second type of conditional distribution for the variable Xt occurs when
the conditioning set is x̃t−1 and theregime Rj , for some j = 1, . . . , l. Trivially,
this distribution is N µt−1,j , [h(j) ]2 , for all j = 1, . . . , l and for all t > max{kj |
                                   (j)  Pkj (j)
j = 1, . . . , l}, where µt−1,j = a0 + i=1     ai xt−i . Here, the conditional variance
function for the process {Xt } is V ar(Xt | x̃t−1 , Rj ) = [h(j) ]2 ) for t > max{kj | j =
1, . . . , l}. Clearly, Rj occurs at time t if and only if zt ∈ Rj . As in the previous
case, it is a step function that intrinsically depends on the values of variable Z.
Interestingly, under this conditional distribution, we can interpret the parameter
h(j) as a conditional standard deviation, j = 1, . . . , l.
    Now, we only consider x̃t−1 as the conditioning information set. In order
to formally establish the main results, we set the following notation: let N be
the set of natural numbers, Xt = (Xt , . . . , X1 ), P = P(N), the power set of N,
Ft = σ(B t × P), the σ-algebra generated by the cartesian product between the
t-dimensional Borelian σ-algebra and P, λt the Lebesgue measure on the mea-
surable space (Rt , B t ), µ the counting measure on the measurable space (N, P),
and P(Xt ,Jt ) the probability induced by (Xt , Jt ) on the product measure space
(Rt × N, Ft , λt × µ).

Proposition 3. Suppose that P(Xt ,Jt ) has a Radon-Nikodym derivative with re-
spect to the product measure λt × µ, then, (i) for all t > max{kj | j = 1, . . . , l},
the conditional distribution of Xt given x̃t−1 is a mixture of conditional normal
distributions and (ii) the conditional variance function of the process {Xt } is given
by
                                                                             2
                           l
                           X         h       l
                                          i2 X                 Xl
      Var(Xt | x̃t−1 ) =         pt,j h(j) +   pt,j µ2t−1,j −    pt,j µt−1,j  ,       (6)
                           j=1                j=1                 j=1



                                         Revista Colombiana de Estadística 39 (2016) 149–165

Univariate Conditional Distributions of a TAR Process                                155

for t > max{kj | j = 1, . . . , l}.

Proof . See the appendix.

   As in Propositions 1 and 2, Moreno (2011) and Moreno & Nieto (2014) proposed
and used in their applications the results shown in Proposition 3. However, no
formal analytic proof, such as the one presented here that is based on measure
theory, was made to support those important results. Because of this, some not-
well defined expressions were used in those papers.
     We note that independent of the TAR-model parameter values, we have that
the right-hand side of equality (6) is always nonnegative. Because pt,j ≈ pj for a t
that is large enough when {Xt } is asymptotically weak stationary, the approximate
               Pl
summand j=1 pj [h(j) ]2 in expression (6) can be interpreted as a communality
term in this type of conditional variance. It is very interesting to note that in the
context of Mixture Autoregressive Models (MAR), expression (6) is very similar
to Wong & Li’s (2000) conditional variance function and that our communality
term is analogous to their base-line conditional variance. It is worth noting that,
additionally on x̃t−1 , the function given by expression (6) depends on all the
regimes via the parameters pt,j and [h(j) ]2 , t > max{kj | j = 1, . . . , l} and j =
1, . . . , l. Hence, this function involves more information about the conditional
probabilistic mechanisms of the TAR process than the previous two.
  In the following section, we shall call the above three conditional distributions
Type I, Type II, and Type III, respectively.


4. Some Examples
   In order to illustrate the three types of univariate conditional distributions of a
TAR process and how the Type-III conditional distribution can explain the pres-
ence of large-value clusters in its sample paths, we present the following examples.


4.1. A Simulated Model
    We consider the TAR(2;1,1) model given by
                       
                          −0.5 − 0.6Xt−1 + εt            if Zt ≤ 0,
                 Xt =
                          0.9 − 0.7Xt−1 + 10.0εt         if Zt > 0,

where Zt = 0.5Zt−1 +at and {at } is a zero-mean Gaussian white noise process with
variance 1, which is independent of {εt }. Notice that {Zt } is a first-order Markov
chain and a strict stationary stochastic process. The length of the simulated time
series is 200. Figure 1 (top) shows the graph of the simulated time series {xt } and
clusters of large values can be seen.
   Since the roots of the polynomials φ1 (z) = 1 + 0.6z and φ2 (z) = 1 + 0.7z,
z ∈ C, are outside of the unit circle, the process {Xt } is weakly stationary. Now,
µ11 = −0.31 (rounding to two decimal digits) and µ12 = 0.53. Clearly, p1 =


                                      Revista Colombiana de Estadística 39 (2016) 149–165

156                                                                          Fabio H. Nieto & Edna C. Moreno

                                                     P∞           i i
p2 = 0.5, thus µ = E(Xt ) = 0.11. Because ψ1 (z) =      i=0 (−0.6) z and ψ2 (z) =
P ∞           i i  2               2
  i=0 (−0.7) z , σ̄1 = 1.56 and σ̄2 = 1.96. In this way, the Type-I conditional
variances are σ12 = 1.56 and σ22 = 196.08, and the marginal variance is Var(Xt ) =
99 for all t.

                                                       Time series
               40
               30
               20
               10
                0
              -10
              -20
              -30
              -40
              -50
                             25        50         75         100       125          150         175     20


                                                 Conditional variance
              59
              58
              57
              56
              55
              54
              53
              52
              51
              50
                        20        40        60      80      100      120      140         160     180   20



  Figure 1: Time series and Type-III conditional variance function for Example 1.


    As was signaled in the above remarks (2), (3), and (4) we have to be careful
with the interpretation and use of the ACVF of the process {Xt }. Here, and only
for theoretical illustration purposes, we describe the way in which this function
can be obtained. In order to do this, we need to compute the quantities pn,jk
and qjk (n) of expression (5), for j, k = 1, 2. Initially, we observe that q12 (n) =
−0.16+17.24(−0.7)n , q21 (n) = −0.16+17.24(−0.6)n , q11 (n) = 0.10+1.56(−0.6)n ,
and q22 (n) = 0.28 + 196.08(−0.7)n . To calculate pn,jk = P (Zt ∈ Rj , Zt−n ∈
Rk ), we remark that the process {Zt } is Gaussian; hence, all of its bivariate
distributions are multinormal and pn,jk is a double integral of the joint pdf on the
bidimensional set Rj × Rk . In this paper we do not compute these values. Thus,
        P2
γ(n) = j,k=1 pn,jk qjk (n) − 0.01 for all n ∈ Z.
    From the above results, the pdf of Xt , for all t, is given by f (x) = 0.5[f1 (x) +
f2 (x)], x ∈ R, where the pdf fj corresponds to a normal distribution with mean
µ1j and variance σj2 , j = 1, 2. The distribution of Xt , conditional on past data
up to t − 1 and a regime, is normal with mean −0.5 − 0.6xt−1 and variance 1 in
the first regime and mean 0.9 − 0.7xt−1 and variance 100 in the second. Now, the
Type-III conditional variance function is given by (rounding to two decimal digits)

               Var(Xt | x̃t−1 ) = 50.50 − 0.58xt−1 + 0.75x2t−1 , t ≥ 2.

Here, the communality value is 50.50 and, as we can see in Figure 1, the base line
for the Type-III conditional variance function is around that value. Furthermore,
we can see there that this function has local extreme values in the time periods
where large-value clusters of the simulated time series have occurred.


                                                  Revista Colombiana de Estadística 39 (2016) 149–165

Univariate Conditional Distributions of a TAR Process                                    157

4.2. Analysis of BOVESPA Index Returns
   In order to illustrate with financial data how well our proposed TAR model
might explain clusters of large values in a time series, we consider the daily
Dow Jones index (DJ) as the threshold variable and the daily BOVESPA in-
dex (Sao Paulo’s stock exchange) as the output variable. More exactly, we set
Xt = ln(BIt ) − ln(BIt−1 ) and Zt = ln(DJt ) − ln(DJt−1 ), where BI denotes the
BOVESPA index. The sample period is December 8, 2000-June 2, 2010 (2473 daily
data), and in Figure 2 we plot the BOVESPA and Dow Jones returns. Morettin
(2008) has undertaken extensive statistical analysis of the BOVESPA time series.
              0.125
              0.100
              0.075
              0.050
              0.025
              -0.000
              -0.025
              -0.050
              -0.075
              -0.100
                        250   500   750     1000   1250   1500   1750   2000   2250

              0.15

              0.10

              0.05

              0.00

              -0.05

              -0.10

              -0.15
                        250   500   750    1000    1250   1500   1750   2000   2250


            Figure 2: Dow Jones (top) and BOVESPA (bottom) returns.


  Using Nieto’s (2005) fitting approach, Moreno (2011) found the following
TAR(3;2,0,4) model for BOVESPA returns:
       
       
        −0.0127 + 0.1113Xt−1 − 0.0685Xt−2 + 0.0198εt if Zt ≤ −0.0054,
       6.81 × 10−4 + 0.0137ε if −0.0054 < Z ≤ 0.0057,
       
                              t               t
  Xt =
       
       
        0.0135 − 0.0837Xt−1 − 0.0684Xt−2 − 0.1687Xt−3
         −0.0633Xt−4 + 0.0191εt if 0.0057 < Zt .
       

Here, the thresholds are the percentiles 25 and 75 of the Dow Jones returns (which
is a strict stationary process); hence, p1 = p3 = 0.25 and p2 = 0.5. Since the
conditions in Proposition 1 are fulfilled, {Xt } is a weakly stationary process, as
expected. To obtain its marginal first two moments, we analyze the Type-I con-
ditional distributions. For the first regime, the expected return is µ11 = −1.32%
with s.d. of 2%; for the second, the expected return is µ12 = 0.07% with s.d.
of 1.41%; and for the third, BOVESPA has an expected return of µ13 = 0.97%
with s.d. of 2%. Then, the marginal expected return is −0.05% (the empirical is
0.058%) and its marginal standard deviation is 1.7% (empirical is 2%).
    Using the Type-II conditional distributions, we found that the conditional ex-
pected return at time t is 0.068% (constant) for the second regime, for the first
it depends on the past two data, and for the third, on the past four observations.

                                          Revista Colombiana de Estadística 39 (2016) 149–165

158                                                                    Fabio H. Nieto & Edna C. Moreno


The conditional variances in this case are 0.01982 , 0.01372 , and 0.01912 , indicat-
ing that there is more Type-II conditional variability in the first and third regime
(almost the same) than in the second regime.
    Conditioning by only using the information set x̃t−1 , we found that the Type-
III conditional variance function is given by

  Var(Xt | x̃t−1 ) = 0.0003 + 0.25µ2t−1,1 + 0.50µ2t−1,2 + 0.25µ2t−1,3
                                                  − (0.25µt−1,1 + 0.50µt−1,2 + 0.25µt−1,3 )2 ,

for each t > 4, where µt−1,1 = −0.0127 + 0.1113xt−1 − 0.0685xt−2 , µt−1,2 = 0.0007
(rounding to four decimal digits), and µt−1,3 = 0.0135−0.0837xt−1 −0.0684xt−2 −
0.1687xt−3 − 0.0633xt−4 .
Note. Moreno (2011) fitted the following GARCH model to BOVESPA returns:

                         Xt = 0.0012 − 0.0475Xt−3 + at ,
                         at = t σt ,
                                                              2
                         σt2 = 0.00001 + 0.0719a2t−1 + 0.8977σt−1 ,

where {t } is a zero-mean Gaussian white noise process with variance 1. We
computed the GARCH-model based conditional variance function and plotted it
jointly with the Type-III conditional variance function in Figure 3. Interestingly,
the two functions locally signal the large-value clusters in the BOVESPA returns by
means of their extreme values, although the GARCH-model function is smoother
than that of the TAR model. Additionally, we can observe that they have almost
the same base line. It is important to remark here that, by no means, are we
trying to compare the TAR and GARCH models. Our main motivation was only to
signal that the two conditional variance functions (obtained from two conceptually
different models) have, approximately, the same behavior.

                                                 TAR MODEL
                0.0008

                0.0007

                0.0006

                0.0005

                0.0004

                0.0003

                0.0002
                              250   500   750     1000   1250   1500   1750   2000   2250


                                                GARCH MODEL
                0.0040
                0.0035
                0.0030
                0.0025
                0.0020
                0.0015
                0.0010
                0.0005
                0.0000
                              250   500   750     1000   1250   1500   1750   2000   2250


          Figure 3: Conditional variance functions for BOVESPA returns.




                                                Revista Colombiana de Estadística 39 (2016) 149–165

Univariate Conditional Distributions of a TAR Process                                                                159

4.3. River Flow and Rainfall Time Series
    Nieto et al. (2013) fitted a TAR model to the daily rainfall (in mm.), as the
input or threshold variable, and the daily flow of the Bedon river (in m3 /sec),
as the output or target variable, in a geographical region on southern Colombia.
Specifically, the data were collected at a meteorological station with coordinates
2.23 north (latitude) and 76.23 west (longitude) and at a hydrological station
with coordinates 2.19 north and 76.15 west. These stations are located in the San
Rafael’s lagoon neighborhood. The sample period is January 1, 1992-November 30,
2000 (3256 data), and the data was assembled by IDEAM, the official Colombian
agency for hydrological and meteorological studies. In Figure 4, one can see the
two time series, where the relationship between the two variables is clear as it is
the presence of large-value clusters in the river flow time series.
                                                              (a)
                  64

                  56

                  48

                  40

                  32

                  24

                  16

                   8

                   0
                         250    500    750    1000    1250   1500   1750   2000   2250   2500   2750   3000   3250


                                                              (b)
                  22.5

                  20.0

                  17.5

                  15.0

                  12.5

                  10.0

                   7.5

                   5.0

                   2.5

                   0.0
                          250    500    750   1000    1250   1500   1750   2000   2250   2500   2750   3000   3250



            Figure 4: Rainfall (top) and river flow (bottom) time series.


    Let Pt and X̃t , respectively, be the rainfall and river flow at day t. Because
of the universal convention for measuring these two variables, we need to make
Zt = Pt−1 . As was suggested by Nieto (2005), the river flow variable needs two
transformations, namely- square root of the data and an adjustment for conditional
heteroscedasticity via an ARCH(1) model. We denote the adjusted river flow
variable as Xt . The two time series had missing data but they were estimated
using Nieto’s (2005) procedure. From now on, we work with the complete (or
interpolated) time series. The fitted model was a TAR(4;3,2,2,2) that is given by
           
           
           1.35 + 0.74Xt−1 − 0.27Xt−2 + 0.12Xt−3 + 1.30εt if Zt ≤ 6.0 ,
           
                          t−1 − 0.30Xt−2 + 1.66εt if 6.0 < Zt ≤ 10.3 ,
           1.96 + 0.75X
     Xt =
           
           
           2.11 +  0.80X t−1 − 0.28Xt−2 + 2.15εt if 10.3 < Zt ≤ 17.18 ,
            2.96 + 0.62Xt−1 − 0.35Xt−2 + 3.18εt if 17.18 < Zt .
           

   The stochastic dynamic of Zt was described by means of a first-order Markov
chain with identical univariate marginal distribution, which is given by fn (z) =

                                                     Revista Colombiana de Estadística 39 (2016) 149–165

160                                                                     Fabio H. Nieto & Edna C. Moreno


phn (z) + (1 − p)g(z), where p = P(Z = 0), g(·) denotes a truncated normal density
at z = 0 with mean 3.24 and variance 7.762 , and
                       
                        0,                        −∞ < z < −1/n
              hn (z) =    nπ/2[cos(nzπ + π/2)] , −1/n ≤ z ≤ 0
                       
                          0,                       z > 0,

with n a positive integer number (see Nieto’s (2005) paper for its interpretation).
Nieto et al. (2013) found that p1 = 0.60, p2 = 0.20, p3 = 0.12, and p4 = 0.08 for
all t.
    Using expression (6), we computed the conditional variance function of the river
flow process, which is plotted in Figure 5. As can be see there, and from a local
point of view, the time periods at which extreme values of both the conditional
variance and the time series occur are similar. The communality value is 2.93.
                                                   River flow
             22.5
             20.0
             17.5
             15.0
             12.5
             10.0
              7.5
              5.0
              2.5
              0.0
                       200    400    600    800    1000   1200   1400   1600   1800   2000   2200


                                            Conditional variance
             50

             40

             30

             20

             10

              0
                      200    400    600    800    1000    1200   1400   1600   1800   2000   2200


             Figure 5: Conditional variance function for the river flow.




5. Conclusions
    In this paper, we have characterized three types of univariate conditional dis-
tributions for a particular case of the open-loop TAR stochastic processes. We
have called them Type I, Type II, and Type III conditional distributions. In the
first type, the conditioning information set is a regime; in the second, the condi-
tioning set is constituted by past information of the output variable and a regime;
and in the third, the distribution is only conditional on the past information of
the output variable. As a by-product, we have found that there is a sufficient
condition to have asymptotic weak stationarity in the process and, under that
condition and the fact that the model white noise is Gaussian, the Type-I condi-
tional distribution is normal. The Type-III conditional distribution is a mixture
of normal distributions. Using some examples, we have illustrated the fact that
the Type-III conditional variance function can explain the presence of large-value
clusters in time series that obey the TAR model of this paper. An interesting


                                                 Revista Colombiana de Estadística 39 (2016) 149–165

Univariate Conditional Distributions of a TAR Process                              161

future investigation could be the ACVF characterization of these kinds of TAR
processes.


Acknowledgements
    The authors acknowledge the financial support given by DIB, the investigation
division of the Universidad Nacional de Colombia in Bogotá, under contract 16010.
Also, they are very grateful to the two anonymous referees for their important
comments and suggestions that allowed into substantially improve the paper.
                                                                
                  Received: September 2014 — Accepted: June 2015

Appendix
Proof of Proposition 1. Because for each j = 1, . . . , l the roots of the polynomial
               Pkj (j) i
φj (z) = 1 − i=1   ai z , z ∈ C are outside the unit circle, there is an inverse
                                           P∞ (j)                      (j)
operator of φj (B). Let ψj (B) = φj (B)−1 = i=0 ψi B i , with ψ0 = 1. Then,
for all x ∈ R,
                                           (j)
   Ft,j (x) = P (Xt ≤ x | Zt ∈ Rj ) = P (a0 ψj (1) + h(j) ψj (B)εt ≤ x | Zt ∈ Rj ).

Now, the random variable ψj (B)εt is well defined for all t and it has a normal
                                     P∞      (j)
distribution with mean 0 and variance i=0 [ψi ]2 = σ̄j2 , given Zt ∈ Rj or, more
precisely, Jt = j. Consequently,
                                                 (j)
                                        x − a0 ψj (1)
                Ft,j (x) = P (ψj (B)εt ≤              | Zt ∈ Rj )
                                            h(j)
                                              (j)
                             ψj (B)εt   x − a0 ψj (1)
                        = P(          ≤                | Zt ∈ Rj ).
                                σ̄j         h(j) σ̄j

This ends the proof.
Proof of Proposition 2. Initially, we note that from expression (2) and Propo-
                                                 Pl
sition 1, the mean function of {Xt } is E(Xt ) =   j=1 pt,j µ1j for all t, where


                                     Revista Colombiana de Estadística 39 (2016) 149–165

Univariate Conditional Distributions of a TAR Process                                            163

         (j)
µ1j = a0 ψj (1). Now, in order to obtain the autocovariance function of the
stochastic process {Xt }, we first obtain the bivariate cdf of variables Xt and Xt−h
for any integer numbers h and t, which we denote as Ft,t−h .
   Let (xt , xt−h ) ∈ R2 , then
 Ft,t−h (xt , xt−h ) = P (Xt ≤ xt , Xt−h ≤ xt−h )
                                                                             
                                                               l
                                                             \ [           
                     = PXt ,Xt−h     (−∞, xt ] × (−∞, xt−h ]       (Rj × Rk ) ,
                                                                             
                                                                               j,k=1

where PXt ,Xt−h is the probability measure induced by the random vector (Xt , Xt−h ).
Now, it is easy to show that {Rj × Rk : j, k = 1, . . . , l} constitutes a partition of
R2 because the regimes Rj , j = 1, . . . , l, constitute a partition of R. In this sense,
we can say that {Rj × Rk : j, k = 1, . . . , l} is the set of bidimensional regimes in
R2 . Hence,
                            l
                            X                  n                           \        o
   Ft,t−h (xt , xt−h ) =           PXt ,Xt−h        (−∞, xt ] × (−∞, xt−h ]     Rj × Rk .
                           j,k=1


   Equivalently,
                           l
                           X
  Ft,t−h (xt , xt−h ) =            P (Xt ≤ xt , Xt−h ≤ xt−h | Zt ∈ Rj , Zt−h ∈ Rk )
                           j,k=1

                                                                     × P (Zt ∈ Rj , Zt−h ∈ Rk ).
Let P (Zt ∈ Rj , Zt−h ∈ Rk ) = pt,t−h,jk for all j, k = 1, . . . , l and t ∈ Z and
       Ft,t−h;jk (xt , xt−h ) = P (Xt ≤ xt , Xt−h ≤ xt−h | Zt ∈ Rj , Zt−h ∈ Rk ),
then, we obtain that
                                            l
                                            X
                 Ft,t−h (xt , xt−h ) =              pt,t−h,jk Ft,t−h;jk (xt , xt−h ),
                                           j,k=1
      Pl
where j,k=1 pt,t−h,jk = 1. This means that the joint cdf of Xt and Xt−h is a
mixture of conditional bivariate cdf’s. Thus,
                               l
                               X
           E(Xt Xt−h ) =               pt,t−h,jk E(Xt Xt−h | Zt ∈ Rj , Zt−h ∈ Rk ).
                               j,k=1

                                                                   P∞ (j)
    Following the proof of Proposition 1, we obtain Xt = µ1j + h(j) s=0 ψs εt−s
               (j)                              P∞      (k)
if Zt ∈ Rj (ψ0 = 1), and Xt−h = µ1k + h(k) m=0 ψm εt−h−m if Zt−h ∈ Rk .
Then,
                                                                              ∞
                                                                                        (j)
                                                                              X
       E(Xt Xt−h | Zt ∈ Rj , Zt−h ∈ Rk ) = µ1j µ1k + h(j) h(k)                      (k)
                                                                                   ψm   ψh+m ,
                                                                             m=0


                                               Revista Colombiana de Estadística 39 (2016) 149–165

164                                                          Fabio H. Nieto & Edna C. Moreno


where, without loss of generality, we assumed that h > 0. Consequently,
                                                          ∞
                         l
                                                                      !
                                                                  (j)
                        X                                 X
        E(Xt Xt−h ) =       pt,t−h,jk µ1j µ1k + h(j) h(k)    (k)
                                                            ψm   ψh+m ,
                         j,k=1                                           m=0

and
                                                                      ∞
                      l
                                                                                       !
                                                                             (k) (j)
                      X                                               X
                                                         (j) (k)
  Cov(Xt , Xt−h ) =           pt,t−h,jk       µ1j µ1k + h   h               ψm  ψh+m
                      j,k=1                                           m=0
                                                                                                  
                                                                l
                                                                X                    l
                                                                                     X
                                                        −            pt,j µ1j           pt−h,j µ1j .
                                                                j=1                  j=1


      This completes the proof.
Proof of Proposition 3. Let t > max{kj | j = 1, . . . , l} be given, then we con-
sider x̃t−1 as a realization of the random vector Xt−1 . In order to use Billingsley’s
(1995) concept of a conditional probability measure, we set the following additional
notation and theoretical framework. Let (R, B) be the unidimensional Borel space,
λ the corresponding Lebesgue measure, and PJt the probability induced by Jt on
the measure space (N, P, µ). Finally, let PXt |x̃t−1 be the conditional probability
measure associated with Xt , given x̃t−1 , on the measure space (R, B, λ), PXt ,Jt |x̃t−1
be the conditional probability measure corresponding to the random vector (Xt , Jt )
given x̃t−1 on the product measure space (R × N, F1 , λ × µ), PXt |j,x̃t−1 the con-
ditional probability of Xt given j ∈ {1, . . . , l} and x̃t−1 on the measure space
(R, B, λ), and PJt |x̃t−1 the conditional probability of Jt given x̃t−1 on the measure
space (N, P, µ).
    Let g be the Radon-Nikodym derivative of P(Xt ,Jt ) with respect to λt × µ, then
g is a probability density function (pdf) of (Xt , Jt ) with respect to λt × µ. Using
Fubini’s theorem,                 Z
                              f (x) =         g(x, j)dµ(j), x ∈ Rt ,
                                          N

is a nonnegative Borel function on the measurable space (Rt , B t ) and integrable
w.r.t. λt . Now, let A ∈ B t and PXt be the induced probability of Xt on (Rt , B t );
then,
                             Z          Z
                                f dλt =     gd(λt × µ)
                                 A                A×N
                                              = P(Xt ,Jt ) (A × N)
                                              = PXt (A),

because of (Xt , Jt )−1 (A × N) = Xt −1 (A), with the exponent −1 denoting inverse
image. Hence, f is a pdf of Xt w.r.t. λt .
   Using Shao’s (2003, pp. 44) book and letting h be the pdf of Xt−1 w.r.t. λt−1 ,
we obtain that Xt | x̃t−1 has a pdf with respect to the Lebesgue measure on the
measurable space (R, B). This is given by


                                              Revista Colombiana de Estadística 39 (2016) 149–165

Univariate Conditional Distributions of a TAR Process                                       165



                                               f [(x, x̃t−1 )]
                            f (x | x̃t−1 ) =
                                                  h(x̃t−1 )
                                               Pl
                                                  j=1 g[(x, x̃t−1 ), j]
                                          =
                                                      h(x̃t−1 )

if h(x̃t−1 ) > 0.
    Again, using Shao’s (2003, pp. 44) result, we obtain that (Xt , Jt ) conditional
on x̃t−1 has a pdf w.r.t. the product measure λ × µ, g(x, j | x̃t−1 ) say. Then,
because of Shao’s (2003) Theorem 1.7, g[(x, x̃t−1 ), j] = g(x, j | x̃t−1 )h(x̃t−1 ). In
the same manner, we obtain that Xt | j, x̃t−1 and Jt | x̃t−1 have a pdf w.r.t. λ
and µ, respectively. Let them be g(x | j, x̃t−1 ) and k(j | x̃t−1 ), respectively. Then,
g(x, j | x̃t−1 ) = g(x | j, x̃t−1 )k(j | x̃t−1 ), where k(j | x̃t−1 ) = PJt |x̃t−1 ({j}). Since
Zt (consequently Jt ) is independent of Xt−1 , PJt |x̃t−1 ({j}) = PJt ({j}) = pt,j . In
this way,
                                             X l
                            f (x | x̃t−1 ) =      pt,j g(x | j, x̃t−1 ),
                                               j=1

where, for each j = 1, . . . , l, g(x | j, x̃t−1 ) is the pdf of the N (µt−1,j , [h(j) ]2 ). Now,
Var(Xt | x̃t−1 ) = E(Xt2 | x̃t−1 ) − (E(Xt | x̃t−1 ))2 . This completes the proof.




                                          Revista Colombiana de Estadística 39 (2016) 149–165
References
Billingsley P. Probability and Measure.(1995). John Wiley and Sons.
Bollerslev T. Generalized autoregressive conditional heteroskedasticity.(1986). Journal of Econometrics.
Brockwell P, Davis R. Time Series: Theory and Methods.(1991). Springer-Verlag.
Chen R, Tsay R. On the ergodicity of TAR(1) processes.(1991). The Annals of Applied Probability.
Engle R. Autoregressive conditional heteroscedasticity with estimates of the variance of the United Kingdom inflation.(1982). Econometrica.
Hoyos N. Una aplicación del modelo no lineal tar en economía.(2006). Universidad Nacional de Colombia.
Li D, Ling S, Tong H. On moving-average models with feedback.(2012). Bernoulli.
Moreno E. Una aplicación del modelo tar en series de tiempo financieras.(2011). Universidad Nacional de Colombia.
Moreno E, Nieto F. Modelos TAR en series de tiempo financieras.(2014). Comunicaciones en Estadística.
Morettin P. Econometria Financeira-Um Curso em Séries Temporais Financeiras.(2008). Editora Blucher.
Nieto F. Modeling Bivariate Threshold Autoregressive Processes in the Presence of Missing Data.(2005). Communications in Statistics - Theory and Methods.
Nieto F. Forecasting with univariate TAR models.(2008). Statistical Methodology.
Nieto F, Zhang H, Li W. Using the Reversible Jump MCMC procedure for identifying and estimating univariate TAR models.(2013). Communications in Statistics: Simulation and Computation.
Petruccelli J, Woolford S. A Threshold AR(1) Model.(1984). Journal of Applied Probability.
Shao J. Mathematical Statistics.(2003). Springer-Verlag. 
Tong H. On a threshold model.(1978)..Amsterdam.
Tong H. Nonlinear Time Series.(1990).Oxford University Press.
Tong H. Threshold models in time series analysis-30 years on.(2011). Statistics and Its Interface.
Tsay R. Testing and modeling multivariate threshold models.(1998). Journal of the American Statistical Association.
Wong C, Li W. On a mixture autoregressive model.(2000). Journal of the Royal Statistical Society.