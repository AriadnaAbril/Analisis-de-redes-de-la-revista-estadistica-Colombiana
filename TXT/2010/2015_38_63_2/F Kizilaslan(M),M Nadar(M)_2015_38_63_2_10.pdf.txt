Classical and Bayesian Estimation of Reliability in Multicomponent Stress-Strength Model Based on Weibull Distribution. Estimaci√≥n cl√°sica y bayesiana de la confiabilidad de un modelo estr√©s-fuerza basado en la distribuci√≥n Weibull
Gebze Technƒ±cal Unƒ±versƒ±ty, Kocaelƒ±, Turkey. Istanbul Technƒ±cal Unƒ±versƒ±ty, Istanbul, Turkey
Abstract
In this study, we consider a multicomponent system which has k independent and identical strength components X1 , . . . , Xk and each component is exposed to a common random stress Y when the underlying distributions are Weibull. The system is regarded as operating only if at least s out of k (1 ‚â§ s ‚â§ k) strength variables exceeds the random stress. We estimate the reliability of the system by using frequentist and Bayesian approaches. The Bayes estimate of the reliability has been developed by using Lindley‚Äôs approximation and the Markov Chain Monte Carlo methods due to the lack of explicit forms. The asymptotic confidence interval and the highest probability density credible interval are constructed for the reliability. The comparison of the reliability estimators is made in terms of the estimated risks by the Monte Carlo simulations.
Key words: Stress-Strength Model, System Reliability, Weibull Distribution.
Resumen
En este estudio, consideramos un sistema multicomponente con k componentes de fuerzaindependientes y cada componente expuesto a un estr√©s com√∫n aleatorio Y cuando seconsidera una distribuci√≥n Bernoulli. El sistema se considera operativo si por lo menos s de los k (1 ‚â§ s ‚â§ k) exceden el estr√©s aleatorio. Se estima la confiabilidad del sistema usando m√©todos bayesianos y frecuentistas. La estimaci√≥n de Bayes de la confiabilidad ha sido desarrollada usando una aproximaci√≥n de Lindley y m√©todos MCMC debido a la falta de formas expl√≠citas. El intervalo de confianza asint√≥tico y el intervalo de la densidad deprobabilidad m√°s alta se construyen para la confiabilidad. La comparaci√≥n de los estimadores de confiabilidad se hace en t√©rmino de los riesgos estimados por medio de simulaciones Monte Carlo.
Palabras clave: distribuci√≥n Weibull, modelo estr√©s-fuerza, sistema de confiabilidad.

1. Introduction

    In the reliability context, the stress-strength model can be described as an
assessment of reliability of a system in terms of random variables X representing
stress experienced by the system and Y representing the strength of the system
available to overcome the stress. If the stress exceeds the strength, then the
system will fail. Thus R = P (X < Y ) is the reliability of a system. The main
idea was introduced by Birnbaum (1956) and developed by Birnbaum & McCarty
(1958). Estimation of R = P (X < Y ) when the random variables X and Y
follow a specified distribution has been extensively discussed by many authors in
the literature. When the X and Y are independent and follow the generalized
exponential, Weibull, three-parameter Weibull and Kumaraswamy distributions,
the estimation of R was studied by Kundu & Gupta (2005), Kundu & Gupta
(2006), Kundu & Raqab (2009) and Nadar, Kizilaslan & Papadopoulos (2014),
respectively. Kotz, Lumelskii & Pensky (2003) provide an excellent review of the
development of the stress-strength up to the year 2003.
    The reliability in a multicomponent stress-strength model was developed by
Bhattacharyya & Johnson (1974). This system consists of k independent and
identical strengths component and a common stress, functions when s (1 ‚â§ s ‚â§ k)
or more of the components simultaneously survive. This model corresponds to the
s-out-of-k : G system. Its practical applications range from communication and
industrial systems to logistic and military systems. For example, in suspension
bridges, the deck is supported by a series of vertical cables hung from the towers.
Suppose a suspension bridge consisting of k number of vertical cable pairs. The
bridge will only survive if a minimum s number of vertical cable through the
deck is not damaged when subjected to stresses due to wind loading, heavy trafic,
corrosion, etc. As another example, with a V-8 engine of an automobile it may be
possible to drive the car if only four cylinders are firing. However, if less than four
cylinders fire, then the automobile cannot be driven. Thus, the functioning of the
engine may be represented by a 4-out-of-8 : G system. Other examples include
an electrical power station containing eight generating units which produce the
right amount of electricity only if at least 6 units are working; the demand of the
electricity of a district is fulfilled only if s-out-of-k wind rose are operating at all
times; a communication system for a navy can be successful only if 6 transmitters
out of 10 are operational to cover a district; a semi-trailer pulled by a truck can


                                      Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

Multicomponent Stress-Strength for Weibull Distribution                              469

be driven safely as long as 6-out-of-8 tires are in good condition. For an extensive
reviews of s-out-of-k and related systems see Kuo & Zuo (2003).
    Let Y, X1 , . . . , Xk be independent, G(y) be the cumulative distribution func-
tion (cdf) of Y and F (x) be the common cdf of X1 , . . . , Xk . The reliability in a
multicomponent stress-strength model is given by

                Rs,k = P (at least s of the (X1 , . . . , Xk ) exceed Y )
                        k       Z ‚àû
                       X      k                                                      (1)
                     =                  (1 ‚àí F (y))i (F (y))k‚àíi dG(y).
                               i    ‚àí‚àû
                         i=s


This reliability can be written as P (Xk‚àís+1:k > Y ) where Xk‚àís+1:k is (k ‚àí s + 1)
the order statistics of (X1 , . . . , Xk ). This system reliability was considered by Jae
& Eun (1981), when the stress and the strength distributions are Weibull with un-
known scale parameters and the same known shape parameter. The maximum like-
lihood estimation (MLE) and the minimum variance unbiased estimation of system
reliability were obtained in this study. The system reliability was considered by
Hanagal (1999), when (X1 , . . . , Xk ) follow an absolutely continuous multivariate
exponential distribution and Y follows an independent exponential distribution.
Estimation of system reliability which is given as R = P (Xk+1 < min(X1 , . . . , Xk ))
under the assumption of the strengths of the k components (X1 , . . . , Xk ) are sub-
jected to an independent common stress Xk+1 was considered by Hanagal (2003)
when (X1 , . . . , Xk+1 ) follow (k + 1) independent of Gamma or Weibull or Pareto
distributions. The stress-strength reliability of a system which has n independent
components each consisting of m dependent elements was considered by Eryilmaz
(2008). The reliability of stress-strength for a general coherent system was studied
by Eryilmaz (2010). Recently, estimation of reliability in multicomponent stress-
strength for the log-logistic, generalized exponential, generalized inverted exponen-
tial, Rayleigh, inverse Rayleigh and Burr Type XII distributions were considered
by Rao & Kantam (2010), Rao (2012a), Rao (2012b), Rao (2012c), Rao, Kantam,
Rosaiah & Reddy (2013) and Rao, Aslam & Kundu (2014), respectively. In these
studies, maximum likelihood (ML), moment estimates and asymptotic confidence
interval for the reliability in multicomponent stress-strength were obtained, but
Bayesian approach was not taken into consideration.
    In this study, we consider the multicomponent stress-strength model which
has k independent and identical strength components and a common stress. We
assume that the strength variables and stress variable follow Weibull distribution.
The system functions if s (1 ‚â§ s ‚â§ k) or more of the components simultaneously
operate. The estimation of reliability for this system is obtained under the classical
and Bayesian frameworks. The Lindley‚Äôs approximation and Markov Chain Monte
Carlo (MCMC) technique are carried out to obtain the Bayes estimates. Moreover,
the asymptotic confidence and the highest probability density (HPD) credible
intervals are obtained.
   A Weibull distribution with the shape parameter œÉ and scale parameter Œ∏ will
be denoted by W E(œÉ, Œ∏). The probability density function (pdf) and the cdf of a
random variable X ‚àº W E(œÉ, Œ∏) are given as


                                      Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

470                                                               Fatih Kizilaslan & Mustafa Nadar


                                                          œÉ
                      f (x; œÉ, Œ∏) = œÉŒ∏xœÉ‚àí1 e‚àíŒ∏x , x > 0, Œ∏, œÉ > 0,                              (2)
and                                                   œÉ
                        F (x; œÉ, Œ∏) = 1 ‚àí e‚àíŒ∏x , x > 0, Œ∏, œÉ > 0.                               (3)
   The rest of the paper is organized as follows. In Section 2, the MLE and the
asymptotic confidence interval of Rs,k are obtained when the parameters Œ±, Œ≤ and
œÉ are unknown. In Section 3, the Bayes estimates of Rs,k are obtained by using
Lindley‚Äôs approximation and MCMC method when the parameters Œ±, Œ≤ and œÉ have
independent Gamma priors. The HPD credible interval for Rs,k is also constructed.
In Section 4, a simulation study is performed to compare the estimates of Rs,k by
using Monte Carlo simulations and findings are illustrated by tables and plots.
Finally, we conclude the paper in Section 5.


2. Maximum Likelihood Estimation of Rs,k
    In our case, we assume that X1 , . . . , Xk be a random sample from Weibull
distribution with parameters (œÉ, Œ±) and Y be a random variable from Weibull
distribution with parameters (œÉ, Œ≤). Therefore, for our case Rs,k is given by using
equations (1)-(3)
                 k            Z ‚àû
               X       k                      œÉ                 œÉ
        Rs,k =               Œ≤œÉ      y œÉ‚àí1 e‚àíy (Œ±i+Œ≤) (1 ‚àí e‚àíŒ±y )k‚àíi dy
                        i         0
                i=s
                 k           Z ‚àû
               X       k
             =               Œ≤      e‚àíu(Œ±i+Œ≤) (1 ‚àí e‚àíŒ±u )k‚àíi du, where u = y œÉ
                        i       0
                i=s
                 k Xk‚àíi                         Z ‚àû                         (4)
               X           k        k‚àíi          j         ‚àíu(Œ±i+Œ±j+Œ≤)
             =                              (‚àí1) Œ≤       e             du
                           i         j               0
                  i=s j=0
                    k‚àíi 
                  k X
                                                        (‚àí1)j Œ≤
                                 
                  X       k    k‚àíi
              =                                                     .
                            i              j        [Œ± (i + j) + Œ≤]
                  i=s j=0

    In order to obtain the estimators of Rs,k , suppose that n systems are put
on life-testing experiment. In this case, we obtain the following observed data
Xi1 , Xi2 , . . . , Xik and Yi , i = 1, . . . , n. Then, the likelihood function of the ob-
served sample is given as
                                     Ô£´              Ô£∂
                                  Yn   Y k
            L(Œ±, Œ≤, œÉ; x, y) =       Ô£≠ f (xij )Ô£∏ g(yi )
                                i=1       j=1
                                                              "       (      n
                                                                                           )#
                                                                             X
                            = œÉ n(k+1) Œ±nk Œ≤ n exp (œÉ ‚àí 1) x‚àó +                    ln yi        (5)
                                                                             i=1
                                      "               n
                                                                  #
                                                      X
                            √ó exp ‚àíŒ±xœÉ ‚àí Œ≤                    yiœÉ ,
                                                      i=1



                                               Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

Multicomponent Stress-Strength for Weibull Distribution                                                      471

and the log-likelihood function is
                                                                                   (       n
                                                                                                         )
                                                                                           X
                                                                                       ‚àó
   l(Œ±, Œ≤, œÉ; x, y) = n(k + 1) ln œÉ + nk ln Œ± + n ln Œ≤ + (œÉ ‚àí 1) x +                             ln yi
                                                                                           i=1
                                    n
                                    X
                      ‚àí Œ±xœÉ ‚àí Œ≤           yiœÉ ,
                                    i=1
             Pn       Pk                             Pn       Pk
where x‚àó =      i=1     j=1 ln xij and xœÉ =             i=1
                                                                       œÉ
                                                                  j=1 xij . The MLEs of Œ±, Œ≤ and œÉ
are given by
                                             nk b       n
                                     b=
                                     Œ±           , Œ≤= P
                                                      n      .                                               (6)
                                             XœÉb
                                                        YiœÉb
                                                            i=1

The MLE of œÉ, œÉ
              b is the solution of the following nonlinear equation
                  n   k                       n                   n
   n(k + 1) nk X X œÉb                  n X œÉb                ‚àó
                                                                 X
           ‚àí             xij ln xij ‚àí P
                                      n          yi ln yi + x  +     ln yi = 0.                              (7)
      œÉ      xœÉb i=1 j=1
                                        yiœÉb i=1
      b                                                          i=1
                                                  i=1

Therefore, œÉ
           b can be obtained as a solution of the nonlinear equation of the form
H(œÉ) = œÉ where
                           Ô£Æ                                                                Ô£π‚àí1
                             n X k                        n                      n
                       Ô£Ø nk X                       n X œÉ
                                                                                                             (8)
                                                                                X
                                      œÉ                                     ‚àó
                                                                                          Ô£∫
       H(œÉ) = n(k + 1) Ô£Ø
                       Ô£∞ xœÉ         x ij ln x ij + n         y i ln y i ‚àí x   ‚àí     ln yi Ô£∫
                                                                                          Ô£ª        .
                                                     yiœÉ i=1
                                                   P
                            i=1 j=1                                             i=1
                                                        i=1

Since, œÉ
       b is a fixed point solution of the nonlinear equation (8), its value can be
obtained using an iterative scheme as:

                                          œÉ(j+1) = H(œÉ(j) ),

where œÉ(j) is the jth iterate of œÉ
                                 b. The iteration procedure should be stopped when
 œÉ(j) ‚àí œÉ(j+1) is sufficiently small. When we obtain œÉ b, the MLEs of Œ± and Œ≤ are
obtained from equation (6). Hence, the MLE of Rs,k is obtained from equation
(4) by using the invariance property of MLE‚Äôs
                                 k‚àíi 
                               k X
                                                                        (‚àí1)j Œ≤b
                                              
                               X       k    k‚àíi
                   bs,k =
                   R                                              h                 i.                       (9)
                                            i           j             b (i + j) + Œ≤b
                                                                      Œ±
                               i=s j=0



2.1. Asymptotic Distribution and Confidence Interval for Rs,k
   The Fisher information matrix of Œ∏ = (Œ∏1 , Œ∏2 , Œ∏3 ) ‚â° (Œ±, Œ≤, œÉ) is given as
           Ô£´     2         2          2  Ô£∂
                  ‚àÇ l         ‚àÇ L           ‚àÇ L
              E ‚àÇŒ±   2    E ‚àÇŒ±‚àÇŒ≤       E ‚àÇŒ±‚àÇœÉ               Ô£´
                                                                I11 I12 I13
                                                                                Ô£∂
           Ô£¨     2         2          2  Ô£∑
                   ‚àÇ L
  I(Œ∏) = ‚àí Ô£¨ E ‚àÇŒ≤‚àÇŒ±       E ‚àÇ‚àÇŒ≤L2           ‚àÇ L
                                       E ‚àÇŒ≤‚àÇœÉ          Ô£∑ = Ô£≠ I21 I22 I23 Ô£∏ .
           Ô£¨                                           Ô£∑
                                                                I31 I32 I33
           Ô£≠     2         2          2  Ô£∏
                   ‚àÇ L        ‚àÇ L
              E ‚àÇœÉ‚àÇŒ±      E ‚àÇœÉ‚àÇŒ≤       E ‚àÇ‚àÇœÉL2


                                                Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

472                                                              Fatih Kizilaslan & Mustafa Nadar


The elements of the matrix are obtained as I11 = nk/Œ±2 , I22 = n/Œ≤ 2 , I33 =
                                                                         2
n/Œ±2 , I12 = I21 = 0. When X ‚àº W E(œÉ, Œ±), E(X œÉ ln X) and E(X œÉ (ln X) ) are
evaluated by using the formulas 4.352(1) and 4.358(2) in Gradshteyn & Ryzhik
(1994)
                   Z ‚àû
                                            Œ± ‚àû                   œà(2) ‚àí ln Œ±
                                              Z
                         2œÉ‚àí1 ‚àíŒ±xœÉ
       œÉ
 E(X ln X) = Œ±œÉ        x     e     ln xdx =       u ln ue‚àíŒ±u du =             ,
                    0                       œÉ  0                      œÉŒ±
                                    Z ‚àû                                             2
                       Œ±2                                (œà(2) ‚àí ln Œ±) + Œæ(2, 2)
                                                          2
              œÉ
        E(X (ln X) ) = 2                    ue‚àíŒ±u (ln u) du =                    ,
                      œÉ            0                               œÉ2 Œ±
                    d
                                                          P‚àû
where œà(x) = dx        ln Œì(x) is Psi function, Œæ(z, q) = n=0 1/(q + n)z , Re z > 1,
qP6= 0, ‚àí1, ‚àí2, . . . is a series representation of Riemann Zeta function and Œæ(2, 2) =
   ‚àû               2        2
   n=0 1/(2 + n) = (œÄ /6) ‚àí 1. Similarly, when Y ‚àº W E(œÉ, Œ≤),

                                                                                    2
                            œà(2) ‚àí ln Œ≤                2    (œà(2) ‚àí ln Œ≤) + Œæ(2, 2)
        E(Y œÉ ln Y ) =                  , E(Y œÉ (ln Y ) ) =                         .
                                œÉŒ≤                                    œÉ2 Œ≤

Hence, the other elements of the information matrix are given as
                                      k
                                    n X
                                    X
                                                 œÉ               nk
                  I13 = I31 =                 E(Xij ln Xij ) =      (œà(2) ‚àí ln Œ±) ,
                                    i=1 j=1
                                                                 œÉŒ±

                                          n
                                         X                    n
                    I23 = I32 =              E(TiœÉ ln Ti ) =    (œà(2) ‚àí ln Œ≤) ,
                                         i=1
                                                             œÉŒ≤

                      n X k                            n
        n(k + 1)     X
                                 œÉ           2
                                                     X                 2
I33 =            + Œ±         E(Xij (ln X ij )  ) + Œ≤     E(YiœÉ (ln Yi ) )
           œÉ2        i=1 j=1                         i=1
        n(k + 1) nk    n
                                       2
                                                     o    n n                  2
                                                                                           o
      =          +       (œà(2) ‚àí ln Œ±)   +  Œæ(2,  2)   +      (œà(2)  ‚àí   ln Œ≤)   + Œæ(2, 2)   .
           œÉ2      œÉ2                                    œÉ2
                  bs,k is asymptotically normal with mean Rs,k and variance
The MLE of Rs,k , R
                                                3
                                              3 X
                                 2
                                              X   ‚àÇRs,k ‚àÇRs,k        ‚àí1
                                œÉR     =                            Iij ,
                                   s,k
                                              j=1 i=1
                                                        ‚àÇŒ∏i   ‚àÇŒ∏j

       ‚àí1
where Iij is the (i, j)th element of the inverse of the I(Œ∏), see Rao (1965). Then,
                                   2                                             2
              2             ‚àÇRs,k         ‚àí1      ‚àÇRs,k ‚àÇRs,k ‚àí1            ‚àÇRs,k         ‚àí1
             œÉR     =                    I11 +2              I +                         I22 ,   (10)
                s,k
                             ‚àÇŒ±                    ‚àÇŒ± ‚àÇŒ≤ 12                  ‚àÇŒ≤

where
                           k Xk‚àíi 
                                               (‚àí1)j+1 Œ≤(i + j)
                                           
                  ‚àÇRs,k   X         k    k‚àíi
                        =                                       2 ,                              (11)
                   ‚àÇŒ±               i     j     [Œ± (i + j) + Œ≤]
                          i=s j=0


                                                Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

Multicomponent Stress-Strength for Weibull Distribution                                     473

and
                           k Xk‚àíi 
                                                (‚àí1)j Œ±(i + j)
                                           
                  ‚àÇRs,k   X         k    k‚àíi
                        =                                      2.                          (12)
                   ‚àÇŒ≤               i     j    [Œ± (i + j) + Œ≤]
                          i=s j=0

Therefore, an asymptotic 100(1 ‚àí Œ≥)% confidence interval of Rs,k is given by
                                                   
                          Rs,k ‚àà R bs,k ¬± zŒ≥/2 œÉ
                                               bRs,k ,

where zŒ≥/2 is the upper Œ≥/2th quantile of the standard normal distribution and
bRs,k is the value of œÉRs,k at the MLE of the parameters.
œÉ


3. Bayes Estimation of Rs,k
   In this section, we assume that all parameters Œ±, Œ≤ and œÉ are unknown and
have independent Gamma prior distributions with parameters (ci , di ), i = 1, 2, 3,
respectively. The pdf of a Gamma random variable X with parameters (Œ±, Œ≤) is
                                      Œ≤ Œ± Œ±‚àí1 ‚àíxŒ≤
                       f (x) =            x  e    , x > 0, Œ±, Œ≤ > 0.
                                     Œì(Œ±)
Then, the joint posterior density function of Œ±, Œ≤ and œÉ is

      œÄ(Œ±, Œ≤, œÉ |x, y ) = I(x, y)Œ±nk+c1 ‚àí1 Œ≤ n+c2 ‚àí1 œÉ n(k+1)+c3 ‚àí1 e‚àíŒ±(xœÉ +d1 )
                           (       n
                                               !                      n
                                                                              !)
                                  X
                                       œÉ                        ‚àó
                                                                     X                     (13)
                        exp ‚àíŒ≤       yi + d2 ‚àí œÉ d3 ‚àí x ‚àí               ln yi    ,
                                       i=1                              i=1

where
                  ‚àí1         Z ‚àû                                         Pn
      [I(x, y)]                        œÉ n(k+1)+c3 ‚àí1 exp {‚àíœÉ (d3 ‚àí x‚àó ‚àí i=1 ln yi )}
                        =                              nk+c1 Pn
                                                                                      dœÉ.
  Œì(nk + c1 )Œì(n + c2 )          0          (xœÉ + d1 )      ( i=1 yiœÉ + d2 ) n+c2
Then, the Bayes estimator of Rs,k under the SE loss function is given by
                       Z ‚àûZ ‚àûZ ‚àû
              R
              bs,k,B =               Rs,k œÄ(Œ±, Œ≤, œÉ |x, y ) dŒ± dŒ≤ dœÉ.                      (14)
                             0        0      0

It is not possible to compute equation (14) analytically. Two approaches can
be applied to approximate equation (14), namely, Lindley‚Äôs approximation and
MCMC method.


3.1. Lindley‚Äôs Approximation
    Lindley (1980) introduced an approximate procedure for the computation of
two integrals. This procedure employed to the posterior expectation of the function
U (Œª), for a given x, is

                                          u(Œª)eQ(Œª) dŒª
                                        R
                          E(u(Œª) |x ) = R Q(Œª)         ,
                                            e     dŒª

                                             Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

474                                                          Fatih Kizilaslan & Mustafa Nadar


where Q(Œª) = l(Œª) + œÅ(Œª), l(Œª) is the logarithm of the likelihood function and
œÅ(Œª) is the logarithm of the prior density of Œª. Using the Lindley‚Äôs approximation,
E(u(Œª) |x ) is approximately estimated by
                Ô£Æ                                                                   Ô£π
                      1 XX                          1 XXXX
 E(u(Œª) |x ) = Ô£∞u +            (uij + 2ui œÅj )œÉij +                 Lijk œÉij œÉkl ul Ô£ª
                      2 i j                         2 i j
                                                                        k     l
                                                                                            Œª
                                                                                            b
                                     ‚àí2
                + terms of order n        or smaller,

                                                              b is the MLE of Œª, u = u(Œª),
where Œª = (Œª1 , Œª2 , . . . , Œªm ), i, j, k, l = 1, . . . , m, Œª
ui = ‚àÇu/‚àÇŒªi , uij = ‚àÇ 2 u/‚àÇŒªi ‚àÇŒªj , Lijk = ‚àÇ 3 l/‚àÇŒªi ‚àÇŒªj ‚àÇŒªk , œÅj = ‚àÇœÅ/‚àÇŒªj , and œÉij =
(i, j)th element in the inverse of the matrix {‚àíLij } all are evaluated at the MLE
of the parameters.
      For the three parameter case Œª = (Œª1 , Œª2 , Œª3 ), Lindley‚Äôs approximation leads
to

      u
      bB    = E(u(Œª) |x ) = u + (u1 a1 + u2 a2 + u3 a3 + a4 + a5 )
                                                                             
                1 A(u1 œÉ11 + u2 œÉ12 + u3 œÉ13 ) + B(u1 œÉ21 + u2 œÉ22 + u3 œÉ23 )
              +                                                                 ,
                2                 +C(u1 œÉ31 + u2 œÉ32 + u3 œÉ33 )

             b = (Œª
evaluated at Œª         b2 , Œª
                  b1 , Œª    b3 ), where


                          ai = œÅ1 œÉi1 + œÅ2 œÉi2 + œÅ3 œÉi3 , i = 1, 2, 3,
                                                        1
           a4 = u12 œÉ12 + u13 œÉ13 + u23 œÉ23 , a5 =        (u11 œÉ11 + u22 œÉ22 + u33 œÉ33 ),
                                                        2
        A = œÉ11 L111 + 2œÉ12 L121 + 2œÉ13 L131 + 2œÉ23 L231 + œÉ22 L221 + œÉ33 L331 ,

        B = œÉ11 L112 + 2œÉ12 L122 + 2œÉ13 L132 + 2œÉ23 L232 + œÉ22 L222 + œÉ33 L332 ,

        C = œÉ11 L113 + 2œÉ12 L123 + 2œÉ13 L133 + 2œÉ23 L233 + œÉ22 L223 + œÉ33 L333 .
In our case, for (Œª1 , Œª2 , Œª3 ) ‚â° (Œ±, Œ≤, œÉ) and u ‚â° u(Œ±, Œ≤, œÉ) = Rs,k as given in
equation (4), we have

                     (c1 ‚àí 1)             (c2 ‚àí 1)             (c3 ‚àí 1)
              œÅ1 =            ‚àí d1 , œÅ2 =          ‚àí d2 , œÅ3 =          ‚àí d3 ,
                         Œ±                    Œ≤                    œÉ

                                             nk          n
                                  L11 = ‚àí       , L22 = ‚àí 2 ,
                                             Œ±2          Œ≤
                                  k
                                n X
                                X                                       n
                                                                        X
              L13 = L31 = ‚àí               xœÉij ln xij , L23 = L32 = ‚àí         yiœÉ ln yi ,
                                i=1 j=1                                 i=1

                                      n X k                         n
                        n(k + 1)     X
                                               œÉ             2
                                                                   X               2
              L33 = ‚àí            ‚àí Œ±         x ij (ln x ij )   ‚àí Œ≤     yiœÉ (ln yi ) ,
                           œÉ2        i=1 j=1                       i=1


                                           Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

Multicomponent Stress-Strength for Weibull Distribution                                                            475

œÉij , i, j = 1, 2, 3 are obtained by using Lij , i, j = 1, 2, 3 and
                                            2nk          2n
                                  L111 =       3
                                                 , L222 = 3 ,
                                             Œ±           Œ≤
                           n X
                           X k                                                       n
                                                                                     X
                                                      2                                                       2
      L133 = L331 = ‚àí                 xœÉij (ln xij ) , L233 = L322 = ‚àí                     yiœÉ (ln yi ) ,
                            i=1 j=1                                                  i=1
                                        n X
                                          k                              n
                      2n(k + 1)         X                3
                                                                         X    3
            L333 =              ‚àíŒ±         xœÉij (ln xij ) ‚àí Œ≤     yiœÉ (ln yi ) .
                         œÉ3        i=1 j=1                    i=1

Moreover, u3 = ‚àÇRs,k /‚àÇœÉ = 0, u13 = u23 = u31 = u32 = u33 = 0 and u1 , u2 are
given in equations (11), (12) and
                      k Xk‚àíi 
          ‚àÇ 2 Rs,k                        (‚àí1)j+1 (i + j) [Œ±(i + j) ‚àí Œ≤]
                                      
                     X         k    k‚àíi
   u12 =           =                                            3        , (15)
          ‚àÇŒ±‚àÇŒ≤                 i     j          [Œ± (i + j) + Œ≤]
                     i=s j=0

                                 k Xk‚àíi 
                     ‚àÇ 2 Rs,k                        (‚àí1)j 2Œ≤(i + j)2
                                                 
                                X         k    k‚àíi
             u11 =        2
                              =                                      3 ,                                          (16)
                       ‚àÇŒ±                 i     j     [Œ± (i + j) + Œ≤]
                                i=s j=0
                              k Xk‚àíi 
                  ‚àÇ 2 Rs,k                        (‚àí1)j+1 2Œ±(i + j)
                                              
                             X         k    k‚àíi
            u22 =          =                                      3 .                                             (17)
                    ‚àÇŒ≤ 2     i=s j=0
                                       i     j     [Œ± (i + j) + Œ≤]
Hence,
                                         1
                                           (u11 œÉ11 + u22 œÉ22 ),
                         a4 = u12 œÉ12 , a5 =
                                         2
A = œÉ11 L111 +œÉ33 L331 , B = œÉ22 L222 +œÉ33 L332 , C = 2œÉ13 L133 +2œÉ23 L233 +œÉ33 L333 .
Then, the Bayes estimator of Rs,k is
               bs,k,B = Rs,k + [u1 a1 + u2 a2 + a4 + a5 ]
               R
                                                                                                                  (18)
                                                                        
                        1    A [u1 œÉ11 + u2 œÉ12 ] + B [u1 œÉ21 + u2 œÉ22 ]
                      +                                                    .
                        2              +C [u1 œÉ31 + u2 œÉ32 ]

                                             Œ±, Œ≤,
Notice that all parameters are evaluated at (b  bœÉ b).


3.2. MCMC Method
    The joint posterior density function of Œ±, Œ≤ and œÉ is given in equation (13). It
is easily seen that the posterior density functions of Œ±, Œ≤ and œÉ are, respectively,
                                                                                                n
                                                                                                X
Œ± |œÉ, x, y ‚àº Gamma(nk + c1 , xœÉ + d1 ), Œ≤ |œÉ, x, y ‚àº Gamma(n + c2 ,                                       yiœÉ + d2 ),
                                                                                                i=1

and
                                                                       n                      n
                                                  (                                  !                    )
                                                                                                                  (19)
                                                                       X                      X
   œÄ(œÉ |Œ±, Œ≤, x, y ) ‚àù œÉ n(k+1)+c3 ‚àí1 e‚àíŒ±xœÉ exp       ‚àíœÉ   d3 ‚àí x‚àó ‚àí         ln yi       ‚àíŒ≤         yiœÉ       ,
                                                                       i=1                    i=1

where x‚àó and xœÉ are defined before the equation (6).


                                           Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

476                                                          Fatih Kizilaslan & Mustafa Nadar


    Therefore, samples of Œ± and Œ≤ can be easily generated by using Gamma dis-
tribution. However, the posterior distribution of œÉ cannot be reduced analytically
to well known distributions and therefore it is not possible to sample directly by
standard methods. It is observed that the plot of the posterior distribution is simi-
lar to Gaussian distribution. The hybrid Metropolis-Hastings and Gibbs sampling
algorithm, which will be used to solve our problem, is suggested by Tierney (1994).
This algorithm combines the Metropolis-Hastings with the Gibbs sampling scheme
under the Gaussian proposal distribution.
      Step 1. Start with initial guess œÉ (0) .
      Step 2. Set i = 1.
                           ‚àó(i)
      Step 3. Generate Œ∏1   from Gamma(nk + c1 , xœÉ(i‚àí1) + d1 ).
                        (i)                  Pn         (i‚àí1)
      Step 4. Generate Œ∏2 from Gamma(n + c2 , i=1 yiœÉ         + d2 ).
                        (i)
    Step 5. Generate œÉ from œÄ(œÉ |Œ±, Œ≤, x, y ) using the Metropolis-Hastings algo-
rithm with the proposal distribution q(œÉ) ‚â° N (œÉ (i‚àí1) , 1) :
           (a) Let v = œÉ (i‚àí1) .
           (b) Generate w from the proposal distribution q.
                                (                                  )
                                    œÄ(w Œ±(i) , Œ≤ (i) , x, y ) q(v)
           (c) Let p(v, w) = min 1,                                 .
                                    œÄ(v Œ±(i) , Œ≤ (i) , x, y ) q(w)
        (d) Generate u from U nif orm(0, 1). If u ‚â§ p(v, w) then accept the pro-
posal and set œÉ (i) = w; otherwise, set œÉ (i) = v.
                                   (i)
      Step 6. Compute the Rs,k at (Œ±(i) , Œ≤ (i) , œÉ (i) ).
      Step 7. Set i = i + 1.
                                                                                         (i)
   Step 8. Repeat Steps 2-7, N times, and obtain the posterior sample Rs,k ,
i = 1, . . . , N .
    This sample is used to compute the Bayes estimate and to construct the HPD
credible interval for Rs,k . The Bayes estimate of Rs,k under SE loss function is
given as
                                             ‚àíM
                                            NX
                               B      1            (i)
                             R
                             bs,k =              Rs,k ,
                                    N ‚àíM
                                                   i=M +1

where M is the burn-in period.
   The HPD 100(1 ‚àí Œ≥)% credible interval of Rs,k is obtained by the method of
Chen & Shao (1999).


4. Simulation Study
    In this section, we present some numerical results to compare the performance
of the estimates of Rs,k which is obtained by using different methods for different
sample sizes and different priors. The performances of the point estimators are
compared by using estimated risks (ERs). The performances of the confidence and
credible intervals are compared by using average confidence lengths and coverage

                                          Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

Multicomponent Stress-Strength for Weibull Distribution                                    477

probabilities (cps). The estimated risk (ER) of Œ∏, when Œ∏ is estimated by Œ∏,
                                                                          b is
given by
                                       N          2
                                     1 X b
                           ER(Œ∏) =         Œ∏i ‚àí Œ∏i ,
                                    N i=1
under the SE loss function. All of the computations are performed by using Matlab
R2010a. All the results are based on 2000 replications.
    The findings based on ML and Bayesian methods are listed in Tables 1-3.
Firstly, we generate Œ±i , Œ≤i and œÉi from the prior distributions 2000 times. Then,
we use the average values of these numbers as (Œ±, Œ≤, œÉ) to generate samples. The
following prior sets are used in the simulation

         Prior 1:   (c1 , d1 ) = (8, 2), (c2 , d2 ) = (2, 1), (c3 , d3 ) = (3, 1),
         Prior 2:   (c1 , d1 ) = (6, 2), (c2 , d2 ) = (5, 1.5), (c3 , d3 ) = (3, 1),
         Prior 3:   (c1 , d1 ) = (4, 2), (c2 , d2 ) = (8, 2), (c3 , d3 ) = (3, 1).

The corresponding (Œ±, Œ≤, œÉ) values for the prior sets 1, 2 and 3 are (Œ±, Œ≤, œÉ) =
(3.9831, 2.0367, 2.9901), (3.0387, 3.3055, 2.9969) and (2.0522, 3.9554, 3.0066), respec-
tively. The strength and stress populations are generated with these (Œ±, Œ≤, œÉ)
values for different sample sizes n = 10(10)50. The true values of reliability in
multicomponent stress-strength with the given combinations for (s, k) = (1, 3) are
0.5498, 0.7723, 0.8941 and for (s, k) = (2, 4) are 0.3967, 0.6263 and 0.7908.
    In the MCMC case, we ran three MCMC chains with fairly different initial
values and generated 10000 iterations for each chain. To diminish the effect of the
starting distribution, we discard the first half of each sequence and focus on the
second half. To provide relatively independent samples for improvement of predic-
tion accuracy, we calculate the Bayesian MCMC estimates by the means of every
5th sampled values after discarding the first half of the chains (see Gelman,
                                                                          q Carlin,
                                                                   p
                                                                           V ar(œà)
Stern & Rubin (2003)). The scale reduction factor estimate R         b =           is  W
used to monitor convergence of MCMC simulations where œà is the estimate of
interest, V ar(œà) = n‚àí1        1
                      n W + n B with the iteration number n for each chain, the
between- and within- sequence variances B and W (see Gelman et al. (2003)). In
our case, the scale factor value of the all MCMC estimators are found below 1.1
which is an acceptable value for their convergency.




                                       Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

478                                                       Fatih Kizilaslan & Mustafa Nadar

 Table 1: Estimates of Rs,k by using Prior 1 for (Œ±, Œ≤, œÉ) = (3.9831, 2.0367, 2.9901).
                                Bayes estimates        Asymptotic             Bayesian
 (s, k) Rs,k  n    MLE         Lindley MCMC            Confidence I        HPD credible I
 (1,3) 0.5498 10 0.552116     0.549087 0.549279    (0.335479,0.768752)   (0.357839,0.737275)
                 0.014483     0.006322 0.008537    0.433274/0.9010       0.379436/0.9535
              20 0.548894     0.545784 0.551357    (0.391438,0.706351)   (0.405469,0.695500)
                 0.006336     0.004478 0.004954    0.314913/0.9410       0.290031/0.9565
              30 0.550783     0.548090 0.555215    (0.421417,0.680149)   (0.432979,0.676443)
                 0.004333     0.003479 0.003727    0.258732/0.9405       0.243464/0.9470
              40 0.551508     0.549312 0.556915    (0.439096,0.663920)   (0.449297,0.663292)
                 0.003273     0.002781 0.003022    0.224823/0.9400       0.213995/0.9445
              50 0.549520     0.547795 0.555857    (0.448781,0.650259)   (0.458847,0.652023)
                 0.002692     0.002378 0.002555    0.201477/0.9385       0.193176/0.9375
 (2,4) 0.3967 10 0.404343     0.397337 0.401447    (0.211493,0.597192)   (0.233468,0.573529)
                 0.010705     0.005114 0.006520    0.385699/0.9240       0.340061/0.9595
              20 0.402272     0.399213 0.404097    (0.263906,0.540638)   (0.276413,0.534011)
                 0.005313     0.003888 0.004290    0.276732/0.9330       0.257598/0.9445
              30 0.400578     0.398747 0.404213    (0.287207,0.513949)   (0.297231,0.512886)
                 0.003529     0.002897 0.003152    0.226741/0.9360       0.215654/0.9430
              40 0.400138     0.398795 0.404612    (0.301737,0.498538)   (0.310674,0.499730)
                 0.002620     0.002267 0.002475    0.196800/0.9420       0.189056/0.94050
              50 0.399262     0.398238 0.404191    (0.311224,0.487300)   (0.319507,0.489970)
                 0.002188     0.001953 0.002126    0.176076/0.9410       0.170464/0.9365
 Note: The first row represents the average estimates and the second row represents corre-
 sponding ERs. The last two columns, the first row represents a 95% confidence interval and
 the second row represents their lengths and cp‚Äôs.



 Table 2: Estimates of Rs,k by using Prior 2 for (Œ±, Œ≤, œÉ) = (3.0387, 3.3055, 2.9969).
                                 Bayes estimates      Asymptotic             Bayesian
  (s, k) Rs,k   n     MLE      Lindley MCMC          Confidence I         HPD credible I
  (1,3) 0.7723 10 0.774650 0.749877 0.761863 (0.599831,0.949470) (0.606490,0.902124)
                    0.009090 0.003327 0.003863 0.349639/0.8890        0.295634/0.9850
                20 0.774791 0.764015 0.765870 (0.647557,0.902025) (0.646528,0.876312)
                    0.004402 0.002645 0.002435 0.254468/0.9150        0.229783/0.9800
                30 0.771936 0.765645 0.765545 (0.666440,0.877433) (0.664663,0.860212)
                    0.002920 0.002125 0.001821 0.210993/0.9355        0.195549/0.9805
                40 0.773666 0.768900 0.767725 (0.682332,0.865000) (0.679257,0.851355)
                    0.002336 0.001837 0.001536 0.182668/0.9245        0.172098/0.9715
                50 0.772542 0.768905 0.767533 (0.690389,0.854695) (0.687424,0.843681)
                    0.001796 0.001494 0.001222 0.164306/0.9355        0.156256/0.9755
  (2,4) 0.6263 10 0.637016 0.603617 0.621503 (0.432619,0.841414) (0.447369,0.788962)
                    0.012606 0.003956 0.005122 0.408795/0.8955        0.341592/0.9815
                20 0.630516 0.619811 0.622449 (0.481766,0.779267) (0.487480,0.753297)
                    0.006129 0.003518 0.003422 0.297501/0.9280        0.265817/0.9755
                30 0.629322 0.623200 0.623133 (0.506826,0.751819) (0.508891,0.734375)
                    0.004019 0.002800 0.002502 0.244993/0.9345        0.225484/0.9725
                40 0.628509 0.624227 0.623246 (0.522002,0.735016) (0.522410,0.721629)
                    0.003067 0.002370 0.002052 0.213014/0.9385        0.199219/0.9670
                50 0.626783 0.623734 0.622440 (0.531272,0.722295) (0.531238,0.711618)
                    0.002519 0.002055 0.001744 0.191023/0.9370        0.180379/0.9645
  Note: The first row represents the average estimates and the second row represents corre-
  sponding ERs. The last two columns, the first row represents a 95% confidence interval and
  the second row represents their lengths and cp‚Äôs.




                                        Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

Multicomponent Stress-Strength for Weibull Distribution                                        479

 Table 3: Estimates of Rs,k by using Prior 3 for (Œ±, Œ≤, œÉ) = (2.0522, 3.9554, 3.0066).
                                 Bayes estimates        Asymptotic             Bayesian
  (s, k) Rs,k  n    MLE         Lindley MCMC            Confidence I        HPD credible I
  (1,3) 0.8941 10 0.888686     0.867476 0.873702    (0.772861,1.004512)   (0.768702,0.961745)
                  0.004049     0.001947 0.001874    0.231651/0.8800       0.193042/0.9915
               20 0.892971     0.883291 0.876870    (0.810618,0.975325)   (0.795453,0.948097)
                  0.001964     0.001082 0.001266    0.164707/0.8985       0.152645/0.9850
               30 0.893508     0.887472 0.877495    (0.825607,0.961409)   (0.808309,0.939511)
                  0.001194     0.000796 0.000950    0.135802/0.9300       0.131201/0.9850
               40 0.894257     0.889670 0.878031    (0.835440,0.953075)   (0.816854,0.933553)
                  0.000894     0.000647 0.000792    0.117635/0.93000      0.116699/0.9815
               50 0.894013     0.890538 0.878040    (0.841187,0.946839)   (0.822634,0.928947)
                  0.000747     0.000574 0.000728    0.105651/0.9295       0.106313/0.9735
  (2,4) 0.7908 10 0.794729     0.760735 0.772829    (0.628402,0.961057)   (0.630880,0.901261)
                  0.008218     0.002782 0.003140    0.332655/0.8735       0.270381/0.9895
               20 0.791122     0.778822 0.771762    (0.668485,0.913758)   (0.659213,0.876185)
                  0.004008     0.001886 0.002234    0.245273/0.9205       0.216972/0.9840
               30 0.790362     0.783109 0.771188    (0.689121,0.891603)   (0.674815,0.861450)
                  0.002737     0.001648 0.001851    0.202482/0.9280       0.186635/0.9805
               40 0.792298     0.786783 0.772508    (0.704543,0.880053)   (0.687150,0.853207)
                  0.001983     0.001336 0.001463    0.175510/0.9335       0.166057/0.9755
               50 0.793238     0.788857 0.773573    (0.714734,0.871741)   (0.696178,0.846931)
                  0.001675     0.001224 0.001312    0.157007/0.9240       0.150753/0.9750
  Note: The first row represents the average estimates and the second row represents corre-
  sponding ERs. The last two columns, the first row represents a 95% confidence interval and
  the second row represents their lengths and cp‚Äôs


    It is observed that the average ERs for the estimates of Rs,k decrease as the
sample size increases in all cases and all tables, as expected. The Bayes estimates
of Rs,k under the SE loss function have smaller ER than that of MLEs in all
tables. Moreover, the ERs of the Bayes estimates which is obtained from Lindley‚Äôs
approximation are generally smaller than that of the MCMC method. Also, these
ERs are close to each other for sufficiently large sample sizes. The average lengths
of the intervals decrease as the sample size increases. The average lengths of
the Bayesian credible intervals are smaller than that of the asymptotic confidence
intervals. Moreover, the coverage probabilities of the Bayesian credible intervals
are closet to the nominal level 95% than asymptotic confidence intervals.
    On the other hand, to compare the performance of ML and Bayes estimates,
we obtain the graphs for Biases and MSE‚Äôs based on MLE and Lindley methods.
Different sets of hyperparameters Œ±, Œ≤ and œÉ are generated from the corresponding
Gamma distributions and their averages are used to obtain Rs,k . This procedure is
repeated 50 times to obtain different true values of Rs,k when (s, k) = (1, 3), (2, 4)
for given Œ±, Œ≤ and œÉ. After that we use the following algorithm for the comparison
of the estimates
   1. For given Œ±, Œ≤ and œÉ, we compute R1,3 (or R2,4 ).
   2. For given n, we generate a sample from Weibull distribution for strength
and stress variables.
   3. The MLE and Bayes estimates are computed by using the equations (9) and
(18).


                                         Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

480                                                                                                          Fatih Kizilaslan & Mustafa Nadar


    4. Steps 2-3 are repeated 2000 times, the Biases and MSE‚Äôs are calculated and
                              PN b(i)                                  PN b(i)
are given by Bias(Rs,k ) = N1 i=1 (R  s,k ‚àíRs,k ) and M SE(Rs,k ) = N
                                                                     1
                                                                          i=1 (Rs,k ‚àí
Rs,k )2 .
    The Figures 1-6 illustrate the Biases and MSEs of R bs,k and R
                                                                 bs,k,B for different
sample sizes n = 10, 30, 50. It is observed that, the Biases and MSEs of the
estimates decrease when the sample size increases, as expected. Moreover, when
Rs,k is around 0.5 the corresponding MSEs are large and when Rs,k is small or
large corresponding MSEs take small values for both estimates.

         0.025                                                                              0.012
                                                                   MLE Bias                                                                             MLE MSE
          0.02                                                     Lindley Bias                                                                         Lindley MSE
                                                                                             0.01
         0.015

          0.01
                                                                                            0.008
         0.005




                                                                                      MSE
 Bias




              0                                                                             0.006

        ‚àí0.005
                                                                                            0.004
         ‚àí0.01

        ‚àí0.015
                                                                                            0.002
         ‚àí0.02

        ‚àí0.025                                                                                    0
             0.2         0.3     0.4     0.5    0.6    0.7   0.8      0.9         1               0.2          0.3     0.4    0.5    0.6    0.7   0.8      0.9        1
                                                R13                                                                                  R13


                                             Figure 1: Bias and MSE for R1,3 when n = 10.


                  ‚àí3
             x 10                                                                                 x 10
                                                                                                        ‚àí3
         6                                                                                   5
                                                                   MLE Bias                                                                             MLE MSE
                                                                   Lindley Bias             4.5                                                         Lindley MSE
         4
                                                                                             4
         2
                                                                                            3.5


         0                                                                                   3
 Bias




                                                                                      MSE




                                                                                            2.5
        ‚àí2
                                                                                             2

        ‚àí4                                                                                  1.5

                                                                                             1
        ‚àí6
                                                                                            0.5

        ‚àí8                                                                                   0
         0.2           0.3     0.4     0.5     0.6    0.7    0.8      0.9         1          0.2             0.3     0.4     0.5    0.6    0.7    0.8      0.9        1
                                               R                                                                                    R13
                                                13


                                             Figure 2: Bias and MSE for R1,3 when n = 30.




                                                                            Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

Multicomponent Stress-Strength for Weibull Distribution                                                                                                                                                  481


                           ‚àí3
                     x 10                                                                                                 ‚àí3
                 2                                                                                                     x 10
                                                                                    MLE Bias                       3
                                                                                    Lindley Bias                                                                                     MLE MSE
                 1                                                                                                                                                                   Lindley MSE
                                                                                                                 2.5

                 0
                                                                                                                   2
               ‚àí1
        Bias




                                                                                                           MSE
                                                                                                                 1.5
               ‚àí2

                                                                                                                   1
               ‚àí3


               ‚àí4                                                                                                0.5



               ‚àí5                                                                                                  0
                0.2             0.3       0.4         0.5     0.6     0.7     0.8      0.9          1              0.2             0.3       0.4       0.5    0.6    0.7     0.8         0.9         1
                                                              R13                                                                                             R13


                                                          Figure 3: Bias and MSE for R1,3 when n = 50.




          0.015                                                                                                0.014
                                                                                    MLE Bias                                             MLE MSE
               0.01                                                                 Lindley Bias                                         Lindley MSE
                                                                                                               0.012
          0.005
                                                                                                                 0.01
                 0

        ‚àí0.005
                                                                                                               0.008
                                                                                                         MSE
 Bias




          ‚àí0.01
                                                                                                               0.006
        ‚àí0.015

          ‚àí0.02                                                                                                0.004

        ‚àí0.025
                                                                                                               0.002
          ‚àí0.03

        ‚àí0.035                                                                                                     0
             0.1                  0.2         0.3     0.4     0.5     0.6    0.7       0.8         0.9             0.1              0.2        0.3      0.4    0.5     0.6         0.7         0.8       0.9
                                                              R24                                                                                              R24


                                                          Figure 4: Bias and MSE for R2,4 when n = 10.




                      ‚àí3
                x 10                                                                                                   x 10
                                                                                                                              ‚àí3
          8                                                                                                       4
                                MLE Bias                                                                                             MLE MSE
                                Lindley Bias                                                                                         Lindley MSE
          6                                                                                                      3.5


          4                                                                                                       3


          2                                                                                                      2.5
 Bias




                                                                                                          MSE




          0                                                                                                       2


        ‚àí2                                                                                                       1.5


        ‚àí4                                                                                                        1


        ‚àí6                                                                                                       0.5
         0.1                0.2         0.3         0.4     0.5     0.6     0.7      0.8      0.9                  0.1             0.2        0.3       0.4    0.5     0.6     0.7         0.8           0.9
                                                            R24                                                                                                R24


                                                          Figure 5: Bias and MSE for R2,4 when n = 30.




                                                                                             Revista Colombiana de Estad√≠stica 38 (2015) 467‚Äì484

482                                                                                                Fatih Kizilaslan & Mustafa Nadar

               ‚àí3                                                                            ‚àí3
            x 10                                                                          x 10
        1                                                                           2.5
                                                         MLE Bias                                   MLE MSE
                                                         Lindley Bias                               Lindley MSE
        0

                                                                                     2
       ‚àí1


       ‚àí2
                                                                                    1.5
Bias




                                                                              MSE
       ‚àí3


       ‚àí4                                                                            1


       ‚àí5
                                                                                    0.5
       ‚àí6


       ‚àí7                                                                            0
        0.1         0.2   0.3   0.4    0.5   0.6   0.7      0.8         0.9          0.1          0.2     0.3     0.4   0.5   0.6   0.7   0.8   0.9
                                       R24                                                                              R24


                                      Figure 6: Bias and MSE for R2,4 when n = 50.




5. Conclusions
    In this paper, we have studied the multicomponent system which hs k indepen-
dent and identical strength components and each element exposed to a common
random stress. We assume that the underlying distributions for both strength and
stress variables are Weibull. The reliability of the system is estimated by using
ML and Bayesian approaches. The Bayesian estimates are obtained by using Lind-
ley‚Äôs approximation and MCMC method. The simulation results indicate that the
average ERs for the estimates of Rs,k and the average lengths of the intervals de-
crease as the sample size increases. The ERs of the ML estimates are greater than
that of Bayes estimates. The ERs of Bayes estimates which are obtained by using
Lindley‚Äôs approximation and MCMC method are close to each other for sufficiently
large sample sizes. Due to the heavy computational burden of the MCMC method,
Lindley‚Äôs approximation maybe considered as a better alternative for large sample
sizes.
                                                                            
                                   Received: June 2014 ‚Äî Accepted: March 2015


References
Bhattacharyya, G. K. & Johnson, R. A. (1974), ‚ÄòEstimation of reliability in multicomponent stress-strength model‚Äô, Journal of the American Statistical Association 69, 966‚Äì970.
Birnbaum, Z. W. (1956), ‚ÄòOn a use of Mann-Whitney statistics‚Äô, Proceeding Third Berkeley Symposium on Mathematical Statistics and Probability 1, 13‚Äì17.
Birnbaum, Z. W. & McCarty, B. C. (1958), ‚ÄòA distribution-free upper confidence bounds for P r(Y < X) based on independent samples of X and Y ‚Äô, The Annals of Mathematical Statistics 29(2), 558‚Äì562.
Chen, M. H. & Shao, Q. M. (1999), ‚ÄòMonte Carlo estimation of Bayesian credible and HPD intervals‚Äô, Journal of Computational and Graphical Statistics 8(1), 69‚Äì92.
Eryilmaz, S. (2008), ‚ÄòMultivariate stress-strength reliability model and its evaluation for coherent structures‚Äô, Journal of Multivariate Analysis 99, 1878‚Äì1887.
Eryilmaz, S. (2010), ‚ÄòOn system reliability in stress-strength setup‚Äô, Statistics and Probability Letters 80, 834‚Äì839.
Gelman, A., Carlin, J. B., Stern, H. S. & Rubin, D. B. (2003), Bayesian Data Analysis, 2 edn, Chapman & Hall, London.
Gradshteyn, I. S. & Ryzhik, I. M. (1994), Table of Integrals, Series and Products, fifth edn, Academic Press, Boston.
Hanagal, D. D. (1999), ‚ÄòEstimation of system reliability‚Äô, Statistical Papers 40, 99‚Äì106.
Hanagal, D. D. (2003), ‚ÄòEstimation of system reliability in multicomponent series stress-strength models‚Äô, Journal of Indian Statistical Association 41, 1‚Äì7.
Jae, J. K. & Eun, M. K. (1981), ‚ÄòEstimation of reliability in a multicomponent stress-strength model in Weibull case‚Äô, Journal of the Korean Society forQuality Management 9(1), 3‚Äì11.
Kotz, S., Lumelskii, Y. & Pensky, M. (2003), The Stress-Strength Model and its Generalizations: Theory and Applications, World Scientific, Singapore.
Kundu, D. & Gupta, R. D. (2005), ‚ÄòEstimation of P (Y < X) for generalizedexponential distribution‚Äô, Metrika 61, 291‚Äì308.
Kundu, D. & Gupta, R. D. (2006), ‚ÄòEstimation of P (Y < X) for Weibull distribution‚Äô, IEEE Transactions on Reliability Analysis 52(2), 270‚Äì280.
Kundu, D. & Raqab, M. Z. (2009), ‚ÄòEstimation of R = P (Y < X) for three-parameter Weibull distribution‚Äô, Statistics and Probability Letters 79, 1839‚Äì1846.
Kuo, W. & Zuo, M. J. (2003), Optimal Reliability Modeling, Principles and Applications, John Wiley & Sons, New York.
Lindley, D. V. (1980), ‚ÄòApproximate Bayes method‚Äô, Trabajos de Estadistica 3, 281‚Äì288.
Nadar, M., Kizilaslan, F. & Papadopoulos, A. (2014), ‚ÄòClassical and Bayesian estimation of P (Y < X) for Kumaraswamy‚Äôs distribution‚Äô, Journal of Statistical Computation and Simulation 84(7), 1505‚Äì1529.
Rao, C. R. (1965), Linear Statistical Inference and Its Applications, John Wiley & Sons, New York.
Rao, G. S. (2012a), ‚ÄòEstimation of reliability in multicomponent stress-strength model based on generalized exponential distribution‚Äô, Revista Colombiana de Estad√≠stica 35(1), 67‚Äì76.
Rao, G. S. (2012b), ‚ÄòEstimation of reliability in multicomponent stress-strength model based on generalized inverted exponential distribution‚Äô, International Journal of Current Research and Review 4(21), 48‚Äì56.
Rao, G. S. (2012c), ‚ÄòEstimation of reliability in multicomponent stress-strength model based on Rayleigh distribution‚Äô, ProbStat Forum 5, 150‚Äì161.
Rao, G. S., Aslam, M. & Kundu, D. (2014), ‚ÄòBurr Type XII distribution parametric estimation and estimation of reliability in multicomponent stress-strength model‚Äô, Communication in Statistics-Theory and Methods 1.
Rao, G. S. & Kantam, R. R. L. (2010), ‚ÄòEstimation of reliability in multicomponent stress-strength model: log-logistic distribution‚Äô, Electronic Journal of Applied Statistical Analysis 3(2), 75‚Äì84.
Rao, G. S., Kantam, R. R. L., Rosaiah, K. & Reddy, J. P. (2013), ‚ÄòEstimation of reliability in multicomponent stress-strength model based on inverse Rayleigh distribution‚Äô, Journal of Statistics Applications & Probability 3, 261‚Äì267.
Tierney, L. (1994), ‚ÄòMarkov chains for exploring posterior distributions‚Äô, The Annals of Statistics 22(4), 1701‚Äì1728.
