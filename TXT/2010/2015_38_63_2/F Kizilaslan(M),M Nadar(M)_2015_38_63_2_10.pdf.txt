Classical and Bayesian Estimation of Reliability in Multicomponent Stress-Strength Model Based on Weibull Distribution. Estimación clásica y bayesiana de la confiabilidad de un modelo estrés-fuerza basado en la distribución Weibull
Gebze Technıcal Unıversıty, Kocaelı, Turkey. Istanbul Technıcal Unıversıty, Istanbul, Turkey
Abstract
In this study, we consider a multicomponent system which has k independent and identical strength components X1 , . . . , Xk and each component is exposed to a common random stress Y when the underlying distributions are Weibull. The system is regarded as operating only if at least s out of k (1 ≤ s ≤ k) strength variables exceeds the random stress. We estimate the reliability of the system by using frequentist and Bayesian approaches. The Bayes estimate of the reliability has been developed by using Lindley’s approximation and the Markov Chain Monte Carlo methods due to the lack of explicit forms. The asymptotic confidence interval and the highest probability density credible interval are constructed for the reliability. The comparison of the reliability estimators is made in terms of the estimated risks by the Monte Carlo simulations.
Key words: Stress-Strength Model, System Reliability, Weibull Distribution.
Resumen
En este estudio, consideramos un sistema multicomponente con k componentes de fuerzaindependientes y cada componente expuesto a un estrés común aleatorio Y cuando seconsidera una distribución Bernoulli. El sistema se considera operativo si por lo menos s de los k (1 ≤ s ≤ k) exceden el estrés aleatorio. Se estima la confiabilidad del sistema usando métodos bayesianos y frecuentistas. La estimación de Bayes de la confiabilidad ha sido desarrollada usando una aproximación de Lindley y métodos MCMC debido a la falta de formas explícitas. El intervalo de confianza asintótico y el intervalo de la densidad deprobabilidad más alta se construyen para la confiabilidad. La comparación de los estimadores de confiabilidad se hace en término de los riesgos estimados por medio de simulaciones Monte Carlo.
Palabras clave: distribución Weibull, modelo estrés-fuerza, sistema de confiabilidad.

1. Introduction

    In the reliability context, the stress-strength model can be described as an
assessment of reliability of a system in terms of random variables X representing
stress experienced by the system and Y representing the strength of the system
available to overcome the stress. If the stress exceeds the strength, then the
system will fail. Thus R = P (X < Y ) is the reliability of a system. The main
idea was introduced by Birnbaum (1956) and developed by Birnbaum & McCarty
(1958). Estimation of R = P (X < Y ) when the random variables X and Y
follow a specified distribution has been extensively discussed by many authors in
the literature. When the X and Y are independent and follow the generalized
exponential, Weibull, three-parameter Weibull and Kumaraswamy distributions,
the estimation of R was studied by Kundu & Gupta (2005), Kundu & Gupta
(2006), Kundu & Raqab (2009) and Nadar, Kizilaslan & Papadopoulos (2014),
respectively. Kotz, Lumelskii & Pensky (2003) provide an excellent review of the
development of the stress-strength up to the year 2003.
    The reliability in a multicomponent stress-strength model was developed by
Bhattacharyya & Johnson (1974). This system consists of k independent and
identical strengths component and a common stress, functions when s (1 ≤ s ≤ k)
or more of the components simultaneously survive. This model corresponds to the
s-out-of-k : G system. Its practical applications range from communication and
industrial systems to logistic and military systems. For example, in suspension
bridges, the deck is supported by a series of vertical cables hung from the towers.
Suppose a suspension bridge consisting of k number of vertical cable pairs. The
bridge will only survive if a minimum s number of vertical cable through the
deck is not damaged when subjected to stresses due to wind loading, heavy trafic,
corrosion, etc. As another example, with a V-8 engine of an automobile it may be
possible to drive the car if only four cylinders are firing. However, if less than four
cylinders fire, then the automobile cannot be driven. Thus, the functioning of the
engine may be represented by a 4-out-of-8 : G system. Other examples include
an electrical power station containing eight generating units which produce the
right amount of electricity only if at least 6 units are working; the demand of the
electricity of a district is fulfilled only if s-out-of-k wind rose are operating at all
times; a communication system for a navy can be successful only if 6 transmitters
out of 10 are operational to cover a district; a semi-trailer pulled by a truck can


                                      Revista Colombiana de Estadística 38 (2015) 467–484

Multicomponent Stress-Strength for Weibull Distribution                              469

be driven safely as long as 6-out-of-8 tires are in good condition. For an extensive
reviews of s-out-of-k and related systems see Kuo & Zuo (2003).
    Let Y, X1 , . . . , Xk be independent, G(y) be the cumulative distribution func-
tion (cdf) of Y and F (x) be the common cdf of X1 , . . . , Xk . The reliability in a
multicomponent stress-strength model is given by

                Rs,k = P (at least s of the (X1 , . . . , Xk ) exceed Y )
                        k       Z ∞
                       X      k                                                      (1)
                     =                  (1 − F (y))i (F (y))k−i dG(y).
                               i    −∞
                         i=s


This reliability can be written as P (Xk−s+1:k > Y ) where Xk−s+1:k is (k − s + 1)
the order statistics of (X1 , . . . , Xk ). This system reliability was considered by Jae
& Eun (1981), when the stress and the strength distributions are Weibull with un-
known scale parameters and the same known shape parameter. The maximum like-
lihood estimation (MLE) and the minimum variance unbiased estimation of system
reliability were obtained in this study. The system reliability was considered by
Hanagal (1999), when (X1 , . . . , Xk ) follow an absolutely continuous multivariate
exponential distribution and Y follows an independent exponential distribution.
Estimation of system reliability which is given as R = P (Xk+1 < min(X1 , . . . , Xk ))
under the assumption of the strengths of the k components (X1 , . . . , Xk ) are sub-
jected to an independent common stress Xk+1 was considered by Hanagal (2003)
when (X1 , . . . , Xk+1 ) follow (k + 1) independent of Gamma or Weibull or Pareto
distributions. The stress-strength reliability of a system which has n independent
components each consisting of m dependent elements was considered by Eryilmaz
(2008). The reliability of stress-strength for a general coherent system was studied
by Eryilmaz (2010). Recently, estimation of reliability in multicomponent stress-
strength for the log-logistic, generalized exponential, generalized inverted exponen-
tial, Rayleigh, inverse Rayleigh and Burr Type XII distributions were considered
by Rao & Kantam (2010), Rao (2012a), Rao (2012b), Rao (2012c), Rao, Kantam,
Rosaiah & Reddy (2013) and Rao, Aslam & Kundu (2014), respectively. In these
studies, maximum likelihood (ML), moment estimates and asymptotic confidence
interval for the reliability in multicomponent stress-strength were obtained, but
Bayesian approach was not taken into consideration.
    In this study, we consider the multicomponent stress-strength model which
has k independent and identical strength components and a common stress. We
assume that the strength variables and stress variable follow Weibull distribution.
The system functions if s (1 ≤ s ≤ k) or more of the components simultaneously
operate. The estimation of reliability for this system is obtained under the classical
and Bayesian frameworks. The Lindley’s approximation and Markov Chain Monte
Carlo (MCMC) technique are carried out to obtain the Bayes estimates. Moreover,
the asymptotic confidence and the highest probability density (HPD) credible
intervals are obtained.
   A Weibull distribution with the shape parameter σ and scale parameter θ will
be denoted by W E(σ, θ). The probability density function (pdf) and the cdf of a
random variable X ∼ W E(σ, θ) are given as


                                      Revista Colombiana de Estadística 38 (2015) 467–484

470                                                               Fatih Kizilaslan & Mustafa Nadar


                                                          σ
                      f (x; σ, θ) = σθxσ−1 e−θx , x > 0, θ, σ > 0,                              (2)
and                                                   σ
                        F (x; σ, θ) = 1 − e−θx , x > 0, θ, σ > 0.                               (3)
   The rest of the paper is organized as follows. In Section 2, the MLE and the
asymptotic confidence interval of Rs,k are obtained when the parameters α, β and
σ are unknown. In Section 3, the Bayes estimates of Rs,k are obtained by using
Lindley’s approximation and MCMC method when the parameters α, β and σ have
independent Gamma priors. The HPD credible interval for Rs,k is also constructed.
In Section 4, a simulation study is performed to compare the estimates of Rs,k by
using Monte Carlo simulations and findings are illustrated by tables and plots.
Finally, we conclude the paper in Section 5.


2. Maximum Likelihood Estimation of Rs,k
    In our case, we assume that X1 , . . . , Xk be a random sample from Weibull
distribution with parameters (σ, α) and Y be a random variable from Weibull
distribution with parameters (σ, β). Therefore, for our case Rs,k is given by using
equations (1)-(3)
                 k            Z ∞
               X       k                      σ                 σ
        Rs,k =               βσ      y σ−1 e−y (αi+β) (1 − e−αy )k−i dy
                        i         0
                i=s
                 k           Z ∞
               X       k
             =               β      e−u(αi+β) (1 − e−αu )k−i du, where u = y σ
                        i       0
                i=s
                 k Xk−i                         Z ∞                         (4)
               X           k        k−i          j         −u(αi+αj+β)
             =                              (−1) β       e             du
                           i         j               0
                  i=s j=0
                    k−i 
                  k X
                                                        (−1)j β
                                 
                  X       k    k−i
              =                                                     .
                            i              j        [α (i + j) + β]
                  i=s j=0

    In order to obtain the estimators of Rs,k , suppose that n systems are put
on life-testing experiment. In this case, we obtain the following observed data
Xi1 , Xi2 , . . . , Xik and Yi , i = 1, . . . , n. Then, the likelihood function of the ob-
served sample is given as
                                                   
                                  Yn   Y k
            L(α, β, σ; x, y) =        f (xij ) g(yi )
                                i=1       j=1
                                                              "       (      n
                                                                                           )#
                                                                             X
                            = σ n(k+1) αnk β n exp (σ − 1) x∗ +                    ln yi        (5)
                                                                             i=1
                                      "               n
                                                                  #
                                                      X
                            × exp −αxσ − β                    yiσ ,
                                                      i=1



                                               Revista Colombiana de Estadística 38 (2015) 467–484

Multicomponent Stress-Strength for Weibull Distribution                                                      471

and the log-likelihood function is
                                                                                   (       n
                                                                                                         )
                                                                                           X
                                                                                       ∗
   l(α, β, σ; x, y) = n(k + 1) ln σ + nk ln α + n ln β + (σ − 1) x +                             ln yi
                                                                                           i=1
                                    n
                                    X
                      − αxσ − β           yiσ ,
                                    i=1
             Pn       Pk                             Pn       Pk
where x∗ =      i=1     j=1 ln xij and xσ =             i=1
                                                                       σ
                                                                  j=1 xij . The MLEs of α, β and σ
are given by
                                             nk b       n
                                     b=
                                     α           , β= P
                                                      n      .                                               (6)
                                             Xσb
                                                        Yiσb
                                                            i=1

The MLE of σ, σ
              b is the solution of the following nonlinear equation
                  n   k                       n                   n
   n(k + 1) nk X X σb                  n X σb                ∗
                                                                 X
           −             xij ln xij − P
                                      n          yi ln yi + x  +     ln yi = 0.                              (7)
      σ      xσb i=1 j=1
                                        yiσb i=1
      b                                                          i=1
                                                  i=1

Therefore, σ
           b can be obtained as a solution of the nonlinear equation of the form
H(σ) = σ where
                                                                                           −1
                             n X k                        n                      n
                        nk X                       n X σ
                                                                                                             (8)
                                                                                X
                                      σ                                     ∗
                                                                                          
       H(σ) = n(k + 1) 
                        xσ         x ij ln x ij + n         y i ln y i − x   −     ln yi 
                                                                                                  .
                                                     yiσ i=1
                                                   P
                            i=1 j=1                                             i=1
                                                        i=1

Since, σ
       b is a fixed point solution of the nonlinear equation (8), its value can be
obtained using an iterative scheme as:

                                          σ(j+1) = H(σ(j) ),

where σ(j) is the jth iterate of σ
                                 b. The iteration procedure should be stopped when
 σ(j) − σ(j+1) is sufficiently small. When we obtain σ b, the MLEs of α and β are
obtained from equation (6). Hence, the MLE of Rs,k is obtained from equation
(4) by using the invariance property of MLE’s
                                 k−i 
                               k X
                                                                        (−1)j βb
                                              
                               X       k    k−i
                   bs,k =
                   R                                              h                 i.                       (9)
                                            i           j             b (i + j) + βb
                                                                      α
                               i=s j=0



2.1. Asymptotic Distribution and Confidence Interval for Rs,k
   The Fisher information matrix of θ = (θ1 , θ2 , θ3 ) ≡ (α, β, σ) is given as
                2         2          2  
                  ∂ l         ∂ L           ∂ L
              E ∂α   2    E ∂α∂β       E ∂α∂σ               
                                                                I11 I12 I13
                                                                                
                2         2          2  
                   ∂ L
  I(θ) = −  E ∂β∂α       E ∂∂βL2           ∂ L
                                       E ∂β∂σ           =  I21 I22 I23  .
                                                      
                                                                I31 I32 I33
                2         2          2  
                   ∂ L        ∂ L
              E ∂σ∂α      E ∂σ∂β       E ∂∂σL2


                                                Revista Colombiana de Estadística 38 (2015) 467–484

472                                                              Fatih Kizilaslan & Mustafa Nadar


The elements of the matrix are obtained as I11 = nk/α2 , I22 = n/β 2 , I33 =
                                                                         2
n/α2 , I12 = I21 = 0. When X ∼ W E(σ, α), E(X σ ln X) and E(X σ (ln X) ) are
evaluated by using the formulas 4.352(1) and 4.358(2) in Gradshteyn & Ryzhik
(1994)
                   Z ∞
                                            α ∞                   ψ(2) − ln α
                                              Z
                         2σ−1 −αxσ
       σ
 E(X ln X) = ασ        x     e     ln xdx =       u ln ue−αu du =             ,
                    0                       σ  0                      σα
                                    Z ∞                                             2
                       α2                                (ψ(2) − ln α) + ξ(2, 2)
                                                          2
              σ
        E(X (ln X) ) = 2                    ue−αu (ln u) du =                    ,
                      σ            0                               σ2 α
                    d
                                                          P∞
where ψ(x) = dx        ln Γ(x) is Psi function, ξ(z, q) = n=0 1/(q + n)z , Re z > 1,
qP6= 0, −1, −2, . . . is a series representation of Riemann Zeta function and ξ(2, 2) =
   ∞               2        2
   n=0 1/(2 + n) = (π /6) − 1. Similarly, when Y ∼ W E(σ, β),

                                                                                    2
                            ψ(2) − ln β                2    (ψ(2) − ln β) + ξ(2, 2)
        E(Y σ ln Y ) =                  , E(Y σ (ln Y ) ) =                         .
                                σβ                                    σ2 β

Hence, the other elements of the information matrix are given as
                                      k
                                    n X
                                    X
                                                 σ               nk
                  I13 = I31 =                 E(Xij ln Xij ) =      (ψ(2) − ln α) ,
                                    i=1 j=1
                                                                 σα

                                          n
                                         X                    n
                    I23 = I32 =              E(Tiσ ln Ti ) =    (ψ(2) − ln β) ,
                                         i=1
                                                             σβ

                      n X k                            n
        n(k + 1)     X
                                 σ           2
                                                     X                 2
I33 =            + α         E(Xij (ln X ij )  ) + β     E(Yiσ (ln Yi ) )
           σ2        i=1 j=1                         i=1
        n(k + 1) nk    n
                                       2
                                                     o    n n                  2
                                                                                           o
      =          +       (ψ(2) − ln α)   +  ξ(2,  2)   +      (ψ(2)  −   ln β)   + ξ(2, 2)   .
           σ2      σ2                                    σ2
                  bs,k is asymptotically normal with mean Rs,k and variance
The MLE of Rs,k , R
                                                3
                                              3 X
                                 2
                                              X   ∂Rs,k ∂Rs,k        −1
                                σR     =                            Iij ,
                                   s,k
                                              j=1 i=1
                                                        ∂θi   ∂θj

       −1
where Iij is the (i, j)th element of the inverse of the I(θ), see Rao (1965). Then,
                                   2                                             2
              2             ∂Rs,k         −1      ∂Rs,k ∂Rs,k −1            ∂Rs,k         −1
             σR     =                    I11 +2              I +                         I22 ,   (10)
                s,k
                             ∂α                    ∂α ∂β 12                  ∂β

where
                           k Xk−i 
                                               (−1)j+1 β(i + j)
                                           
                  ∂Rs,k   X         k    k−i
                        =                                       2 ,                              (11)
                   ∂α               i     j     [α (i + j) + β]
                          i=s j=0


                                                Revista Colombiana de Estadística 38 (2015) 467–484

Multicomponent Stress-Strength for Weibull Distribution                                     473

and
                           k Xk−i 
                                                (−1)j α(i + j)
                                           
                  ∂Rs,k   X         k    k−i
                        =                                      2.                          (12)
                   ∂β               i     j    [α (i + j) + β]
                          i=s j=0

Therefore, an asymptotic 100(1 − γ)% confidence interval of Rs,k is given by
                                                   
                          Rs,k ∈ R bs,k ± zγ/2 σ
                                               bRs,k ,

where zγ/2 is the upper γ/2th quantile of the standard normal distribution and
bRs,k is the value of σRs,k at the MLE of the parameters.
σ


3. Bayes Estimation of Rs,k
   In this section, we assume that all parameters α, β and σ are unknown and
have independent Gamma prior distributions with parameters (ci , di ), i = 1, 2, 3,
respectively. The pdf of a Gamma random variable X with parameters (α, β) is
                                      β α α−1 −xβ
                       f (x) =            x  e    , x > 0, α, β > 0.
                                     Γ(α)
Then, the joint posterior density function of α, β and σ is

      π(α, β, σ |x, y ) = I(x, y)αnk+c1 −1 β n+c2 −1 σ n(k+1)+c3 −1 e−α(xσ +d1 )
                           (       n
                                               !                      n
                                                                              !)
                                  X
                                       σ                        ∗
                                                                     X                     (13)
                        exp −β       yi + d2 − σ d3 − x −               ln yi    ,
                                       i=1                              i=1

where
                  −1         Z ∞                                         Pn
      [I(x, y)]                        σ n(k+1)+c3 −1 exp {−σ (d3 − x∗ − i=1 ln yi )}
                        =                              nk+c1 Pn
                                                                                      dσ.
  Γ(nk + c1 )Γ(n + c2 )          0          (xσ + d1 )      ( i=1 yiσ + d2 ) n+c2
Then, the Bayes estimator of Rs,k under the SE loss function is given by
                       Z ∞Z ∞Z ∞
              R
              bs,k,B =               Rs,k π(α, β, σ |x, y ) dα dβ dσ.                      (14)
                             0        0      0

It is not possible to compute equation (14) analytically. Two approaches can
be applied to approximate equation (14), namely, Lindley’s approximation and
MCMC method.


3.1. Lindley’s Approximation
    Lindley (1980) introduced an approximate procedure for the computation of
two integrals. This procedure employed to the posterior expectation of the function
U (λ), for a given x, is

                                          u(λ)eQ(λ) dλ
                                        R
                          E(u(λ) |x ) = R Q(λ)         ,
                                            e     dλ

                                             Revista Colombiana de Estadística 38 (2015) 467–484

474                                                          Fatih Kizilaslan & Mustafa Nadar


where Q(λ) = l(λ) + ρ(λ), l(λ) is the logarithm of the likelihood function and
ρ(λ) is the logarithm of the prior density of λ. Using the Lindley’s approximation,
E(u(λ) |x ) is approximately estimated by
                                                                                   
                      1 XX                          1 XXXX
 E(u(λ) |x ) = u +            (uij + 2ui ρj )σij +                 Lijk σij σkl ul 
                      2 i j                         2 i j
                                                                        k     l
                                                                                            λ
                                                                                            b
                                     −2
                + terms of order n        or smaller,

                                                              b is the MLE of λ, u = u(λ),
where λ = (λ1 , λ2 , . . . , λm ), i, j, k, l = 1, . . . , m, λ
ui = ∂u/∂λi , uij = ∂ 2 u/∂λi ∂λj , Lijk = ∂ 3 l/∂λi ∂λj ∂λk , ρj = ∂ρ/∂λj , and σij =
(i, j)th element in the inverse of the matrix {−Lij } all are evaluated at the MLE
of the parameters.
      For the three parameter case λ = (λ1 , λ2 , λ3 ), Lindley’s approximation leads
to

      u
      bB    = E(u(λ) |x ) = u + (u1 a1 + u2 a2 + u3 a3 + a4 + a5 )
                                                                             
                1 A(u1 σ11 + u2 σ12 + u3 σ13 ) + B(u1 σ21 + u2 σ22 + u3 σ23 )
              +                                                                 ,
                2                 +C(u1 σ31 + u2 σ32 + u3 σ33 )

             b = (λ
evaluated at λ         b2 , λ
                  b1 , λ    b3 ), where


                          ai = ρ1 σi1 + ρ2 σi2 + ρ3 σi3 , i = 1, 2, 3,
                                                        1
           a4 = u12 σ12 + u13 σ13 + u23 σ23 , a5 =        (u11 σ11 + u22 σ22 + u33 σ33 ),
                                                        2
        A = σ11 L111 + 2σ12 L121 + 2σ13 L131 + 2σ23 L231 + σ22 L221 + σ33 L331 ,

        B = σ11 L112 + 2σ12 L122 + 2σ13 L132 + 2σ23 L232 + σ22 L222 + σ33 L332 ,

        C = σ11 L113 + 2σ12 L123 + 2σ13 L133 + 2σ23 L233 + σ22 L223 + σ33 L333 .
In our case, for (λ1 , λ2 , λ3 ) ≡ (α, β, σ) and u ≡ u(α, β, σ) = Rs,k as given in
equation (4), we have

                     (c1 − 1)             (c2 − 1)             (c3 − 1)
              ρ1 =            − d1 , ρ2 =          − d2 , ρ3 =          − d3 ,
                         α                    β                    σ

                                             nk          n
                                  L11 = −       , L22 = − 2 ,
                                             α2          β
                                  k
                                n X
                                X                                       n
                                                                        X
              L13 = L31 = −               xσij ln xij , L23 = L32 = −         yiσ ln yi ,
                                i=1 j=1                                 i=1

                                      n X k                         n
                        n(k + 1)     X
                                               σ             2
                                                                   X               2
              L33 = −            − α         x ij (ln x ij )   − β     yiσ (ln yi ) ,
                           σ2        i=1 j=1                       i=1


                                           Revista Colombiana de Estadística 38 (2015) 467–484

Multicomponent Stress-Strength for Weibull Distribution                                                            475

σij , i, j = 1, 2, 3 are obtained by using Lij , i, j = 1, 2, 3 and
                                            2nk          2n
                                  L111 =       3
                                                 , L222 = 3 ,
                                             α           β
                           n X
                           X k                                                       n
                                                                                     X
                                                      2                                                       2
      L133 = L331 = −                 xσij (ln xij ) , L233 = L322 = −                     yiσ (ln yi ) ,
                            i=1 j=1                                                  i=1
                                        n X
                                          k                              n
                      2n(k + 1)         X                3
                                                                         X    3
            L333 =              −α         xσij (ln xij ) − β     yiσ (ln yi ) .
                         σ3        i=1 j=1                    i=1

Moreover, u3 = ∂Rs,k /∂σ = 0, u13 = u23 = u31 = u32 = u33 = 0 and u1 , u2 are
given in equations (11), (12) and
                      k Xk−i 
          ∂ 2 Rs,k                        (−1)j+1 (i + j) [α(i + j) − β]
                                      
                     X         k    k−i
   u12 =           =                                            3        , (15)
          ∂α∂β                 i     j          [α (i + j) + β]
                     i=s j=0

                                 k Xk−i 
                     ∂ 2 Rs,k                        (−1)j 2β(i + j)2
                                                 
                                X         k    k−i
             u11 =        2
                              =                                      3 ,                                          (16)
                       ∂α                 i     j     [α (i + j) + β]
                                i=s j=0
                              k Xk−i 
                  ∂ 2 Rs,k                        (−1)j+1 2α(i + j)
                                              
                             X         k    k−i
            u22 =          =                                      3 .                                             (17)
                    ∂β 2     i=s j=0
                                       i     j     [α (i + j) + β]
Hence,
                                         1
                                           (u11 σ11 + u22 σ22 ),
                         a4 = u12 σ12 , a5 =
                                         2
A = σ11 L111 +σ33 L331 , B = σ22 L222 +σ33 L332 , C = 2σ13 L133 +2σ23 L233 +σ33 L333 .
Then, the Bayes estimator of Rs,k is
               bs,k,B = Rs,k + [u1 a1 + u2 a2 + a4 + a5 ]
               R
                                                                                                                  (18)
                                                                        
                        1    A [u1 σ11 + u2 σ12 ] + B [u1 σ21 + u2 σ22 ]
                      +                                                    .
                        2              +C [u1 σ31 + u2 σ32 ]

                                             α, β,
Notice that all parameters are evaluated at (b  bσ b).


3.2. MCMC Method
    The joint posterior density function of α, β and σ is given in equation (13). It
is easily seen that the posterior density functions of α, β and σ are, respectively,
                                                                                                n
                                                                                                X
α |σ, x, y ∼ Gamma(nk + c1 , xσ + d1 ), β |σ, x, y ∼ Gamma(n + c2 ,                                       yiσ + d2 ),
                                                                                                i=1

and
                                                                       n                      n
                                                  (                                  !                    )
                                                                                                                  (19)
                                                                       X                      X
   π(σ |α, β, x, y ) ∝ σ n(k+1)+c3 −1 e−αxσ exp       −σ   d3 − x∗ −         ln yi       −β         yiσ       ,
                                                                       i=1                    i=1

where x∗ and xσ are defined before the equation (6).


                                           Revista Colombiana de Estadística 38 (2015) 467–484

476                                                          Fatih Kizilaslan & Mustafa Nadar


    Therefore, samples of α and β can be easily generated by using Gamma dis-
tribution. However, the posterior distribution of σ cannot be reduced analytically
to well known distributions and therefore it is not possible to sample directly by
standard methods. It is observed that the plot of the posterior distribution is simi-
lar to Gaussian distribution. The hybrid Metropolis-Hastings and Gibbs sampling
algorithm, which will be used to solve our problem, is suggested by Tierney (1994).
This algorithm combines the Metropolis-Hastings with the Gibbs sampling scheme
under the Gaussian proposal distribution.
      Step 1. Start with initial guess σ (0) .
      Step 2. Set i = 1.
                           ∗(i)
      Step 3. Generate θ1   from Gamma(nk + c1 , xσ(i−1) + d1 ).
                        (i)                  Pn         (i−1)
      Step 4. Generate θ2 from Gamma(n + c2 , i=1 yiσ         + d2 ).
                        (i)
    Step 5. Generate σ from π(σ |α, β, x, y ) using the Metropolis-Hastings algo-
rithm with the proposal distribution q(σ) ≡ N (σ (i−1) , 1) :
           (a) Let v = σ (i−1) .
           (b) Generate w from the proposal distribution q.
                                (                                  )
                                    π(w α(i) , β (i) , x, y ) q(v)
           (c) Let p(v, w) = min 1,                                 .
                                    π(v α(i) , β (i) , x, y ) q(w)
        (d) Generate u from U nif orm(0, 1). If u ≤ p(v, w) then accept the pro-
posal and set σ (i) = w; otherwise, set σ (i) = v.
                                   (i)
      Step 6. Compute the Rs,k at (α(i) , β (i) , σ (i) ).
      Step 7. Set i = i + 1.
                                                                                         (i)
   Step 8. Repeat Steps 2-7, N times, and obtain the posterior sample Rs,k ,
i = 1, . . . , N .
    This sample is used to compute the Bayes estimate and to construct the HPD
credible interval for Rs,k . The Bayes estimate of Rs,k under SE loss function is
given as
                                             −M
                                            NX
                               B      1            (i)
                             R
                             bs,k =              Rs,k ,
                                    N −M
                                                   i=M +1

where M is the burn-in period.
   The HPD 100(1 − γ)% credible interval of Rs,k is obtained by the method of
Chen & Shao (1999).


4. Simulation Study
    In this section, we present some numerical results to compare the performance
of the estimates of Rs,k which is obtained by using different methods for different
sample sizes and different priors. The performances of the point estimators are
compared by using estimated risks (ERs). The performances of the confidence and
credible intervals are compared by using average confidence lengths and coverage

                                          Revista Colombiana de Estadística 38 (2015) 467–484

Multicomponent Stress-Strength for Weibull Distribution                                    477

probabilities (cps). The estimated risk (ER) of θ, when θ is estimated by θ,
                                                                          b is
given by
                                       N          2
                                     1 X b
                           ER(θ) =         θi − θi ,
                                    N i=1
under the SE loss function. All of the computations are performed by using Matlab
R2010a. All the results are based on 2000 replications.
    The findings based on ML and Bayesian methods are listed in Tables 1-3.
Firstly, we generate αi , βi and σi from the prior distributions 2000 times. Then,
we use the average values of these numbers as (α, β, σ) to generate samples. The
following prior sets are used in the simulation

         Prior 1:   (c1 , d1 ) = (8, 2), (c2 , d2 ) = (2, 1), (c3 , d3 ) = (3, 1),
         Prior 2:   (c1 , d1 ) = (6, 2), (c2 , d2 ) = (5, 1.5), (c3 , d3 ) = (3, 1),
         Prior 3:   (c1 , d1 ) = (4, 2), (c2 , d2 ) = (8, 2), (c3 , d3 ) = (3, 1).

The corresponding (α, β, σ) values for the prior sets 1, 2 and 3 are (α, β, σ) =
(3.9831, 2.0367, 2.9901), (3.0387, 3.3055, 2.9969) and (2.0522, 3.9554, 3.0066), respec-
tively. The strength and stress populations are generated with these (α, β, σ)
values for different sample sizes n = 10(10)50. The true values of reliability in
multicomponent stress-strength with the given combinations for (s, k) = (1, 3) are
0.5498, 0.7723, 0.8941 and for (s, k) = (2, 4) are 0.3967, 0.6263 and 0.7908.
    In the MCMC case, we ran three MCMC chains with fairly different initial
values and generated 10000 iterations for each chain. To diminish the effect of the
starting distribution, we discard the first half of each sequence and focus on the
second half. To provide relatively independent samples for improvement of predic-
tion accuracy, we calculate the Bayesian MCMC estimates by the means of every
5th sampled values after discarding the first half of the chains (see Gelman,
                                                                          q Carlin,
                                                                   p
                                                                           V ar(ψ)
Stern & Rubin (2003)). The scale reduction factor estimate R         b =           is  W
used to monitor convergence of MCMC simulations where ψ is the estimate of
interest, V ar(ψ) = n−1        1
                      n W + n B with the iteration number n for each chain, the
between- and within- sequence variances B and W (see Gelman et al. (2003)). In
our case, the scale factor value of the all MCMC estimators are found below 1.1
which is an acceptable value for their convergency.




                                       Revista Colombiana de Estadística 38 (2015) 467–484

478                                                       Fatih Kizilaslan & Mustafa Nadar

 Table 1: Estimates of Rs,k by using Prior 1 for (α, β, σ) = (3.9831, 2.0367, 2.9901).
                                Bayes estimates        Asymptotic             Bayesian
 (s, k) Rs,k  n    MLE         Lindley MCMC            Confidence I        HPD credible I
 (1,3) 0.5498 10 0.552116     0.549087 0.549279    (0.335479,0.768752)   (0.357839,0.737275)
                 0.014483     0.006322 0.008537    0.433274/0.9010       0.379436/0.9535
              20 0.548894     0.545784 0.551357    (0.391438,0.706351)   (0.405469,0.695500)
                 0.006336     0.004478 0.004954    0.314913/0.9410       0.290031/0.9565
              30 0.550783     0.548090 0.555215    (0.421417,0.680149)   (0.432979,0.676443)
                 0.004333     0.003479 0.003727    0.258732/0.9405       0.243464/0.9470
              40 0.551508     0.549312 0.556915    (0.439096,0.663920)   (0.449297,0.663292)
                 0.003273     0.002781 0.003022    0.224823/0.9400       0.213995/0.9445
              50 0.549520     0.547795 0.555857    (0.448781,0.650259)   (0.458847,0.652023)
                 0.002692     0.002378 0.002555    0.201477/0.9385       0.193176/0.9375
 (2,4) 0.3967 10 0.404343     0.397337 0.401447    (0.211493,0.597192)   (0.233468,0.573529)
                 0.010705     0.005114 0.006520    0.385699/0.9240       0.340061/0.9595
              20 0.402272     0.399213 0.404097    (0.263906,0.540638)   (0.276413,0.534011)
                 0.005313     0.003888 0.004290    0.276732/0.9330       0.257598/0.9445
              30 0.400578     0.398747 0.404213    (0.287207,0.513949)   (0.297231,0.512886)
                 0.003529     0.002897 0.003152    0.226741/0.9360       0.215654/0.9430
              40 0.400138     0.398795 0.404612    (0.301737,0.498538)   (0.310674,0.499730)
                 0.002620     0.002267 0.002475    0.196800/0.9420       0.189056/0.94050
              50 0.399262     0.398238 0.404191    (0.311224,0.487300)   (0.319507,0.489970)
                 0.002188     0.001953 0.002126    0.176076/0.9410       0.170464/0.9365
 Note: The first row represents the average estimates and the second row represents corre-
 sponding ERs. The last two columns, the first row represents a 95% confidence interval and
 the second row represents their lengths and cp’s.



 Table 2: Estimates of Rs,k by using Prior 2 for (α, β, σ) = (3.0387, 3.3055, 2.9969).
                                 Bayes estimates      Asymptotic             Bayesian
  (s, k) Rs,k   n     MLE      Lindley MCMC          Confidence I         HPD credible I
  (1,3) 0.7723 10 0.774650 0.749877 0.761863 (0.599831,0.949470) (0.606490,0.902124)
                    0.009090 0.003327 0.003863 0.349639/0.8890        0.295634/0.9850
                20 0.774791 0.764015 0.765870 (0.647557,0.902025) (0.646528,0.876312)
                    0.004402 0.002645 0.002435 0.254468/0.9150        0.229783/0.9800
                30 0.771936 0.765645 0.765545 (0.666440,0.877433) (0.664663,0.860212)
                    0.002920 0.002125 0.001821 0.210993/0.9355        0.195549/0.9805
                40 0.773666 0.768900 0.767725 (0.682332,0.865000) (0.679257,0.851355)
                    0.002336 0.001837 0.001536 0.182668/0.9245        0.172098/0.9715
                50 0.772542 0.768905 0.767533 (0.690389,0.854695) (0.687424,0.843681)
                    0.001796 0.001494 0.001222 0.164306/0.9355        0.156256/0.9755
  (2,4) 0.6263 10 0.637016 0.603617 0.621503 (0.432619,0.841414) (0.447369,0.788962)
                    0.012606 0.003956 0.005122 0.408795/0.8955        0.341592/0.9815
                20 0.630516 0.619811 0.622449 (0.481766,0.779267) (0.487480,0.753297)
                    0.006129 0.003518 0.003422 0.297501/0.9280        0.265817/0.9755
                30 0.629322 0.623200 0.623133 (0.506826,0.751819) (0.508891,0.734375)
                    0.004019 0.002800 0.002502 0.244993/0.9345        0.225484/0.9725
                40 0.628509 0.624227 0.623246 (0.522002,0.735016) (0.522410,0.721629)
                    0.003067 0.002370 0.002052 0.213014/0.9385        0.199219/0.9670
                50 0.626783 0.623734 0.622440 (0.531272,0.722295) (0.531238,0.711618)
                    0.002519 0.002055 0.001744 0.191023/0.9370        0.180379/0.9645
  Note: The first row represents the average estimates and the second row represents corre-
  sponding ERs. The last two columns, the first row represents a 95% confidence interval and
  the second row represents their lengths and cp’s.




                                        Revista Colombiana de Estadística 38 (2015) 467–484

Multicomponent Stress-Strength for Weibull Distribution                                        479

 Table 3: Estimates of Rs,k by using Prior 3 for (α, β, σ) = (2.0522, 3.9554, 3.0066).
                                 Bayes estimates        Asymptotic             Bayesian
  (s, k) Rs,k  n    MLE         Lindley MCMC            Confidence I        HPD credible I
  (1,3) 0.8941 10 0.888686     0.867476 0.873702    (0.772861,1.004512)   (0.768702,0.961745)
                  0.004049     0.001947 0.001874    0.231651/0.8800       0.193042/0.9915
               20 0.892971     0.883291 0.876870    (0.810618,0.975325)   (0.795453,0.948097)
                  0.001964     0.001082 0.001266    0.164707/0.8985       0.152645/0.9850
               30 0.893508     0.887472 0.877495    (0.825607,0.961409)   (0.808309,0.939511)
                  0.001194     0.000796 0.000950    0.135802/0.9300       0.131201/0.9850
               40 0.894257     0.889670 0.878031    (0.835440,0.953075)   (0.816854,0.933553)
                  0.000894     0.000647 0.000792    0.117635/0.93000      0.116699/0.9815
               50 0.894013     0.890538 0.878040    (0.841187,0.946839)   (0.822634,0.928947)
                  0.000747     0.000574 0.000728    0.105651/0.9295       0.106313/0.9735
  (2,4) 0.7908 10 0.794729     0.760735 0.772829    (0.628402,0.961057)   (0.630880,0.901261)
                  0.008218     0.002782 0.003140    0.332655/0.8735       0.270381/0.9895
               20 0.791122     0.778822 0.771762    (0.668485,0.913758)   (0.659213,0.876185)
                  0.004008     0.001886 0.002234    0.245273/0.9205       0.216972/0.9840
               30 0.790362     0.783109 0.771188    (0.689121,0.891603)   (0.674815,0.861450)
                  0.002737     0.001648 0.001851    0.202482/0.9280       0.186635/0.9805
               40 0.792298     0.786783 0.772508    (0.704543,0.880053)   (0.687150,0.853207)
                  0.001983     0.001336 0.001463    0.175510/0.9335       0.166057/0.9755
               50 0.793238     0.788857 0.773573    (0.714734,0.871741)   (0.696178,0.846931)
                  0.001675     0.001224 0.001312    0.157007/0.9240       0.150753/0.9750
  Note: The first row represents the average estimates and the second row represents corre-
  sponding ERs. The last two columns, the first row represents a 95% confidence interval and
  the second row represents their lengths and cp’s


    It is observed that the average ERs for the estimates of Rs,k decrease as the
sample size increases in all cases and all tables, as expected. The Bayes estimates
of Rs,k under the SE loss function have smaller ER than that of MLEs in all
tables. Moreover, the ERs of the Bayes estimates which is obtained from Lindley’s
approximation are generally smaller than that of the MCMC method. Also, these
ERs are close to each other for sufficiently large sample sizes. The average lengths
of the intervals decrease as the sample size increases. The average lengths of
the Bayesian credible intervals are smaller than that of the asymptotic confidence
intervals. Moreover, the coverage probabilities of the Bayesian credible intervals
are closet to the nominal level 95% than asymptotic confidence intervals.
    On the other hand, to compare the performance of ML and Bayes estimates,
we obtain the graphs for Biases and MSE’s based on MLE and Lindley methods.
Different sets of hyperparameters α, β and σ are generated from the corresponding
Gamma distributions and their averages are used to obtain Rs,k . This procedure is
repeated 50 times to obtain different true values of Rs,k when (s, k) = (1, 3), (2, 4)
for given α, β and σ. After that we use the following algorithm for the comparison
of the estimates
   1. For given α, β and σ, we compute R1,3 (or R2,4 ).
   2. For given n, we generate a sample from Weibull distribution for strength
and stress variables.
   3. The MLE and Bayes estimates are computed by using the equations (9) and
(18).


                                         Revista Colombiana de Estadística 38 (2015) 467–484

480                                                                                                          Fatih Kizilaslan & Mustafa Nadar


    4. Steps 2-3 are repeated 2000 times, the Biases and MSE’s are calculated and
                              PN b(i)                                  PN b(i)
are given by Bias(Rs,k ) = N1 i=1 (R  s,k −Rs,k ) and M SE(Rs,k ) = N
                                                                     1
                                                                          i=1 (Rs,k −
Rs,k )2 .
    The Figures 1-6 illustrate the Biases and MSEs of R bs,k and R
                                                                 bs,k,B for different
sample sizes n = 10, 30, 50. It is observed that, the Biases and MSEs of the
estimates decrease when the sample size increases, as expected. Moreover, when
Rs,k is around 0.5 the corresponding MSEs are large and when Rs,k is small or
large corresponding MSEs take small values for both estimates.

         0.025                                                                              0.012
                                                                   MLE Bias                                                                             MLE MSE
          0.02                                                     Lindley Bias                                                                         Lindley MSE
                                                                                             0.01
         0.015

          0.01
                                                                                            0.008
         0.005




                                                                                      MSE
 Bias




              0                                                                             0.006

        −0.005
                                                                                            0.004
         −0.01

        −0.015
                                                                                            0.002
         −0.02

        −0.025                                                                                    0
             0.2         0.3     0.4     0.5    0.6    0.7   0.8      0.9         1               0.2          0.3     0.4    0.5    0.6    0.7   0.8      0.9        1
                                                R13                                                                                  R13


                                             Figure 1: Bias and MSE for R1,3 when n = 10.


                  −3
             x 10                                                                                 x 10
                                                                                                        −3
         6                                                                                   5
                                                                   MLE Bias                                                                             MLE MSE
                                                                   Lindley Bias             4.5                                                         Lindley MSE
         4
                                                                                             4
         2
                                                                                            3.5


         0                                                                                   3
 Bias




                                                                                      MSE




                                                                                            2.5
        −2
                                                                                             2

        −4                                                                                  1.5

                                                                                             1
        −6
                                                                                            0.5

        −8                                                                                   0
         0.2           0.3     0.4     0.5     0.6    0.7    0.8      0.9         1          0.2             0.3     0.4     0.5    0.6    0.7    0.8      0.9        1
                                               R                                                                                    R13
                                                13


                                             Figure 2: Bias and MSE for R1,3 when n = 30.




                                                                            Revista Colombiana de Estadística 38 (2015) 467–484

Multicomponent Stress-Strength for Weibull Distribution                                                                                                                                                  481


                           −3
                     x 10                                                                                                 −3
                 2                                                                                                     x 10
                                                                                    MLE Bias                       3
                                                                                    Lindley Bias                                                                                     MLE MSE
                 1                                                                                                                                                                   Lindley MSE
                                                                                                                 2.5

                 0
                                                                                                                   2
               −1
        Bias




                                                                                                           MSE
                                                                                                                 1.5
               −2

                                                                                                                   1
               −3


               −4                                                                                                0.5



               −5                                                                                                  0
                0.2             0.3       0.4         0.5     0.6     0.7     0.8      0.9          1              0.2             0.3       0.4       0.5    0.6    0.7     0.8         0.9         1
                                                              R13                                                                                             R13


                                                          Figure 3: Bias and MSE for R1,3 when n = 50.




          0.015                                                                                                0.014
                                                                                    MLE Bias                                             MLE MSE
               0.01                                                                 Lindley Bias                                         Lindley MSE
                                                                                                               0.012
          0.005
                                                                                                                 0.01
                 0

        −0.005
                                                                                                               0.008
                                                                                                         MSE
 Bias




          −0.01
                                                                                                               0.006
        −0.015

          −0.02                                                                                                0.004

        −0.025
                                                                                                               0.002
          −0.03

        −0.035                                                                                                     0
             0.1                  0.2         0.3     0.4     0.5     0.6    0.7       0.8         0.9             0.1              0.2        0.3      0.4    0.5     0.6         0.7         0.8       0.9
                                                              R24                                                                                              R24


                                                          Figure 4: Bias and MSE for R2,4 when n = 10.




                      −3
                x 10                                                                                                   x 10
                                                                                                                              −3
          8                                                                                                       4
                                MLE Bias                                                                                             MLE MSE
                                Lindley Bias                                                                                         Lindley MSE
          6                                                                                                      3.5


          4                                                                                                       3


          2                                                                                                      2.5
 Bias




                                                                                                          MSE




          0                                                                                                       2


        −2                                                                                                       1.5


        −4                                                                                                        1


        −6                                                                                                       0.5
         0.1                0.2         0.3         0.4     0.5     0.6     0.7      0.8      0.9                  0.1             0.2        0.3       0.4    0.5     0.6     0.7         0.8           0.9
                                                            R24                                                                                                R24


                                                          Figure 5: Bias and MSE for R2,4 when n = 30.




                                                                                             Revista Colombiana de Estadística 38 (2015) 467–484

482                                                                                                Fatih Kizilaslan & Mustafa Nadar

               −3                                                                            −3
            x 10                                                                          x 10
        1                                                                           2.5
                                                         MLE Bias                                   MLE MSE
                                                         Lindley Bias                               Lindley MSE
        0

                                                                                     2
       −1


       −2
                                                                                    1.5
Bias




                                                                              MSE
       −3


       −4                                                                            1


       −5
                                                                                    0.5
       −6


       −7                                                                            0
        0.1         0.2   0.3   0.4    0.5   0.6   0.7      0.8         0.9          0.1          0.2     0.3     0.4   0.5   0.6   0.7   0.8   0.9
                                       R24                                                                              R24


                                      Figure 6: Bias and MSE for R2,4 when n = 50.




5. Conclusions
    In this paper, we have studied the multicomponent system which hs k indepen-
dent and identical strength components and each element exposed to a common
random stress. We assume that the underlying distributions for both strength and
stress variables are Weibull. The reliability of the system is estimated by using
ML and Bayesian approaches. The Bayesian estimates are obtained by using Lind-
ley’s approximation and MCMC method. The simulation results indicate that the
average ERs for the estimates of Rs,k and the average lengths of the intervals de-
crease as the sample size increases. The ERs of the ML estimates are greater than
that of Bayes estimates. The ERs of Bayes estimates which are obtained by using
Lindley’s approximation and MCMC method are close to each other for sufficiently
large sample sizes. Due to the heavy computational burden of the MCMC method,
Lindley’s approximation maybe considered as a better alternative for large sample
sizes.
                                                                            
                                   Received: June 2014 — Accepted: March 2015


References
Bhattacharyya, G. K. & Johnson, R. A. (1974), ‘Estimation of reliability in multicomponent stress-strength model’, Journal of the American Statistical Association 69, 966–970.
Birnbaum, Z. W. (1956), ‘On a use of Mann-Whitney statistics’, Proceeding Third Berkeley Symposium on Mathematical Statistics and Probability 1, 13–17.
Birnbaum, Z. W. & McCarty, B. C. (1958), ‘A distribution-free upper confidence bounds for P r(Y < X) based on independent samples of X and Y ’, The Annals of Mathematical Statistics 29(2), 558–562.
Chen, M. H. & Shao, Q. M. (1999), ‘Monte Carlo estimation of Bayesian credible and HPD intervals’, Journal of Computational and Graphical Statistics 8(1), 69–92.
Eryilmaz, S. (2008), ‘Multivariate stress-strength reliability model and its evaluation for coherent structures’, Journal of Multivariate Analysis 99, 1878–1887.
Eryilmaz, S. (2010), ‘On system reliability in stress-strength setup’, Statistics and Probability Letters 80, 834–839.
Gelman, A., Carlin, J. B., Stern, H. S. & Rubin, D. B. (2003), Bayesian Data Analysis, 2 edn, Chapman & Hall, London.
Gradshteyn, I. S. & Ryzhik, I. M. (1994), Table of Integrals, Series and Products, fifth edn, Academic Press, Boston.
Hanagal, D. D. (1999), ‘Estimation of system reliability’, Statistical Papers 40, 99–106.
Hanagal, D. D. (2003), ‘Estimation of system reliability in multicomponent series stress-strength models’, Journal of Indian Statistical Association 41, 1–7.
Jae, J. K. & Eun, M. K. (1981), ‘Estimation of reliability in a multicomponent stress-strength model in Weibull case’, Journal of the Korean Society forQuality Management 9(1), 3–11.
Kotz, S., Lumelskii, Y. & Pensky, M. (2003), The Stress-Strength Model and its Generalizations: Theory and Applications, World Scientific, Singapore.
Kundu, D. & Gupta, R. D. (2005), ‘Estimation of P (Y < X) for generalizedexponential distribution’, Metrika 61, 291–308.
Kundu, D. & Gupta, R. D. (2006), ‘Estimation of P (Y < X) for Weibull distribution’, IEEE Transactions on Reliability Analysis 52(2), 270–280.
Kundu, D. & Raqab, M. Z. (2009), ‘Estimation of R = P (Y < X) for three-parameter Weibull distribution’, Statistics and Probability Letters 79, 1839–1846.
Kuo, W. & Zuo, M. J. (2003), Optimal Reliability Modeling, Principles and Applications, John Wiley & Sons, New York.
Lindley, D. V. (1980), ‘Approximate Bayes method’, Trabajos de Estadistica 3, 281–288.
Nadar, M., Kizilaslan, F. & Papadopoulos, A. (2014), ‘Classical and Bayesian estimation of P (Y < X) for Kumaraswamy’s distribution’, Journal of Statistical Computation and Simulation 84(7), 1505–1529.
Rao, C. R. (1965), Linear Statistical Inference and Its Applications, John Wiley & Sons, New York.
Rao, G. S. (2012a), ‘Estimation of reliability in multicomponent stress-strength model based on generalized exponential distribution’, Revista Colombiana de Estadística 35(1), 67–76.
Rao, G. S. (2012b), ‘Estimation of reliability in multicomponent stress-strength model based on generalized inverted exponential distribution’, International Journal of Current Research and Review 4(21), 48–56.
Rao, G. S. (2012c), ‘Estimation of reliability in multicomponent stress-strength model based on Rayleigh distribution’, ProbStat Forum 5, 150–161.
Rao, G. S., Aslam, M. & Kundu, D. (2014), ‘Burr Type XII distribution parametric estimation and estimation of reliability in multicomponent stress-strength model’, Communication in Statistics-Theory and Methods 1.
Rao, G. S. & Kantam, R. R. L. (2010), ‘Estimation of reliability in multicomponent stress-strength model: log-logistic distribution’, Electronic Journal of Applied Statistical Analysis 3(2), 75–84.
Rao, G. S., Kantam, R. R. L., Rosaiah, K. & Reddy, J. P. (2013), ‘Estimation of reliability in multicomponent stress-strength model based on inverse Rayleigh distribution’, Journal of Statistics Applications & Probability 3, 261–267.
Tierney, L. (1994), ‘Markov chains for exploring posterior distributions’, The Annals of Statistics 22(4), 1701–1728.
