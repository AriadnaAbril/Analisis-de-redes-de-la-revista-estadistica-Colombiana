Locally D-Optimal Designs with Heteroscedasticity: A Comparison between Two Methodologies. Dise√±os D-√≥ptimos locales con heterocedasticidad: una comparaci√≥n entre dos metodolog√≠as
Universidad Nacional de Colombia, Medell√≠n, Colombia
Abstract
The classic theory of optimal experimental designs assumes that the errors of the model are independent and have a normal distribution with constant variance. However, the assumption of homogeneity of variance is not always satisfied. For example when the variability of the response is a function of the mean, it is probably that a heterogeneity model be more adequate than a homogeneous one. To solve this problem there are two methods: The first one consists of incorporating a function which models the error variancein the model, the second one is to apply some of the Box-Cox transformations to both sides on the nonlinear regression model to achieve a homoscedastic model (Carroll Ruppert 1988, Chapter 4). In both cases it is possible to find the optimal design but the problem becomes more complex because it is necessary to find an expression for the Fisher information matrix of the model. In this paper we present the two mentioned methodologies for the D-optimality criteria and we show a result which is useful to find D-optimal designs for heteroscedastic models when the variance of the response is a function of the mean. Then we apply both methods with an example, where the model is nonlinear and the variance is not constant. Finally we find the D-optimal designs with each methodology, calculate the efficiencies and evaluate the goodness of fit of the obtained designs via simulations.
Key words: D-efficiency, D-optimal design, Box-Cox transformations, Heteroscedasticity.
Resumen
La teor√≠a cl√°sica de los dise√±os experimentales √≥ptimos supone que los errores del modelo son independientes y tienen una distribuci√≥n normal con varianza constante. Sin embargo, el supuesto de homogeneidad de varianza no siempre se satisface. Por ejemplo, cuando la variabilidad de la respuesta es una funci√≥n de la media, es probable que un modelo heteroced√°stico sea m√°s adecuado que uno homog√©neo. Para solucionar este problema hay dos m√©todos: el primero consiste en incorporar una funci√≥n que modele la varianza del error en el modelo; el segundo consiste en aplicar alguna de las transformaciones de Box-Cox en el modelo de regresi√≥n no lineal (Carroll Ruppert 1988, Cap√≠tulo 4). En ambos casos es posible hallar el dise√±o √≥ptimo, pero el problema se vuelve m√°s complejo porque es necesario encontrar una expresi√≥n de la matriz de informaci√≥n de Fisher del modelo. En este art√≠culo se presentan las dos metodolog√≠as mencionadas para el criterio D-optimalidad y se muestra un resultado que es √∫til para encontrar dise√±os D-√≥ptimos para modelos heteroced√°sticos cuando la varianza de la respuesta es una funci√≥n de la media. Luego, se aplican ambos m√©todos en un ejemplo donde el modelo es no lineal y la varianza no constante. Finalmente se encuentra el dise√±o D-√≥ptimo con cada metodolog√≠a, se calculan las eficiencias y se eval√∫a la bondad del ajuste de los dise√±os obtenidos a trav√©s de simulaciones.
Palabras clave: D-eficiencia, Dise√±os D-√≥ptimos, heterocedasticidad, transformaci√≥n de Box-Cox.



1. Introduction
    The optimal experimental designs are a tool that allows the researcher to know
which factor levels should be experimented in order to obtain a best estimate of the
parameters of the model with certain statistical criterion. One of the most popular
criteria is the D-optimality which involves finding the design that minimizes the
generalized variance of the parameter vector. The design depends on a regression
model (1) that relates the response variable Y with the independent variable x

                                     Y = Œ∑(x, Œ≤) +                                    (1)

with Œ∑(x, Œ≤) a linear or nonlinear function of the parameter vector Œ≤ and x.
    Besides, if the researcher has the possibility to run N observations of the model
(1), then there are the following assumptions:

     1. the error components i , for i = 1, 2, . . . , N , are independent and

     2. have a normal distribution with constant variance œÉ 2 .

    For more information about the classic theory of optimal designs see Kiefer
(1959), O‚ÄôBrien Funk (2003), Atkinson, Donev Tobias (2007, Chapter 9),
L√≥pez Ramos (2007). However, in practice there are cases where the homogene-
ity assumption is not satisfied. For example when the variance of the response

                                         Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

D-Optimal Designs                                                                   97

is a function of the mean, it can increase or decrease depending of the structure
of the variance. The issue of heteroscedasticity in nonlinear regression models is
discussed in detail in Seber Wild (1989, pp. 68-72). Basically there are two
methodologies to handle this problem. The first one is to apply some of the Box-
Cox transformations to the model (1) with an appropriate Œª1 that stabilizes the
variance of the errors. We identify the transformed model like model A:

                              YiŒª1 = Œ∑(xi , Œ≤)Œª1 + ‚àói                             (2)

where is assumed that the new errors ‚àói have a normal distribution with constant
variance.
   The second model, which we identify as model B, consists of incorporating the
variance structure of the errors in the model as follows:

                                 Yi = Œ∑(xi , Œ≤) + i                               (3)

where the errors i are independent N (0, œÉ 2 (Œ∑(xi , Œ≤))Œª2 ), with Œª2 an adequate
power parameter that models the variance of the errors.
     As Seber Wild (1989) emphasize, the difference between models A and B is
‚Äúthat model A transforms so that y (Œª1 ) has a different distribution from y as well
as having a homogeneous variance structure, while model B models the variance
heterogeneity but leaves the distribution of y unchanged‚Äù. Also, the authors affirm
that model B has often been preferred to model A when the deterministic function
is linear, whereas models like A have been preferred in nonlinear models.
    Now, in the context of optimal designs when the model has heteroscedasticity,
the problem to find D-optimal designs is more complicated than in the homoge-
neous case, because the D-optimality criterion maximizes the determinant of the
Fisher information matrix of the model and the expression of this matrix changes
when the variance is not constant. Because the information matrix depends of the
model used, the two methodologies mentioned before for handling of heteroscedas-
ticity are traditionally applied in separate ways. For example, Atkinson Cook
(1997) apply some of the Box-Cox transformations that makes the transformed
model be linear with a constant variance and then they find local and Bayesian
D-optimal designs to several models. On the other hand, in the case of linear
models, Atkinson Cook (1995) find local D-optimal designs for heteroscedastic
linear models for various structures of variance, one of them is when the logarithm
of variance is a linear function of the independent variable. Other authors have
worked with nonlinear models, see for example Dette Wong (1999).
    In this paper we compare the methodologies mentioned above, analyze the
structure of the information matrix and we find the D-optimal design for a specific
model. Finally we compare the designs obtained through the D- efficiency. This
paper is divided in four sections. In section 2 we present a brief summary of both
methodologies for the D-optimality criterion and show a result which is useful
to find D-optimal designs for heteroscedastic models when the variance of the
response is a function of the mean (we omit the proof due to length constraints).
In section 3 we illustrate both methods with an example and we compare results
using the D-efficiency of each design. Then, we simulate observations of the model


                                     Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

98                                  Jaime Andr√©s Gaviria V√≠ctor Ignacio L√≥pez-R√≠os


for each design and we calculate the relative error and mean square error. Finally,
in section 4 we present some conclusions, discussions and suggestions.


2. Methodologies
    Starting with a regression model of the form (1) with the usual assumptions,
the problem of optimal designs consists to find the levels of the x factor where
the researcher should experiment to obtain a best estimate of the parameters
of the model under certain statistical criterion. In this paper we focus on the D-
optimality criterion, which finds the design that minimizes the generalized variance
of the parameter vector (Atkinson et al. 2007, pp. 135). More precisely, a design
Œæ is defined as a measure of probability with finite support denoted by:
                                                      
                                    x1 x2 ¬∑ ¬∑ ¬∑ xn
                             Œæ=                                                  (4)
                                    w1 w2 ¬∑ ¬∑ ¬∑ wn

where n is the number of support points, x1 , x2 , . . . , xn arePthe support points of
                                                                   n
the design with associated weights wi ‚â• 0 and such that i=1 wi = 1 (O‚ÄôBrien
& Funk 2003). If the weight wi is any number between 0 and 1, the design Œæ is
known as a continuous design. However in practice all designs are exact. This
means that the weights wi are associated with the frequency of the support points
(Atkinson et al. 2007, pp. 120).
    Now, the main problem of optimal designs is to find a design Œæ over a compact
region œá, that maximizes a functional of the information matrix M (Œæ). This ma-
trix plays an important role in the theory of optimal experimental designs. The
structure of this matrix depends on the linear nature of the model and on the
assumptions about the errors. When the variance of the errors is constant, this
matrix has a known expression, see for example L√≥pez Ramos (2007). However,
in the case of heteroscedastic models this expression is more complex and depends
of the methodology applied. So, in the next two sections we analyze the structure
of the Fisher information matrix with each of the two methodologies mentioned
before.


2.1. Variance Modelling
    When the variance of the error is not constant, one way to solve this problem
is to find an adequate function which models the error variance and incorporate
it in the regression model. There are many ways to do this, see for example Huet,
Bouvier, Poursat Jolivet (2004, pp. 65) and Seber Wild (1989, pp. 68-72).
One form is when the variance of the response is a power function of the mean:

                 Yi = Œ∑(xi , Œ≤) + i , with var(i ) = œÉ 2 (Œ∑(xi , Œ≤))2œÑ             (5)

where œÉ 2 is the constant variance, œÑ is an unknown parameter and it should be
estimated. The model (5) with variance structure is known as the power of the
mean variance model (Ritz Streibig 2008, pp. 74).


                                       Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

D-Optimal Designs                                                                         99

    Now, some authors have worked the problem to find D-optimal designs mo-
deling the variance. For example Dette Wong (1999) find D-optimal designs
for the Michaelis-Menten model when the variance is a function of the mean and
Atkinson Cook (1995) find D-optimal designs for heteroscedastic linear models.
The following result is taken from Downing, Fedorov Leonov (2001); they show
the expression of the information matrix for a more general model than the power
of the mean variance model (5):

                        Y = Œ∑(x, Œ∏) + , with var() = S(x, Œ∏)                            (6)

where Œ∏ is the parameter vector and it can include the parameters of the deter-
ministic function Œ∑ and those of the function S(x, Œ∏) as a positive function used
to model the variance of the error. Observe that the power of the mean variance
model (5) is a nested model of the more general model (6). In this case the pa-
rameter vector Œ∏ includes all the possible parameters of the model: Œ≤, œÑ and œÉ 2 .
So, results about the general model (for instance the next theorem)can be applied
in particular for the power of the mean variance model.
Theorem 1. Information Matrix.
    Let Y with normal distribution, with expected mean E[Y |x] = Œ∑(x, Œ∏) and vari-
ance V ar[Y |x] = S(x, Œ∏), where S(x, Œ∏) > 0 is a positive function, Œ∏ q√óq is the
parameter vector and œá a compact set. If the N observations {yi , xi }Ni=1 are in-
dependent, then the Fisher information matrix for the approximate design Œæ over
the regression design œá is
                                         Z
                           M (Œæ, Œ∏)q√óq =    I(x, Œ∏)dŒæ(x)                       (7)
                                                  œá

where
                         1    ‚àÇŒ∑(x, Œ∏) ‚àÇŒ∑(x, Œ∏) 1     1      ‚àÇS(x, Œ∏) ‚àÇS(x, Œ∏)
        I(x, Œ∏)q√óq =                       T
                                               +                                          (8)
                       S(x, Œ∏) ‚àÇŒ∏       ‚àÇŒ∏       2 S(x, Œ∏) 2   ‚àÇŒ∏      ‚àÇŒ∏ T

   This theorem is the main tool of this methodology, because it allows the re-
searcher many ways of modelling the variance and incorporate it in the model.
Corollary 1. For the power of the mean variance model given in (1), where the
errors are independent and have normal distribution with mean zero and variance
var(i ) = œÉ 2 (Œ∑(xi , Œ≤))2œÑ with Œ≤, œÑ and œÉ 2 parameters, the information matrix is
given by
                             M (Œæ, Œ∏) = U W U T + V W V T                        (9)
where
            U (p+2)√ón = (u1 , u2 , . . . , un ) V (p+2)√ón = (v 1 , v 2 , . . . , v n )   (10)
                                        w1 0 ¬∑ ¬∑ ¬∑ 0
                                  Ô£´                        Ô£∂
                                  Ô£¨ 0 w2                   Ô£∑
                          W =Ô£¨ .                                                         (11)
                                  Ô£¨                        Ô£∑
                                  Ô£≠ ..             ..      Ô£∑
                                                      .    Ô£∏
                                          0             wr

                                           Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

100                                        Jaime Andr√©s Gaviria V√≠ctor Ignacio L√≥pez-R√≠os


and for i = 1, 2, . . . , n:
                                                               T
                                         1      ‚àÇŒ∑(xi , Œ≤)
                         ui =                              , 0.0                          (12)
                                     œÉŒ∑(xi , Œ≤)œÑ ‚àÇŒ≤ T            (p+2)√ó1

                           ‚àö                                           !T
                           2œÑ ‚àÇŒ∑(xi , Œ≤) ‚àö                   1
               vi =                  T
                                        , 2 log Œ∑(xi , Œ≤), ‚àö                              (13)
                        Œ∑(xi , Œ≤) ‚àÇŒ≤                         2œÉ 2
                                                                           (p+2)√ó1

    This result is the key at the construction of D-optimal designs and can be
implemented computationally to obtain the designs. We will illustrate the use of
this corollary with an application in the next section. But before we need the
following important result which is one of the equivalence theorems. This theorem
allows to verify if the obtained design is in fact the optimal design (Kiefer &
Wolfowitz 1960)
Theorem 2. D-optimality equivalence theorem.
    Let M (Œæ, Œ∏)q√óq the information matrix of the design Œæ positive, Œ®(Œæ, Œ∏) =
log |M (Œæ, Œ∏)| the D-optimality criterion and œá a compact set. Then the design Œæ ‚àó
is D-optimal if the directional derivative of œÜ in Œæ ‚àó on the direction of Œæx holds
                               œÜ(M (Œæ ‚àó , Œ∏), M (Œæx , Œ∏)) ‚â§ 0 ‚àÄx ‚àà œá                      (14)
                ‚àó                                      ‚àí1   ‚àó
where œÜ(M (Œæ , Œ∏), M (Œæx , Œ∏)) = T r(M (Œæx )M (Œæ )) ‚àí q and Œæx is the design that
puts all probability in x. Also, œÜ(M (Œæ ‚àó ), M (Œæx )) = 0 at the support points of
design Œæ ‚àó .

    This result is useful to verify the D-optimality of a design Œæ ‚àó , because one can
plot the directional derivative œÜ(M (Œæ ‚àó , Œ∏), M (Œæx , Œ∏)) over x ‚àà œá and to check that
this function at most zero over all experimental region (œá) and also that in the
support points of the design, the equality holds.


2.2. Transformation of the Model
   The second methodology consists of applying an adequate transformation on
the model to obtain constant variance. We focus on the Box-Cox transformations,
which are given by Box Cox (1964).
                                  ( Œª
                                    y ‚àí1
                           (Œª)        Œª    for Œª 6= 0
                          y =                                              (15)
                                    log y for Œª = 0

   The value of the parameter Œª usually is unknown, but in some cases it can be
assessed depending on the response. For instance, if the response is a volume, the
appropriate transformation can be the cube root (Œª = 1/3) and the square root if
the response corresponds to count data (Atkinson Cook 1997).
   Now, Atkinson Cook (1997) find D-optimal designs when a Box-Cox trans-
formation is applied, the resulting model is linear
                                       Y (Œª) = f T (x)Œ≤ + ‚àó                              (16)


                                             Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

D-Optimal Designs                                                                        101

and the errors have normal distribution with constant variance ‚àó ‚àº N (0, œÉ 2 ).
   However, as illustrated in the example and since the original model is nonlinear,
we must find some appropriate Œª such that when we apply the transformation to
both sides of the model, the transformed model is linear in the parameters. It is
important to observe that in our case, the parameter Œª will be known, which is an
advantage, because we do not need to estimate this parameter. However, when the
parameter Œª is unknown, it is possible to find the design, see for example Atkinson
(2003) for more details.
   Then, the authors show that the information matrix over the design region for
the transformed model is (see the details in Atkinson Cook 1997)
                                        Z
                            M (Œæ, Œ∏) =     I(Œ∏)Œæ(dx)                        (17)
                                              œá

where the symmetric matrix I(Œ∏) is given by
                       2                     
                        ‚àÇ log f (Y i |xi , Œ∏)
          I(Œ∏) = ‚àíE
                               ‚àÇŒ∏ 2
                   Ô£´                                                    (Œª)
                                                                                     Ô£∂
                         ffT               0                 ‚àí f E(œÉYÃá2       )
                   Ô£¨                                                ‚àó     (Œª)        Ô£∑
               = Ô£≠ Ô£¨       0               1
                                         2œÉ 4               ‚àí E( œÉYÃá4          )    Ô£∑
                                                                                     Ô£∏   (18)
                                              ‚àó (Œª)
                                   (Œª)
                                                        E(YÃá (Œª) )2 +E(‚àó YÃà (Œª) )
                         ‚àí f E(œÉYÃá2 )    ‚àí E( œÉYÃá4 )               œÉ2


with ‚àó = Y (Œª) ‚àí f T (x)Œ≤, f = f (x) and YÃá (Œª) , YÃà (Œª) denote the first and second
derivative respect to Œª and are given by:

                                    Y Œª log Y Œª ‚àí Y Œª + 1
                         YÃá (Œª) =                         and                            (19)
                                              Œª2
                                Y Œª (log Y Œª ‚àí 1)2 + Y Œª ‚àí 2
                        YÃà (Œª) =                                              (20)
                                              Œª3
However, these expressions have to be approximated using first-order Taylor ap-
proximations, since the expected values can not be calculated exactly. Finally,
once the design is found using the above expressions, is necessary verify the D-
optimality of the design using a similar result of the equivalence theorem 2.


3. Example
   In Section 2 we described the two methodologies commonly used to handle the
heteroscedasticity of a model. Now we illustrate these methods with one example.


3.1. PCB Model
   The example consists of a study realized in 1972 in Lake Cayuga, New York,
where the concentrations of Polychlorinated biphenyls (PCB) were made in a group

                                         Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

102                                                  Jaime Andr√©s Gaviria V√≠ctor Ignacio L√≥pez-R√≠os


of 28 trout at several ages in years. ‚ÄúThe ages of the fish were accurately known
because the fish are annually stocked as yearlings and distinctly marked as to year
class‚Äù (Bates Watts 1988, pp. 267‚Äì268). The data taken from Bates Watts
(1988), are shown in the table 1 and the scatter plot is shown in figure 1.

                                             Table 1: Lake Cayuga data.
                   Age                      1.00   1.00      1.00    1.00      2.00    2.00    2.00
          Concentration                     0.60   1.60      0.50    1.20      2.00    1.30    2.50
                   Age                      3.00   3.00      3.00    4.00      4.00    4.00    5.00
          Concentration                     2.20   2.40      1.20    3.50      4.10    5.10    5.70
                   Age                      6.00   6.00      6.00    7.00      7.00    7.00    8.00
          Concentration                     3.40   9.70      8.60    4.00      5.50   10.50   17.50
                   Age                      8.00   8.00      9.00   11.00     12.00   12.00   12.00
          Concentration                    13.40   4.50     30.40   12.40     13.40   26.20    7.40



                                      30

                                      25
                  PCB concentration




                                      20

                                      15

                                      10

                                       5

                                       0
                                               2      4        6          8    10     12
                                                             Age(years)
                            Figure 1: Scatter plot of Lake Cayuga data.


   The plot of the data shows that the concentration of Polychlorinated biphenyls
(PCB) increases when the age of the trout does. Also, the relationship between
the variables clearly is not linear, so we propose to fit the nonlinear model:
                                                    Y = Œ≤1 eŒ≤2 x +                                    (21)
with Œ≤1 , Œ≤2 are unknown parameters to be estimated.
   Now, we are going to find the D optimal design for this model with the two
methodologies described above. Because our designs are local, we use the data
only with the purpose to have a good local value of the parameter vector.

3.1.1. Variance Modelling

    First, we apply the methodology consisting on modelling the variance of the
errors with an appropriate function. In figure 1, we see that the variability of the
concentration increases as a power function of the mean, so we propose to fit the
model (21) with variance structure (5)
                  Y = Œ≤1 eŒ≤2 x + , where  ‚àº N (0, œÉ 2 (Œ≤1 eŒ≤2 x )2œÑ )                                (22)


                                                          Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

D-Optimal Designs                                                                           103

with œÑ an unknown parameter to be estimated.
    Now, we fit the model (22) in R Development Core Team (2013) and we used
the gnls function for the generalized nonlinear least squares method. The results
of the estimation are showed in table 2.

              Table 2: Generalized nonlinear least squares estimation.
                                    Parameter    Estimation
                                       Œ≤1           0.91
                                       Œ≤2           0.31
                                        œÑ           1.19
                                        œÉ           0.34


   Next, we perform the likelihood ratio test to determine if the model with
variance structure (22) is better than the model with constant variance (21). The
results of the test are showed in table 3 (the model 1 corresponds to the model
with variance structure (22) and the model 2 to the model with constant variance
(21) ).

                    Table 3: ANOVA for the likelihood ratio test.
           Model    df     AIC          BIC         logLik    Test     L.Ratio    p-value
    (22)    1       4    134.5534     139.8822    -63.27671
    (21)    2       3    178.8002     182.7968    -86.40008   1 vs 2   46.24674   <.0001


    The conclusion from this test that is the parameter œÑ 6= 0, e.g. the model with
variance structure (22) is better than the model with constant variance (21) with
a signification level of 1%.


3.1.2. D-Optimal Design

    Now, we find the D-optimal design for the model with variance structure (22).
Because we work with local designs, we use the estimation of the parameters
obtained previously like the local value for Œ∏; that is, we use the local value
Œ∏ 0 = (Œ≤1 , Œ≤2 , œÑ, œÉ) = (0.91, 0.31, 1.19, 0.34). Then we implement the corollary 1
through an algorithm in R Development Core Team (2013) and minimize
‚àí log(|M (Œæ, Œ∏)|). In this optimization problem we use the function nlminb over
the experimental region (œá). The local D-optimal design obtained is shown in
table 4 and is denoted by ŒæD . The xi are the support points of the design and
the wi the weights. As we can see, even though the model with variance structure
(22) has four parameters to be estimated, the design consists only of two points,
which are the extreme points of the regression range œá = [1, 12]. In this sense, if we
could repeat the experiment and our objective are to estimate the parameters with
minimum variance, then we measure the Polychlorinated biphenyls concentration
in trout with ages of one and twelve and with equal number of replicates.
   Then we check that the obtained design ŒæD is D-optimal. With this in mind,
by the D-optimality equivalence in theorem 2, we must verify that the directional
derivative of Œ® at ŒæD in the direction of the design that puts all mass at x, Œæx ,


                                          Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

104                                         Jaime Andr√©s Gaviria V√≠ctor Ignacio L√≥pez-R√≠os


                  Table 4: Local D-optimal design ŒæD to the model (22).
                                           xi       1.00       12.00
                                           wi       0.50        0.50



satisfies
                œÜ(M (ŒæD , Œ∏), M (Œæx , Œ∏)) = T r(M (Œæx )M ‚àí1 (ŒæD )) ‚àí 4 ‚â§ 0                    (23)

‚àÄx ‚àà œá = [1, 12]. As we can see in figure 2, this condition holds and the derivative
equals zero at the support points, so the design ŒæD is indeed D-optimal.

                               0.0


                             ‚àí0.5


                             ‚àí1.0
                           y




                             ‚àí1.5


                             ‚àí2.0
                                       2        4          6      8    10   12
                                                           Age
                         Figure 2: Plot of the directional derivative.




3.1.3. Simulations

      We simulate 1,000 times 28 observations of the model with variance structure

            Yi = Œ≤1 eŒ≤2 xi + i , i ‚àº N (0, œÉ 2 (Œ≤1 eŒ≤2 xi )2œÑ ), for i = 1, 2, . . . , 28   (24)

taking the values of xi like the support points of the design ŒæD . Then we sim-
ulate the errors i ‚àº N (0, œÉ 2 (Œ≤1 eŒ≤2 )2œÑ ) for i = 1, 2, . . . , 28; use the estimations
obtained in table 2 like the values of the parameters and with the model (24),
we calculate the response yi0 s. Then, with these simulated data, we obtain the
estimated parameter Œ∏ÃÇ and calculate the relative and mean square error (RE and
MSE respectively). We repeat this process 1,000 times and summarize it in table
5, showing the descriptive measures for both errors. This table shows the mean,
median, range and standard deviation for the MSE of each parameter of the model
(24) and the relative error in percentage RE(Œ∏)√ó100%. For the parameter vector Œ∏
we propose an overall discrepancy measure, ODM, defined as ODM (Œ∏ÃÇ) = ||Œ∏ ‚àí Œ∏ÃÇ||2 .
From this table, we see that the central tendency measures for the MSE are small
as the variability between the simulations. Also, the mean and median for the
RE are very close to 10%. In general, all these measures indicate that the local
design ŒæD provides good parameter estimates, even though the design only has
two experimental points and the model four parameters.


                                                Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

D-Optimal Designs                                                                     105

 Table 5: Simulations with variance modelling (Std denotes the Standard deviation).
               M SE(Œ≤1 )   M SE(Œ≤2 )     M SE(œÑ )    M SE(œÉ)    ODM (Œ∏)     RE(Œ∏)%
       Mean     9.08e-03    3.13e-04     1.08e-02    5.97e-03    2.61e-02      9.31
      Median    4.28e-03    1.50e-04     5.40e-03    2.68e-03    1.86e-02      8.71
       Range    9.60e-02    5.78e-03     1.15e-01    1.09e-01    2.01e-01     27.60
         Std    1.28e-02    4.61e-04     1.45e-02    8.84e-03    2.56e-02      4.45



3.1.4. Efficiencies

   Finally, we show the robustness of the design ŒæD with respect to the choice of
the local value Œ∏0 , through the D-efficiency of any design Œæ:
                                                  1/p
                                          |M (Œæ)|
                               Deff =                                        (25)
                                         |M (ŒæD )|
where p is the number of parameters of the model and M (Œæ) denotes the informa-
tion matrix of the design, where Œæ is another design obtained with another local
values of parameter vector. With this in mind, we perturb each one of the four
parameters of the model (22) in a percentage ‚àÜ:

                                       Œ∏i ¬± ‚àÜ √ó Œ∏i                                    (26)

    Since the model has four parameters and each one can be perturbed at left,
at right or not be perturbed; it is clear that the total number of perturbations
is 34 = 81. Then each one of these perturbations will give us a design Œæ and
with (25) we calculate how far we are of the local D-optimal design. Then for
a fixed ‚àÜ = 0.6 (we could used another), we obtain 81 designs and for each one
we calculate the respective D-efficiency. However, because most of these designs
were equal to the two point design ŒæD , we only show in table 9 (see the appendix)
the support points, the weights and the D-efficiency of the 36 designs that were
different to the optimal. Figure 3 summarizes the results of the efficiencies and
shows that the design ŒæD is robust respect the choice of the local value Œ∏0 , because
the D-efficiencies are high (at least 0.80).


3.2. Transformation of the Model
    Previously we apply the first methodology of variance modelling and find the
local D-optimal design. Now we use the second methodology, that consists on
applying an adequate transformation on the model. As we described in section
2.2, this transformation should be such that the transformed model is linear and
homoscedastic. In this case as the model (1) is exponential, the appropriate Box-
Cox transformation consists on applying logarithm to both sides:

                               log Y = log Œ≤1 + Œ≤2 x + ‚àó                             (27)

or equivalently in the form:

                                 Y ‚àó = Œ≤1‚àó + Œ≤2 x + ‚àó                                (28)


                                        Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

106                                           Jaime Andr√©s Gaviria V√≠ctor Ignacio L√≥pez-R√≠os




                   0.95
                   0.90
            Deff
                   0.85
                   0.80




                          0        5     10         15        20     25    30      35
                                                         Designs
                              Figure 3: D-efficiencies perturbing Œ∏ in 60%.



where Y ‚àó = log Y , Œ≤1‚àó = log Œ≤1 and the new errors ‚àó are normal with constant
variance. Then we fitted the linear model (28) and we obtained the estimations
Œ≤ÀÜ‚àó = (0.03, 0.26)T , œÉ
                      b = 0.57, and then Œ≤ÃÇ = (e0.03 , 0.26)T = (1.03, 0.26)T . Finally,
we implemented an algorithm in R Development Core Team (2013) to find the in-
formation matrix with Œª = 0 and to obtain the design that minimizes ‚àí log M (Œæ, Œ∏)
over œá = [1, 12]. The resulting design in table 6, shows that in this case the de-
sign is the same obtained with first methodology. However, we have to point out
that despite that the resulting design is the same with both methodologies, it is
attributed to the fact that with each method we used the best local value for the
parameter Œ∏ and as we saw when we calculate the D-efficiencies, the design can
have three support points depending on the local value used.

                              Table 6: D-optimal design to the model (27).
                                               i       1         2
                                              xi    1.00     12.00
                                              wi    0.50      0.50




3.2.1. Simulations

     Analogously to the first methodology, we simulated 28 observations of the
model (28). The results of the 1, 000 simulations are summarized in table 7. This
is similar to the table 5 and shows the mean, median, range and standard deviation
for the MSE of each parameter of the model (27) and relative error in percentage
RE(Œ∏) √ó 100%. For the parameter vector Œ∏ we propose a measure defined as
ODM (Œ∏ÃÇ) = ||Œ∏ ‚àí Œ∏ÃÇ||2 , which is a kind of square distance between the estimated
parameter and the original. The conclusions from these results are similar as the
obtained with the first methodology, although when we compare the measures for
the relative error (RE), is noteworthy that all the descriptive measures are almost
three times the correspondent to the first methodology. But in general, all these
measures indicate that the local design ŒæD fits well the model.


                                                   Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

D-Optimal Designs                                                                      107

Table 7: Simulations for the logarithmic transformation model (Std denotes the Stan-
         dard deviation).
                        M SE(Œ≤1 )   M SE(Œ≤2 )     M SE(œÉ)      ODM (Œ∏)     RE(Œ∏)%
            Mean         1.80e-01    9.57e-04     1.27e-02      1.93e-01      34.0
           Median        1.39e-01    6.48e-04     8.43e-03      1.53e-01      32.4
            Range       1.18e+00     8.65e-03     9.34e-02     1.18e+00       84.0
              Std        1.55e-01    1.00e-03     1.36e-02      1.53e-01      13.1



3.2.2. Efficiencies

    Finally, we obtain the D-efficiencies following the same procedure described in
section 3.1.4. In this case because we perturb three parameters: Œ≤1 , Œ≤2 and œÉ,
we only have 33 = 27 combinations (the parameter Œª = 0). But again most of
all these designs were equal to the D-optimal design, so we only show in table 8
the six designs that correspond to a perturbation ‚àÜ = 60% and were different to
the optimal. In this table we use the symbols ‚àí, + or 0 to indicate the specific
combinations of the parameters.
    For instance, the first design is obtained when we disturb 60% to the left (‚àí)
the parameters Œ≤1 and œÉ and we do not perturb (0) the parameter Œ≤2 . Then the
support points for this design are 1, 6.5 and 12 and the D-efficiency of the design is
0.93. It indicates that if we use this design instead of the unperturbed D-optimal
design, we would need around 7% more observations to obtain the same efficiency
that the D-optimal. Even more, it is remarkable that all six designs have exactly
3 support points: The extremes of the interval [1, 12] and the middle point 6.5.
The only difference between these designs is the weight (in parentheses with two
decimal places) and the D-efficiency, that can be 0.89 or 0.93, but in both cases
it is high, so we can conclude that the D-optimal design is robust respect to the
choice of the local value Œ∏0 .

Table 8: Support points, weights and D-efficiencies perturbing 60% to left (‚àí), right
         (+) or not (0).
              Design     Œ≤1   Œ≤2    œÉ   x1         x2           x3         Def f
                    1    ‚àí    0     ‚àí   1(0.40)    6.5(0.20)    12(0.40)   0.93
                    2    0    0     ‚àí   1(0.40)    6.5(0.20)    12(0.40)   0.93
                    3    +    0     ‚àí   1(0.40)    6.5(0.20)    12(0.40)   0.93
                    4    ‚àí    +     ‚àí   1(0.36)    6.5(0.28)    12(0.36)   0.89
                    5    0    +     ‚àí   1(0.36)    6.5(0.28)    12(0.36)   0.89
                    6    +    +     ‚àí   1(0.36)    6.5(0.28)    12(0.36)   0.89




4. Conclusions
   We have presented a brief summary of two methodologies that can be im-
plemented to find D-optimal designs when the model under study presents hete-
roscedasticity. In both cases the main problem is to find an expression for the
Fisher information matrix of the model. We have illustrated both methods with

                                         Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

108                               Jaime Andr√©s Gaviria V√≠ctor Ignacio L√≥pez-R√≠os


Lake Cayuga data from which clearly do not have constant variance. However,
there is an important difference between the methods that applied: The variance
modelling methodology has the assumption that the errors of the original model
has a normal distribution. However, the second methodology only requires a nor-
mal distribution for the transformed model, not the original. This can be an
advantage of this methodology compared with variance modelling.
    Under both methods, we find the same D-optimal design with two support
points and with equal weights. But this fact is attributed only to the local values
used in an independent way, that in this case were the estimations of the param-
eter vector using the data. Because the optimal design is local, we determine the
robustness of this design with each methodology by disturbing the parameters of
the corresponding model and calculating the D-efficiency of the obtained designs.
In both cases, the efficiencies were high indicating that the D-optimal design is a
robust design respect the choice of the local value Œ∏0 . Also, with each methodol-
ogy we simulate 1, 000 observations of the model and calculate some descriptive
measures for the relative and mean square errors. The results were similar. The
only important difference is that measures for the relative errors of the second
methodology were almost three times the correspondent to the first methodology.
We cannot conclude which methodology is better because each one has its pros
and shortcoming, with the example we obtained similar results.
    Finally, we want to point out that we have not study two potential problems:
First, the problem of heteroscedasticity for G optimality criterion and second, the
problem of nonnormality (for D-optimality or not). Respect to the former, further
work includes finding optimal designs for heteroscedastic models with another
optimality criteria different to D-optimality. For instance, Wong Cook (1993)
have worked with G-optimal designs with linear models when the variance of the
errors is incorporated in the model. With non normality, we did not find too many
published papers, so this can be an interesting problem to work. Finally we have
found local designs, but other option is to use the Bayesian approach.




                                    Revista Colombiana de Estad√≠stica 37 (2014) 95‚Äì110

D-Optimal Designs                                                                         109

Table 9: D-efficiencies, support points and weights with a 60% of perturbation of the
         parameter vector: disturb to left (‚àí), to right (+) or do not (0).
                   Œæi Œ≤1 Œ≤2 œÑ       œÉ   x 1 x2     x3 w 1      w2     w3     Def f
                    1   ‚àí   0   ‚àí   ‚àí   1   5.6    12   0.48   0.02   0.5    0.9883
                    2   0   0   ‚àí   ‚àí   1   5.6    12   0.48   0.02   0.5    0.9883
                    3   +   0   ‚àí   ‚àí   1   5.6    12   0.48   0.02   0.5    0.9883
                    4   ‚àí   +   ‚àí   ‚àí   1   8.26   12   0.27   0.28   0.45   0.8337
                    5   0   +   ‚àí   ‚àí   1   8.26   12   0.27   0.28   0.45   0.8337
                    6   +   +   ‚àí   ‚àí   1   8.26   12   0.27   0.28   0.45   0.8337
                    7   ‚àí   0   +   ‚àí   1   4.45   12   0.44   0.3    0.26   0.8194
                    8   0   0   +   ‚àí   1   4.45   12   0.44   0.3    0.26   0.8194
                    9   +   0   +   ‚àí   1   4.45   12   0.44   0.3    0.26   0.8194
                   10   ‚àí   +   +   ‚àí   1   3.12   12   0.42   0.34   0.24   0.7987
                   11   0   +   +   ‚àí   1   3.12   12   0.42   0.34   0.24   0.7987
                   12   +   +   +   ‚àí   1   3.12   12   0.42   0.34   0.24   0.7987
                   13   ‚àí   0   ‚àí   0   1   5.6    12   0.48   0.02   0.5    0.9883
                   14   0   0   ‚àí   0   1   5.6    12   0.48   0.02   0.5    0.9883
                   15   +   0   ‚àí   0   1   5.6    12   0.48   0.02   0.5    0.9883
                   16   ‚àí   +   ‚àí   0   1   8.26   12   0.27   0.28   0.45   0.8337
                   17   0   +   ‚àí   0   1   8.26   12   0.27   0.28   0.45   0.8337
                   18   +   +   ‚àí   0   1   8.26   12   0.27   0.28   0.45   0.8337
                   19   ‚àí   0   +   0   1   4.45   12   0.44   0.3    0.26   0.8194
                   20   0   0   +   0   1   4.45   12   0.44   0.3    0.26   0.8194
                   21   +   0   +   0   1   4.45   12   0.44   0.3    0.26   0.8194
                   22   ‚àí   +   +   0   1   3.12   12   0.42   0.34   0.24   0.7987
                   23   0   +   +   0   1   3.12   12   0.42   0.34   0.24   0.7987
                   24   +   +   +   0   1   3.12   12   0.42   0.34   0.24   0.7987
                   25   ‚àí   0   ‚àí   +   1   5.6    12   0.48   0.02   0.5    0.9883
                   26   0   0   ‚àí   +   1   5.6    12   0.48   0.02   0.5    0.9883
                   27   +   0   ‚àí   +   1   5.6    12   0.48   0.02   0.5    0.9883
                   28   ‚àí   +   ‚àí   +   1   8.26   12   0.27   0.28   0.45   0.8337
                   29   0   +   ‚àí   +   1   8.26   12   0.27   0.28   0.45   0.8337
                   30   +   +   ‚àí   +   1   8.26   12   0.27   0.28   0.45   0.8337
                   31   ‚àí   0   +   +   1   4.45   12   0.44   0.3    0.26   0.8194
                   32   0   0   +   +   1   4.45   12   0.44   0.3    0.26   0.8194
                   33   +   0   +   +   1   4.45   12   0.44   0.3    0.26   0.8194
                   34   ‚àí   +   +   +   1   3.12   12   0.42   0.34   0.24   0.7987
                   35   0   +   +   +   1   3.12   12   0.42   0.34   0.24   0.7987
                   36   +   +   +   +   1   3.12   12   0.42   0.34   0.24   0.7987




               Recibido: mayo de 2013 ‚Äî Aceptado: enero de 2014
                                                                                     
References
Atkinson A C. Horwitz‚Äôs rule transforming both sides and the design of experiments for mechanistic models.(2003). Journal of the Royal Statistical Society.
Atkinson A C, Cook R D. D-optimum designs for heteroscedastic linear models.(1995). Journal of the American Statistical Association.
Atkinson A C, Cook R D. Designing for a response transformation parameter.(1997). Journal of the Royal Statistical Society. 
Atkinson A C, Donev A N, Tobias R D. Optimum Experimental Designs with SAS.(2007). Oxford Science Publications.
Bates D M, Watts D G. Nonlinear Regression Analysis and its Applications.(1988). John Wiley and Sons.
Box G E P, Cox D R. An analysis of transformations.(1964). Journal of the Royal Statistical Society.
Carroll R, Ruppert D. Transformation and Weighting in Regression.(1988). Taylor Francis.
Dette H, Wong K. Optimal Designs When the Variance Is a Function of the Mean.(1999). Biometrics.
Downing D, Fedorov V, Leonov S. Extracting Information from the Variance Function: Optimal Design.(2001). Springer.
Huet S, Bouvier A, Poursat M, Jolivet E. Statistical Tools for Nonlinear Regression: A Practical Guide With S-PLUS and R Examples.(2004). Springer-Verlag.
Kiefer J. Optimum experimental designs.(1959). Journal of the Royal Statistical Society. 
Kiefer J, Wolfowitz J. The equivalence of two extremum problems.(1960). Canadian Journal of Mathematics.
L√≥pez V, Ramos R. Introducci√≥n a los dise√±os √≥ptimos.(2007). Revista Colombiana de Estad√≠stica.
O‚ÄôBrien T, Funk G M. A gentle introduction to optimal design for regression models.(2003). Journal of the American Statistical Association.
R Development Core Team. R: A Language and Environment for Statistical Computing.(2013). R Foundation for Statistical Computing.
Ritz C, Streibig J. Nonlinear Regression with R.(2008). Springer.
Seber G, Wild C. Nonlinear Regression.(1989). John Wiley.
Wong W K, Cook R D. Heteroscedastic G-optimal designs.(1993). Journal of the Royal Statistical Society.
