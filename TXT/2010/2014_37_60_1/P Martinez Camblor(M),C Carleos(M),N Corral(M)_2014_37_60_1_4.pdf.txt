Cramér-Von Mises Statistic for Repeated Measures. El estadístico de Cramér-Von Mises para medidas repetidas
FICYT, Oviedo, Spain.  Universidad de Oviedo, Asturias, Spain
Abstract
The Cramér-von Mises criterion is employed to compare whether the marginal distribution functions of a k-dimensional random variable are equal or not. The well-known Donsker invariance principle and the KarhunenLoéve expansion is used in order to derive its asymptotic distribution. Two different resampling plans (one based on permutations and the other one based on the general bootstrap algorithm, gBA) are also considered to approximate its distribution. The practical behaviour of the proposed test is studied from a Monte Carlo simulation study. The statistical power of the test based on the Cramér-von Mises criterion is competitive when the underlying distributions are different in location and is clearly better than the Friedman one when the sole difference among the involved distributions is the spread or the shape. Both resampling plans lead to similar results although the gBA avoids the usual required interchangeability assumption. Finally, the method is applied on the study of the evolution inequality incomes distribution between some European countries along the years 2000 and 2011.
Key words: Asymptotic Distribution, Bootstrap, Cramér-von Mises statistic, Hypothesis testing, Permutation test, Repeated Measures.
Resumen
El criterio de Cramér-von Mises es empleado para comparar la igualdad entre las distribuciones marginales de una variable aleatoria k-dimensional. El conocido principio de invaranza de Donsker y la expansión de KarhunenLoéve se usan para derivar su distribución asintótica. Dos planes de remuestreo diferentes (uno basado en permutaciones y el otro basado en el algoritmo bootstrap general, gBA) son usados para aproximar su distribución. El comportamiento práctico del test propuesto es estudiado mediante simulaciones de Monte Carlo. La potencia estadística del test basado en el criterio de Cramér-von Mises es competitiva cuando la distribuciones subyacentes difieren en el parámetro de localización. Este test es claramente superior al de Friedman cuando las únicas diferencias son en la dispersión o la forma. Ambos planes de remuestreo obtienen resultados similares aunque el gBA evita la hipótesis de intercambiabilidad. Finalmente, el método propuesto es aplicado al estudio de la evolución de las desigualdades en los ingresos entre algunos países Europeos entre los años 2000 y 2011.
Palabras clave: Bootstrap, distribución asintótica, estadístico de Cramérvon Mises, medidas repetidas, test de hipótesis, test de permutaciones.


1. Introduction
    The comparison of the equality among the marginal distribution functions of
a k-dimensional random variable is a common problem in statistical inference (for
example, in biomedicine, in problems of comparing diagnostic procedures or bioe-
quivalence (Freitag, Czado & Munk 2007). In practice, most frequent cases are
the study of one feature measured on the same subjects at different time moments
(analysis of repeated measures) and matched studies. Despite of, there exists a
number of methods of comparing the equality among k-distributions from inde-
pendent samples, the k-sample problem for dependent data has not been as widely
studied and, the traditional parametric (ANOVA) and nonparametric (Friedman
test) repeated measures procedures are the usual used techniques to solve these
problems.
    In this context, several rank tests have been proposed. In a non exhaustive
revision: Ciba-Geigy & Olsson (1982) developed a specific one for comparing dis-
persion in paired samples design; Lam & Longnecker (1983) introduced modifi-
cations which improve the power of the classical Wilcoxon rank sum test for this
topic; Munzel (1999a) used the normalized version of distribution functions to de-
rive an asymptotic theory for rank statistics including ties and considered a mixed
model which permits almost arbitrary dependences; Munzel (1999b) studied dif-
ferent nonparametric permutation methods for repeated measures problems in a
two sample framework; most recently, Freitag et al. (2007) proposed a test based
on the Mallows distance with this goal. Other authors as Govindarajulu (1995)
Govindarajulu (1997) or Podgor & Gastwirth (1996) also dealt with this topic
from different approaches.
    Although the use of bootstrap on multivariate problems is straightforward in
order to build confidence intervals and related estimates, the way to resampling
under the null (in particular, the way to involve this assumption on the resampling)
for preserving the original data structure is not direct and the use of bootstrap on
hypothesis testing (which involve paired design) is not so clear. It is not trivial
how to involve the (null) hypothesis of equality of the k marginal distributions of a
multivariate random variable. The most common procedure, the permutation test
(see, for example, Good 2000, Munzel 1999b), implies that the different components
of the k-dimensional random vector must be interchangeable (see Venkatraman &
Begg 1996 or, most recently, Nelsen 2007). Under the null, this is not a very strong


                                       Revista Colombiana de Estadística 37 (2014) 45–67

Cramér-Von Mises Statistic for Repeated Measures                                     47

assumption to compare two samples (most of the previous cited works engage, ex-
clusively, on this particular case) but, for three or more samples it means that the
relationship between each pair must be the same (it is also known as sphericity
hypothesis) and, in spite of for most of the usual statistics, in practice, the permu-
tation test has demonstrated its robustness with respect to this assumption, it is
usually violated.
    In this paper, the authors deal with the problem of comparing the equality
among the k marginal distribution functions from a typical multivariate problem.
With this goal, the traditional Cramér-von Mises criterion is considered. The
Donsker invariance principle and the classical Gaussian processes theory, in par-
ticular, the Karhunen-Loève expansion, are used in order to obtain (a not explicit
version of) the asymptotic distribution for the Cramér-von Mises statistic when
the samples are from the same subjects. The properties of this statistic allow
to develop a resampling procedure which does not need the (usual) interchange-
ability (or sphericity) assumption. This method is described and its consistency
is proved. We think it is worth mentioning that, the considered procedures (the
asymptotic, permutation and the bootstrap ones), are simple, useful and easily to
implement. A simulation study is carried out (Section 3); its results suggest that
the Cramér-von Mises criterion obtains good results in all considered situations
and it is clearly better than the Friedman test when distributions differ mainly
in their spread or shape. These results are the usual ones when the Cramér-von
Mises criterion is used in other context (see, for example, Martínez-Camblor &
Uña-Álvarez (2009) or Martínez-Camblor (2011)). Finally, the proposed method
is applied on the study of the inequality incomes between thirty European coun-
tries during the years 2000 and 2011 (Section 4).
   During the revision process of this paper, it has been published the work of
Quessy & Éthier (2012) (QE) which, from a slight different approach, deals with
the same problem. The main results of the present manuscript had been devel-
oped around 2008-2009 and, of course, independently of the previously cited work.
In order to keep this independence and, in spite of several reported results are
overlapping with the obtained by QE, we have maintained them in the appendix.


2. Cramér-von Mises Statistic for Repeated
   Measures
    The well-known Cramér-von Mises criterion introduced, separately by Harald
Crámer and Richard Edler von Mises (Cramér 1928, Von Mises 1991), was origi-
nally to compare the goodness of fit of a probability distribution F ∗ and a fixed
distribution function F0 and is given by
                                Z
                         W = (F ∗ (t) − F0 (t))2 dF0 (t)
                           2


In the immediately one-sample applications, F0 is the theoretical cumulative dis-
tribution function (CDF) and F ∗ is the empirical cumulative distribution func-
tion (ECDF), F̂n . Csörgo & Faraway (1996) derived the exact distribution for


                                       Revista Colombiana de Estadística 37 (2014) 45–67

48                            Pablo Martínez-Camblor, Carlos Carleos & Norberto Corral


this statistic and proposed a correction for its asymptotic distribution. Anderson
(1962) derived the asymptotic distribution for the two-sample case. A standard
k-dimensional generalization was proposed by Kiefer (1959) which considered the
expression
                       Xk    Z
                    2
                 Wk =      ni (F̂ni (Xi , t) − F̂N (X, t))2 dF̂N (X, t)
                           i=1
              Pk
where N = i=1 ni and F̂ni (Xi , t) and F̂n (X, t) are the ECDF referred to the
ith sample (1 ≤ i ≤ k) and to the pooled sample, respectively. Brown (1982)
also dealt with the k-sample problem, he studied the asymptotic distribution and
introduced a permutation test based on the same criterion. In Martínez-Camblor
& Uña-Álvarez (2009), the statistical power of this statistic was considered in a
simulation study (joint with other six statistics based on the ECDF and four more
based on the kernel density estimator). The Wk2 test obtained very competitive
results in the eight considered models (four symmetrical and four asymmetrical).
    In this section we study the different approximations for the distribution of Wk2
when data are from a multivariate variable i.e., in our case, we have a k-dimensional
random sample X = (X1 , . . . , Xk ) with Xi = (xi1 , . . . , xin ) (n subjects have been
collected) for i ∈ 1, . . . , k, from a k-dimensional random variable ξ = (ξ1 , . . . , ξk ).
For each u = (u1 , . . . , uk ) with u1 , . . . , uk ∈ R the k dimensional functions

                     F̂ n (X, u) =(F̂n,1 (X1 , u1 ), . . . , F̂n,k (Xk , uk ))
                           F (u) =(F1 (u1 ), . . . , Fk (uk ))
denote the vectors with the ECDFs and the theoretical cumulative distribution
functions (CDFs), respectively. In Theorem 1, it is proved (we must remark; a
non explicit version of) the asymptotic distribution for the statistic
                           k
                           X  Z
               Wk2 (n) =     n (F̂n,i (Xi , t) − F̂n,• (X, t))2 dF̂n,• (X, t)
                           i=1

where F̂n,i (Xi , t) (1 ≤ i ≤ k) is the ECDF referred to the ith sample and
                    Pk
F̂n,• (X, t) = k −1 i=1 F̂n,i (Xi , t), when the (null) hypothesis
                                  H0 : F1 = · · · = Fk (= F )                              (1)
is true.
Theorem 1. Let ξ be a k-dimensional random vector and let X be a random
sample from ξ (with size n), by using the above notation, if F1 = · · · = Fk (= F )
(null hypothesis), it is hold the (weak) convergence
                                                k X
                                          L
                                                X
                                 Wk2 (n) −→n                    2
                                                          λi,l Mi,l
                                                i=1 l∈N

where {M l = (M1,l , . . . , Mk,l )}l∈N is a sequence of k-dimensional, normal dis-
tributed random variables whose marginals followPa N(0, 1) distribution and
{{λi,l }ki=1 }l∈N are non negative constants satisfying l∈N λ2i,l < ∞ for 1 ≤ i ≤ k.


                                              Revista Colombiana de Estadística 37 (2014) 45–67

Cramér-Von Mises Statistic for Repeated Measures                                        49

    The above Theorem guarantees the consistency and gives the convergence rate
for the studied statistic. However, strictly speaking, this result does not provide
its distribution in full. In order to build asymptotic critical regions, the explicit
values for the {{λi,l }ki=1 }l∈N coefficients must been known (eigenvalues and eigen-
functions must be computed). However, we want to note that this is a non-trivial
problem which involves complex (and sometimes, for some readers, cumbersome
analysis see, for example, Deheuvels 2005). In addition, these eigenvalues depend
on the covariance data structure and they should be computed particularly for each
problem. The following remark is devoted to point out some comments about the
eigenvalues calculation in the two-sample case.
                                                                   2
Note 1. In the two sample-case, the asymptotic R distribution of 2Wk (n) under the
null is equivalent to the distribution of W = (W1 {t} − W2 {t}) dt, where Wi {t}
                                           2

(i ∈ 1, 2) is a standard Brownian bridge. Eigenvalues and eigenfunctions are the
non zero solutions to the Fredholm type integral equation
                                         Z
                              λj ej (u) = C(u, v)e( v)dv

with the above restrictions on the eigenfunctions, ej (i.e. orthonormality). In this
particular setting,
                 C(u, v) =E[(W1 {u} − W2 {u})(W1 {v} − W2 {v})]
                            =2 (u ∧ v − uv) − (f (u, v) + f (v, u))
where f (s, t) = E[W1 {s}W2 {t}] (note that f (s, t) = 0 for independent samples).
Obviously, the particular solutions depend on the function f . For instance, as-
suming f (u, v) + f (v, u) = u ∧ v − uv, functions sin(jπu) and cos(jπu) (j ∈ N)
are possible solutions which lead to eigenvalues in the form λj = (jπ)−2 (see, for
instance, Van der Vaart 1998). 
    Usually, in order to approximate the asymptotic distribution, the largest eigen-
value is taken and the other ones are ignored i.e., by using the coefficients proper-
ties (see the Theorem 1 proof in the Appendix, in particular, equation (8)), it is
obtained the approximation
    k X                k
                                                  !      k
   X                   X   X                            X
                 2                    2                             2
                                                                               
           λi,l Mi,l =         λi,l Mi,l − 1 + Ci ∼         λi,1 Mi,1  − 1 + Ci
   i=1 l∈N            i=1     l∈N                           i=1

Unfortunately, the first eigenvalue is also unknown. However, for each i ∈ 1, . . . , k,
we can approximate the first (and, therefore, the biggest) eigenvalue by
                                        ZZ
                       λ2i,1 ∼ λ̃2i,1 =    Ci,i (s, t)2 dF (s)dF (t)

Note that it is known that λ̃i,1 ≥ λi,1 (i ∈ 1, . . . , k) and the equality is true
only when λi,l = 0 ∀l > 1. Finally, in order to save the relationship among
the different involved samples, we build M 1 = (M1,1 , . . . , Mk,1 ) such that, for
1 ≤ i, j ≤ k
                        Z                               Z                              
                           {YFii (t) − ȲF,• (t)}2 dF (t) {YFjj (t) − ȲF,• (t)}2 dF (t)
          2     2
                   
 Ci Cj E Mi,1 Mj,1   =E


                                          Revista Colombiana de Estadística 37 (2014) 45–67

50                          Pablo Martínez-Camblor, Carlos Carleos & Norberto Corral


We can work, without loss of generality, with E [M1,1 M2,1 ]. It is easy to check that
                        2
2 E[M1,1 M2,1 ]2 = E[M1,1    2
                          M2,1  ] − 1 and
                          Z                               Z                            
    2    2
                   1             1                2            2         2      2
 E M1,1 M2,1 =          E     {YF1 (t) − ȲF,• (t)} dF (t) {YF2 (t) − YF,• (t)} dF (t)
                  C1 C2
                          Z Z                                                          
                    1               1                2   2                2
                =       E      {YF1 (t) − ȲF,• (t)} {YF2 (s) − ȲF,• (s)} dF (t)dF (s)
                  C1 C2
                        ZZ
                    1
                             E (Y F (t)at1 )2 (Y F (s)at2 )2 dF (t)dF (s)
                                                           
                =
                  C1 C2
With some additional computes and taking into account that, for 1 ≤ i, j ≤ k,
Fi,j (u, v) = Fj,i (v, u), it is obtained
                C1,2 (s, t) =E (Y F (s)at1 )(Y F (t)at2 )
                                                        

                         =F1,2 (s, t) − F̄1,· (s, t) − F̄2,· (t, s) + F̄·,· (s, t)     (2)
then,
                                   ZZ
           2    2
                           1               2
                                                                     
         E M1,1 M2,1   =                 2 C1,2 (s, t) + C1 (s)C2 (t) dF (s)dF (t)     (3)
                           C1 C2
and the asymptotic distribution can be approximated by
                                   k 
                                   X                         
                                                2
                                                       
                           CA =          λ̃i,1 Mi,1 − 1 + Ci                           (4)
                                   i=1

We compute λ̃i,1 (1 ≤ i ≤ k) by using the estimation of some parameters of
the statistic and, unfortunately, from this method we cannot estimate any other
eigenvalue. In the independent case, the quality of this approximation has been
checked via simulations (see, for instance, Martínez-Camblor, Carelos & Corral
(2012), and references therein).
    Note that both the expected value and the variance of CA are equal to the
Wk2 (n) ones. The (theoretical) unknown parameters which are involved in the
equation (4) can be estimated by putting the respective ECDFs instead of the the-
oretical ones (typical plug-in method) in their explicit expressions (equations (2)
and (3)). At this point, it is worth to remember that, under the null hypothesis,
all the marginal functions are equal. Once these values are computed, the asymp-
totic distribution under the null might be approximated by using some bound for
the quadratic forms (see, for example, Alkarni & Siddiqui 2001) or by using the
Monte Carlo method: Generating T independent samples (with the original sam-
ple size) from the k-dimensional normal distribution (previously we must compute
its correlation matrix by using the corresponding equations) and computing the
respective T asymptotic values of the statistic by using (4). In Section 3, the latter
possibility is employed in the simulation study.
   On the other hand, the Cramér-von Mises statistic properties allow to pro-
pose an useful resampling plan in order to approximate its distribution for paired
samples in small size problems. The following subsection is devoted to develop a
bootstrap approximation in the current context.


                                          Revista Colombiana de Estadística 37 (2014) 45–67

Cramér-Von Mises Statistic for Repeated Measures                                               51

2.1. Bootstrap Approximation
    The bootstrap, introduced and explored in detail by Bradley Efron (Efron 1979,
Efron 1982), is an (not only but mainly nonparametric) intensive computer-based
method of statistical inference which is often used in order to solve many real ques-
tions without the need of knowing the underlying mathematical formulas. Besides,
under regularity conditions, the distribution bootstrap estimation is asymptoti-
cally minimax among all possible estimates (Beran 1982).
    Despite of the bootstrap method has received a great deal of attention and
popularity, its use on statistical hypothesis testing has received considerable, al-
though minor attention (Martin 2007). Following Hall & Wilson (1991), many
authors such as Westfall & Young (1993) have promoted null resampling as crit-
ical to the proper construction of bootstrap tests. However, in related sample
distribution comparison, it is not straightforward how to resample under the null
and the permutation tests (Good 2000) are the usual ones employed with this
goal. In order to guarantee the consistency of the last method, exchangeability
among the different components must be assumed (Venkatraman & Begg 1996)
and, although for most of the statistics, in practice, this technique has proved its
robustness with respect to this assumption, in k-dimensional problems (k > 2) it
is usually violated. Recently, Martínez-Camblor et al. (2012) proposed a general
resampling plan which focus its use on hypothesis testing without the need of as-
suming additional conditions. In particular, for the present problem, under the
null, it is easy to prove that:


Theorem 2. Under the Theorem 1 assumptions and by using the same nota-
tion. Let X ∗ = (X1∗ , . . . , Xk∗ ) be an independent random sample generated from
F̂ n (X, ·) (multivariate ECDF referred to the random sample X). If
                      k
                      X  Z
        Wk2,∗ (n) =          ∗
                        n {F̂n,i                                 ∗
                                 (Xi∗ , t) − F̂n,i (Xi , t)}2 dF̂n,• (X ∗ , t)
                      i=1
                                      Z
                               − nk          ∗
                                          {F̂n,• (X ∗ , t) − F̂n,• (X, t)}2 dF̂n,•
                                                                               ∗
                                                                                   (X ∗ , t)

                                   ∗
where for each i ∈ 1, . . . , k, F̂n,i                                             ∗
                                       (Xi∗ , t) is the ECDF referred to Xi∗ and F̂n,• (X ∗ , t)
   −1
      Pk       ∗      ∗
=k       i=1 F̂n,i (Xi , t). Under the null, it is held,
             n                                           o
               PX Wk∈,∗ (\) ≤ u − P Wk∈ (\) ≤ u                 −→n 0        a.s.

where PX denotes probability conditionally on sample X.

   The above result proves the punctual convergence (for each, fixed, u ∈ R) of
the bootstrap method. Uniform convergence can also be derived (under mild and
usual conditions) from general theory of U and V statistics (see, for example,
Arcones & Gine 1992). Theorem 2 guarantees that the distribution of Wk2 (n)
can be approximated by the Wk2,∗ (n) one and, as usual, this distribution can be
approximated by using the Monte Carlo method following the algorithm:


                                             Revista Colombiana de Estadística 37 (2014) 45–67

52                           Pablo Martínez-Camblor, Carlos Carleos & Norberto Corral


 B1 . From the original sample, X, compute Wk2 (n).

 B2 . From the multivariate cumulative empirical distribution function, F̂ n (X, t),
      draw B independent k-dimensional random samples with size n,

                             X ∗,b = (X1∗ , . . . , Xk∗ ),   1≤b≤B

 B3 . For b ∈ 1, . . . , B compute Wk2,∗,b (n), from X ∗,b .

 B4 . The distribution of Wk2 (n) is approximated by {Wk2,∗,1 (n), . . . , Wk2,∗,B (n)}
      i.e., the final P -value is given by
                                        B
                                    1 X
                              P =       I{Wk2,∗,b (n) > Wk2 (n)}
                                    B
                                       b=1


    The main difference between this algorithm and the classical bootstrap is that,
in the proposed method, the null hypothesis (and only the null hyporthesis) is
used in order to compute the statistic (bootstrap) values instead of to be used to
draw the bootstrap samples. We do not resampling from the null and this fact,
allows to preserve the original data structure.
    Permutation method is based on the idea that within the same subject, each
value can be located in any position. For this claim, not only the null must be
true but the interchangeability it also must be hold. Although, in practice, the
permutation method has proved its robustness for a wide variety of statistics, let
us to go to an extreme. We consider a three-sample problem (sample size n) where
the first and second variables are the same and the third one is independent from
the other two. In this setting it is derived the equality
            Z                                       
   2            1                                  2
Wk (n) =n         {F̂n,1 (X1 , t) − F̂n,3 (X3 , t)} dF̂n,• (X, t)
                9
               Z                                        
                   1                                   2
           +n        {F̂n,1 (X1 , t) − F̂n,3 (X3 , t)} dF̂n,• (X, t)
                   9
               Z                                        
                   4
           +n        {F̂n,3 (X3 , t) − F̂n,1 (X1 , t)}2 dF̂n,• (X, t) = Sn,1 + Sn,2 + Sn,3 .
                   9

   It is obvious that the value of the difference between the F̂n,1 and F̂n,3 has
not the same weigth in the three summands. However the permutation algorithm
assumes that the summands have the same distribution, in particular the same
expected value. Table 1 depicts the means of Sn,i (labelled as S̄n,i ) for i ∈ 1, 2, 3 in
2,000 Monte Carlo (MC) simulations and when the permutation (P) and the pro-
posed bootstrap (B) are used. The observed rejection proportion (α = 0.05) and
the value of Wk2 (n) are also included. The underlying distributions are uniforms
on [0, 1] and n = 50.
   Although the Wk2 (n) is, in general, well estimated by the permutation method
(the mean is similar to the expected one), the total value is evenly distributed


                                            Revista Colombiana de Estadística 37 (2014) 45–67

Cramér-Von Mises Statistic for Repeated Measures                                              53

Table 1: Means for the three summands and for Wk2 (n) in the problem above described
         for the Monte Carlo approximation (MC) (2,000 iterations) and for the Boot-
         strap and Permutation methods. Observed rejection percentages (α = 0.05)
         are also included.
                         S̄n,1     S̄n,2    S̄n,3    Wk2 (n)        % Rejection
                MC      0.0378    0.0378   0.1456    0.2213            5.0%
                 P      0.0753    0.0744   0.0749    0.2247            8.8%
                 B      0.0368    0.0368   0.1473    0.2210            5.4%



among the three summands. In spite of for the Wk2 (n) the results are, in gen-
eral, good (the observed rejection proportion is too big, but this is an extreme
and bit realistic problem), permutation method does not reflect the data structure
and this fact can drive to mistake when different weighting are considered for the
involved summands or, for instance, in presence of different missing data frame-
works. In summary, the correct performance of the permutation method can not
be guaranteed in absence of the exchangeability hyptothesis.


3. Simulation Study
    In order to investigate the practical behaviour of the proposed methodology,
a Monte Carlo simulation study has been carried out. We estimate the statistical
power (α = 0.05) from 2,000 Monte Carlo replications for different problems. For
the Cramér-von Mises test, asymptotic approximation, CA (the P -value is ap-
proximated from 499 Monte Carlo replications following the approximation given
in (4)), bootstrap approximation, CB (B = 499 in algorithm B1 -B4 ) and the
permutation method, CP (the P -value is also approximated from T = 499 repli-
cations) are considered. Although the number of random combinations is small
to obtain a good estimation for a particular P -value, it is enough to obtain a
good estimation for the statistical power. Note that, here, we are not interested
in the result for each particular problem but in the final rejection proportion. The
classical non-parametric Friedman (FR ) test is also included as the reference one.
Let be Z = (Z1 , Z2 , Z3 ) a three dimensional random vector from a N3 (0, Σ) dis-
tribution where 0 = (0, 0, 0) and the components of the covariance matrix are
σi,j = 1 if i = j and σ1,2 = σ1,3 = 1/4 and σ2,3 = b (cases b = 1/4 and b = 3/4
are considered) and let be Ni , 1 ≤ i ≤ 4, independent random variables with
standard normal distribution. A three dimensional random sample with size n,
X = (X1 , X2 , X3 ), is drawn from the following symmetrical models (MD):
0-I.   X1 ≡ Z1 , X2 ≡ Z2 , X3 ≡ Z3 (Null hypothesis).
1-I.   X1 ≡ Z1 , X2 ≡ Z2 , X3 ≡ (1 − a) ∗ Z3 + a ∗ 3Z3 .
2-I.   X1 ≡ Z1 , X2 ≡ Z2 , X3 ≡ (1 − a) ∗ Z3 + a ∗ (Z
                                                    √3 + 1).
3-I.   X1 ≡ Z1 , X2 ≡ Z2 , X3 ≡ (1 − a) ∗ Z3 + a ∗ ( 3Z3 + 1).
    The following asymmetrical models are also considered:
0-II. X1 ≡ Z12 + N12 + N22 , X2 ≡ Z22 + N12 + N32 , X3 ≡ Z32 + N22 + N32 (Null hypothesis).
1-II. X1 ≡ Z12 +N12 +N22 , X2 ≡ Z22 +N12 +N32 , X3 ≡ (1−a)∗(Z32 +N22 +N32 )+a∗(Z3 +3).
2-II. X1 ≡ Z12 + N12 + N22 , X2 ≡ Z22 + N12 + N32 , X3 ≡ (1 − a) ∗ (Z32 + N22 + N32 ) + a ∗ Z32 .


                                            Revista Colombiana de Estadística 37 (2014) 45–67

54                                                              Pablo Martínez-Camblor, Carlos Carleos & Norberto Corral


3-II. X1 ≡ Z12 + N12 + N22 , X2 ≡ Z22 + N12 + N32 , X3 ≡ (1 − a) ∗ (Z32 + N22 + N32 ) + a ∗
(Z32 + 4i=1 Ni2 ).
      P

Where a = 3/4 and M = (1 − b) ∗ X + b ∗ Y denotes a mixture which takes values
on X with probability (1 − b) and on Y otherwise. A graphical representation
for the respective density functions is shown in Figure 1.
                                                      Type I Models                                              Type II Models


               0.4         f0 (Z3)                                                          0.4       f0   (Z23 + N22 + N23)
                           f1 (0.25Z3 + 0.75*3Z3)                                                     f1   (0.25(Z23 + N22 + N23) + 0.75(Z3 + 3))
                           f2 (0.25Z3 + 0.75(Z3 + 1))                                                 f2   (0.25(Z32 + N22 + N32) + 0.75Z32)
                           f3 (0.25Z3 + 0.75( 3Z3 + 1))                                               f3   (0.25(Z23 + N22 + N23) + 0.75(Z23 + N21 + N22 + N23 + N24))


               0.3                                                                          0.3
     Density




                                                                                  Density
               0.2                                                                          0.2




               0.1                                                                          0.1




               0.0                                                                          0.0


                     −6          −4             −2          0         2   4   6                   0        5                                   10                        15

                                                            t                                                                  t

                          Figure 1: Density functions for the different considered models.


    Table 2 shows the observed rejection proportions for type I (symmetrical)
model for two different sample sizes (n = 25, 50). Figure 2 depicts the ob-
served statistical power for the type I models against sample size (sample sizes
of 10, 25, 40, 50, 65 and 75 were considered). Despite of the rejected observed
percentages are bit larger than the expected ones (in special for the CP approxi-
mation for b = 3/4) the nominal level is, in general, well respected. On the other
hand, the Cramér-von Mises test obtains better results than the Friedman one
even when the difference among the distributions is only in the position parameter
while the variance-covariance structure is the same. Approximations by permuta-
tion and bootstrap obtain quite similar results, although the permutation one is a
bit better for σ2,3 = 3/4. The asymptotic approximation obtains worst results for
small sample sizes but quite similar than the other ones for middle sample sizes
(n > 40).
    Table 3 and Figure 3 are analogous to Table 2 and Figure 2, respectively, for
type II (asymmetrical) models. The nominal level is well respected in all considered
cases. For type II models (Figure 3) the Cramér-von Mises criterion is still the
best when the main difference is not the location parameter (model 1-II). When
the location parameter is the main difference among the curves, the Friedman
test is the best one in model 3-II and the Cramér-von Mises test is the best for
model 2-II, although both tests obtain quite similar results. In this scheme the
approximation to the asymptotic distribution for the Cramér-von Mises test is
slow and, in general, its results are not competitive for n ≤ 50.




                                                                              Revista Colombiana de Estadística 37 (2014) 45–67

Cramér-Von Mises Statistic for Repeated Measures                                                                                                           55

Table 2: Observed rejection probabilities for type I (symmetrical ones) models. The
         nominal level is α = 0.05.
                                                              b = 1/4                                                          b = 3/4
                                    n          CB           CP      CA           FR                                 CB       CP      CA            FR
                            0-I     25        0.059        0.060   0.037        0.051                              0.065    0.074   0.042         0.068
                                    50        0.051        0.052   0.051        0.048                              0.048    0.057   0.045         0.039
                            1-I     25        0.319        0.335   0.219        0.059                              0.365    0.435   0.255         0.058
                                    50        0.713        0.733   0.699        0.050                              0.804    0.856   0.778         0.049
                            2-I     25        0.793        0.780   0.772        0.711                              0.875    0.889   0.815         0.913
                                    50        0.980        0.980   0.980        0.938                              1.000    1.000   1.000         1.000
                            3-I     25        0.576        0.578   0.500        0.410                              0.645    0.682   0.528         0.585
                                    50        0.874        0.873   0.874        0.688                              0.985    0.990   0.980         0.877


                                                MD 1−I, b=1/4                                                                MD 1−I, b=3/4

                          1.0                                                                            1.0
                                    CB
                                    CP
                          0.8                                                                            0.8
                                    CA
   Rejection Proportion




                                                                                  Rejection Proportion
                                    FR
                          0.6                                                                            0.6


                          0.4                                                                            0.4


                          0.2                                                                            0.2


                          0.0                                                                            0.0

                                0        20           40        60         80                                  0       20         40         60       80

                                                      n                                                                            n



                                                MD 2−I, b=1/4                                                                MD 2−I, b=3/4

                          1.0                                                                            1.0


                          0.8                                                                            0.8
   Rejection Proportion




                                                                                  Rejection Proportion




                          0.6                                                                            0.6


                          0.4                                                                            0.4


                          0.2                                                                            0.2


                          0.0                                                                            0.0

                                0        20           40        60         80                                  0       20         40         60       80

                                                      n                                                                            n



                                                MD 3−I, b=1/4                                                                MD 3−I, b=3/4

                          1.0                                                                            1.0


                          0.8                                                                            0.8
   Rejection Proportion




                                                                                  Rejection Proportion




                          0.6                                                                            0.6


                          0.4                                                                            0.4


                          0.2                                                                            0.2


                          0.0                                                                            0.0

                                0        20           40        60         80                                  0       20         40         60       80

                                                      n                                                                            n


Figure 2: Observed rejection probabilities (α = 0.05) for the three different consid-
          ered approximations of the Crámer-von Mises statistic distribution and the
          Friedman test against sample size for the symmetrical (type I) models.




                                                                            Revista Colombiana de Estadística 37 (2014) 45–67

56                                                         Pablo Martínez-Camblor, Carlos Carleos & Norberto Corral


Table 3: Observed rejection probabilities for type II (asymmetrical ones) models. The
         nominal level α = 0.05.
                                                             b = 1/4                                                         b = 3/4
                                      n         CB         CP      CA           FR                                CB       CP      CA             FR
                              0-II    25       0.052      0.058   0.030        0.058                             0.056    0.062   0.032          0.054
                                      50       0.061      0.063   0.057        0.058                             0.054    0.060   0.051          0.054
                              1-II    25       0.293      0.295   0.197        0.106                             0.312    0.304   0.207          0.108
                                      50       0.632      0.628   0.603        0.163                             0.619    0.625   0.592          0.159
                              2-II    25       0.902      0.904   0.872        0.772                             1.000    1.000   1.000          0.999
                                      50       0.932      0.931   0.906        0.845                             1.000    1.000   1.000          1.000
                              3-II    25       0.726      0.738   0.624        0.847                             0.737    0.752   0.632          0.875
                                      50       0.985      0.985   0.979        1.000                             1.000    1.000   0.995          1.000


                                               MD 1−II, b=1/4                                                              MD 1−II, b=3/4

                        1.0                                                                            1.0
                                     CB
                                     CP
                        0.8                                                                            0.8
                                     CA
 Rejection Proportion




                                                                                Rejection Proportion
                                     FR
                        0.6                                                                            0.6


                        0.4                                                                            0.4


                        0.2                                                                            0.2


                        0.0                                                                            0.0

                               0          20         40         60        80                                 0       20          40         60           80

                                                     n                                                                           n



                                               MD 2−II, b=1/4                                                              MD 2−II, b=3/4

                        1.0                                                                            1.0


                        0.8                                                                            0.8
 Rejection Proportion




                                                                                Rejection Proportion




                        0.6                                                                            0.6


                        0.4                                                                            0.4


                        0.2                                                                            0.2


                        0.0                                                                            0.0

                               0          20         40         60        80                                 0       20          40         60           80

                                                     n                                                                           n



                                               MD 3−II, b=1/4                                                              MD 3−II, b=3/4

                        1.0                                                                            1.0


                        0.8                                                                            0.8
 Rejection Proportion




                                                                                Rejection Proportion




                        0.6                                                                            0.6


                        0.4                                                                            0.4


                        0.2                                                                            0.2


                        0.0                                                                            0.0

                               0          20         40         60        80                                 0       20          40         60           80

                                                     n                                                                           n


Figure 3: Observed rejection probabilities (α = 0.05) for the three different consid-
          ered approximations of the Crámer-von Mises statistic distribution and the
          Friedman test against sample size for the asymmetrical (type II) models.




                                                                           Revista Colombiana de Estadística 37 (2014) 45–67

Cramér-Von Mises Statistic for Repeated Measures                                    57

4. Inequality Incomes Analysis
    In order to illustrate the practical performance of the proposed method we
considered the study of the inequality incomes between thirty European countries.
The inequality measure is a complex problem which has been addressed from dif-
ferent approaches (see Cowel (2009) and references therein). Although the Gini
index is, probably, the most popular measure of inequality, other approaches have
also been considered (see, for instance, Martínez-Camblor 2007). Our objective
is to study the (possible) changes in the income distribution inequalities in Eu-
rope. With this goal the GDP per capita in PPS (quote from the site http://epp.
eurostat.ec.europa.eu/tgm/table.do?tab=table&plugin=1&language=
en&pcode=tec00114: Gross Domestic Product (GDP) is a measure for the eco-
nomic activity. It is defined as the value of all goods and services produced less
the value of any goods or services used in their creation. The volume index of
GDP per capita in Purchasing Power Standards (PPS) is expressed in relation to
the European Union (EU-27) average set to equal 100. If the index of a coun-
try is higher than 100, this country’s level of GDP per head is higher than the
EU average and vice versa. Basic figures are expressed in PPS, i.e. a common
currency that eliminates the differences in price levels between countries allowing
meaningful volume comparisons of GDP between countries. Please note that the
index, calculated from PPS figures and expressed with respect to EU27 = 100, is
intended for cross-country comparisons rather than for temporal comparisons.) in
thirty European countries in the years 2000 and 2011 have been collected (down-
loaded from the above website). Due to our objective is not to study the incomes
distribution but the inequalities of these incomes, we have considered the relative
GDP per capita in PPS distribution i.e., the considered variable are 100 times
the original values divided by the European Union one (considering the currently
twenty-seven countries members) and the particular mean has been sustracted.
Figure 4 depicts the empirical cummulative distribution function (ECDF) and the
density estimation function for the considered GDP transformations.
    The value of the Cramér-von Mises statistics between these two distributions
was 0.171. The approximate P-values were 0.012, 0.005 and 0.001 from the asymp-
totic, bootstrap and permutation algorithms (based on 10,000 replications), re-
spectively. All of them reject the null and it can be concluded the inequality of
the incomes does not be equal in 2000 and 2011. The Gini indices were 0.251 and
0.220, respectively.


5. Main Conclusions
    The Cramér-von Mises criterion is widely used in order to compare cumula-
tive distribution functions. Despite of different situations have been considered,
independent k-sample comparison is the most studied problem. We propose the
use of this criterion in a typical k-related sample design. By using the Donsker
invariance principle and the Karhunen-Loève decomposition for stochastic Gaus-
sian processes its asymptotic distribution is developed. Although its explicit


                                      Revista Colombiana de Estadística 37 (2014) 45–67

58                                                            Pablo Martínez-Camblor, Carlos Carleos & Norberto Corral




                                                                                                        0.010
                                   1.0




                                                                                                        0.008
                                   0.8
        Distribution Estimations




                                                                                  Density Estimations
                                                                                                        0.006
                                   0.6




                                                                                                        0.004
                                   0.4




                                                                                                        0.002
                                   0.2




                                                                     2000
                                                                     2011




                                                                                                        0.000
                                   0.0




                                         −100             0        100      200                                 −100       0        100   200

                                                              t                                                                 t




                                                Density




                                                                                                                GDP pc (2000)
                                                          GDP pc (2011)


Figure 4: Upper, distribution (left) and density (right) estimation functions for the
          relative GDP per capita in PPS in thirty European countries in the years
          2000 (black) and 2011 (gray). Lower, bivariate density estimation for the
          GDP per capita in PPS in years 2000 and 2011.



asymptotic distribution is still unknown, the obtained results allow to develop
an useful approximation. As usual, we also explore two different resampling ap-
proximations: the classical and well-known permutation test and the most recent
general bootstrap algorithm (gBA).
    For independent samples, the Cramér-von Mises statistic is underlying distribu-
tion-free, its distribution does not depend on the distribution function where the
samples were drawn, and it can be tabulated in order to obtain the P-value for a
particular problem. In a paired sample design, the statistic distribution depends
on the relationships among the involved variables; this relationship always must
be estimated from the sample (therefore, universal eigenvalues do not exist for this
topic), increasing the necessary time to compute the given asymptotic approxima-
tion. This is the main handicap for using the asymptotic approximation which, in
general, obtains good results for moderate sample sizes.
    A general bootstrap algorithm (gBA) and the usual permutation method are
also studied. The considered bootstrap procedure exploits a particular pivotal
function and introduce the null hypothesis at the moment of computing the value
of the (bootstrap) statistic instead of in the random bootstrap samples genera-
tion process. The main advantage is that the data structure is preserved and


                                                                             Revista Colombiana de Estadística 37 (2014) 45–67

Cramér-Von Mises Statistic for Repeated Measures                                    59

no additional assumptions (only the null) are required. Some details of its con-
sistency are also reported, however reader is referred to Martínez-Camblor et al.
(2012) for more details. This technique has already been used with success in
a paired sample extension of the AC-statistic (Martínez-Camblor 2010) and in
inference on a particular ecological diversity index (Martínez-Camblor, Corral &
Vicente 2011). In an extreme example is showed how the permutation method
can lead to mistakes when the interchangeability assumption is violated, which is
the usual situation when k > 2. However, the observed statistical power in our
simulation study is similar for the three different considered methods. We must
remark that the asymptotic and the bootstrap method avoid the exchangeability
assumption (Von Mises 1991, Nelsen 2007) and do not increase the methodology
complexity.
    As in the independent case (see, for example Martínez-Camblor & Uña-Álvarez
2009), the simulation study results suggest that the Cramér-von Mises criterion is
clearly better than the (classical) Friedman test when the main difference among
the curves is not the location parameter and it obtains very good results otherwise.
On the other hand, the proposed asymptotic approximation obtains similar statis-
tical power than the ones based on resampling for moderate sample sizes. Relevant
differences between two considered variance-covariance matrix structures (b = 1/4
and b = 3/4) have not been observed.
    We think that the considered practical case is specially good in order to illus-
trate the use of the proposed methodology. When the focus is not the location
parameter but the shape, which is the case of the inequality, the Cramér-von Mises
statistics conventionally obtains good powers in order to check the equality of the
involved distribution functions. In this context, traditional text like Friedman or
the Student T-test do not work but the Cramér-von Mises criterion has proved
that is a poweful test and a valuable tool for this kind of goals.
   Part of the results provided in this manuscript are overlapped with the ones
obtained in Quessy & Éthier (2012). However, the present work has been developed
independent and previously to the publication of the Quessy and Éthier one. The
main differences between the works are:

 (a) Our approach is more practical and, from our point of view more easy to
     understand for non probabilistic readers.
 (b) The permutation method is considered and discussed. A pathological case
     where this method fails has been provided.

 (c) A practical use of the gBA and a simulation study where the quality of the
     provided approximations can be checked.
 (d) The considered practical problem illustrates a situation where the equality
     among the location parameters is not the hypothesis to be tested.




                                      Revista Colombiana de Estadística 37 (2014) 45–67

60                        Pablo Martínez-Camblor, Carlos Carleos & Norberto Corral


Acknowledgements
    As usual, we are grateful with Susana Díaz Coto for the final manuscript re-
vision. First author was supported by the research Grant MTM2011-23204 of the
Spanish Ministerio de Ciencia e Innovación (FEDER support included).
                                                                   
          Recibido: septiembre de 2013 — Aceptado: diciembre de 2013


References
Adler, R. J. (1990), An introduction to continuity, extrema and related topics for general gaussian processes, in ‘IMS Lecture Notes-Monograph Series’, Vol. 12, Institute of Mathematical Statistics, Hayward, California.
Alkarni, S. H. & Siddiqui, M. M. (2001), ‘An upper bound for the distribution function of a positive definite quadratic form’, Journal of Statistical Computation and Simulation 69(1), 51–56.
Anderson, T. W. (1962), ‘On the distribution of the two-sample cramér-von mises criterion’, Annals of Mathematical Statistics 33(3), 1148–1159.
Arcones, M. A. & Gine, E. (1992), ‘On the bootstrap of u and v statistics’, Annals of Statistics 20(2), 655–674.
Beran, R. (1982), ‘Estimated sampling distributions: The bootstrap and competitors’, Annals of Statistics 10, 212–225.
Ciba-Geigy, L. S. & Olsson, B. (1982), ‘A nearly distribution-free test for comparing dispersion in paired samples’, Biometrika 69(2), 484–485.
Cowel, F. A. (2009), Measuring inequality. Accesed 16/04/2013. *http://darp.lse.ac.uk/papersdb/cowell_measuringinequality3.pdf
Cramér, H. (1928), ‘On the composition of elementary errors: II statistical applications’, Skandinavisk Aktuarietidskrift 11, 141–180.
Csörgo, S. & Faraway, J. J. (1996), ‘The exact and asymptotic distributions of Cramér-von Mises statistics’, Journals of the Royal Statistical Society B 58(1), 221–234.
Deheuvels, P. (2005), ‘Weighted multivariate Cramér-von Mises-type statistics’, Afrika Statistika 1(1), 1–14.
Efron, B. (1979), ‘Bootstrap methods: Another look at the jackknife’, Annals of Statistics 7, 1–26.
Efron, E. (1982), The Jackknife, the Bootstrap and Other Resampling Plans, Society for Industrial and Applied Mathematics. *http://epubs.siam.org/doi/abs/10.1137/1.9781611970319
Freitag, G., Czado, C. & Munk, A. (2007), ‘A nonparametric test for similarity of marginals–with applications to the assessment of population bioequivalence’, Journal of Statistical Planning & Inference 137(3), 697–711.
Good, P. (2000), Permutation Tests: A Practical Guide to Resampling Methods for Testing Hypotheses, Springer Verlag, New York.
Govindarajulu, Z. (1995), ‘A class of asymptotically distribution free test procedures for equality of marginals under multivariate dependence’, American Journal of Mathematical and Management Sciences 15, 375–394.
Govindarajulu, Z. (1997), ‘A class of asymptotically distribution free tests for equality of marginals in multivariate populations’, Mathematical Methods of Statistics 6, 92–111.Hall, P. & Wilson, S. R. (1991), ‘Two guidelines for bootstrap hypothesis testing’, Biometrics 47, 757–762.
Horváth, L. & Steinebach, J. (1999), ‘On the best approximation for bootstrapped empirical processes’, Statistical & Probability Letters 41, 117–122.
Kiefer, J. (1959), ‘k-Sample analogues of the Kolmogorov-Smirnov, Cramér-von Mises tests’, Annals of Mathematical Statistis 30, 420–447.
Lam, F. C. & Longnecker, M. T. (1983), ‘Modified Wilcoxon rank sum test for paired data’, Biometrika 70(2), 510–513.
Martin, M. A. (2007), ‘Bootstrap hypothesis testing for some common statistical problems: A critical evaluation of size and power properties’, Computational Statistics & Data Analysis 51, 6321–6342.
Martínez-Camblor, P. (2007), ‘Central limit theorems for S-Gini and Theil inequality coefficients’, Revista Colombiana de Estadística 30(2), 287–300.
Martínez-Camblor, P. (2010), ‘Nonparametric k-sample test based on kernel density estimator for paired design’, Computational Statistics & Data Analysis 54, 2035–2045.
Martínez-Camblor, P. (2011), ‘Testing the equality among distribution functions from independent and right censored samples via Cramér-von Mises criterion’, Journal of Applied Statistics 38(6), 1117–1131.
Martínez-Camblor, P., Carelos, C. & Corral, N. (2012), ‘Sobre el estadístico de Cramér-von Mises’, Revista de Matemáticas: Teoría y Aplicaciones 19, 89–101.
Martínez-Camblor, P., Corral, N. & Vicente, D. (2011), ‘Statistical comparison of the genetic sequence type diversity of invasive Neisseria meningitidis isolates in northern Spain (1997-2008)’, Ecological Informatics 6(6), 391–398.
Martínez-Camblor, P. & Uña-Álvarez, J. (2009), ‘Non-parametric k-sample tests: density functions vs distribution functions’, Computational Statistics & Data Analysis 53(9), 3344–3357.
Munzel, U. (1999a), ‘Linear rank score statistics when ties are present’, Statistics & Probability Letters 41, 389–395.
Munzel, U. (1999b), ‘Nonparametric methods for paired samples’, Statistica Neerlandica 53(3), 277–286.
Nelsen, R. B. (2007), ‘Extremes of non-exchangeability’, Statistical Papers 48, 329–336.
Podgor, M. J. & Gastwirth, J. L. (1996), Efficiency robust rank tests for stratified data, in E. Brunner & M. Denker, eds, ‘Research Developments in Probability and Statistics’, Festschrift in honor of Madan L. Puri. VSP International Science Publishers, Leiden, Netherlands.
Quessy, J. F. & Éthier, F. (2012), ‘Cramér-von Mises and characteristic function tests for the two and k-sample problems with dependent data’, Computational Statistics and Data Analysis 56, 2097–2111.
Van der Vaart, A. W. (1998), Asymptotic Statistics, Cambridge University Press, Cambridge.
Venkatraman, E. S. & Begg, C. B. (1996), ‘A distribution-free procedure for comparing receiver operating characteristic curves from a paired experiment’, Biometrika 83(4), 835–848.
Von Mises, R. E. (1991), Wahrscheinlichkeitsrechnung, Deuticke, Vienna.
Westfall, P. H. & Young, S. S. (1993), Resampling-Based Multiple Testing: Examples and Methods for p-value Adjustment, Wiley, New York.



Appendix
    In this appendix we provide proofs for the two previously enunciated theorems.
In particular, Theorem 1 is based on the well-known Donsker invariance principle
and on classical Gaussian processes theory. In particular, we used the Karhunen-
Loéve decomposition in order to guarantee the existence of the necessary variables
and coefficients. These coefficients values (eigenvalues) are not explicitly com-
puted (the respective eigenfunctions are neither computed). These calculus are,
in general, cumbersome and complex depending, in the present case, on the data
covariance structure (therefore, they are different for each particular problem, uni-
versal coefficients do not exist). The following auxiliar result is, directly, derived
from the Donsker invariance principle:


                                       Revista Colombiana de Estadística 37 (2014) 45–67

Cramér-Von Mises Statistic for Repeated Measures                                                 63

Lemma 1. Let ξ be a k-dimensional random vector and let X be a random sample
from ξ (with size n), by using the above notation, it is had the following weak
convergence
                     √                        L
                       n{Fˆn (X, u) − F (u)} −→n Y F (u)
where Y F (u) = (YF11 (u1 ), . . . , YFkk (uk )) is a k-dimensional Gaussian process which
follows a distribution Nk (0, Σ(u)) where
                                                                              
                         σ1,1 (u1 , u1 ) σ1,2 (u1 , u2 ) . . . σ1,k (u1 , uk )
              Σ(u) = . . . . . . . . . . . . . . . .                ...              (5)
                         σk,1 (uk , u1 ) σk,2 (uk , u2 ) . . . σk,k (uk , uk )
and σi,j (ui , uj ) = Fi,j (ui , uj ) − Fi (ui )Fj (uj ) and Fi,j (ui , uj ) = P{ξi ≤ ui ∩ ξ| ≤
u| } for 1 ≤ i, j ≤ k.
    Furthermore, for u, v ∈ R and 1 ≤ i, j ≤ k, E[YFii (u)YFjj (v)] = σi,j (u, v) =
Fi,j (u, v) − Fi (u)Fj (v) where if (u ∧ v) = min{u, v},
                                   (
                                    P{ξi ≤ u ∩ ξ| ≤ v} if i 6= j
                     Fi,j (u, v) =
                                     P{ξi ≤ (u ∧ v)}     if i = j

      Under the null given in (1) and if for each 1 ≤ i, j ≤ k and for u, v ∈ R we
                                          Pk                                      Pk
define the functions: F̄·,i (u) = k −1 j=1 Fj,i (u, u), F̄·,· (v) = k −1 i=1 F·,i (v, v),
                     Pk                                    Pk
F̄·,i (u, v) = k −1 j=1 Fj,i (u, v), F̄·,· (u, v) = k −1 i=1 F·,i (u, v), Ci (u) = F (u) −
2F̄·,i (u) + F̄·,· (u) and Ci,j (u, v) = Fi,j (u, v) − F̄·,i (v, u) − F̄·,j (u, v) + F̄·,· (u, v) we
can obtain the following result,
Theorem 3. By using the Lemma 1 notation, if F1 = · · · = Fk (= F ) (null
hypothesis), it is held the (weak) convergence
                                                 k X
                                           L
                                                 X
                                Wk2 (n) −→n                      2
                                                           λi,l Mi,l ,
                                                 i=1 l∈N

where {M l = (M1,l , . . . , Mk,l )}l∈N is a sequence of k-dimensional, normal dis-
tributed random variables whose marginals follow P       a N(0, 1) distribution and
{{λi,l }ki=1 }l∈N are non negative constants satisfying l∈N λ2i,l < ∞ for 1 ≤ i ≤ k.

                                                          Pk
Proof . Keeping the Lemma 1 notation, if ȲF,• (t) = k −1 i=1 YFii (t) and taking
into account the well-known convergence supt∈R {F̂n (X, t) − F (t)} −→n 0 (a.s.).
It is easy to see that
                 Xk    Z
       Wk2 (n) =     n {F̂n,i (Xi , t)                                        (6)
                   i=1
                                                       k Z
                                                  L
                                                       X
               − F̂n,• (X, t)}2 dF̂n,• (X, t) −→n               {YFii (t) − ȲF,• (t)}2 dF (t)
                                                        i=1
or equivalently, ∀u ∈ R,




                                               Revista Colombiana de Estadística 37 (2014) 45–67

64                              Pablo Martínez-Camblor, Carlos Carleos & Norberto Corral



                                                         
                   k Z                                   
                            i
                      X
  P Wk∈ (\) ≤ u − P      {YFi (t) − ȲF ,• (t)}∈ dF(t) ≤ u −→N 0 a.s.
                                                           
                                i=∞

                                            i
On the other hand, if X(i) (t) = {YFi (t) − ȲF ,• (t)} (1 ≤ i ≤ k) then, under the
null,
                         X (t) = (X(∞) (t), . . . , X(k) (t))
is a centred k-dimensional Gaussian process. Moreover, if for t ∈ R, t = (t, . . . , t)
and Σ(t) stands for the matrix defined in (2), for symmetry and under the null,
for i ∈ 1, . . . , k it is obtained,

E[X(i) (t)∈ ] =ai Σ(t)ati
              =σi,i (t, t) − σ̄·,i (t) − σ̄i,· (t) + σ̄·,· (t) = F (t) − 2F̄·,i (t) + F̄·,· (t) = Ci (t)

                                                     (i)                                   Pk
where for 1 ≤ i ≤ k, ai = (−1/k, . . . , (k − 1)/k, . . . , −1/k), σ̄·,i (t) = k −1 j=1
                             Pk                                   Pk
σj,i (t, t), σ̄i,· (t) = k −1 j=1 σi,j (t, t) and σ̄·,· (t) = k −1 i=1 σ̄i,· (t, t). In addition,
it is had the covariance

 Ci,j (s, t) =E[X(i) (∫ ) X(|) (t)]
            =Fi,j (s, t) − F̄·,i (s, t) − F̄·,j (s, t) + F̄·,· (s, t) = Ci,j (s, t)   (1 ≤ i, j ≤ k)

and it is easy to check that, for i ∈ 1, . . . , k,
                          ZZ
                               Ci,i (s, t)2 dF (s)dF (t) < ∞

This property allows to apply the Karhunen-Loève decomposition (see, for exam-
ple, Adler 1990) in order to obtain the representation
                          Xq
             X(i) (t) =     λi,l ei,l (t) Mi,l               (for each i ∈ 1, . . . , k)            (7)
                          l∈N


where (for each i ∈ 1, . . . , k) {ei,l (t)}l∈N is a convergent orthonormal sequence
(also known as eigenfunctions) i.e.,
                                                   (
                                                     0 if p 6= q
                      Z
                          ei,p (t)ei,q (t)dF (t) =
                                                     1 if p = q

{M l = (M1,l , . . . , Mk,l )}l∈N are k-dimensional random vectors which marginal
distributions follow a N(0, 1) and, for 1 ≤ i ≤ k {{λi,j }ki=1 }j∈N , are non negative
constants (also known as eigenvalues) satisfying

                       λi,1 ≥ · · · ≥ λi,l ≥ · · · ≥ 0        ∀i ∈ 1, . . . , k.


                                                Revista Colombiana de Estadística 37 (2014) 45–67

Cramér-Von Mises Statistic for Repeated Measures                                                              65

From (7), it is straightforward that, for i ∈ 1, . . . , k,
      Z                     Z X                           !2
                  ∈
                                    p
         X(i) (t) dF(t) =              λi,l ei,l (t) Mi,l dF (t)
                                            l∈N
                                     Z XX
                                                    p          p
                                 =                      λi,l       λi,j ei,l (t)ei,j (t)Mi,l Mi,j dF (t)
                                        l∈N j∈N
                                     XXp                                        Z
                                                           p
                                 =                  λi,l       λi,j Mi,l Mi,j       ei,l (t)ei,j (t)dF (t)    (8)
                                     l∈N j∈N
                                     X
                                                 2
                                 =         λi,l Mi,l                                                          (9)
                                     l∈N

Therefore, from the Fubini Theorem, for i ∈ 1, . . . , k,
             X          Z                  Z
                            X(i) (t)∈ dF(t) = E X(i) (t)∈ dF (t)
                                                          
               λi,l = E
               l∈N                                                                                           (10)
                                                                       Z
                                                                   =       Ci (t)dF (t) = Ci

and                                        ZZ
                           X
                                 λ2i,l =          Ci,i (s, t)2 dF (s)dF (t) < ∞                              (11)
                           l∈N
Now, we are interested in studying the joint distribution of M l (for each fixed
                                  Pk
l ∈ N). We will prove that i=1 ai Mi,l follows a normal distribution for each
a1 , . . . , ak ∈ R and for l ∈ N. Note that, for each (fixed) l ∈ N, we have that
                    X ∗ (t) = (a1 X(∞) (t) e∞,l (t), · · · , ak X(k) (t) ek,l (t))
is a k-dimensional centred Gaussian process. From (7), for each i ∈ 1, . . . , k
                            Xp
                ai ei,l (t)   λi,l ei,j (t) Mi,j = ai X(i) (t) ei,l (t)
                                  j∈N

hence,
              Xp         Z                            Z
         ai     λi,j Mi,j ei,l (t) ei,j (t)dF (t) = ai X(i) (t) ei,l (t)dF(t)
              j∈N

 We can assume that λi,l 6= 0 for 1 ≤ i ≤ k (if some λi,l = 0 (1 ≤ i ≤ k),
Mi,l does not interfere in any definition and we would have freedom to select it
independently with the other ones) hence, from the eigenfunctions properties
                  k             k          Z
                 X             X     ai
                     ai Mi,l =     p          X(i) (t) ei,l (t)dF(t)
                 i=1           i=1
                                      λi,l
                               Z X k
                                        a
                             =        p i X(i) (t) ei,l (t)dF(t)
                                  i=1
                                         λi,l
follows a normal distribution.




                                                    Revista Colombiana de Estadística 37 (2014) 45–67

66                             Pablo Martínez-Camblor, Carlos Carleos & Norberto Corral


    From (6), (7) and (8) we know that there exists a sequence of k-dimensional
normal distributed random variables, {M j }j∈N whose marginals follow a N(0, 1)
distribution and non negative constants {{λi,j }ki=1 }j∈N satisfying (9) and (10),
such that
                                       k X
                                   L
                                      X
                          Wk2 (n) −→n                 2
                                              λi,j Mi,j
                                                     i=1 j∈N

and the proof is concluded.

Theorem 4. Under the Lemma 1 assumptions and by using the same nota-
tion. Let X ∗ = (X1∗ , . . . , Xk∗ ) be an independent random sample generated from
F̂ n (X, ·) (multivariate ECDF referred to the random sample X). If

                     k
                     X  Z
       Wk2,∗ (n) =          ∗
                       n {F̂n,i                                 ∗
                                (Xi∗ , t) − F̂n,i (Xi , t)}2 dF̂n,• (X ∗ , t)
                     i=1
                                          Z
                                   − nk          ∗
                                              {F̂n,• (X ∗ , t) − F̂n,• (X, t)}2 dF̂n,•
                                                                                   ∗
                                                                                       (X ∗ , t)

                                          ∗
where for each i ∈ 1, . . . , k, F̂n,i      (Xi∗ , t) is the ECDF referred to Xi∗ and
                       k
  ∗
      (X ∗ , t) = k −1 i=1 F̂n,i
                             ∗
                                 (Xi∗ , t). Under the null, it is derived,
                      P
F̂n,•
             n                             o
              PX Wk∈,∗ (\) ≤ u − P Wk∈ (\) ≤ u   −→n 0                                  a.s.

where PX denotes probability conditionally on sample X.

Proof . It is easy to check that,
                           k
                           X  Z
              Wk2 (n) =      n {F̂n,i (Xi , t) − F̂n,• (X, t)}2 dF̂n,• (X, t)
                           i=1
                         k
                         X  Z
                       =   n {F̂n,i (Xi , t) − Fi (t)}2 dF̂n,• (X, t)
                           i=1
                               Z
                       −nk         {F̂n,• (X, t) − F (t)}2 dF̂n,• (X, t).

And, directly from the Lemma 1,
                                   k Z                               Z
                           L
                                   X
               Wk2 (n) −→n                    YFii (t)2 dF (t) − k       ȲF,• (t)2 dF (t)
                                   i=1

Of course, the above equation is equivalent to the one in (6). Also from the Lemma
1 and classical theory of stochastic processes (in particular, Horváth & Steinebach
(1999) proved that the expressions supt∈R |F̂n (X, t)−F (t)| and supt∈R |F̂n∗ (X ∗ , t)−
F̂n (X, t)| where X ∗ is an independent random sample with size n generated from


                                                  Revista Colombiana de Estadística 37 (2014) 45–67

Cramér-Von Mises Statistic for Repeated Measures                                     67

F̂n (X, ·) (ECDF referred to the random sample X which sample size is n) have
the same asymptotic distribution), for each u ∈ R, it is had the convergence,
                                                          
                             k                           
                                         i
     PX Wk∈,∗ (\) ≤ u − P 
                               X
                                   I\ YF̂ , YF̂\ ,• (t) ≤ u −→n 0          a.s.
                                          \,i                
                               i=∞


where YF̂n,i (1 ≤ i ≤ k) and ȲF̂n ,• are the processes which appear in the Lemma
2.1 and, for i ∈ 1, . . . , k,
                            Z                         Z
     In YF̂i , YF̂n ,• (t) = YF̂i (t)2 dF̂n,• (X, t) − k ȲF̂n ,• (t)2 dF̂n,• (X, t)
           n,i                   n,i



Due, under the null hypothesis, ∀t ∈ R, it is had the convergence F̂ n (X, t) −→n
F (t) (a.s.), for each u ∈ R, it is directly derived that
               n                                    o
                PX Wk∈,∗ (\) ≤ u − P Wk∈ (\) ≤ u          −→n 0  a.s.




                                       Revista Colombiana de Estadística 37 (2014) 45–67

