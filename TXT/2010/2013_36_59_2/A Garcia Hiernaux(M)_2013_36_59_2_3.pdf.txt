Generalized Portmanteau Tests Based on Subspace Methods
Universidad Complutense de Madrid
Abstract
The problem of diagnostic checking is tackled from the perspective of the subspace methods. Two statistics are presented and their asymptotic distributions are derived under the null hypothesis. The procedures are devised to deal with univariate and multivariate processes, are flexible and able to separately check regular and seasonal correlations. The performance in finite samples of the proposals is illustrated via Monte Carlo simulations and two examples with real data.
Key words: Diagnostic checking, Portmanteau test, Residual autocorrelation, Residuals.
Resumen
Este artículo trata el problema de la diagnosis residual desde la perspectiva de los métodos de subespacios. Se presentan dos estadísticos y sus distribuciones asintóticas bajo la hipótesis nula. Ambos estadísticos pueden usarse con procesos univariantes o multivariantes, son flexibles y permiten contrastar separadamente las correlaciones regulares y estacionales. El comportamiento en muestras finitas de las dos propuestas se ilustra mediante simulaciones de Monte Carlo y dos ejemplos con datos reales.
Palabras clave: autocorrelación residual, diagnosis de residuos, test de Portmanteau, residuos.



1. Introduction
   Since the seminal work by Box Pierce (1970), or the enhanced version by
Ljung Box (1978), many studies have focused in the ability of the statistical
  a Professor. E-mail: agarciah@ucm.es




                                            221

222                                                             Alfredo García-Hiernaux


tests to determine the adequacy of a model. The procedures suggested in this
paper cope with this problem from a novel perspective.
   We use a subspace methods-based approach to derive two tests and their
asymptotic distributions under the null of zero correlations up to order k. As
subspace methods, the procedures are devised to deal with univariate and multi-
variate processes that leads to a generalization of Ljung Box (1978) and Hosking
(1980) -which is the Ljung-Box multivariate version- statistics, hereafter QLB and
PH , respectively.
    The flexibility of the tests allows use to obtain gains in terms of statistical power
and robustness against non-robust competitors as QLB and PH . We propose that
these gains can improve by tuning a specific matrix that may be modified by
the user. Although this is not investigated in this paper, the question is briefly
addressed in the conclusion. However, no comparison against robust statistics is
performed as ours do not belong to this type of test. Our proposals are also able
to separately test seasonal correlations. When applied to seasonal data, our tests
present a gain in terms of degrees of freedom with respect to alternatives devised
to cope with seasonality, as McLeod (1978) or Ursu Duchesne (2009), and in
terms of statistical power when compared to QLB . A Monte Carlo study shows
that the finite sample properties of one of our tests outperform those of QLB in
terms of nominal size, when the number of lags chosen grows, and in statistical
power.
    Finally, results in Aoki (1990), Casals, Sotoca Jerez (1999) and Casals,
García-Hiernaux Jerez (2012) imply that Multiple-Source Error (MSE) state
space, Single-Source Error (SSE) state space and VARMAX models are equally
general and freely interchangeable. This means that our derivation of the distri-
bution for the residuals of a VARMA model permits to test the adequacy of its
equivalent MSE or SSE state space model. Consequently, our procedures can be
sequentially used to determine the system order in a state space model (since the
null hypothesis can always be written as residuals with system order equal to zero)
which is a critical decision in the subspace methods literature and applied data
modeling.
   The plan of the paper is as follows. Section 2 presents previous results in
subspace methods that will be used later. Some distributional results and the
two tests proposed are derived in Sections 3 and 4, respectively. Lastly, Section
5 compares the performance of our proposals with Ljung-Box and Hoskings’ tests
using Monte Carlo experiments and two applications to real data.
   To express the results precisely, we introduce the following notation which will
                                 d                                       a.s.
be use throughout the paper: → means converges in distribution to, → means
converges almost surely to and plim means convergence in probability. These
three concepts are defined, e.g., in White (2001). Furthermore, I n will be an
n-dimensional identity matrix and Am a square m−by−m matrix, unless defined
otherwise. The proofs of the propositions are given in the Appendix.




                                      Revista Colombiana de Estadística 36 (2013) 221–235

Portmanteau Tests Using Subspace Methods                                                223

2. Previous Results in Subspace Methods
    Consider a linear fixed-coefficients system that can be described by the follow-
ing state space model:
                                 xt+1     =   Φxt + Eψ t                               (1a)
                                    zt    =   Hxt + ψ t                                (1b)
where xt is a state n-vector, n being the true order of the system. In addition,
z t is an observable output m-vector, which is assumed to be zero-mean, ψ t is
an unobservable input m-vector, and Φ, E and H are parameter matrices with
dimensions (n × n), (m × m) and (n × m), respectively. We suppose that the
following assumptions hold in (1a-1b).
Assumptions. A.1: ψ t is a sequence of zero-mean uncorrelated variables with
E(ψ t ψ 0t ) = Γ, Γ, where Γ is a positive definite matrix. A.2: The system is stable
and strictly minimum-phase, i.e., all the eigenvalues of Φ and (Φ − EH) lie inside
the unit circle.
    We use the SSE, or also called innovations, form (1a-1b) since it is general
and simpler than other representations. Its generality is discussed by Casals et al.
(2012), who show that SSE, MSE and VARMAX models are equally general and
freely interchangeable.
    Additionally, throughout the paper we will also use z̄ t , a standardized version
                             −1                      T
of z t , defined as z̄ t = Σ̂ 2 z t , where Σ̂ = T −1 z t z 0t and T is the sample size.
                                                     P
                                                     t=1
    García-Hiernaux, Jerez Casals (2010) show that model (1a-1b) can be trans-
formed into a single equation in matrix form as Z f = OX f +V Ψf , where: a) Z f is
a block Hankel matrix whose columns can be generally defined as [z 0t , . . . , z 0t+f −1 ]0
and each column is specified by a different value of t such that: t = p + 1, . . . , T −
f + 1;1 b) p and f are two integers chosen by the user, where p > n; and, c) X f
and Ψf are as Z f but with xt or ψ t , respectively, instead of z t . For simplic-
ity, we assume p = f , denoting this integer by i. In this case, Z f and Ψf are
im × (T − 2i + 1) matrices. To simplify the notation, we denote the number of
columns of both matrices by T∗ = T − 2i + 1. Last, as it is detailed in García-
Hiernaux et al. (2010), Section 2, matrices O and V are known functions of the
original parameter matrices, Φ, E and H:
                                                               0
               O := H 0 (HΦ)0 (HΦ2 )0 . . . (HΦi−1 )0 im×n                              (2)

                                                                         
                      Im               0             0          ...    0
                    HE               Im             0          ...    0
                                                                         
                     HΦE              HE            Im          ...    0               (3)
                                                                         
              V := 
                      ..              ..            ..          ..    .. 
                        .               .             .           .     . 
                                                                         
                   
                       i−2             i−3           i−4
                    HΦ E             HΦ E          HΦ E         ...   I m im

  1 From now on all the block Hankel matrices will be defined in a similar way.




                                         Revista Colombiana de Estadística 36 (2013) 221–235

224                                                                  Alfredo García-Hiernaux


    Given A.2 and for large values of i and T , X f is to a close approximation
representable as a linear combination of the past of the output, M Z p , where
Z p := [z 0t−p , . . . , z 0t−1 ]0 with t = p + 1, . . . , T − f + 1. Then, the relation between
the past and the future of the output can be expressed by:
                                    Z f ' βZ p + V Ψf                                       (4)
where β = OM . For a given system order n, subspace methods first solve a
reduced-rank (as β is an im square matrix with rank n < im) weighted least
squares problem by estimating β as:
                                   β̂ = Z f Z 0p (Z p Z 0p )−1                              (5)
and splitting it to estimate O and M , and then V . Finally, the parameter matrices
in (1a-1b) can be obtained from the estimates Ô, M̂ and V̂ , see, e.g., Katayama
(2005).


3. Some Distributional Results
    We begin by establishing the null hypothesis that z t has no correlations differ-
ent from zero up to lag order k, i.e., H0 : ρj = 0, j = 1, 2, . . . , k, where ρj is the
correlation coefficient of order j. It is common in the literature that the user just
chooses k to conduct the hypothesis testing. Accordingly, we define i as a function
of k, such that i is the integer rounded toward infinity of (k + 1)/2. However, the
tests could be directly adapted to any other value of i, or even different values of
p and f .
     The first proposal uses a generalized least squares approach. Using the pre-
viously defined standardized version of the output and input, we have Z̄ f =
β̄ Z̄ p + V̄ Ψ̄f , where Z̄ p , Ψ̄p are as Z p , Ψp but with z̄ t , ψ̄ t instead of the origi-
nal z t , ψ t . Matrix β̄ can be estimated as (5), but with the standardized matrices
Z̄ p and Z̄ f instead of Z p and Z f . Notice that an immediate consequence of the
null hypothesis is that β̄ = 0im . By applying the vec operator, which stacks the
columns of a matrix into a long vector, on β̄      ˆ we state the following proposition:
                                                    √        ˆ|Z̄ ) →   d
Proposition 1. Given A.1-A.2, under H0 , T∗ vec(β̄                 p       N 0, Π̄), where Π̄
is derived in the Appendix.

    The second test comes from a canonical correlation approach. This one is
based on the information held in O, which affects Z f through β, see (4). The
canonical correlation analysis (CCA) between Z f and Z p is usually performed
                                       1                      1
by analyzing the product (Z f Z 0f )− 2 Z f Z 0p (Z p Z 0p )− 2 , see Katayama (2005) for a
detailed description on CCA. From equation (5), one could get the product above
                  1                                           1                            1
from (Z f Z 0f )− 2 Ô, estimating O as Z f Z 0p (Z p Z 0p )− 2 and then M as (Z p Z 0p )− 2 ,
so that the equality β̂ = Ô M̂ holds. This second alternative leads to Proposition
2:
                                                  √                     1     d
Proposition 2. Given A.1-A.2, under H0 , T∗ vec (Z f Z 0f )− 2 Ô|Z p → N 0, Π̄).


                                         Revista Colombiana de Estadística 36 (2013) 221–235

Portmanteau Tests Using Subspace Methods                                            225

4. The Test Statistics
    The covariance matrix Π̄ is not, generally, the identity matrix. In fact, it is
                                                                   1
only so when i = 1. For i > 1 some elements in β̂ and (Z f Z 0f )− 2 Ô are perfectly
correlated by construction, see equation (8) in the Appendix. However, as the
structure of Π̄ is known, the following proposition applies.
                                                      √           d
Proposition 3. For any random matrix A such that T∗ vecA → N 0, Π̄), there
                                                                                      d
is an idempotent matrix P (im)2 of rank m2 k, such that SA = T∗ vec(A)0 P vec(A) →
χ2m2 k .

Corollary 1. Consequently, by combining Propositions 1, 2 and 3, we get that both,
                       ˆ) and S = T vec (Z Z 0 )− 21 Ô 0 P vec (Z Z 0 )− 12 Ô  con-
             ˆ)0 P vec(β̄
Sβ = T∗ vec(β̄                 O     ∗       f f                   f f
verge to a chi-square distribution with m2 k degrees of freedom.
    Matrix P is the product of two weighting matrices that average the perfectly
correlated elements of vec(A) in a vector of m2 k uncorrelated elements. This point
deserves further discussion, as it makes the procedure flexible by tuning matrix P
according on the specific case. For instance, some P could be chosen with the aim
of reducing the effects of outliers or increasing the statistical power of the tests.
    We have seen that, when i > 1 some elements in β̄        ˆ and (Z Z 0 )− 21 Ô are
                                                                        f   f
perfectly correlated. Matrix P , as it is proposed in the proof of Proposition
3 averages the perfectly correlated elements to obtain a vector of uncorrelated
components. The procedure computes each k-order correlation for different non-
disjoint subsamples and averages them to obtain a single one. In this way, the effect
of an outlier will be mitigated, provided that it only affects a small proportion of
the weighted correlations. This will be more likely the more subsamples we use,
i.e., the higher i is. Obviously, our statistics do not use robust estimation methods,
as M-estimators or MM-estimators, and therefore they are not robust statistics and
will perform worse than those methods in the presence of outliers. However, we
expect that they present a better performance than non-robust statistics as QLB
in such cases; specifically, innovational outliers, additive outliers or level changes
(see, for definitions, Tsay 1988). An example illustrates this feature in the next
section.
    An interesting point that deserves more attention is that one could easily tune
the matrix P according to the data. If we are suspicious about the presence of
outliers then, instead of calculating the mean of several k-order correlation (which
is the proposal here), the median or the minimum could be used. In these cases,
the distribution of the statistics should be derived but the statistics are likely to
be more robust.
    On the other hand, often in practice, only the low-order correlations are of
interest to analysts. Consequently, the possibility of modifying P by increasing
the weights of low lags (either ad-hoc or using a more sophisticated mechanism)
should increase the power of the tests.
   In any case, a standard use of the Portmanteau tests is to check the residuals
obtained from fitting Vector Autoregressive Moving Average, VARMA, models.


                                     Revista Colombiana de Estadística 36 (2013) 221–235

226                                                                     Alfredo García-Hiernaux


Here we adopt the usual definition of a stationary m-variate ARMA(p, q) process
(see, e.g., Liu 2006, p. 14.2). Nevertheless, when z t are the residuals from a
VARMA model, the asymptotic distribution of Sβ and SO is not as it has been
shown. The reason is that A.1 does not hold, as residuals, contrary to innovations,
present some linear constraints inherit from the VARMA estimation (see, e.g.,
Mauricio 2007). In these circumstances, the following proposition establishes the
asymptotic distribution of both statistics.

Proposition 4. When z t in (1b) are the residuals from a fitted m-vector ARMA(p,q)
model, then, under H0 , Sβ and SO converge in distribution to a χ2m2 (k−p−q) .

    At this point, notice that testing H0 in any m-variate process requires (if
the Ljung-Box test is used) a Q-matrix that leads to m2 different statistics. As
Hosking (1980) test, ours offer a more natural scalar statistic instead. Further,
it is straightforward to see that for p = 1 and f = k + 1 both, Sβ and SO , are
equivalent to: (i) Ljung-Box statistic when m = 1 and (ii) Hoskings’ statistic when
m ≥ 1 (see, Hosking 1980, p. 605). In short, our procedures generalize Ljung-Box
and Hosking’s procedures, allowing for different values of p and f .
       Furthermore, these results are extended to multiplicative seasonal VARMA(p, q)
×(P, Q)s models, where s is the seasonal period and (P, Q) are the seasonal au-
toregressive and moving average orders, respectively (see, Liu 2006, p. 14.36).
Regarding this, McLeod (1978), for the univariate case (m = 1), and Ursu Duch-
esne (2009), for multivariate processes, proved that an adjusted version of the Q-
statistic follows a χ2m2 (k−p−q−P −Q) . With our proposals, if one only identifies and
estimates the seasonal parameters (P, Q), Sβ or SO and Proposition 4 could easily
be used to check whether there is seasonal correlation in the residuals, testing H0 :
ρj = 0, j = s, 2s, . . . , ks. The statistics should be computed by replacing Z p and
Z f by their seasonal counterparts Z sp := [z 0t−si , z 0t−s(i−1) , . . . , z 0t−s ]0 and Z sf :=
[z 0t , z 0t+s , . . . , z 0t+s(i−1) ]0 , where t = si+1, s(i+1)+1, . . . , T −s(i−1). In those cases
Sβ and SO follow a χ2m2 (k−P −Q) . Hence, the adequacy of a VARMA(p, q)×(P, Q)s
model can be checked by sequentially identifying, estimating and applying the tests
using the seasonal matrices, Z sp and Z sf , and then the regular ones, Z p and Z f .
The sequential procedure implies a gain in terms of degrees of freedom with re-
spect to Ursu Duchesne (2009) when testing for seasonal correlation, as we only
consider the seasonal part and not the complete model. This may be a great
advantage in very short samples.


5. Numerical Examples
    In this section we investigate the finite sample properties of the proposed tests.
Its performance is compared with that of Ljung-Box (QLB ) and Hosking (PH )
statistics, as they are the most common and cited diagnostic tests in the literature
for the univariate and the multivariate case, respectively. As said previously, no
comparison against robust methods is made as ours do not fulfill those character-
istics. However, in order to analyze its behavior in different situations, we split the


                                           Revista Colombiana de Estadística 36 (2013) 221–235

Portmanteau Tests Using Subspace Methods                                                                                                                        227

study into some Monte Carlo simulations of univariate processes without outliers
contamination and two applications to real data in which, at least the first one,
contains documented additive outliers.


5.1. Monte Carlo Simulations
    Firstly, we will study how the autocorrelation structure affects the empirical
size and power of the tests.

                                         (1+φB)zt= at; k = 5 and T = 50.                                                 z t = (1+θB)at; k = 5 and T = 50.
                             1                                                                              1
                                                   Sβ                                                                              Sβ
                                                   SO                                                                              SO
                           0.8
    Null rejection prob.




                                                                                                           0.8




                                                                                   Null rejection prob.
                                                  QLB                                                                             QLB
                           0.6                                                                             0.6

                           0.4                                                                             0.4

                           0.2                                                                             0.2

                             0                                                                              0
                                 -0.6    -0.4   -0.2    0.0   0.2    0.4     0.6                                 -0.6    -0.4   -0.2    0.0    0.2    0.4     0.6
                                                          φ                                                                               θ
                                        (1+φB)zt = at; k = 10 and T = 300.                                              z t = (1+θB)at; k = 10 and T = 100.
                            1                                                                                1
                                                  Sβ                                                                               Sβ
                                                  SO                                                                               SO
                           0.8
  Null rejection prob.




                                                                                                           0.8
                                                                                    Null rejection prob.




                                                 QLB                                                                              QLB
                           0.6                                                                             0.6

                           0.4                                                                             0.4

                           0.2                                                                             0.2

                            0                                                                                0
                                 -0.6    -0.4   -0.2    0.0   0.2    0.4     0.6                                 -0.6    -0.4   -0.2    0.0    0.2    0.4     0.6
                                                         φ                                                                              θ
                                           (1+ΦB12) zt = at and T = 200.                                                   z t = (1+ΘB12)at and T = 200.
                             1                                                                              1
                                                   Sβ                                                                              Sβ
                                                   SO                                                                              SO
                           0.8
    Null rejection prob.




                                                                                                           0.8
                                                                                   Null rejection prob.




                                                  QLB                                                                             QLB
                           0.6                                                                             0.6

                           0.4                                                                             0.4

                           0.2                                                                             0.2

                             0                                                                              0
                                 -0.6    -0.4   -0.2    0.0   0.2    0.4     0.6                                 -0.6    -0.4   -0.2    0.0    0.2    0.4     0.6
                                                         Φ                                                                              Θ
Figure 1: Empirical size and power of Sβ , SO and QLB for different ARMA processes
          (computed with a χ2k at 5% and 5000 replications). The graphs at the bottom
          depict the size and power for two seasonal processes. In these cases, QLB is
          computed with k = 24 to be able to capture the seasonal structure, while Sβ
          and SO are computed with the seasonal matrices Z sp and Z sf and ks = 2.


   Figure 1 presents the empirical size and power of SO , Sβ and QLB for alter-
native AR(1) and MA(1) processes, with different k (lags) and T (sample size).

                                                                           Revista Colombiana de Estadística 36 (2013) 221–235

228                                                                 Alfredo García-Hiernaux


Hosking’s test is omitted as it coincides with QLB in univariate processes.2 The
most noticeable features of this exercise are:

   1. In processes without seasonality and short samples (T = 50):

        a) QLB and Sβ perform very similarly with autoregressive structures, both
           being slightly more powerful than SO .
        b) The empirical power of QLB is clearly outperformed by our two pro-
           posals when MA structures. This result partially coincides with Monti
           (1994) who proposes a test using the residual partial autocorrelations
           whose behavior is better than that of QLB if the order of the MA is
           understated. However, in that case it was shown that QLB was more
           powerful if the order of the AR part was understated. In contrast, we
           did not find any evidence of this when applying Sβ .

   2. The asymptotically equivalence of the three tests is observed when T grows.
      For T = 300 and a AR(1) process the performance of the three tests is almost
      identical. When T = 200 and a MA(1) process our tests still outperform
      QLB , although less evidently than when T = 50.

   3. In seasonal processes, SO and Sβ clearly outperform QLB in terms of statis-
      tical power. Not surprisingly, this enhancement is even bigger with seasonal
      MA(1) processes. The explanation comes from the fact that SO and Sβ are
      computed with the seasonal matrices Z sp and Z sf defined in Section 4 and
      the test is then computed with k s = 2. However, QLB is computed with
      k = 24 to be able to capture the seasonal correlation.

    Secondly, we analyze the empirical distribution of the statistics under H0 for
white noise samples and increasing values of k. Notice that in those cases the null
distribution follows a χ2k . In this context, Figure 2 shows that Sβ better fits the
theoretical distribution than QLB and SO , when k = 15 and T = 50. Interestingly
enough, the simulations evidence that QLB and SO empirical distributions get
further away from the theoretical one when k increases for a given T . Nevertheless,
the distribution of Sβ correctly fits its theoretical counterpart regardless of the
value of k.3


5.2. Two Examples with Real Data
    The first example with real data considers the Residence Telephone Extensions
Inward Movement known as RESEX series (yt ). The left plot of Figure 3 shows
the original monthly series that goes from January 1966 to May 1973, where obser-
vations t = 83, 84 are larger than the rest. These two outliers have a known cause,
namely a bargain month, in which residence extensions could be requested free of
   2 Simulations with higher lags in pure autoregressive, pure moving average or ARMA models

show similar or mixed results that do not suggest additional conclusions and, consequently, are
not presented here. However, they are available from the author upon request.
   3 Additional simulations not shown here are available from the author upon request.




                                         Revista Colombiana de Estadística 36 (2013) 221–235

Portmanteau Tests Using Subspace Methods                                                                                                              229

                                                                   0.1                                                             2
                                                                  0.08                                                            χ15
                                                                  0.06                                                            Sβ
                                                                  0.04
                                                                  0.02




                             Probability Density Function f(x)
                                                                     0
                                                                         0               10                   20             30              40
                                                                   0.1                                                             2
                                                                  0.08                                                            χ15
                                                                  0.06                                                            SO
                                                                  0.04
                                                                  0.02
                                                                     0
                                                                         0               10                   20             30              40
                                                                   0.1                                                             2
                                                                  0.08                                                            χ15
                                                                  0.06                                                        QLB
                                                                  0.04
                                                                  0.02
                                                                     0
                                                                         0               10                   20             30              40
                                                                                                                   x
Figure 2: Empirical distribution for Sβ , SO and QLB compared to a theoretical χ215 ;
          250,000 replications for T = 50 and k = 15.



charge. Robust methods identify an AR(1) in the regularly and seasonally differ-
enced transformation (∇∇12 yt ), see, e.g., Rousseeuw Leroy (1987) or Li (2004).
On the contrary, standard methods usually do not capture the autocorrelation
structure due to the effect of the outliers.

                   80                                                                                          0.85
                                                                 Resex Original Series                                                  Sβ
                   70                                                                                          0.75                     SO
                                                                                                                                       QLB
                   60                                                                                          0.65
 Inward movement




                   50                                                                                          0.55
                                                                                                    P-value




                                                                                                               0.45
                   40
                                                                                                               0.35
                   30
                                                                                                               0.25
                   20                                                                                          0.15
                   10                                                                                          0.05
                    0                                                                                         -0.05
                    1966 1967 1968 1969 1970 1971 1972 1973                                                            1 3 5 7 9 11 13 15 17 19 21 23 25
                                        Year                                                                                       k (lags)
Figure 3: Top plot: Original RESEX series (yt ). Bottom plot: P-values of Sβ , SO
          and QLB for lags (k) from 1 to 25 obtained by applying the statistics to the
          transformed series ∇∇12 log yt .


    When we apply Sβ , SO and QLB to the transformed series ∇∇12 log yt , we find
that QLB does not reject the null from k = 7 at 5% of significance and from k = 8
at 10%. However, SO rejects the null at a 5% for all k except when k = 12 − 17,
where the p-values always remain below 16%. Finally, Sβ behaves much better
than QLB and SO with this data, rejecting the null at 1% of significance for all
k studied. This example is relevant as most empirical works only show the QLB
values for high lags (usually 10, 15 or 20) without paying attention to the loss of


                                                                                              Revista Colombiana de Estadística 36 (2013) 221–235

230                                                                       Alfredo García-Hiernaux


power when k increases, that can grow dramatically in the presence of outliers. Sβ
behavior explanation lies in the fact that i has been defined as a positive function
of k (see Section 2), so when k grows, i increases. As i is the number of subsamples
to compute the autocorrelations of the same order, when i increases, the weight
of the contaminated subsamples diminishes.
    The second example deals with the logarithms of indices of monthly flour prices
in the cities of Buffalo, Minneapolis and Kansas City, over the period from August
1972 to November 1980, which give us 100 observations at each site. The aim of
modeling these data is to illustrate the performance of the proposed statistics, as
specification tools, and compare it with QLB and PH .
    Since all series appear non-stationary, we use the log-difference transformation
z t = ∇ log(y t ), where y t are the original series. Table 1 shows the results of
applying the statistics to z t with different lags. The first conclusion is that even if
all the tests suggest that there are significant correlations, at least up to order one,
QLB presents very low power when a (not-so) large lag is chosen. It seems that
the significant correlations at lag one are diluted by insignificant correlations at
other lags, and this effect is much more important in QLB than in Sβ , SO or PH .
In this context, notice that Sβ is the only statistic that keeps its p-value under 5%
for k = 5, 10. Additionally, QLB only reveals 5 out of 9 correlations statistically
significant at 5%, when k = 1.

  Table 1: P-value of the statistics. H0 : There are no correlations up to lag k in z t .
                k (lag)    SO       Sβ        PH                  QLB
                                                                  .026∗    .047∗
                                                                                
                                                       .172
                   1      .000∗    .000∗     .000∗    .103       .027∗     .056 
                                                      .045∗       .018∗     .066
                                                                              
                                                        .822      .416     .506
                   5      .241     .035∗      .072     .716      .421     .493
                                                           .470   .309     .549
                                                                              
                                                        .954      .744     .632
                  10      .155     .003∗      .082     .918      .734     .545
                                                        .779      .682     .573
                ∗ rejects at 5%.




    Following the results obtained with QLB at 5% in Table 1 when k = 1, a
restricted VAR(1) model (I − Φ1 B)z t = at is tentatively specified. Parameter
estimates result in:

                    −.188∗       −.035
                                                                            
          0                                           2.263        2.296 2.202
 Φ̂1 =  0          −.289∗         0 ,        Γ̂a =              2.496 2.364 × 10−3 , (6)
        −.401∗       .117          0                                     2.770

where ‘0’ denotes an entry constrained to be zero and ‘∗ ’ means the parameter
is significant at 5%. Table 2 presents the p-value of the diagnostic tests on the
residuals of model (6).

                                           Revista Colombiana de Estadística 36 (2013) 221–235

Portmanteau Tests Using Subspace Methods                                              231

Table 2: P-value of the statistics. H0 : There are no correlations up to lag k in model
         (6) residuals.
                                                    k (lags)
         Statistic
                               2               5                 10            15
          SO                .003∗            .200               .110          .202
           Sβ               .000∗           .003∗              .006∗         .007∗
          PH                .000∗           .037∗               .052          .256
          Q†LB               .429            .869               .792          .884
         Q†LB is to the lowest p-value among all the elements of the QLB matrix.
         ∗ rejects at 5%.




    QLB suggests that the correlations are zero for k = 2, 5, 10, 15 at 10% level
of significance, implying that model (6) is appropriate. However, SO , PH and
Sβ reject H0 for k = 2, k = 2, 5, 10 and k = 2, 5, 10, 15, respectively, at 5%
level. Hence, SO , PH and particularly Sβ strongly evidence that QLB leads to
an inappropriate specification. Instead, if we specify an unrestricted VAR(1), the
estimation returns:

           1.226∗ −1.355∗ .005
                                                                  
                                                2.033 2.140 2.039
  Φ̂1 =  .830∗ −1.027∗ .035 , Γ̂a =                  2.390 2.253 × 10−3 (7)
            .463    −.813∗ .142                                2.647

To check if the residual correlations of model (7) are zero, the four procedures are
again employed. Table 3 shows these results. None of the tests rejects H0 for any
value of k. Surprisingly, QLB presents the smallest evidence in favor of the null
out of the four alternative for k = 2, 5. Model (7) was proposed by Lütkepohl &
Poskitt (1996) and, as it was shown in Grubb (1992), is better than many other
alternatives, in particular model (6).

Table 3: P-value of the statistics. H0 : There are no correlations up to lag k in model
         (7) residuals.
                                                    k (lags)
          Statistic
                               2              5             10               15
            SO               .953           .952           .480             .454
             Sβ              .937           .952           .445             .506
            PH               .945           .951           .601             .838
            Q†LB             .455           .756           .736             .858
          Q†LB is to the lowest p-value among all the elements of the QLB matrix.
          ∗ rejects at 5%.



     From this exercise with multiple series we conclude that: (i) multivariate Port-
manteau statistics, Sβ , SO and PH , perform better than the multiple QLB , and
(ii) Sβ seems to be more powerful than SO and PH when k grows.




                                       Revista Colombiana de Estadística 36 (2013) 221–235

232                                                          Alfredo García-Hiernaux


6. Concluding Remarks
    This work tackles the problem of diagnostic checking from an original view-
point. Two statistics based on subspace methods are presented and their asymp-
totic distributions are derived under the null. They generalize the Box-Pierce
statistic for single series, the Hoskings’ statistic in the multivariate case and are
able to separately test seasonal and regular correlations. Monte Carlo simulations
and two examples with real data show that our proposals perform better than the
common Ljung-Box Q-statistic in many different situations. The procedures can
sequentially be used to determine the system order, as the null hypothesis can
always be written as n = 0, which is a critical decision in the subspace methods
literature and the applied data modeling.
    Moreover, the subspace structure and the possibility of tuning a weight matrix
make the tests more flexible and robust against outliers than non-robust alterna-
tives. In this paper we just propose a particular form for this matrix P (see proof
of Proposition 3), but others are possible and could be fitted to the characteris-
tics of the data. A deeper analysis of this point with the suggestion of different
matrices P could be the core of a next research.
   Finally, the procedures used in the numerical examples and described in the pa-
per are implemented in a MATLAB toolbox for time series modeling called E4 that
can be downloaded from the webpage www.ucm.es/info/icae/e4. The source
code for all the functions in the toolbox is freely provided under the terms of the
GNU General Public License. This site also includes a complete user manual and
other materials.


Acknowledgment
    Manuel Domínguez, Miguel Jerez and two anonymous referees made useful
comments and suggestions to previous versions of this work. The author grate-
fully acknowledges financial support from Ministerio de Educación y Ciencia, ref.
ECO2011-23972 and the Ramón Areces Foundation.
                                                                
             Recibido: noviembre de 2012 — Aceptado: mayo de 2013


Appendix
    Proof of Proposition 1. Equation (4) can be written as an equality by
including a term that tends to zero at an exponential rate as a result of the
minimum-phase assumption. For the lack of simplicity, we neglect this term during
the proof and treat equation (4) as an equality. By applying the vec operator to the
                                                            0
standardized version of equation (4), we have vecZ̄ f = (Z̄ p ⊗ I im )vecβ̄ + vecΨ̄f ,
where we use that, under H , V̄ = I . From this, vecβ̄     ˆ = [(Z̄ 0 ⊗ I )0 (Z̄ 0 ⊗
                                   0        im                                  p    im     p
              0                                            ˆ                −1 0
I im )] (Z̄ p ⊗ I im ) vecZ̄ f , and hence we get vec(β̄ − β̄) = H̄ Ā vecΨ̄f , where
      −1               0
         0                0                                                 ˆ conditional to Z̄
H̄ = Ā Ā and Ā = Z̄ p ⊗I im . Therefore, the covariance of vecβ̄                             p
             ˆ           −1   0               −1
is cov[vecβ̄ |Z̄ p ] = H̄ Ā (Ω ⊗ I m )ĀH̄ , where (Ω ⊗ I m ) denotes de covariance
                                                                0
of vecΨ̄ and we use that, under H0 , E(z̄ t z̄ 0t ) = E(ψ̄ t ψ̄ t ) = I m . Asymptotically, the
                                                                                          0
Ergodic Theorem (see, Theorem 3.34, White 2001) and H0 ensure that T∗−1 Ā (Ω⊗
        a.s.               −1 a.s.
I m )Ā → Π̄ and T∗ H̄         → I (im)2 , where Π̄ has the following structure:
                                                                          
                            I im2      Πi−1        Πi−2         ...    Π1
                          Π0          I im2       Πi−1         ...    Π2 
                           i−1                                            
                           0
                           Π           Π0i−1       I im2        ...    Π3                           (8)
                                                                           
                     Π̄ = 
                           i−2
                           ..            ..          ..        ..      .. 
                           .              .           .           .     . 
                                                                           
                             Π01        Π02         Π03         ...    I im2   (im)2

where Πi−j is a diagonal im2 matrix with ω i−j in the main diagonal,
                                             
                                 0 I m(i−j)
                   ω i−j =                             and j = 1, 2, . . . , T* − 1                  (9)
                                 0    0           im


    Moreover, when j ≥ i, ω i−j is an im zero-matrix. This particular composi-
                                                               √      ˆ|Z̄ ) →
                                                                             d
tion of Π̄ is inherited from the structure of Ψ . Consequently, T vec(β̄
                                                            f                          ∗         p
N 0, Π̄).      

                                                   1                       1                 1
Proof of Proposition 2. Let (Z f Z 0f )− 2 Ô = (Z f Z 0f )− 2 Z f Z 0p (Z p Z 0p )− 2 , which
                      1                  1                                 1
becomes (Z f Z 0f )− 2 Ô = (Z f Z 0f )− 2 (OM Z p + Ψf )Z 0p (Z p Z 0p )− 2 under the null.
                                   1                                           1
Substituting M = (Z p Z 0p )− 2 and vectorizing, we get vec[(Z f Z 0f )− 2 (Ô − O)] =
              1                     1
  (Z p Z p )− 2 Z 0p ⊗ (Z f Z 0f )− 2 vecΨf .
                                    
                                                       1
   The covariance matrix of vec[(Z f Z 0f )− 2 (Ô − O)] conditional to Z p is written
 h            1                   1                               1              1
                                                                                          i
E (Z p Z 0p )− 2 Z p ⊗(Z f Z 0f )− 2 vecΨf vecΨ0f Z 0p (Z p Z 0p )− 2 ⊗(Z f Z 0f )− 2 |Z p .
                                                
                             1                 1
By replacing (Z f Z 0f )− 2 = (Z f Z 0f )− 2 and using that, under H0 , Z f |Z p = Z f ,
                                        1                1                          1
the covariance becomes (Z p Z 0p )− 2 Z p ⊗ (Z f Z 0f )− 2 (Ω ⊗ Q) Z 0p (Z p Z 0p )− 2 ⊗
                                                                 
             1                                        √             1  a.s.            1
(Z f Z 0f )− 2 . Again under the null hypothesis, T∗ (Z f Z 0f )− 2 → I i ⊗ Γ− 2
     √              1 a.s.          1
and T∗ (Z p Z 0p )− 2 → I i ⊗ Γ− 2 hold. Using the properties of the Kronecker

                                          Revista Colombiana de Estadística 36 (2013) 221–235

Portmanteau Tests Using Subspace Methods                                                     235
                                                                          h             1
                                                      1       a.s.
product, we can finally write cov[vec((Z f Z 0f )− 2 Ô)] → T∗−2               (I i ⊗ Γ− 2 )Z p ⊗
                                                                                               

                     1       i
I i Ω Z 0p (I i ⊗ Γ− 2 ) ⊗ I i ⊗ I m .
    

                                                                −1                            0
    On the other hand, the covariance of vec(β̂|Z p ) is H̄          (Z̄ p ⊗I im )(Ω⊗I m )(Z̄ p ⊗
        0−1 a.s.                                                      1
I im )H̄    → T∗−1 Π̄. Finally, as limT →∞ |Z̄p − (I i ⊗ Γ− 2 )Z p | = 0, then both,
vec(β̄ˆ|Z ) and cov[vec((Z Z 0 )− 12 Ô)], tend asymptotically to T −1 Π̄. 
         p                f f                                       ∗


Proof of Proposition 3. As matrix Π̄ is known, it is straightforward to see
that not all the elements in A are independent, except when i = 1, that implies
Π̄ = I m2 . Given the structure of Π̄ and using the submatrix Matlab notation:
(i) The first im elements of vecA, which are A1:im,1:m , are uncorrelated as the
                                                                         0
square submatrix Π̄1:im = I im2 , and (ii) as the first m rows of Π̄i−1 are ze-
ros, then the elements of the submatrix A1:m,m+1:m+2 are also uncorrelated with
those of A1:im,1:m . This occurs for every element in the submatrix A1:m,m+1:im
                                     0
due to the structure of zeros in Π̄i−k , k = 1, 2, . . . , i − 1. Then the elements
in A1:m,m+1:im are uncorrelated with those of A1:im,1:m and, therefore, Π̄ is of
rank m2 (2i − 1). In order to extract m2 k independent elements from A, we use
the singular value decomposition (SVD) of Π̄, yielding a matrix B (im)2 ×m2 k such
         svd           1   1
that Π̄ = U S 2 S 2 V 0 = BB 0 . Consequently, we have B † Π̄B 0† = I m2 k , where
                                                              d
‘†’ denotes the Moore-Penrose pseudo inverse, and B † vec(A) → N 0, T∗−1 I m2 k )
                                                d
which leads to SA = T∗ vec(A)0 P vec(A) → χ2m2 k , P = B 0† B † being a symmetric
idempotent matrix of rank m2 k. 

Proof of Proposition 4. Let the rth autocovariance matrix of the innova-
tions be C r = T −1 ψ t ψ 0t−r and the rth residual autocovariance matrix be Ĉ r =
         0
T −1 ψ̂ t ψ̂ t−r . Further, define C = (C 1 C 2 . . . C k ) and similary Ĉ. (Hosking 1980)
proved that vec(Ĉ) = Dvec(C) where D is idempotent of rank m2 (k − p − q). Let
ˆ be as in (5) but using z̄ instead of z and assuming that z̄ are the standardized
β̄∗                                 t             t                   t
residuals from a VARMA(p, q) model. In such a case, β̄            ˆ a.s.
                                                                     →   ₡̂(I i ⊗ I m )−1 = ₡̂
                                                                   ∗
where:
              Ĉ k̄−i+1    Ĉ k̄−i    ...     Ĉ 1
                                                     
           Ĉ k̄−i+2 Ĉ k̄−i+1 . . .         Ĉ 2                   k if k is odd
                                                                   
    ₡̂ =          ..          ..      ..      ..        with k̄ ≡
                                                     
                                          .                           k + 1 if k is even.
                                                      
                   .           .               .     
                 Ĉ k̄     Ĉ k̄−1 . . . Ĉ k̄−i+1 im
                                                                                          (10)
                                  †     ˆ           †   ˆ
     Then, we can write B vec(β̄ ∗ ) = D̄B vec(β̄ ) as it was done by (Hosking 1980),
since B † vec(β̄    ˆ ) and B † vec(β̄ˆ) have, asymptotically, the same elements as vec(Ĉ)
                   ∗
and vec(C), respectively, but sorted in different order. Likewise, D̄ has the same
rows as D, but ordered differently, that yields rank(D̄) = rank(D) = m2 (k − p −
                                                ˆ|Z ) →
q). Finally, we previously showed that B † vec(β̄
                                                       d
                                                         N 0, T −1 I 2 ) and, con-
                                                          p                ∗      m k
                   ˆ |Z ) →
sequently, B † vec(β̄
                          d                                                 ˆ )→
                                                                 ˆ )0 P vec(β̄
                            N 0, T∗−1 D̄), which leads to T∗ vec(β̄
                                                                                 d
                      ∗ p                                           ∗          ∗
  2
χm2 (k−p−q) . 
References
Aoki M. State Space Modelling of Time Series.(1990). Springer-Verlag.
Box G E P, Pierce D A. Distribution of residuals autocorrelations in autoregressive-integrated moving average time series models.(1970). Journal of the American Statistical Association.
Casals J, García Hiernaux A, Jerez M. From general State-Space to VARMAX models.(2012). Mathematics and Computers in Simulation.
Casals J, Sotoca S, Jerez M. A fast and stable method to compute the likelihood of time invariant state space models.(1999). Economics Letters.
García Hiernaux A, Jerez M, Casals J. Unit roots and cointegration modeling through a family of flexible information criteria.(2010). Journal of Statistical Computation and Simulation.
Grubb H. A multivariate time series analysis of some flour price data.(1992). Applied Statistics.
Hosking J R M. The multivariate Pormanteau statistic.(1980). Journal of the American Statistical Association.
Katayama T. Subspace Methods for System Identification.(2005). Springer-Verlag.
Li W K. Diagnostic Checks in Time Series.(2004). Chapman and Hall/CRC.
Liu L M. Time Series Analysis and Forecasting.(2006). Scientific Computing Associates Corporation.
Ljung G M, Box G E P. On a measure of lack of fit in time series models.(1978). Biometrika.
Lütkepohl H, Poskitt D S. Specification of echelon form VARMA models.(1996). Journal of Business and Economic Statistics.
Mauricio J A. Computing and using residuals in time series models. (2007). Computational Statistics and Data Analysis.
McLeod A I. On the distribution of residual autocorrelations in BoxJenkins model.(1978). Journal of the Royal Statistics Society.
Monti A C. A proposal for residual autocorrelation test in linear models.(1994). Biometrika.
Rousseeuw P J, Leroy A M. Robust Regression and Outlier Detection.(1987). John Wiley.
Tsay R S.Outliers Level shifts and variance changes in time series.(1988). Journal of Forecasting.
Ursu E,Duchesne P.On multiplicative seasonal modelling for vector time series.(2009). Statistics and Probability Letters.
White H. Asymptotic Theory for Econometricians.(2001). Academic Press.