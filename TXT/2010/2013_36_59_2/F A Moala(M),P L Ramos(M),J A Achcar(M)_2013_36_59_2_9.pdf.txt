Bayesian Inference for Two-Parameter Gamma, Distribution Assuming Different Noninformative Priors. Inferencia Bayesiana para la distribución Gamma de dos parámetros asumiendo diferentes a prioris no informativas
Universidade Estadual Paulista, Presidente Prudente, Brasil. Universidade de São Paulo, Ribeirão Preto, Brasil
Abstract
In this paper distinct prior distributions are derived in a Bayesian inference of the two-parameters Gamma distribution. Noniformative priors, such as Jeffreys, reference, MDIP, Tibshirani and an innovative prior based on the copula approach are investigated. We show that the maximal data information prior provides in an improper posterior density and that the different choices of the parameter of interest lead to different reference priors in this case. Based on the simulated data sets, the Bayesian estimates and credible intervals for the unknown parameters are computed and the performance of the prior distributions are evaluated. The Bayesian analysis is conducted using the Markov Chain Monte Carlo (MCMC) methods to generate samples from the posterior distributions under the above priors.
Key words: Gamma distribution, noninformative prior, copula, conjugate, Jeffreys prior, reference, MDIP, orthogonal, MCMC.
Resumen
En este artículo diferentes distribuciones a priori son derivadas en una inferencia Bayesiana de la distribución Gamma de dos parámetros. A prioris no informativas tales como las de Jeffrey, de referencia, MDIP, Tibshirani y una priori innovativa basada en la alternativa por cópulas son investigadas. Se muestra que una a priori de información de datos maximales conlleva a una a posteriori impropia y que las diferentes escogencias del parámetro de interés permiten diferentes a prioris de referencia en este caso. Datos simulados permiten calcular las estimaciones Bayesianas e intervalos de credibilidad para los parámetros desconocidos así como la evaluación del desempeño de las distribuciones a priori evaluadas. El análisis Bayesiano se desarrolla usando métodos MCMC (Markov Chain Monte Carlo) para generar las muestras de la distribución a posteriori bajo las a priori consideradas.
Palabras clave: a prioris de Jeffrey, a prioris no informativas, conjugada, cópulas, distribución Gamma, MCMC, MDIP, ortogonal, referencia.


1. Introduction
    The Gamma distribution is widely used in reliability analysis and life testing
(see for example, Lawless 1982) and it is a good alternative to the popular Weibull
distribution. It is a flexible distribution that commonly offers a good fit to any
variable such as in environmental, meteorology, climatology, and other physical
situations.
   Let X be representing the lifetime of a component with a Gamma distribution,
denoted by Γ(α, β) and given by
                                    β α α−1
                  f (x | α, β) =        x   exp{−βx}, for all x > 0                    (1)
                                   Γ(α)
where α > 0 and β > 0 are unknown shape and scale parameters, respectively.
    There are many papers considering Bayesian inference for the estimation of
the Gamma parameters. Son Oh (2006) assume vague priors for the param-
eters to the estimation of parameters using Gibbs sampling. Apolloni Bassis
(2099) compute the joint probability distribution of the parameters without as-
suming any prior. They propose a numerical algorithm based on an approximate
analytical expression of the probability distribution. Pradhan Kundu (2011)
assume that the scale parameter has a Gamma prior and the shape parameter
has any log-concave prior and they are independently distributed. However, most
of these papers have in common the use of proper priors and the assumption of
independence a priori of the parameters. Although this is not a problem and
have been much used in the literature we, would like to propose a noninformative
prior for the Gamma parameters which incorporates the dependence structure of
parameters. Some of priors proposed in the literature are Jeffreys (1967), MDIP
(Zellner 1977, Zellner 1984, Zellner 1990, Tibshirani 1989), and reference prior
(Bernardo 1979). Moala (2010) provides a comparison of these priors to estimate
the Weibull parameters.
    Therefore, the main aim of this paper is to present different noninformative
priors for a Bayesian estimation of the two-parameter Gamma distribution. We
also propose a bivariate prior distribution derived from copula functions (see for
example, Nelsen 1999, Trivedi Zimmer 2005a, Trivedi Zimmer 2005b) in order
to construct a prior distribution to capture the dependence structure between the
parameters α and β.


                                       Revista Colombiana de Estadística 36 (2013) 319–336

Bayesian Inference for Two-Parameter Gamma Distribution                            321

    We investigate the performance of the prior distributions through a simulation
study using a small data set. Accurate inference for the parameters of the Gamma
is obtained using MCMC (Markov Chain Monte Carlo) methods.


2. Maximum Likelihood Estimation
   Let X1 , . . ., Xn be a complete sample from (1) then the likelihood function is
                                        n               n
                                  β nα Y α−1     n   X      o
                L(α, β | x) =         n    xi   exp −β     xi                      (2)
                                [Γ(α)] i=1             i=1

for α > 0 and β > 0.
                 ∂              ∂
   Considering ∂α  log L and ∂β   log L equal to 0 and after some algebric manip-
ulations we get the likelihood equations given by
                                                            !
                           α                              X
                                         b − ψ(b
                           b
                    β=
                     b        and log α        α) = log ∼                     (3)
                          X                               X
                                0
where ψ(k) = ∂k  ∂               (k)
                   log Γ(k)= ΓΓ(k)   (see Lawless 1982) is the diGamma function,
      Pn                 Q         1/n
           xi                n
X = i=1  n    and X =        i=1 xi      . The solutions for these equations provide
the maximum likelihood estimators α     b and βb for the parameters of the Gamma
distribution (1). As closed form solution is not possible to evaluate (3), numerical
techniques must used. The Fisher information matrix is given by
                                          "              #
                                            ψ 0 (α) − β1
                              I(α, β) =              α                           (4)
                                             − β1    β2

where ψ 0 (α) is the derivative of ψ(α) called as triGamma function.
   For large samples, approximated confidence intervals can be constructed for
the parameters α and β through normal marginal distributions given by

                  b ∼ N (α, σ12 ) and βb ∼ N (0, σ22 ), for n → ∞
                  α                                                                (5)
                                                           2
where σ12 = vb  α) = αbψ ’(b
             ar(b         α          2       b = βb ψ ’(bα)
                                          ar(β)
                           α)−1 and σ2 = vb            α)−1 . In this case, the
                          b
                                                  bψ ’(b
                                                  α
approximated 100(1−Γ)% confidence intervals for each parameter α and β are
given by

                             b + z Γ σ1 and βb − z Γ σ2 < β < βb + z Γ σ2
            b − z Γ σ1 < α < α
            α                                                                      (6)
                  2                 2              2                 2


respectively.




                                    Revista Colombiana de Estadística 36 (2013) 319–336

322                  Fernando Antonio Moala, Pedro Luiz Ramos Jorge Alberto Achcar


3. Jeffrey’s Prior
    A well-known weak prior to represent a situation with little information about
the parameters was proposed by Jeffreys (1967). This prior denoted by πJ (α, β)
is derived from the Fisher information matrix I(α, λ) given in (4) as
                                        p
                             πJ (α, β) ∝ det I(α, β)                           (7)

   Jeffrey’s prior is widely used due to its invariance property under one-to-one
transformations of parameters although there has been an ongoing discussion
about whether the multivariate form prior is appropriate.
      Thus, from (4) and (7) the Jeffreys prior for (α, β) parameters is given by:
                                          p
                                             αψ 0 (α) − 1
                              πJ (α, β) ∝                                          (8)
                                                 β


4. Maximal Data Information Prior (MDIP)
    It is of interest that the data gives more information about the parameter than
the information on the prior density; otherwise, there would not be justification
for the realization of the experiment. Thus, we wish a prior distribution π(φ) that
provides a gain in the information supplied by data in which the largest possible
relative to the prior information of the parameter, that is, which maximize the
information on the data. With this idea Zellner (1977), Zellner (1984), Zellner
(1990) and Min Zellner (1993) derived a prior which maximize the average
information in the data density relative to that one in the prior. Let
                                Z
                        H(φ) =      f (x | φ)lnf (x | φ)dx, x ∈ Rx               (9)
                                    Rx

be the negative entropy of f (x | φ), the measure of the information in f (x | φ)
and Rx the range of density f (x | φ). Thus, the following functional criterion is
employed in the MDIP approach:
                          Z b                Z b
                G[π(φ)] =      H(φ)π(φ)dφ −      π(φ) ln π(φ)dφ               (10)
                                a                     a

which is the prior average information in the data density minus the information in
                                                                       Rb
the prior density. G[π(φ)] is maximized by selection of π(φ) subject to a π(φ)dφ =
1. The solution is then a proper prior given by
                                      n       o
                         π(φ) = k exp H(φ) a ≤ φ ≤ b                           (11)
                Rb     n     o
where k −1 =     a
                   exp  H(φ)  dφ is the normalizing constant.
    Therefore, the MDIP is a prior that leads to an emphasis on the information
in the data density or likelihood function. That is, its information is weak in
comparison with data information.


                                         Revista Colombiana de Estadística 36 (2013) 319–336

Bayesian Inference for Two-Parameter Gamma Distribution                             323

    Zellner (1977), Zellner (1984), Zellner (1990) shows several interesting proper-
ties of MDIP and additional conditions that can also be imposed to the approach
reflection given initial information. However, the MDIP has restrictive invariance
properties.

Theorem 1. Suppose that we do not have much prior information available about
α and β. Under this condition, the prior distribution MDIP, denoted by πZ (α, β),
for the parameters (α, β) of the Gamma density (1) is given by:

                                    β      n                o
                     πZ (α, β) ∝        exp (α − 1)ψ(α) − α                        (12)
                                   Γ(α)

Proof . Firstly, we have to evaluate the measure information H(α, β) for the
Gamma density which is given by
                       Z ∞  α
                                β                 
             H(α, β) =      ln      xα−1 exp{−βx} f (x | α, β) dx       (13)
                         0     Γ(α)

and after some algebra, the result is
                                            Z ∞
     H(α, β) = α ln β − ln Γ(α) + (α − 1)         ln(x)f (x | α, β) dx − βE(X)     (14)
                                            0

with E(X) = α
            β.

                               R∞
   Since the integral functions 0 uα−1 e−u du = Γ(α) and
R∞
 0
   uα−1 log(u)e−u du = Γ0 (α), the function (14) envolving these integrals can be
expressed as
                 H(α, β) = − ln Γ(α) + ln β + (α − 1)ψ(α) − α                (15)

     Therefore, the MDIP prior for the parameters α and β is given by
                                    β      n                o
                     πZ (α, β) ∝        exp (α − 1)ψ(α) − α                        (16)
                                   Γ(α)

    However, the corresponding joint posterior density is not proper, but surpris-
ingly, the prior density given by

                                    β      n        ψ(α)    o
                     πZ (α, β) ∝        exp (α − 1)      −α                        (17)
                                   Γ(α)             Γ(α)

yields a proper posteriory density. Thus, we will use (17) as MDIP prior in the
numerical illustration in Section 8.


5. Reference Prior
   Another well-known class of noninformative priors is the reference prior, first
described by Bernardo (1979) and further developed by Berger Bernardo (1992).

                                     Revista Colombiana de Estadística 36 (2013) 319–336

324                 Fernando Antonio Moala, Pedro Luiz Ramos Jorge Alberto Achcar


    The idea is to derive a prior π(φ) that maximizes the expected posterior infor-
mation about the parameters provided by independent replications of an experi-
ment relative to the information in the prior. A natural measure of the expected
information about φ provided by data x is given by
                              I(φ) = Ex [K(p(φ | x), π(φ))]                            (18)
where
                                                     p(φ | x)
                                           Z
                    K(p(φ | x), π(φ)) =         p(φ | x) log   dφ             (19)
                                        Φ               π(φ)
is the Kullback-Leibler distance. So, the reference prior is defined as the prior
π(φ) that maximizes the expected Kullback-Leibler distance between the posterior
distribution p(φ | x) and the prior distribution π(φ), taken over the experimental
data.
    The prior density π(φ) which maximizes the functional (19) is found through
calculus of variation and, the solution is not explicit. However, when the poste-
rior p(φ | x) is asymptotically normal, this approach leads to Jeffreys prior for
a single parameter situation. If on the other hand, we are interested in one of
the parameters, being the remaining parameters nuisances, the situation is quite
different, and the appropriated reference prior is not a multivariate Jeffrey prior.
Bernardo (1979) argues that when nuisance parameters are present the reference
prior should depend on which parameter(s) are considered to be of primary inter-
est. The reference prior in this case is derived as follows. We will present here
the two-parameters case in details. For the multiparameter case, see Berger &
Bernardo (1992).
   Let θ = (θ1 , θ2 ) be the whole parameter, θ1 being the parameter of interest
and θ2 the nuisance parameter. The algorithm is as follows:
   Step 1: Determine π2 (θ2 | θ1 ), the conditional reference prior for θ2 assuming
that θ1 is known, is given by,
                                            p
                             π2 (θ2 | θ1 ) = I22 (θ1 , θ2 )                    (20)
where I22 (θ1 , θ2 ) is the (2,2)-entry of the Fisher Information Matrix.
      Step 2: Normalize π2 (θ2 | θ1 ).
    If π2 (θ2 | θ1 ) is improper, choose a sequence of subsets Ω1 ⊆ Ω2 ⊆ . . . → Ω on
which π2 (θ2 | θ1 ) is proper. Define the normalizing constant and the proper prior
pm (θ2 | θ1 ) respectively as
                                                    1
                               cm (θ1 ) = R                                            (21)
                                                π (θ
                                              Ωm 2 2
                                                      | θ1 )dθ2
and
                        pm (θ2 | θ1 ) = cm (θ1 )π2 (θ2 | θ1 )1Ωm (θ2 ),                (22)
   Step 3: Find the marginal reference prior πm (θ1 ) for θ1 the reference prior for
the experiment found by marginalizing out with respect to pm (θ2 | θ1 ). We obtain
                          n 1 Z                    det I(θ1 , θ2 )     o
           πm (θ1 ) ∝ exp         pm (θ2 | θ1 )log                 dθ2         (23)
                            2 Ωm                    I22 (θ1 , θ2 )

                                         Revista Colombiana de Estadística 36 (2013) 319–336

Bayesian Inference for Two-Parameter Gamma Distribution                             325

    Step 4: Compute the reference prior πθ1 (θ1 , θ2 ) when θ1 is the parameter of
interest                                              
                                      cm (θ1 )πm (θ1 )
               πθ1 (θ1 , θ2 ) = lim                      π(θ2 | θ1 )          (24)
                               m→∞ cm (θ ∗ ) πm (θ ∗ )
                                          1        1
where θ1∗ is any fixed point with positive density for all πm .
    We will derive the reference prior for the parameters of the Gamma distribution
given in (1), where α will be considered as the parameter of interest and β the
nuisance parameter.
Theorem 2. The reference prior for the parameters of the Gamma distribution
given in (1), where α will be considered as the parameter of interest and β the
nuisance parameter, is given by:
                                         r
                                       1 αψ 0 (α) − 1
                           πα (α, β) =                                     (25)
                                       β       α

   If β is the parameter of interest and α the nuisance, thus the prior is
                                           p
                                             ψ 0 (α)
                               πβ (α, β) ∝                                         (26)
                                              β

Proof . By the approach proposed by Berger Bernardo (1992), we find the
reference prior for the nuisance parameter β, conditionally on the parameter of
interest α, given by
                                                        1
                                         q
                             π(β | α) = Iββ (α, β) ∝                              (27)
                                                        β
where Iββ (α, β) is the (2,2)-entry of the Fisher Information Matrix given in (4).

    As in Moala (2010), a natural sequence of compact sets for (α, β) is (l1n , l2n )×
(q1n , q2n ), so that l1i , q1i → 0 and l2i , q2i → ∞ when i → ∞. Therefore, the
normalizing constant is given by,
                                    1                  1
                      ci (α) = R q2i 1     =                     .                 (28)
                                q1i β
                                      dβ       log q2i − log q1i

   Now from (23), the marginal reference prior for α is given by

                             n 1 Z q2i                  αψ 0 (α)−1
                                              1             β2
                                                                          o
                 πi (α) = exp          ci (α)   log          α       dβ            (29)
                               2 q1i          β             β2

which after some mathematical arrangement, we have
                          r                         Z q2i
                            αψ 0 (α) − 1    n1            1 o
                 πi (α) =                exp ci (α)        dβ                      (30)
                                  α          2       q1i β

   Therefore, the resulting marginal reference prior for α is given by
                                      r
                                         αψ 0 (α) − 1
                             πi (α) ∝                                              (31)
                                               α

                                     Revista Colombiana de Estadística 36 (2013) 319–336

326               Fernando Antonio Moala, Pedro Luiz Ramos Jorge Alberto Achcar


and the global reference prior for (α, β) with parameter of interest α is given by,
                                                           r
                                                         1 αψ 0 (α) − 1
                                           
                              ci (α)πi (α)
          πα (α, β) = lim                     π(β | α) ∝                       (32)
                      i→∞ ci (α∗ ) πi (α∗ )              β        α

considering α∗ = 1
    Similarly we obtain the reference prior considering β as the parameter of in-
terest and α as nuisance. In this case, the prior is
                                            p
                                              ψ 0 (α)
                               πβ (α, β) ∝                                  (33)
                                               β


6. Tibishirani’s Prior
    Given a vector parameter φ, Tibshirani (1989) developed an alternative method
to derive a noninformative prior π(δ) for the parameter of interest δ = t(φ) so that
the credible interval for δ has coverage error O(n−1 ) in the frequentist sense. This
means that the difference between the posterior and frequentist confidence interval
should be small. To achieve that, Tibshirani (1989) proposed to reparametrize the
model in terms of the orthogonal parameters (δ, λ) (see Cox Reid 1987) where
δ is the parameter of interest and λ is the orthogonal nuisance parameter. In this
way, the approach specifies the weak prior to be any prior of the form
                                             p
                              π(δ, λ) = g(λ) Iδδ (δ, λ)                          (34)

where g(λ)> 0 is an arbitrary function and Iδδ (δ, λ) is the “delta” entry of the
Fisher Information Matrix.

Theorem 3. The Tibishirani’s prior distribution πT (α, β) for the parameters (α,
β) of the Gamma distribution given in (1) by considering α as the parameter of
interest and β the nuisance parameter is given by:
                                         r
                                       1 αψ 0 (α) − 1
                           πT (α, β) ∝                                      (35)
                                       β        α

Proof . For the Gamma model (1), we will propose an orthogonal reparametriza-
tion (δ, λ) where δ = α is the parameter of interest and λ is the nuisance parameter
to be evaluated. The orthogonal parameter λ is obtained by solving the differential
equation:
                                       ∂β
                                   Iββ    = −Iαβ                                (36)
                                       ∂α



      From (4) and (36) we have
                                    α ∂β     1
                                           =                                      (37)
                                    β 2 ∂α   β

                                    Revista Colombiana de Estadística 36 (2013) 319–336

Bayesian Inference for Two-Parameter Gamma Distribution                            327

   Separating the variables, (37) becomes the following,
                                    1     1
                                      ∂β = ∂α                                     (38)
                                    β     α

   Integrating both sides we get,

                                log β = log α + h(λ)                              (39)

where h(λ) is an arbitrary function of λ.
    By chosing h(λ) = log λ, we obtained the solution to (36), the nuisance param-
eter λ orthogonal to δ,
                                          β
                                      λ=                                       (40)
                                          α
   Thus, the information matrix for the orthogonal parameters is given by
                                     0
                                     ψ (δ) − 1δ 0
                                                   
                          I(δ, λ) =              δ                        (41)
                                         0      λ2


   From (34) and (41), the corresponding prior for (δ, λ) is given by
                                          r
                                            δψ 0 (δ) − 1
                         πδ (δ, λ) ∝ g(λ)                                         (42)
                                                  δ
where g(λ) is an arbitrary function.
    Due to a lack of uniqueness in the choice of the orthogonal parametrization,
then the class of orthogonal parameters is of the form g(λ), where g(·) is any
reparametrization. This non-uniqueness is reflected by the function g(·) corre-
sponding to (26). One possibility, in the single nuisance parameter case, is to
require that (δ, λ) also satisfies Stein’s condition (see Tibshirani 1989) for λ with
p taken as the nuisance parameter. Under this condition we obtain
                                                    √
                                                ∗     δ
                                  πλ (δ, λ) ∝ g (δ)                              (43)
                                                     λ
                         q
                              0
                                               √
    Now, requiring g(λ) δψ (δ)−1δ     = g ∗ (δ) λδ we have that
                                            r
                                        1       δψ 0 (δ) − 1
                            πT (δ, λ) ∝                                           (44)
                                        λ             δ

    Thus, from (40), the prior expressed in terms of the (α, β) parametrization is
given by                                 r
                                       1 αψ 0 (α) − 1
                           πT (α, β) ∝                                        (45)
                                       β        α
   Note that this prior coincides with reference prior (25) considering α as the
parameter of interest.

                                    Revista Colombiana de Estadística 36 (2013) 319–336

328                 Fernando Antonio Moala, Pedro Luiz Ramos Jorge Alberto Achcar


7. Copula Prior

    In this section we derive a bivariate prior distribution from copula functions
(see for example, Nelsen 1999, Trivedi Zimmer 2005a, Trivedi Zimmer 2005b)
in order to construct a prior distribution to capture the dependence structure
between the parameters α and β. Copulas can be used to correlate two or more
random variables and they provide great flexibility to fit known marginal densities.
   A special case is given by the Farlie-Gumbel-Morgenstern copula which is suit-
able to model weak dependences (see Morgenstern 1956) with corresponding bi-
variate prior distribution for α and β given ρ,

           π(α, β | ρ) = f1 (α)f2 (β) + ρf1 (α)f2 (β)[1 − 2F1 (α)][1 − 2F2 (β)],       (46)

where f1 (α) and f2 (β) are the marginal densities for the random quantities α and
β; F1 (α) and F2 (β) are the corresponding marginal distribution functions for α
and β, and −1 ≤ ρ ≤ 1.
      Observe that if ρ = 0, we have independence between α and β.
  Different choices could be considered as marginal distributions for α and β as
Gamma, exponential, Weibull or uniform distributions.
     In this paper, we will assume Gamma marginal distribution Γ(a1 , b1 ) and Γ(a2 ,
b2 ) for α and β, respectively, with known hyperparameters a1 , a2 , b1 and b2 . Thus,

                                                            n            o
        π(α, β | a1 , a2 , b1 , b2 , ρ) ∝ αa1 −1 β a2 −1 exp −b1 α − b2 β ×
                                       h                                       i   (47)
                                        1 + ρ 1 − 2I(a1 , b1 α) 1 − 2I(a1 , b1 α)

                        Rx
                 1
where I(k, x) = Γ(k)      0
                              uk−1 e−u du is the incomplete Gamma function.

      Assuming the prior (47), the joint posterior distribution for α, β and ρ is given
by,

                                 n
                       β nα Y α−1 
  p(α, β, ρ | x) ∝         n   x
                     [Γ(α)] i=1 i
                                        n   n
                                            X   o
                                     exp −β   xi π(α, β | a1 , a2 , b1 , b2 , ρ)π(ρ) (48)
                                               i=1


where π(ρ) is a prior distribution for ρ.
   In general, many different priors can be used for ρ; one possibility is to consider
an uniform prior distribution for ρ over the interval [−1, 1].

                                         Revista Colombiana de Estadística 36 (2013) 319–336

Bayesian Inference for Two-Parameter Gamma Distribution                            329

8. Numerical Illustration
8.1. Simulation Study
    In this section, we investigate the performance of the proposed prior distribu-
tions through a simulation study with samples of size n = 5, n = 10 and n = 30
generated from the Gamma distribution with parameters α = 2 and β = 3.
    As we do not have an analytic form for marginal posterior distributions we need
to appeal to the MCMC algorithm to obtain the marginal posterior distributions
and hence to extract characteristics of parameters such as Bayes estimators and
credible intervals. The chain is run for 10,000 iterations with a burn-in period of
1,000. Details of the implementation of the MCMC algorithm used in this paper
are given below.

   i) choose starting values α0 and β0 .
  ii) at step i + 1, we draw a new value αi+1 conditional on the current αi from
      the Gamma distribution Γ(αi /c, c);
 iii) the candidate αi+1 will be accepted with a probability given by the Metropo-
      lis ratio                      (                               )
                                          Γ(αi /c, c)p αi+1 , βi | x
                  u(αi , αi+1 ) = min 1 ,                            
                                          Γ(αi+1 /c, c)p αi , βi | x

 iv) sample the new value β i+1 from the Gamma distribution Γ(βi /d, d);
  v) the candidate βi+1 will be accepted with a probability given by the Metropo-
     lis ratio
                                   (                                 )
                                        Γ(βi /d, d)p αi+1 , βi+1 | x
                u(βi , βi+1 ) = min 1 ,                              
                                        Γ(βi+1 /d, d)p αi+1 , βi | x

    The proposal distribution parameters c and d were chosen to obtain a good
mixing of the chains and the convergence of the MCMC samples of parameters
are assessed using the criteria given by Raftery and Lewis (1992). More details of
MCMC in oder to construct these chains see, for example, Smith Roberts (1993),
Gelfand Smith (1990), Gilks, Clayton, Spiegelhalter, Best, McNiel, Sharples &
Kirby (1993).
    We examine the performance of the priors by computing point estimates for
parameters α and β based on 1,000 simulated samples and then we averaged the
estimates of the parameters, obtain the variances and the coverage probability of
95% confidence intervals. Table 1 shows the point estimates for α and its respective
variances given between parenthesis. Table 2 shows the same summaries for β.
    The results of our numerical studies show that there is little difference between
the point estimates for both parameters α and β. However, the MDIP prior pro-
duces a much smaller variance than using the other assumed priors. The uniform
prior and MLE estimate produce bad estimations with large variances showing


                                    Revista Colombiana de Estadística 36 (2013) 319–336

330                   Fernando Antonio Moala, Pedro Luiz Ramos Jorge Alberto Achcar


                               Table 1: Summaries for parameter α.
  α=2          Jeffreys      MDIP      Tibshirani   Reference    Copula    Uniform      MLE
  n=5           2.2529       2.1894      2.3666      2.3602      2.0909     3.3191     3.2850
               (2.1640)     (0.5112)    (3.0297)    (2.4756)    (2.1987)   (3.1577)   (7.5372)
  n = 10        2.5227       2.2253      2.4138      2.4761      2.3068     2.9769     2.7013
               (1.3638)     (0.3855)    (1.3849)    (1.3301)    (1.2052)   (1.4658)   (1.8308)
  n = 30        2.1259       2.1744      2.0606      2.1079      2.0369     2.2504     2.2253
               (0.2712)     (0.1910)    (0.2651)    (0.2728)    (0.2571)   (0.2829)   (0.3138)


                               Table 2: Summaries for parameter β.
  β=3          Jeffreys      MDIP      Tibshirani   Reference    Copula    Uniform       MLE
  n=5           2.9136       3.2680      3.2161      3.1058      2.7486     4.3419      5.2673
               (4.2292)     (1.6890)    (6.1384)    (4.7787)    (4.2447)   (5.6351)   (23.1881)
 n = 10         3.8577       3.7727      3.6705      3.7649      3.6112     4.5186      4.2960
               (3.8086)     (1.5872)    (3.8110)    (3.6667)    (3.5599)   (3.7803)    (5.4296)
 n = 30         3.2328       3.4255      3.1475      3.1798      3.0805     3.4633      3.4005
               (0.7950)     (0.6292)    (0.7861)    (0.7856)    (0.7453)   (0.8335)    (0.9163)



that, despite being widely used in the literature, they are not suitable for the
Gamma distribution. As expected, the performance of these priors improves when
the sample size increases.
    Frequentist property of coverage probabilities for the parameters α and β have
also been studied to compare the priors and MLE. Table 3 summarizes the sim-
ulated coverage probabilities of 95% confidence intervals. For the three sample
sizes considered here, the intervals of MDIP prior produce an over-coverage for
small sample sizes while, the intervals of uniform prior and MLE seem to have
an under-coverage for some cases. Coverage probabilities are very close to the
nominal value when n increases.

Table 3: Frequentist coverage probability of the 95% confidence intervals for α and β.
      α=2        Jeffreys    MDIP      Tibshirani   Reference   Copula     Uniform     MLE
      n=5        96.30%      99.60%     97.20%       96.10%     95.30%     95.70%     95.60%
      n = 10     96.40%      99.50%     94.90%       95.00%     95.80%     90.60%     95.30%
      n = 30     96.10%      96.20%     98.10%       95.80%     96.80%     95.50%     95.00%
      β=3        Jeffreys    MDIP      Tibshirani   Reference   Copula     Uniform     MLE
      n=5        96.60%      99.60%     97.50%       97.00%     96.30%     99.90%     94.30%
      n = 10     98.10%      98.00%     96.00%       96.70%     97.80%     93.90%     95.70%
      n = 30     97.30%      95.80%     96.90%       96.10%     97.40%     94.90%     96.80%




8.2. Rainfall Data Example
    Data in Table 4 represent the average monthly rainfall obtained from the In-
formation System for Management of Water Resources of the State of São Paulo,
including a period of 56 years from 1947 to 2003, by considering the month of
November.



                                             Revista Colombiana de Estadística 36 (2013) 319–336

Bayesian Inference for Two-Parameter Gamma Distribution                                                            331

   Let us assume a Gamma distribution with density (1) to analyse the data.

       Table 4: Historical rainfall averages over last 56 years in State of São Paulo.
               0.2,3.5,2.8,3.7,8.7,6.9,7.4,0.8,4.8,2.5,2.9,3.1,4.0,5.0,3.8,3.5,5.4,3.3,2.9,
               1.7,7.3,2.9,4.6,1.1,1.4,3.9,6.2,4.1,10.8,3.8,7.3,1.8,6.7,3.5,3.2,5.2,2.8,5.2,
               5.4,2.2,9.9,2.1,4.7,5.5,2.6,4.1,5.4,5.5,2.1,1.9,8.8,1.3,24.1,5.4,6.2,2.9


   Table 5 presents the posterior means assuming the different prior distributions
and maximum likelihood estimates (MLE) for the parameters α and β.

            Table 5: Posterior means for parameters α and β of rainfall data.
                 Uniform               Jeffreys   Ref-β       MDIP          Tibshirani      Copula      MLE
           α      2.493                 2.387     2.393       2.659           2.357          2.380      2.395
           β      0.543                 0.516     0.517       0.641           0.510          0.515      0.518


    From Table 5, we observe similar inference results assuming the different prior
distributions for α and β, except for MDIP prior as observed in the simulation
study introduced in the example presented in section 8.1.
   The 95% posterior credible intervals obtained using the different priors for the
parameters are displayed in Table 6. The MLE intervals for the parameters α and
β are given respectively by (1.56; 3.22) and (0.31; 0.72).
                                0.20
                                0.15
                                0.10
                    Frequency


                                0.05
                                0.00




                                         0          5              10           15            20

                                                        November rainfall
          Figure 1: Histogram and fitted Gamma distribution for rainfall data.



       Table 6: 95% posterior intervals for the parameters α and β of rainfall data.
           Uniform                Jeffreys           Ref-β              MDIP              Tibshirani      Copula
   α     (1.71; 3.43)           (1.63; 3.29)      (1.64; 3.28)       (1.91; 3.52)        (1.60; 3.25)   (1.60; 3.34)
   β     (0.35; 0.76)           (0.33; 0.73)      (0.34; 0.73)       (0.44; 0.87)        (0.33; 0.73)   (0.32; 0.75)



                                                        Revista Colombiana de Estadística 36 (2013) 319–336

332                         Fernando Antonio Moala, Pedro Luiz Ramos Jorge Alberto Achcar


   Figure 2 shows the marginal posterior densities for both parameters α and
β. We can see that the MDIP prior leads to a posterior slightly more sharply
peaked for both parameters, while the other priors are quite similar, agreeing with
simulated data with sample size n = 30.
    To determine the appropriate prior distribution to be used with the rainfall
data fitted by the Gamma distribution, some selection criteria can be examined.
These include information-based criteria (AIC, BIC and DIC) given in the Table
7 for each prior distribution.
                1.4




                                                                               5
                                                     MDIP                                                    MDIP
                                                     Jeffreys                                                Jeffreys
                                                     Tibshirani                                              Tibshirani
                1.2




                                                     Reference                                               Reference
                                                     Cópula                                                  Cópula




                                                                               4
                                                     Uniform                                                 Uniform
                1.0




                                                                               3
                0.8




                                                                      (
      p(α |x)




                                                                    p( β |x
                0.6




                                                                               2
                0.4




                                                                               1
                0.2
                0.0




                                                                               0




                      1.0   1.5   2.0    2.5   3.0    3.5     4.0                  0.2     0.4         0.6    0.8

                                          α                                                        β
Figure 2: Plot of marginal posterior densities for the parameters α and β of rainfall
          data.




Table 7: Information-based model selection criteria (AIC, BIC and DIC) for rainfall
         data.
                                        Prior                AIC               BIC        DIC
                                        Jeffreys            272.213           268.162    267.827
                                        MDIP                272.247           268.196    267.502
                                        Ref-β               272.212           268.162    267.922
                                        Tibshirani          272.219           268.169    268.068
                                        Copula              272.222           268.171    268.197
                                        Uniform             272.266           268.215    267.935



    From the results of Table 7 and Figure 2 we observe that the choice of the
prior distributions for parameters α and β has a negligible effect on the posterior
distribution, surely due to the large amount of data in this study.

                                                              Revista Colombiana de Estadística 36 (2013) 319–336

Bayesian Inference for Two-Parameter Gamma Distribution                                                                 333

8.3. Reliability Data Example
   In this example, we consider a lifetime data set related to an electrical insulator
subjected to constant stress and strain introduced by Lawless (1982). The dataset
does not have censored values and represent the lifetime (in minutes) to failure:
0.96, 4.15, 0.19, 0.78, 8.01, 31.75, 7.35, 6.50, 8.27, 33.91, 32.52, 16.03, 4.85, 2.78,
4.67, 1.31, 12.06, 36.71 and 72.89. Let us denote this data as “Lawless data”. We
assume a Gamma distribution with density (1) to analyse the data.
    The maximum likelihood estimators and the Bayesian summaries for α and β,
considering the different prior distributions are given in Table 8. Table 9 shows the
95% posterior intervals for α and β. The estimated marginal posterior distributions
for the parameters are shown in Figure 3.
                     2.5




                                                                               25
                                                     MDIP                                                  MDIP
                                                     Jeffreys                                              Jeffreys
                                                     Tibshirani                                            Tibshirani
                                                     Reference                                             Reference
                     2.0




                                                     Cópula                                                Cópula




                                                                               20
                                                     Uniform                                               Uniform
                     1.5




                                                                               15
                                                                     (
       p(α |x)




                                                                    p ( β |x
                     1.0




                                                                               10
                     0.5




                                                                               5
                     0.0




                                                                               0




                            0.0      0.5       1.0         1.5                      0.00   0.04     0.08     0.12

                                           α                                                        β
Figure 3: Plot of marginal posterior densities for the parameters α and β for Lawless
          data.


   Tables 8 and 9 present the posterior statistics and 95% confidence intervals for
both parameters resulting from the proposed priors. Again the performance of the
MDIP prior clashes from the others.

                 Table 8: Posterior means for parameters α and β (Lawless data).
                           Uniform     Jeffreys      Ref-β        MDIP          Tibshirani        Copula    MLE
                 α          0.779       0.686        0.681        0.789           0.660            0.666    0.690
                 β          0.058       0.047        0.047        0.063           0.046            0.047    0.048



     Table 9: 95% posterior intervals for the parameters α and β (Lawless data).
      Uniform        Jeffreys        Ref-β          MDIP         Tibshirani      Copula
 α (0.433, 1.229) (0.371, 1.111) (0.374, 1.087) (0.459, 1.232) (0.350, 1.061) (0.353, 1.080)
 β (0.025, 0.105) (0.017, 0.091) (0.018, 0.090) (0.031, 0.108) (0.017, 0.085) (0.017, 0.087)



                                                           Revista Colombiana de Estadística 36 (2013) 319–336

334              Fernando Antonio Moala, Pedro Luiz Ramos Jorge Alberto Achcar


   Table 10 shows the AIC, BIC and DIC values for all priors under investigation,
with similar results as presented in Table 7 are obtained in this comparison which
shows no differences using the different assumed priors.

Table 10: Information-based model selection criteria (AIC, BIC and DIC) for(Lawless
          data.
                       Prior         AIC       BIC       DIC
                       Jeffreys     143.125   141.236   141.409
                       MDIP         143.642   141.753   141.082
                       Ref-β        143.126   141.237   141.168
                       Tibshirani   143.148   141.259   141.247
                       Copula       143.138   141.249   141.471
                       Uniform      143.401   141.512   141.119




9. Conclusion and Discussion
   The large number of noninformative priors can cause difficulties in the choosing
one, especially when these priors does not produce similar results. Thus, in this
paper, we presented a Bayesian analysis using a variety of prior distributions for
the estimation of the parameters of the Gamma distribution.
    We have shown that the use of the maximal data information process proposed
by Zellner (1977), Zellner (1984), Zellner (1990) yields an improper posterior dis-
tribution for the parameters α and β. In this way, we proposed a “modified” MDIP
prior analytically similar to the original one but with proper posterior. We also
shown that the reference prior provides nonuniqueness of prior due to the choice
of the parameter of interest, although the simulation shows the same performance.
We have shown that the Tibshirani prior applied to the parameters of the Gamma
distribution is equal to the reference prior when α is the parameter of interest.
    Besides, a simulation study to check the impact of the use of different noninfor-
mative priors in the posterior distributions was also carried out. From this study
we can conclude that it is necessary to carefully choose a prior for the parameters
of the Gamma distribution when there is not enough data.
    As expected, a moderated large sample size is need to achieve the desirable
accuracy. In this case, the choice of the priors become irrelevant. However, the
disagreement is substantial for small sample sizes.
    Our simulation study indicates that the class of priors: Jeffreys, Reference,
Tibshirani and Copula, had the same performance while the Uniform prior had
worse performance. On the other hand , the “modified” MDIP prior produced the
best estimations for α and β. Thus, the simulation study showed that the effect
of the prior distributions can be substantial in the estimation of parameters and
therefore the modified MDIP prior should be the recommended noninformative
prior for the estimation of parameters of the Gamma distribution.
                                                                   
             Recibido: enero de 2013 — Aceptado: septiembre de 2013


                                     Revista Colombiana de Estadística 36 (2013) 319–336

Bayesian Inference for Two-Parameter Gamma Distribution                            335

References
Apolloni B, Bassis S. Algorithmic inference of two-parameter gamma distribution.(2009).Communications in Statistics - Simulation and Computation.
Berger J, Bernardo J M. On the development of the reference prior method.(1992).Valencia International Meeting on Bayesian Statistics.
Bernardo J M. Reference posterior distributions for Bayesian inference.(1979). Journal of the Royal Statistical Society.
Cox D R, Reid N. Parameter orthogonality and approximate conditional inference (with discussion).(1987). Journal of the Royal Statistical Society.
Gelfand A E, Smith F M. Sampling-based approaches to calculating marginal densities.(1990). Journal of the American Statistical Association.
Gilks W, Clayton D, Spiegelhalter D, Best N, McNiel A, Sharples L, Kirby A. Modeling complexity: Applications of Gibbs sampling inmedicine.(1993). Journal of the Royal Statistical Society.
Jeffreys S H. Theory of Probability.(1967). Oxford University Press.
Lawless J. Statistical Models and Methods for Lifetime Data.(1982). John Wiley.
Min C K,Zellner A.Bayesian Analysis Model Selection and Prediction in Physics and Probability.(1993). Cambridge University Press.
Moala F.Bayesian analysis for the Weibull parameters by using noninformative prior distributions.(2010). Advances and Applications in Statistics.
Morgenstern D. Einfache beispiele sw edimensionaler vertielung.(1956). Mit Mathematics Statistics.
Nelsen R B. An Introduction to Copulas.(1999). Springer-Verlag.
Pradhan B, Kundu D. Bayes estimation and prediction of the two-parameter Gamma distribution.(2011). Journal of Statistical Computation and Simulation.
Smith A, Roberts G. Bayesian computation via the Gibbs sampler and related Markov Chain Monte Carlo Methods.(1993). Journal of the Royal Statistical Society.
Son Y, Oh M. Bayesian estimation of the two-parameter Gamma distribution.(2006). Communications in Statistics – Simulation and Computation.
Tibshirani R. Noninformative prioris for one parameters of many.(1989). Biometrika.
Trivedi P K, Zimmer D M. Copula Modelling.(2005). New Publishers.
Trivedi P K, Zimmer D M. Copula modelling: An introduction to practicioners.(2005). Foundations and Trends in Econometrics.
Zellner A. Maximal data information prior distributions.(1977). The Applications of Bayesian Methods.
Zellner A. Maximal Data Information Prior Distributions Basic Issues in Econometrics.(1984). The University of Chicago Press.
Zellner A. Bayesian methods and entropy in economics and econometrics.(1990).Kluwer Academic Publisher.