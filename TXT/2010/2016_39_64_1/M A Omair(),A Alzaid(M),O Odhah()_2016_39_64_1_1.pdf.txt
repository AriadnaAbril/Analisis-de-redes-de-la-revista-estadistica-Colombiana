A Trinomial Difference Distribution. Una distribución de diferencia trinomial
King Saud University, Riyadh, Saudi Arabia. Prince Sattam Bin Abdulaziz University, Hotat Bani Tamim, Saudi Arabia
Abstract
A trinomial difference distribution is defined and its distributional properties are illustrated. This distribution present the binomial difference distribution as a special case. The moment estimators and maximum likelihood estimators of the trinomial difference distribution are compared via simulation study. Two applications are modeled with the trinomial difference distribution and compared with other possible distributions.
Key words: Binomial Distribution, Discrete Distribution, Maximum Likelihood Estimate, Moment Estimate, Poisson Distribution, Trinomial Distribution.
Resumen
Una distribución de diferencia trinomial se define en este artículo así como sus propiedades distribucionales. Esta distribución cuenta con la distribución de diferencia binomial como un caso particular. Los estimadores de momentos y de máxima verosimilitud son comparados vía un estudio de simulación. Dos aplicaciones son modelados con la distribución diferencia trinomial y se comparan con otras distribuciones posibles.
Palabras clave: distribución binomial, distribución discretos, estimación de máxima verosimilitud, momento estimar, distribución de Poisson, distribución binomial.




 a Assistant Professor. E-mail: maomair@ksu.edu.sa
 b Professor. E-mail: Alzaid@ksu.edu.sa
 c Assistant Professor. E-mail: o.odhah@psau.edu.sa




                                              1

2                              Maha A. Omair, Abdulhamid Alzaid & Omalsad Odhah


1. Introduction

    Recently, discrete distributions defined on the set of integers have attracted the
attention of many researchers. The most popular ways to define distributions on
Z are: the differences between two nonnegative discrete random variables and the
discrete version of continuous distributions on R. The main distributions on the
set Z are Poisson difference (Skellam 1946), discrete normal and discrete Laplace.
    The Poisson difference distribution has many applications in different fields.
Karlis & Ntzoufras (2009) modeled the difference of the number of goals in foot-
ball games with the Poisson difference distribution and the zero inflated Poisson
difference distribution. Karlis & Ntzoufras (2006) also used the Poisson differ-
ence and the zero inflated Poisson difference distributions to model the difference
between the decayed, missing and filled teeth (DMFT) index before and after
treatment. Alzaid & Omair (2010) have used the Poisson difference distribution
to model the difference in the price of a share every minute as number of ticks and
the occupancy in a nursery intensive care unit in a hospital. Alzaid & Omair (2014)
defined the integer valued autoregressive model of first order with the Poisson dif-
ference marginal distribution. Bakouch, Kachour & Nadarajah (2013) proposed
the first reflected version of the Poisson distribution over the set of all integers, re-
ferred to as the extended Poisson (E-Po) distribution. They applied the extended
Poisson distribution to the change in number of students between two sessions of
a course in a specific group from the Bachelor program at IDRAC International
Management School (Lyon, France).
    Ong, Shimizu & Min Ng (2008) defined the general difference between two
discrete random variables from the Panjer family. As a special case, they defined
the difference between two negative binomial distributions. Goodness of fit and
tests have been considered. In order to illustrate, an application to the difference
for the assessment number of palpable lymph nodes deleted by two physicians
on 32 participants on a prospective study of men with AIDS or an AIDS-related
conditions was provided.
    Inusah & Kozubowski (2006) studied discrete skew Laplace distribution (DL).
This distribution shares many properties of the skew Laplace distribution. In
the symmetric case, this leads to a discrete analogue of the classical Laplace
distribution.
   Kemp (1997) presented the discrete Normal distribution (DN-distributions)
and showed that among all discrete distributions with given expectation and vari-
ance and support equal to the set of integers, DN maximizes entropy.
    The difference between two independent random variables following the same
binomial distribution has been derived by Castro (1952). Kotz, Johnson & Kemp
(1992) discussed the distribution of the difference between two independent bino-
mial distributions having the same probability of success and possibly a different
number of trials. They also showed that when the probability of success equals the
probability of failure the distribution of the difference reduces to the binomial dis-
tribution with the general form. The standardized difference of two independent


                                         Revista Colombiana de Estadística 39 (2016) 1–15

A Trinomial Difference Distribution                                                               3

binomial distributions with different parameters tends to unit normal distribution
as both numbers of trials tend to infinity.

Definition 1. For any pair of variables (X, Y ) that can be written as X = W1 +W3
and Y = W2 + W3 with W1 ∼ Bin(n, p) independent of W2 ∼ Bin(n, q) and W3
following any distribution, the probability mass function (p.m.f ) of Z ∗ = X −Y =
W1 − W2 is given by
                       min(n,n−z ∗ )              
             ∗
                            X              n        n z∗ +r r          ∗
       f (z ) =                                        p   q (1 − p)n−z −r (1 − q)n−r ,
                                         z∗ + r     r
                       r=max(0,−z ∗ )


                                        z ∗ = −n, −n + 1, . . . , n.
Z ∗ is said to have the binomial difference distribution denoted by BD(n, p, q). The
random variable W3 can be viewed as a background effect or a correlation between
X and Y that is totally removed after differencing.

    The aim of the paper is to define the trinomial difference distribution on Z,
which extends the binomial difference distribution. It is shown that this distri-
bution can be used to model accident data while the binomial difference fails to
model such data. In the trinomial difference distribution, not all the correlation
between the differenced random variables is removed by differencing. This is not
the case in the definition of the binomial difference distribution when the two dif-
ferenced variables are either independent are either independent or if there is some
background effect then all the dependency is removed by differencing. The trino-
mial difference distribution can be overdispersed i.e. the variance is greater than
the absolute value of the mean, equidispersed or underdispersed and can also be
symmetric, positively skewed or negatively skewed depending on the value of the
parameters. The remainder of this paper is organized as follows: a definition of
the trinomial difference distribution with some properties is introduced in Section
2. In Section 3, moment and maximum likelihood estimators were derived and
compared via simulation. In Section 4, two real applications are modeled with
the trinomial difference distribution and other possible distributions. Finally, a
conclusion is present in Section.


2. Trinomial Difference Definition and Properties
  A random vector (X, Y ) has bivariate binomial distribution denoted by
BBin(n, α, β, γ) if its p.m.f. is given by
             min(x,y)
                 X                       n!
f (x, y) =                                                  αx−i β y−i γ i (1−α−β−γ)n−x−y+i ,
                 i=0
                         i!(x − i)!(y − i)!(n − x − y + i)!

                                   x, y = 0, 1, . . . , n, x + y ≤ n.                           (1)
The corresponding characteristic function (c.f.) is

                                                    Revista Colombiana de Estadística 39 (2016) 1–15

4                                      Maha A. Omair, Abdulhamid Alzaid & Omalsad Odhah



                Qx,y (t1 , t2 ) = [1 − α − β − γ + αeit1 + βeit2 + γei(t1 +t2 ) ]n .            (2)
Two important cases arise from the bivariate binomial distribution
    (i) The independence case:
        In this case the two random variables are independent such that
        X ∼ Bin(n, p) and Y ∼ Bin(n, q). The c.f. of the bivariate binomial
        distribution is

             Qx,y (t1 , t2 ) = [1 − p(1 − q) − q(1 − p) − pq + p(1 − q)eit1
                                                            + q(1 − p)eit2 + pqei(t1 +t2 ) ]n   (3)
        Hence in the independent case, pq = γ, p(1 − q) = α and q(1 − p) = β.
    (ii) The trinomial case:
        In this case the random variables X and Y follow the trinomial distribution.
        The c.f. is
                     Qx,y (t1 , t2 ) = [1 − α − β + αeit1 + βeit2 ]n where γ = 0.               (4)

        Let (X, Y ) have the bivariate binomial distribution (1) and let Z be the
        difference random variable i.e. Z = X − Y then from (2) the c.f. of Z is

                                   Qz (t) = [1 − α − β + αeit + βe−it ]n                        (5)
        Note that the c.f. does not depend on γ and is identical with the one resulting
        from differencing X and Y in the trinomial case (4). The c.f. of the binomial
        difference distribution Z ∗ = X − Y that arise from the independent case (3)
        is
               QZ ∗ (t) = [1 − p(1 − q) − q(1 − p) + p(1 − q)eit + q(1 − p)e−it ]n
        To distinguish the general definition of difference of dependent binomial vari-
        able from the independence special case we give the following definition.
Definition 2. We say that the random variable Z has trinomial difference dis-
tribution with parameters n ∈ Z, 0 ≤ α, β ≤ 1 and α + β < 1 denoted by
Z ∼ T D(n, α, β) if its c.f. is given by (5). The probability function of the trino-
mial distribution is given by
                             
                        n
                 f (x, y) =  αx β y (1 − α − β)n−x−y , x, y = 0, 1, . . . , n;
                       x, y
                                              
                                           n              n!
                 x + y ≤ n where                 =                  .
                                          x, y     x!y!(n − x − y)!
The probability function of the trinomial difference is present as:
                 n−z
                [X2 ]                  
                                  n
    g(z) =                                αz+y β y (1 − α − β)n−z−2y , z = 0, ±1, ±2, . . . , ±n.
                               z + y, y
             y=max(0,−z)
                                                                                                (6)

                                                 Revista Colombiana de Estadística 39 (2016) 1–15

A Trinomial Difference Distribution                                                   5

Note 1. If X and Y follow trinomial distribution and we observed X + W and
Y + W with W being any random variable, the definition of trinomial difference
is not affected and W can be viewed as background effect.
    The above definition implies that the difference between the two independent
binomial random variables with the same number of trials can be thought of as a
difference between the components of trinomial distribution. The reverse of this
conclusion is not true, as can be seen from the following proposition.

Proposition 1. A T D(n, α, β) can be written as binomial difference if and only
if (iff )
                         (1 − α − β)2 − 4αβ ≥ 0.                            (7)

Proof . Note that T D(n, α, β) can be written as the difference between two inde-
pendent (n, p) and (n, q) binomials iff

               1 − α − β + αeit + βe−it = pq + p q + p q eit + q p e−it

where, p = 1 − p and q = 1 − q. This holds iff α = p(1 − q) and β = q(1 − p).
Solving these in equations for p and q in terms of α and β, we get
                                      p
                         1 + α − β ± (1 − α − β)2 − 4αβ
                     p=
                                           2
and                                     p
                            1−α+β±          (1 − α − β)2 − 4αβ
                       q=                                      .
                                              2
Thus a real p and q can be achieved iff (1 − α − β)2 − 4αβ ≥ 0 which is equivalent
to (7).
   To distinguish the case when (7) holds we calling the corresponding distribution
binomial difference distribution (BD(n, p, q)) as in definition 1.

Proposition 2. Let X ∼ T D(n, α, β) then E(X) = n(α − β), V ar(X) = n[α +
                                      2
β − (α − β)2 ], and γ1 = n(α−β)[2(α−β) −3(α+β)+1]
                                          2
                                            3     where γ1 is Pearson’s coefficient
                              [n(α+β−(α−β) ] 2
of skewness.

    The trinomial distribution is symmetric when α = β. This distribution can be
positively skewed or negatively skewed. Figure 1 exhibits the probability function
of T D(n, α, β) for different values of n, α and β.

Proposition 3. Let Xi , i = 1, . . . , n P                  random variables having
                                             be independent P
                                               n              n
T D(ni , α, β) for i = 1, . . . , n, then Z = i=1 Xi ∼ T D( i=1 ni , α, β).

Proposition 4. If X ∼ T D(n, α, β) then Y = −X ∼ T D(n, β, α).

Proposition 5. For a fixed positive λ1 , λ2 and n > λ1 , λ2 , consider a sequence
of random variables Xn ∼ T D(n, λ1 /n, λ2 /n), the limiting distribution of Xn has
Poisson difference distribution.


                                        Revista Colombiana de Estadística 39 (2016) 1–15

6                                   Maha A. Omair, Abdulhamid Alzaid & Omalsad Odhah


Proof .

    Qxn (t) = (1 − (λ1 /n) − (λ2 /n) + (λ1 /n)eit + (λ2 /n)e−it )n , (λ1 + λ2 )/n ≤ 1.

                                  λ1 (eit − 1) + λ2 (e−it − 1) n        it        −it
     lim Qxn (t) = lim (1 +                                   ) = eλ1 (e −1)+λ2 (e −1) .
     n→∞             n→∞                        n
This is the Characteristic function of P D(λ1 , λ2 ).

   Alzaid & Omair (2012) introduced the extended binomial distribution as for
any given two independent Poisson difference distributions the conditional distri-
bution of one given the sum using a special constraint in order to obtain a linear
mean in the parameter.

Definition 3. A random variable X in Z has extended binomial distribution with
parameters 0 < p < 1, (q = 1 − p, θ > 0) and z ∈ Z, denoted by X ∼ EB(z, p, θ) if


                  px q z−x 0 Fe1 (; x + 1; p2 θ)0 Fe1 (; z − x + 1; q 2 θ)
    P (X = x) =                                                            , x = . . . , −1, 0, 1, . . .
                                      0 F1 (; z + 1; θ)
                                        e

where 0 Fe1 is the regularized hypergeometric function defined by
                                                   ∞
                                                   X         zk
                                 0 F1 (; b; z) =                    .
                                   e
                                                         k!Γ(b + k)
                                                   k=0

Bakouch et al. (2013) extended the Poisson distribution over the set of all integers
as follows.

Definition 4. A random variable X in Z has extended Poisson distribution with
parameters 0 ≤ p ≤ 1 and λ > 0, denoted by X ∼ E − P0 (p, λ) if its probability
mass function is defined as
                            
                               −λ
                            e
                                             x=0
                                −λ λx
                 P (X = x) = pe    x!         x = 1, 2, . . .
                                          |x|
                             (1 − p)e−λ λ|x|! x = −1, −2, . . .
                            
                            

Note 2.

     1. The BD(n, p, q) is a convolution of two independent strongly unimodal ran-
        dom variables which implies that it is strongly unimodal.

     2. When (1 − α − β)2 − 4αβ < 0, the trinomial difference distribution is no a
        longer binomial difference distribution and it may not be unimodal as illus-
        trated in Figure 1. However the Poisson difference distribution is strongly
        unimodal and the extended binomial distribution has no proof of unimodal-
        ity. In all the parameters explored till now it appears to be unimodal.


                                                Revista Colombiana de Estadística 39 (2016) 1–15

A Trinomial Difference Distribution                                                                                                                       7

                                              TD(5,0.5,0.4)                                                              TD(5,0.3,0.3)
          0.25                                                                             0.25


           0.2                                                                              0.2


          0.15                                                                             0.15




                                                                                    f(x)
   f(x)



           0.1                                                                              0.1


          0.05                                                                             0.05


            0                                                                                0
                  -5   -4   -3   -2      -1      0     1      2    3   4   5                        -5   -4   -3   -2    -1    0    1    2   3   4   5
                                                 X                                                                             X



                                      TD(10,0.2,0.6)                                                                    TD(10,0.9,0.5)
          0.18                                                                              0.4
          0.16                                                                             0.35
          0.14                                                                              0.3
          0.12
                                                                                           0.25
           0.1
                                                                                            0.2




                                                                                   f(x)
   f(x)




          0.08
          0.06                                                                             0.15

          0.04                                                                              0.1
          0.02                                                                             0.05
            0                                                                                0
                 -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10                            -10 -9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9 10
                                                X                                                                             X

Figure 1: The probability mass function of T D(n, α, β) for different values of the pa-
          rameters.


   3. Unlike the Poisson difference distribution, which is always overdispersed,
      the trinomial difference distribution can be overdispersed or equidispersed
      or underdispersed, depending on the values of α and β as follows:
          If (α − β)2 = 2β or 2α then the distribution is equidispersed.
          If(α − β)2 < min(2α, 2β) then the distribution is overdispersed.
          Otherwise the distribution is underdipersed.
   4. When β = 0 the T D(n, α, β) ≡ binomial(n, α).
   5. When α = 0 the T D(n, α, β) ≡ negation of binomial(n, β).


3. Inference
    Let X1 , . . . , Xm be independent identically distributed (i.i.d.) random variables
                                                                                2
                                                                                   X̄ 2 +nX̄
(r.v.) from T D(n, α, β) the moment estimators of α and β are α      bmm = nS +2n     2

and βbmm = α   b − X̄ n where X̄ and S 2
                                         are the sample  mean and   the  sample  variance,
respectively.
   The Likelihood function is given by

                             m                         [ n−x
                                                          2
                                                             i
                                                               ]                          
                             Y                           X                          n
  L(α, β; x) =                                                                               αxi +y β y (1 − α − β)n−xi −2y
                             i=1 y=max(0 instead of;−xi )
                                                                                 xi + y, y


                                                                               Revista Colombiana de Estadística 39 (2016) 1–15

8                             Maha A. Omair, Abdulhamid Alzaid & Omalsad Odhah


                                      bmle and βbmle are obtained by solving the
    The maximum likelihood estimators α
following two nonlinear equations

                                        ∂ ln L
                                               =0                                         (8)
                                         ∂α
and
                                        ∂ ln L
                                               = 0.                                       (9)
                                         ∂β
After working the last two equation, it is found that
                                                      x̄
                                 bmle − βbmle =
                                 α                       .                              (10)
                                                      n
Hence, to find the maximum likelihood estimators we used (10) and solved only
one nonlinear equation.
    We ran a simulation study for computing the estimates of the parameters of
T D(n, α, β) using the method of moments and the maximum likelihood method.
We simulated 1000 samples of size m from trinomial difference distribution, and we
calculated the bias and used the mean square error as a measure of the estimates
performance properties in all the methods of estimation that were considered, as
follows:
                       Pk                                    Pk
            α) = k1
    1. BIAS(b                αj − α),
                        j=1 (b
                                             b = 1
                                        BIAS(β)  k            j=1 (βj − β)
                                                                     b
                       Pk                                    Pk
    2. M SE(bα) = k1                         b = 1
                             αj − α)2 , M SE(β)
                        j=1 (b                   k
                                                                       b      2
                                                                  j=1 (βj − β) , for k = 1000
       runs.

   We undertook these processes for different values of the parameters n, α and β
and for different sample sizes m.
    The following are the main findings:

    1. The MSE of the maximum likelihood estimates is always smaller than the
       MSE of the moment estimates, except in few cases when n = 1.
    2. For values of the parameter n ≥ 5, the ML estimates are much better than
       the moment estimates in terms of MSE.
    3. For sample sizes m ≥ 30 the MSE of the moment estimates approach to the
       MSE of the ML estimates.
    4. The ML estimates are always negatively biased except when n = 1. The
       moment estimates are positively biased.
    5. In all cases except n = 1, the moment estimates have a smaller absolute bias
       than the ML estimates.
    6. The moment and ML estimates are consistent.

Figures 2-3 show some results.


                                          Revista Colombiana de Estadística 39 (2016) 1–15

A Trinomial Difference Distribution                                                                                                                                   9




                                                                         bias MM(α)                                                                     bias MM(α)
                                      TD(1,0.5,0.4)                                                                 TD(1,0.7,0.1)
                                                                         bias MM(β)                                                                     bias MM(β)
          0.1                                                            bias ML(α)            0.08                                                     bias ML(α)
                                                                         bias ML(β)                                                                     bias ML(β)
          0.1
                                                                                               0.06
          0.1

          0.1                                                                                  0.04
   bias




                                                                                       bias
          0.0

          0.0                                                                                  0.02

          0.0
                                                                                               0.00
          0.0

          0.0                                                                                 -0.02
                  5       10    15     20     30          40   60   80      100                       5   10   15     20        30      40    60   80       100
                                        sample size                                                                         sample size

                                                                         bias MM(α)                                                                     bias MM(α)
                                      TD(5,0.5,0.4)                      bias MM(β)
                                                                                                                    TD(5,0.7,0.1)                       bias MM(β)
     0.05                                                                bias ML(α)           0.02                                                      bias ML(α)
                                                                         bias ML(β)                                                                     bias ML(β)



     0.00                                                                                     0.00
                                                                                       bias
   bias




   -0.05                                                                                      -0.02




   -0.10                                                                                      -0.04
                  5       10    15     20       30        40   60   80      100                       5   10   15     20        30       40   60   80       100
                                            sample size                                                                    sample size

                                                                          bias MM(α)                                                                    bias MM(α)
                                      TD(10,0.5,0.4)                                                                TD(10,0.7,0.1)
                                                                          bias MM(β)                                                                    bias MM(β)
          0.05                                                            bias ML(α)          0.02                                                      bias ML(α)
                                                                          bias ML(β)                                                                    bias ML(β)

          0.00                                                                                0.00
   bias




                                                                                       bias




      -0.05                                                                               -0.02


      -0.10                                                                               -0.04


      -0.15                                                                               -0.06
                      5    10   15      20       30      40    60   80       100                      5   10   15     20       30      40     60   80       100
                                             sample size                                                                   sample size

                                                                         bias MM(α)                                                                      bias MM(α)
                                      TD(15,0.5,0.4)                                                                TD(15,0.7,0.1)                       bias MM(β)
                                                                         bias MM(β)
          0.05                                                                                 0.02                                                      bias ML(α)
                                                                         bias ML(α)
                                                                                                                                                         bias ML(β)
                                                                         bias ML(β)

          0.00                                                                                 0.00
                                                                                       bias
   bias




          -0.05                                                                               -0.02



          -0.10                                                                               -0.04



          -0.15                                                                               -0.06
                      5    10    15     20     30         40   60   80       100                      5   10   15     20        30      40    60   80       100
                                         sample size                                                                          sample size


Figure 2: Plot of bias for moment and maximum likelihood estimators versus sample
          size.




                                                                                   Revista Colombiana de Estadística 39 (2016) 1–15

10                                                                 Maha A. Omair, Abdulhamid Alzaid & Omalsad Odhah




                                                                              MSE MM(α)                                                                            MSE MM(α)
                                          TD(1,0.5,0.4)                                                                        TD(1,0.7,0.1)                       MSE MM(β)
                                                                              MSE MM(β)
           0.08                                                               MSE ML(α)    0.06                                                                    MSE ML(α)
                                                                              MSE ML(β)                                                                            MSE ML(β)


           0.06
                                                                                           0.04




                                                                                          MSE
     MSE




           0.04

                                                                                           0.02
           0.02



           0.00                                                                            0.00
                      5        10    15     20      30        40   60   80       100                   5       10        15     20     30           40   60   80      100
                                             sample size                                                                          sample size

                                                                             MSE MM(α)                                                                             MSE MM(α)
                                           TD(5,0.5,0.4)                     MSE MM(β)                                         TD(5,0.7,0.1)                       MSE MM(β)
                                                                             MSE ML(α)                                                                             MSE ML(α)
     0.15                                                                                 0.04
                                                                             MSE ML(β)                                                                             MSE ML(β)


                                                                                          0.03
     0.10
     MSE




                                                                                          MSE
                                                                                          0.02

     0.05
                                                                                          0.01


     0.00
                  5       10        15     20        30       40   60   80       100      0.00
                                                                                                       5       10        15    20        30       40     60   80      100
                                                sample size                                                                           sample size

                                                                             MSE MM(α)                                                                             MSE MM(α)
                                          TD(10,0.5,0.4)                                                                       TD(10,0.7,0.1)
                                                                             MSE MM(β)                                                                             MSE MM(β)
  0.15                                                                                          0.04                                                               MSE ML(α)
                                                                             MSE ML(α)
                                                                             MSE ML(β)                                                                             MSE ML(β)

                                                                                                0.03
  0.10
                                                                                          MSE
     MSE




                                                                                                0.02


  0.05
                                                                                                0.01



  0.00                                                                                          0.00
                  5       10        15    20        30        40   60   80       100                       5        10    15     20       30       40    60   80      100
                                                  sample size                                                                          sample size

                                                                             MSE MM(α)                                                                             MSE MM(α)
                                          TD(15,0.5,0.4)                     MSE MM(β)
                                                                                                                               TD(15,0.7,0.1)                      MSE MM(β)
       0.15                                                                  MSE ML(α)          0.03                                                               MSE ML(α)
                                                                             MSE ML(β)                                                                             MSE ML(β)



       0.10                                                                                     0.02
     MSE




                                                                                          MSE




       0.05                                                                                     0.01




       0.00                                                                                     0.00
                      5    10        15    20     30          40   60   80       100                       5        10    15     20        30       40   60   80      100
                                            sample size                                                                               sample size


Figure 3: Plot of MSE for moment and maximum likelihood estimators versus sample
          size.




                                                                                       Revista Colombiana de Estadística 39 (2016) 1–15

A Trinomial Difference Distribution                                                                                                                                                                       11

4. Applications
4.1. Motor Cycle Accidents
    In order to examine the so-called underreporting of figures, since 1996 Statistics
Denmark has conducted a study in which data on persons treated by casualty
wards included. The results are published in the MOERKE table (http://www.
statbank.dk/statbank5a/default.asp?w=1920). The data used below are the
number of monthly motor cycle accidents involving persons under the influence
of alcohol in Denmark from 1997 to 2008. The statistics only include injuries
reported by the police. The number of accidents was found to be correlated and
are affected by seasonality. Applying the runs test for motor cycle accidents, the
p − value = 0.000, which implies that the original data is not independent. Taking
a lag 12 difference of the data and applying the runs test, p − value = 0.598, which
implies that the lag 12 difference is independent. This means that the dependence
in the monthly data is due to seasonal additive effect and has been removed by
seasonal differencing. The lag 12 difference correspond to the monthly difference
in number of traffic accidents for a corresponding month between two consecutive
years.

                                                Plot of motor cycle accident                                                                       Plot of motor cycle accident difference
                                                                                                                                     8
                            12

                                                                                                                                     6
                            10
                                                                                                    m otor cy cle acciden t_lag 12




                                                                                                                                     4
    m otor cycle accident




                            8
                                                                                                                                     2


                            6                                                                                                        0


                                                                                                                                     -2
                            4

                                                                                                                                     -4
                            2
                                                                                                                                     -6

                            0
                                                                                                                                     -8
                                 1   14    28     42    56   70      84     98    112   126   140                                         1   14    28    42    56    70      84   98   112   126   140
                                                             Index                                                                                                    Index

                             Figure 4: Time series plot of motor cycle accidents and differenced data.


    Some descriptive statistics for the lag 12 difference of motor cycle data are
illustrated in Table 1.
                                 Table 1: Descriptive statistics of lag 12 difference of motor cycle data.
                                           Variable                  Size        Mean          Variance                                            Minimum             Maximum
                                          Motor cycle                132         -0.152         6.9998                                                -7                  7


    The mean change = −0.152 indicates that the average monthly difference in
the number of traffic accidents for any corresponding month between two consec-
utive years decreases slightly. Sine the data ranges from −7 to 7, the trinomial
difference distribution with n greater than or equal to 7 is a candidate to model
this data. The trinomial difference distribution is fitted assuming different val-
ues of n as well as the Poisson difference distribution, the extended Poisson and
the extended binomial distribution assuming different values of the parameter z.


                                                                                              Revista Colombiana de Estadística 39 (2016) 1–15

12                                                  Maha A. Omair, Abdulhamid Alzaid & Omalsad Odhah


Figure 5 demonstrates the fitted distributions. The maximum likelihood estimates
and the values of the Akaike information criterion AIC are illustrated in Table 2.
The trinomial difference distribution with n = 8 has the smallest AIC. Note that
in this case

                                          (1 − α   b 2 − 4b
                                               b − β)     αβb = −0.726 < 0



                          30


                          25


                          20
              frequency




                          15


                          10

                          5


                          0
                               -9   -8   -7   -6   -5   -4   -3     -2   -1   0       1   2   3   4   5   6    7   8   9
                                                                                  x


                               Motor Cycle Data                   Trinomial Difference n=8        Poisson Difference
                               Extended Binomial z=10             Extended Poisson

                          Figure 5: Motor cycle data and fitted distributions.




Table 2: Maximum likelihood estimates (standard errors) and AIC of the fitted distri-
         butions for motor cycle data.
      Distribution                                                              MLE                                          AIC
      Trinomial Difference n = 7                                b = 0.404 (0.038), βb = 0.425(0.038)
                                                                α                                                          638.904
      Trinomial Difference n = 8                                 b = 0.422(0.037), βb = 0.441(0.037)
                                                                 α                                                         634.254
      Trinomial Difference n = 9                                 b = 0.376(0.043), βb = 0.393(0.042)
                                                                 α                                                         634.676
      Trinomial Difference n = 10                                b = 0.341(0.041), βb = 0.356(0.041)
                                                                 α                                                         634.596
      Extended Poisson                                                              b = 2.015(0.124)
                                                                 pb = 0.453(0.046), λ                                      642.796
      Poisson Difference                                       θb1 = 3.391(0.455), θb2 = 3.543(0.457)                      634.332
      Extended Binomial z = −1                                pb = 0.145(0.231), θb = 794.384(2086.4)                       634.37
      Extended Binomial z = −2                                pb = 0.074(0.115), θb = 2579.58(7341.4)                       634.35
      Extended Binomial z = −4                               pb = 0.037(0.057), θb = 9289.86(273485)                        634.34
      Extended Binomial z = −10                                pb = 0.015(0.023), θb = 54538(163603)                       634.334
      Extended Binomial z = −20                               pb = 0.008(0.011), θb = 213676(644870)                       634.334



   Hence, the data can be modeled by the T D distribution but not by the special
case of binomial difference distribution. The Pearson Chi-square test is performed
to test the fitting of the trinomial difference with n = 8. The test statistic =
5.28 < χ210,0.95 = 18.307 indicates that the trinomial difference fits the data well.

                                                                         Revista Colombiana de Estadística 39 (2016) 1–15

A Trinomial Difference Distribution                                                        13

4.2. Students Number at IDRAC International Management
     School

    Bakouch et al. (2013) fitted the change in number of students between two
sessions in a specific (test) group from the Bachelor program (first year) at IDRAC
International Management school (Lyon, France) who had 60 sessions in marketing
from the period, 1/9/2012 to 1/4/2013 with the extended Poisson distribution and
other discrete distributions on Z. In order to have more of understanding about the
performance of the trinomial difference distribution we compared the fitting of this
data using trinomial, extended Poisson, extended binomial and Poisson difference
distributions. More information about the data can be found in Bakouch et al.
(2013). Table 3 displays the descriptive statistics for the differenced data. Since
the data ranges from −5 to 7 the trinomial difference distribution with n ≥ 7
is a candidate to model this data. The trinomial difference distribution is fitted
assuming different values of n as well as the Poisson difference distribution, the
extended Poisson and the extended binomial distribution assuming different values
of the parameter z. Figure 6 demonstrates the fitted distribution. The maximum
likelihood estimates and the AIC values are illustrated in Table 4. The trinomial
difference distribution with n = 9 has the smallest AIC. Note that in this case

                         (1 − α   b 2 − 4b
                              b − β)     αβb = −0.8036 < 0

Hence, the data can be modeled by the TD distribution but not by the special case
of binomial difference distribution. The Pearson Chi-square test is performed to
test the fitting of the trinomial difference with n = 9. The test statistic= 11.87 <
χ27,0.95 = 14.067 indicates that the trinomial difference fits the data well.




                     Change in number of students   Trinomial Difference n= 9

                     Poisson Difference             Extended Binomial z=1
                     Expected Poisson

       Figure 6: Change in number of students data and fitted distributions.




                                              Revista Colombiana de Estadística 39 (2016) 1–15

14                               Maha A. Omair, Abdulhamid Alzaid & Omalsad Odhah

         Table 3: Descriptive statistics of the change in number of students.
             Variable     Size    Mean     Variance    Minimum       Maximum
             difference    59     0.3898    8.828         −5            7


Table 4: Maximum likelihood estimates (standard errors) and AIC of the fitted distri-
         butions for change in number of students.
       Distribution                                    MLE                      AIC
       Trinomial Difference n = 7     αb = 0.475(0.053), βb = 0.419(0.053)     299.913
       Trinomial Difference n = 8        b = 0.44(0.059), βb = 0.391(0.058)
                                         α                                     301.376
       Trinomial Difference n = 9        b = 0.473(0.056), βb = 0.43(0.056)
                                         α                                     296.96
       Trinomial Difference n = 10    αb = 0.423(0.060), βb = 0.384(0.060)     298.612
       Extended Poisson                pb = 0.509(0.068), λb = 2.458(0.204)    299.134
       Poisson Difference            θ1 = 4.617(2.251), θb2 = 4.228(2.231)
                                     b                                         299.305
       Extended Binomial z = 1          pb = 0.401(0.352), θb = 339.3(230.8)   299.045
       Extended Binomial z = 2       pb = 0.207(0.188), θb = 727.8(1013.3)     299.127
       Extended Binomial z = 3        pb = 0.137(0.128), θb = 1406(2262.3)     299.177



5. Conclusions
    Recently, discrete distributions on Z have attracted the attention of many re-
searchers. In this paper, we defined the difference of two random variables following
trinomial distributions. This distribution can be overdispersed or underdispersed,
unlike the Poisson difference distribution that is always overdispersed. It is also
symmetric or positively skewed or negatively skewed.
    Through two real applications, the paper shows that the trinomial difference
distribution is compatible with the Poisson difference distribution, the extended
Poisson distribution and the extended binomial distribution. It also indicates that
the binomial difference distribution failed to fit these data.


Acknowledgment
   The authors extend their appreciation to the Dean of Scientific Research at
King Saud University for funding the work through the research group project
RGB-VPP-053. The authors are thankful to the referees for the several suggestions
that helped improve the clarity of this paper.
                                                              
                 Received: June 2014 — Accepted: February 2015


References
Alzaid, A. A. & Omair, M. A. (2010), ‘On the poisson difference distribution inference and applications’, Bulletin of the Malaysian Mathematical Sciences Society 8(33), 17–45.
Alzaid, A. A. & Omair, M. A. (2012), ‘An extended binomial distribution with applications’, Communications in Statistics-Theory and Methods 41(19), 3511–3527.
Alzaid, A. A. & Omair, M. A. (2014), ‘Poisson difference integer valued autoregressive model of order one’, Bulletin of the Malaysian Mathematical Sciences Society 2(37), 465–485.
Bakouch, H., Kachour, M. & Nadarajah, S. (2013), An extended Poisson distribution. Working paper or preprint. *https://hal.archives-ouvertes.fr/hal-00959426 Castro, G. (1952), ‘Note on differences of bernoulli and poisson variables’, Portugaliae mathematica 11(4), 173–175.
Inusah, S. & Kozubowski, T. J. (2006), ‘A discrete analogue of the laplace distribution’, Journal of statistical planning and inference 136(3), 1090–1102.
Karlis, D. & Ntzoufras, I. (2006), ‘Bayesian analysis of the differences of count data’, Statistics in medicine 25(11), 1885–1905.
Karlis, D. & Ntzoufras, I. (2009), ‘Bayesian modelling of football outcomes: using the skellam’s distribution for the goal difference’, IMA Journal of Management Mathematics 20(2), 133–145.
Kemp, A. W. (1997), ‘Characterizations of a discrete normal distribution’, Journal of Statistical Planning and Inference 63(2), 223–229.
Kotz, S., Johnson, N. & Kemp, A. (1992), Univariate Discrete Distributions, 2 edn, John Wiley & Sons, Inc., New York.
Ong, S., Shimizu, K. & Min Ng, C. (2008), ‘A class of discrete distributions arising from difference of two random variables’, Computational Statistics & Data Analysis 52(3), 1490–1499.
Skellam, J. G. (1946), ‘The frequency distribution of the difference between two poisson variates belonging to different populations’, Journal of the Royal Statistical Society. Series A 109(3), 296.
