A Two Parameter Discrete Lindley Distribution. DistribuciÃ³n Lindley de dos parÃ¡metros
Government Postgraduate College, Rawalakot, Pakistan. Department of Statistics, Faculty of Sciences, King Abdulaziz University, Jeddah, Saudi Arabia. National College of Business Administration and Economics, Lahore, Pakistan
Abstract
In this article we have proposed and discussed a two parameter discrete Lindley distribution. The derivation of this new model is based on a two step methodology i.e. mixing then discretizing, and can be viewed as a new generalization of geometric distribution. The proposed model has proved itself as the least loss of information model when applied to a number of data sets (in an over and under dispersed structure). The competing models such as Poisson, Negative binomial, Generalized Poisson and discrete gamma distributions are the well known standard discrete distributions. Its Lifetime classification, kurtosis, skewness, ascending and descending factorial moments as well as its recurrence relations, negative moments, parameters estimation via maximum likelihood method, characterization and discretized bi-variate case are presented.
Key words: Characterization, Discretized version, Estimation, Geometric distribution, Mean residual life, Mixture, Negative moments.
Resumen
En este artÃ­culo propusimos y discutimos la distribuciÃ³n Lindley de dos parÃ¡metros. La obtenciÃ³n de este Nuevo modelo estÃ¡ basada en una metodologÃ­a en dos etapas: mezclar y luego discretizar, y puede ser vista como una generalizaciÃ³n de una distribuciÃ³n geomÃ©trica. El modelo propuesto demostrÃ³ tener la menor pÃ©rdida de informaciÃ³n al ser aplicado a un cierto nÃºmero de bases de datos (con estructuras de supra y sobredispersiÃ³n). Los modelos estÃ¡ndar con los que se puede comparar son las distribuciones Poisson, Binomial Negativa, Poisson Generalizado y Gamma discrete.Su clasificaciÃ³n de tiempo de vida, kurtosis, sesgamiento, momentos factorials ascendientes y descendientes, al igual que sus relaciones de recurrencia, momentos negativos, estimaciÃ³n de parÃ¡metros via mÃ¡xima verosimilitud, caracterizaciÃ³n y discretizaciÃ³n del caso bivariado son presentados.
Palabras clave: caracterizaciÃ³n, estimaciÃ³n, distribuciÃ³n GeomÃ©trica, momentos negativos, mixtura, versiÃ³n discretizada, vida media residual.


1. Introduction
    For the last few decades discretized distributions have been studied exten-
sively to model the discrete failure time data in statistical literature. Generally,
discretized versions are obtained from any continuous distribution defined on the
real line R with probability density function (pdf) f (x), and are based on the sup-
port; the set of integers Z = {0, Â±1, Â±2, Â±3, . . .} have a probability mass function
that takes either of the two forms:

                           P (Y = x) = S(x) âˆ’ S(x + 1),                              (1)

or                                                       !âˆ’1
                                              âˆž
                                              X
                        P (Y = x) = f (x)           f (k)      .                     (2)
                                             k=âˆ’âˆž

The former in statistical literature is known as the discrete concentration approach
in which S(x) is the preserved survival function of continuous distribution at in-
tegers, and the latter is called the time discretization approach in which f (x) is
the preserved probability density function (pdf) of the continuous distribution at
integers.
    Following the approach as given in equation (1) Nakagawa & Osaki (1975),
Roy (2003, 2004), Krishna & Pundir (2009, 2007), Jazi, Lai & Alamatsaz (2010),
DeÌ†niz & Ojeda (2011), Chakraborty & Chakravarty (2012), Al-Huniti & Al-Dayian
(2012) and Hussain & Ahmad (2012, 2014) discretized continuous Weibull, Normal,
Rayleigh, Burr and Pareto, Maxwell, Inverse Weibull, Lindley, Gamma, Inverse
Gamma and Burr type -III, Inverse Gamma and Inverse Rayleigh distributions
respectively. Similarly Kemp (1997), Szablowski (2001), Inusah & Kozubowski
(2006), Kozubowski & Inusah (2006), Kemp (2006) and Nekoukhou, Alamatsaz
& Bidram (2012) adopted the latter approach as is presented in equation (2)
to discretize the Normal, Laplace, skew Laplace, half Normal and Generalized
Exponential distributions respectively. Such discretized versions are being applied
in the field of actuaries, engineering and biostatistics in which the lifetimes of
persons, organisms or products are measured in months, weeks or days.
    The discretization phenomenon generally arises when it becomes impossible or
inconvenient to measure the life length of a product or device on a continuous scale.
Such situations may arise, when the lifetimes need to be recorded on a discrete
scale rather than on a continuous analogue. For examples the number of to and


                                       Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

A Two Parameter Discrete Lindley Distribution                                       47

for motions of a pendulum or spring device before resting, the number of times
devices are switched on/off, the number of days a patient stays in an observation
ward, the length of successful stay of a pig (in terms of number of days/weeks, in
the laboratory) and the number of weeks/months/years a cancer patient survives
after treatment etc. Although there are a number of discrete distributions in the
literature to model the above mentioned situations there is still a lot of space left
to develop new discretized distribution that is suitable under different conditions.
    In this article, a two parameter discrete Lindley distribution is proposed. It
does not only have a simple structure, positively skewed and leptokurtic, but it
also has more flexibility than the DeÌ†niz & Ojeda (2011) single parameter discrete
Lindley distribution it also has less loss of information compared with standard
discrete distributions. Derivation of two parameter discrete Lindley distribution,
along with some properties, are given in section two, section three deals with esti-
mation of parameters. In section four characterization issue is addressed, section
five addresses the application of the proposed model and in the sixth section we
study a discretized bivariate version of the two parameter Lindley distribution.


2. Definition and Properties of a Two Parameter
   Discrete Lindley Distribution
2.1. Derivation
    The phenomenon of mixing and then discretizing the continuous distributions
with the help of proper weights and a set of parameters is so far a new one. In
this manuscript, after adopting the mixing and discretization technique, we have
proposed a two parameter discrete Lindley distribution, which can be viewed as
a new generalization of geometric distribution. Suppose W1 âˆ¼ Gamma(1, Î¸) and
                                                                          Î¸
W2 âˆ¼ Gamma(2, Î¸), on mixing these densities with probabilities p1 = Î¸+Î²      and
       Î²
p2 = Î¸+Î²  so that p1 + p2 = 1 and Î² â‰¥ 0, the resulting distribution of the random
variable X will be a two parameter Lindley distribution, i.e. X âˆ¼ p1 W1 + p2 W2 .
This implies that
                     Î¸2
          f (x) =       (1 + Î²x) exp(âˆ’Î¸x),      x â‰¥ 0, Î² â‰¥ 0 and Î¸ > 0.            (3)
                    Î¸+Î²

    In order to model the discrete actuarial failure data DeÌ†niz & Ojeda (2011)
proposed asingle parameter discrete Lindley distribution which is not considered
a flexible model for analyzing different life time and actuarial data. It is used to
model the over dispersed data pattern (see DeÌ†niz & Ojeda 2011), which is math-
ematically a complicated one. Therefore, to increase the flexibility for modeling
purposes, we developed a two parameter discrete Lindley distribution by inserting
equation (3) into equation (2).
    Figure 1 depicts the curve behavior under different parameter combinations;
the curve changes to a reverse J shape as p â†’ 0 and Î² â†’ 0. Moreover, peakedness
of the curve decreases with a long right tail as p and Î² increases.


                                      Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

48                                         Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad



                                                                      Case 1
                                     0,8                              Case 2
                                                                      Case 3
                                                                      Case 4




                     Probabilities
                                     0,6

                                     0,4

                                     0,2

                                      0
                                           0       5             10      15
                                                       x-value
Figure 1: Probability graph for Two parameter Discrete Lindley Distribution Case 1.
        Figura  1: Probability
          Î² = 1.5;              graph
                    p = 0.45; Case  2. for  4.5; parameter
                                        Î² =Two                  3. Î²Lindley
                                                           Discrete
                                                 p = 0.65; Case      = 6.25; p = 0.80;
          Case 4. Î² =Case
        Distribution   0.15;1.Î²
                              p=  1,5;p = 0,45;Case 2.Î² = 4,5;p = 0,65;Case
                                =0.10.
         3.Î² = 6,25;p = 0,80;Case 4.Î² = 0,15;p = 0,10.

Definition 1. A random variable Y has a two parameter discrete Lindley distri-
bution with parameters 0 < p < 1 and Î² â‰¥ 0, denoted by TDL (p, Î²), is defined
as
                           (1 âˆ’ p)2 (1 + Î²x)px
 P (Y = x) = px =                              , x = 0, 1, 2, 3, . . . , 0 < p < 1 and Î² â‰¥ 0 (4)
                              (1 + p(Î² âˆ’ 1))

where exp(âˆ’Î¸) = p. For Î² = 0 the distribution geometrically reduces, and for
Î² = 1 it becomes one a parameter discrete Lindley distribution. The recursive
relation between T DLs probabilities is given by

                 (1 + Î²x)P (Y = x + 1) = p(1 + Î²(x + 1))P (Y = x),                             (5)

for 0 < p < 1,Î² â‰¥ 0 and x = 0, 1, 2, 3, . . .


2.2. Reliability Characteristics of TDL
    Although, most of the statistical research is based on continuous lifetime proba-
bility distributions to model the real lifetime phenomena, reliability engineers/an-
thropologists are looking for solutions, for which time can be interpreted as a
discrete variable such as: the number of times a piece of equipment is operated;
the life of a switch being measured by the number of strokes; the life of equipment
being measured by the number of cycles it completes or the number of times it
is operated prior to failure; the life of a weapon is measured by the number of
rounds fired until failure; and the number of years of a married couple successfully
completed; or the number of miles that a plane is flown before failures etc. In
order to do this they started to discretize the continuous lifetime distributions.
In reliability theory, the survivor, the hazard, the cumulative hazard,the accumu-
lated hazard and mean residual life functions are important characteristics upon


                                                  Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

A Two Parameter Discrete Lindley Distribution                                              49

which the classification of discrete lifetime probability distribution is made. These
classifications, in turn, point out the nature of the product for the reliability an-
alyst, which could be for example, the increasing (decreasing) failure rate IFR
(DFR) class, increasing (decreasing) failure rate average IFRA (DFRA) class, the
new better (worse) than used NBU (NWU) class, new better (worse) than used in
expectation NBUE (NWUE) class and increasing (decreasing) mean residual life-
time IMRL (DMRL) class etc. (see Kemp 2004). These classes are generally based
on reliability/survival functions which give the probability that a component will
survive beyond a specified time. The basic definition and formulae of the above
mentioned characteristics for TDL are givenP    below. Reliability function of TDL is
                                                 âˆž
defined and expressed as Sx = P (Y â‰¥ x) = k=x P (Y = k),
                                   px ((1 âˆ’ p)(1 + Î²x) + pÎ²)
                            Sx =                             ,
                                          1 + p(Î² âˆ’ 1)
0 < p < 1, Î² â‰¥ 0 and x = 0, 1, 2, 3, . . .
   Its failure rate function which gives the probability of failure given that it has
                                                        P (Y =x)
not occurred before a specific time, is defined as hx = P (Y â‰¥x)

                                       (1 âˆ’ p)2 (1 + Î²x)
                             hx =                          ,
                                    ((1 âˆ’ p)(1 + Î²x) + pÎ²)
0 < p < 1,Î² â‰¥ 0 and x = 0, 1, 2, 3, . . .
   Its Mean Residual Life (MRL) function is defined and expressed as M RL(Y ) =
E(Y âˆ’ x|Y â‰¥ x),
                               phx                pÎ²(1 + p)
               M RL(Y ) =           2
                                      +                               ,
                             (1 âˆ’ p)    ((1 âˆ’ p)(1 + Î²x) + pÎ²)(1 âˆ’ p)
0 < p < 1, Î² â‰¥ 0 and x = 0, 1, 2, 3, . . .
Theorem 1. If Y âˆ¼ T DL(p, Î²) then the probability mass function (pmf )of the
random variable Y is log-concave for all choices of Î² and independent of p.

Proof . In order to show that the two parameter discrete Lindley distribution,
as defined in equation (4), is log-concave, it is sufficient to show that for Î² â‰¥ 0,
(px )2 â‰¥ pxâˆ’1 px+1 âˆ€x = 1, 2, . . . This implies that (1 + Î²x)2 â‰¥ (1 + Î²x)2 âˆ’ Î² 2 .
Generally, it is seen that the log-concave probability mass functions are strongly
unimodal (see Kielson & Gerber 1971, Nekoukhou et al. 2012) and have an in-
creasing failure rate (IFR) which suggest an intuitive concept caused by product
wearing out.

   Therefore, we have the following Corollary.
Corollary 1. If Y âˆ¼ T DL(p, Î²) then the mode of the random variable Y is located
at m and m satisfies pÎ²âˆ’(1âˆ’p)
                       (1âˆ’p)Î²  â‰¤ m â‰¤ Î²âˆ’(1âˆ’p)
                                         (1âˆ’p)Î² .This implies that px â‰¥ pxâˆ’1 for
x â‰¤ m and px+1 â‰¤ px for x â‰¥ m as stated by Kielson & Gerber (1971), Abouammoh
& Mashhour (1981) and Nekoukhou et al. (2012). From this, the following chain
of implication for a two parameter discrete Lindley (TDL) distribution (see Kemp
2004) is suggested IF R â‡’ IF RA â‡’ N BU â‡’ N BU E â‡’ DM RL.

                                             Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

50                              Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad


Theorem 2. If Y âˆ¼ T DL(p, Î²), the probability generating function (pgf ) of Y is
given by
                              (1 âˆ’ p)2 (1 âˆ’ pt(1 âˆ’ Î²))
                    GY (t) =                           ,
                              (1 âˆ’ pt)2 (1 âˆ’ p(1 âˆ’ Î²))
Î² â‰¥ 0, 0 < p < 1 for 0 < pt < 1.

                                                                          Pâˆž
Proof . By definition the pgf can be expressed as GY (t) = E(tY ) =          x=0 t
                                                                                     x
                                                                                         P (Y =
x), this implies that
                                                 âˆž
                                     (1 âˆ’ p)2 X
                       GY (t) =                    (pt)x (1 + Î²x),
                                   1 + p(Î² âˆ’ 1) x=0

which on simplification yields

                                      (1 âˆ’ p)2 (1 âˆ’ pt(1 âˆ’ Î²))
                           GY (t) =                            ,
                                      (1 âˆ’ pt)2 (1 âˆ’ p(1 âˆ’ Î²))

Î² â‰¥ 0, 0 < p < 1 for 0 < pt < 1.
     On Replacing t by et we get a moment generating function (mgf) such as

                                      (1 âˆ’ p)2 (1 âˆ’ pet (1 âˆ’ Î²))
                          MY (t) =                               ,                          (6)
                                      (1 âˆ’ pet )2 (1 âˆ’ p(1 âˆ’ Î²))

Î² â‰¥ 0, 0 < p < 1 for 0 < pet < 1.

    The first four derivatives of equation (6), with respect to t at t = 0, yield the
                                               r
first four moments about origin i.e. Âµ0r = d M     Y (t)
                                                 dtr     |t=0 which after simplification
are:
                                    (1 âˆ’ p + Î²(1 + p))p
                            Âµ01 =                           ,
                                   (1 + p(Î² âˆ’ 1))(1 âˆ’ p)

                                   (1 âˆ’ p2 + Î²(1 + 4p + p2 ))p
                           Âµ02 =                               ,
                                     (1 + p(Î² âˆ’ 1))(1 âˆ’ p)2

                       (1 + 3p âˆ’ 3p2 âˆ’ p3 + Î²(1 + 11p + 11p2 + p3 ))p
               Âµ03 =                                                  ,
                                   (1 + p(Î² âˆ’ 1))(1 âˆ’ p)3

                  (1 + 10p âˆ’ 10p3 âˆ’ p4 + Î²(1 + 26p + 66p2 + 26p3 + p4 ))p
          Âµ04 =                                                           ,
                                  (1 + p(Î² âˆ’ 1))(1 âˆ’ p)4

                                (1 âˆ’ p)2 + (1 âˆ’ 3p2 + 2p)Î² + 2(pÎ²)2
                   V ar(Y ) =                                       ,
                                      (1 + p(Î² âˆ’ 1))2 (1 âˆ’ p)2

                                       (1 âˆ’ p)2 + (1 âˆ’ 3p2 + 2p)Î² + 2(pÎ²)2
          Indexof Dispersion =                                               .
                                     (1 + p(Î² âˆ’ 1))(1 + p(Î² âˆ’ 1) + Î²)(1 âˆ’ p)


                                          Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

A Two Parameter Discrete Lindley Distribution                                                  51

2.3. Index of Dispersion
     Index of dispersion (ID) for discrete distributions is defined as variance to mean
ratio, it indicates whether a certain distribution is suitable for under or over dis-
persed data sets, and is used widely in ecology as a standard measure for measuring
clustering (over dispersion) or repulsion (under dispersion) (see Johnson, Kotz &
Kemp 1992). If IDâ‰¥ 1(â‰¤ 1) the distribution is over dispersed (under dispersed).
It is observed that if either p â†’ 1 or Î² â†’ 0, the distribution will always follow over
dispersion and if p â†’ 0, Î² â†’ âˆž it will follow the under dispersion phenomenon.
Moreover, the distribution is positively skewed with a longer tail compared to a
one parameter discrete Lindley and leptokurtic in nature, which is evident from
the ratio of the square of the third mean moment to the cube of the second mean
moment and the ratio of the fourth mean moment to the square of variance. TDL
is positively skewed for Î² â†’ 0 and p â†’ 0. Also, it approaches 2 and zero (0)
as p â†’ 1 and Î² â†’ âˆž respectively, which is evident in Table 1. Moreover, it is
leptokurtic in nature, and has high peakedness as p â†’ 0 and Î² â†’0 (see Table
2. Its peakedness approaches six as p â†’ 1 and for smaller values of p and higher
values of Î² it becomes equal to 3.

                                  Table 1: Skewness.
     Î² â†“ pâ†’     0.05    0.10    0.2     0.3     0.4     0.5     0.6     0.7     0.8     0.9
       0.05    21.09   11.61   6.95    5.45    4.75    4.34    4.08    3.86    3.59    3.11
       0.50    14.89    8.24   4.90    3.78    3.19    2.82    2.55    2.34    2.17    2.05
       3.50     4.31    2.34   1.68    1.68    1.78    1.87    1.93    1.97    1.99    1.99
       6.50     2.18    1.26   1.28    1.58    1.80    1.92    1.97    1.99    2.00    2.00
      10.50    1.12    0.77    1.22    1.67    1.90    1.99    2.02    2.02    2.01    2.00



                                  Table 2: Kurtosis.
    Î²â†“pâ†’       0.05     0.10     0.2     0.3     0.4     0.5     0.6     0.7     0.8     0.9
      0.05    26.08    16.59   11.93   10.42    9.69    9.26    8.95    8.65    8.26    7.50
      0.50    19.41    12.71    9.31    8.08    7.43    6.98    6.66    6.39    6.19    6.05
      3.50     7.28     5.63    5.40    5.59    5.76    5.87    5.94    5.97    5.99    6.00
      6.50     4.85     4.52    5.18    5.64    5.85    5.95    5.98    6.00    6.00    6.00
     10.50    3.74     4.23    5.37     5.83    5.99    6.02    6.03    6.02    6.01    6.00



Theorem 3. If Yâˆ¼ TDL(p,Î²) and rth , descending factorial moment of Y is given
by
                         r!pr (1 âˆ’ p)âˆ’r (1 + Î²r + (Î² âˆ’ 1)p)
                 Âµ0(r) =                                    ,             (7)
                                   (1 + p(Î² âˆ’ 1))

where Î² â‰¥ 0, 0 < p < 1, r = 0, 1, . . . , (a)n = a(a + 1)(a + 2) Â· Â· Â· (a + n âˆ’ 1) and
Âµ0(0) = 1.


Proof . The rth descending factorial moment for r.v. Y can be defined as Âµ0(r) =
           Pâˆž
E(Y (r) ) = x=0 x(r) P (Y = x), which will from now an use the relation x(r) =

                                         Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

52                                   Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad

                               x!
x(x âˆ’ 1) . . . (x âˆ’ r + 1) = (xâˆ’r)! . Then, we have

                                                  âˆž
                                     (1 âˆ’ p)2    X      x!
                        Âµ0(r) =                               (1 + Î²x)px ,
                                  (1 + p(Î² âˆ’ 1)) x=r (x âˆ’ r)!
                                                     Pâˆž       (a)n z n
by using the binomial series (1 âˆ’ z)âˆ’a =              x=0       n! , (see Rainville 1965).   The
followings reached:

                (1 âˆ’ p)2 r!pr
     Âµ0(r) =
               (1 + p(Î² âˆ’ 1))
                                                                              p2
                                                                                   
                              âˆ’(r+1)
                   Ã— (1 âˆ’ p)         + Î²r + (r + 1)(r + 1)p + (r + 1)2 (r + 2) . . . ,
                                                                              2!

          (1 âˆ’ p)âˆ’r r!pr n                                                        o
Âµ0(r) =                   (1 âˆ’ p)âˆ’(r+1) + Î²r(1 âˆ’ p)âˆ’(r+1) + Î²p(r + 1)(1 âˆ’ p)âˆ’(r+2) ,
          (1 + p(Î² âˆ’ 1))
After some algebraic manipulation, equation (7) is attained, which generates a
recursive relation between r and r âˆ’ 1, descending factorial moments such as

       Âµ0(r) {(1 âˆ’ p)(1 + Î²(r âˆ’ 1) + (Î² âˆ’ 1)p)} = {rp(1 + Î²r + (Î² âˆ’ 1)p)} Âµ0(râˆ’1)

Î² â‰¥ 0, 0 < p < 1, r = 1, 2, . . .

Theorem 4. If Y âˆ¼ T DL(p, Î²), the rth ascending factorial moment of Y is given
by
                          r!p(1 âˆ’ p)âˆ’r (1 + Î² âˆ’ p + Î²pr)
                  Âµ0[r] =                                ,                 (8)
                                  (1 + p(Î² âˆ’ 1))
                                                      p(1+Î²âˆ’p)
where Î² â‰¥ 0, 0 < p < 1, r = 0, 1, 2, . . . , Âµ0[0] = (1+p(Î²âˆ’1)) and (a)n = a(a + 1)(a +
2) . . . (a + n âˆ’ 1).

Proof . The rth , absolute ascending
                              Pâˆž        factorial moment can be defined and ex-
pressed as Âµ0[r] = E((Y )r ) = x=0 (x)r P (Y = x). This implies that
                                               (âˆž                âˆž
                                                                                     )
                                 (1 âˆ’ p)2       X                X
                    Âµ0[r] =                               x
                                                    (x)r p + Î²         x(x)r p   x
                                                                                         ,
                              (1 + p(Î² âˆ’ 1))   x=0               x=0

                                 Pâˆž (a)n zn
by using the series P(1 âˆ’ z)âˆ’a =    x=0    n!          Pâˆž 1965), we can get
                                               (see Rainville
                       âˆž
equation (8), where x=0 (x)r px = r!p(1 âˆ’ p)âˆ’râˆ’1 and Î² x=0 x(x)r px = Î²r!p(1 âˆ’
p)âˆ’râˆ’2 (1 + pr). Equation (8) yields a recursive relation between r and r âˆ’ 1
ascending factorial moments such as

          Âµ0[r] {(1 âˆ’ p)(1 + Î² âˆ’ p + Î²p(r âˆ’ 1))} = {r(1 + Î² âˆ’ p + Î²pr)} Âµ0[râˆ’1] ,

Î² â‰¥ 0, 0 < p < 1, r = 1, 2, . . .

      Thus the theorem.

                                               Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

A Two Parameter Discrete Lindley Distribution                                                                       53

Theorem 5. If Y âˆ¼ T DL(p, Î²) the first order negative moment of Y is given by

                  (1 âˆ’ p)2
  E(Y + a)âˆ’1 =
               (1 + p(Î² âˆ’ 1))
          Ã— a 2 F1 (a, 1; a + 1; p) + Î²p(a + 1)âˆ’1 2 F1 (a + 1, 2; a + 2; p) , (9)
              âˆ’1

                                                                          Pâˆž        (a)n (b)n z n
where a > 0, Î² â‰¥ 0, 0 < p < 1 and 2 F1 (a, b; c; z) =                         n=0     (c)n n! .


                           1
                                              Pâˆž                   âˆ’1
Proof . By definition E( Y +a )=                 x=0 (x + a)            P (Y = x), so we have

                                              âˆž
                        1        (1 âˆ’ p)2    X
                 E(        )=                   (x + a)âˆ’1 px (1 + Î²x).
                      Y +a    (1 + p(Î² âˆ’ 1)) x=0
                                              Pâˆž
After simplification
         Pâˆž          we get equation (9) where x=0 (x+a)âˆ’1 px = aâˆ’1 2 F1 (a, 1; a+
1; p) and x=0 (x + a)âˆ’1 Î²xpx = Î²p(a + 1)âˆ’1 2 F1 (a + 1, 2; a + 2; p).

Corollary 2. The sth order negative moment of Y âˆ¼ T DL(p, Î²) can be expressed
as

                     (1 âˆ’ p)2
  E(Y + a)âˆ’s =                   aâˆ’s s+1 Fs (a, . . . , a, 1; a + 1, . . . , a + 1; p)
                  (1 + p(Î² âˆ’ 1))
           (1 âˆ’ p)2
      +                Î²p(a + 1)âˆ’s s+1 Fs (a + 1, Â· Â· Â· , a + 1, 2; a + 2, Â· Â· Â· , a + 2; p),
        (1 + p(Î² âˆ’ 1))

where
                                                                 âˆž
                                                                 X (a1 )n , . . . , (as )n z n
                s Fu (a1 , . . . , as ; b1 , . . . , bu ; z) =                                       ,
                                                                 n=0
                                                                        (b1 )n , . . . , (bu )n n!

the series converges for s = u + 1 and |z| < 1.

Theorem 6. If Y âˆ¼ T DL(p, Î²), the sth order negative factorial moment of Y is
given by

              (1 âˆ’ p)2
  Âµ0âˆ’[s] =
           (1 + p(Î² âˆ’ 1))
    Ã— ((a)s )âˆ’1 2 F1 (a, 1; a + s; p) + Î²p((a + 1)s )âˆ’1 2 F1 (a + 1, 2; a + s + 1; p) ,
       

                                                                                     (10)
                                                                                               Pâˆž          (a)n (b)n z n
where a > 0, s = 0, 1, 2, . . . , Î² â‰¥ 0, 0 < p < 1 and 2 F1 (a, b; c; z) =                           n=0     (c)n n! .


Proof . The sth order negative factorial moment for Y is defined as
                                               âˆž sâˆ’1
                                  1           X   Y
               Âµ0âˆ’[s] = E((          )[s] ) =         (x + a + i)âˆ’1 P (Y = x),
                                Y +a          x=0 i=0


                                                   Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

54                                 Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad


on incorporating equation (4) we get
                                          âˆž sâˆ’1
                             (1 âˆ’ p)2    X   Y
              Âµ0âˆ’[s] =                           (x + a + i)âˆ’1 px (1 + Î²x),
                          (1 + p(Î² âˆ’ 1)) x=0 i=0

which after simplification yields equation (10).
           Pâˆž Qsâˆ’1                                                 Pâˆž Qsâˆ’1
   Where x=0 i=0 (x+a+i)âˆ’1 px = ((a)s )âˆ’1 2 F1 (a, 1; a + s; p) and x=0 i=0 (x+
a + i)âˆ’1 Î²xpx = Î²p((a + 1)s )âˆ’1 2 F1 (a + 1, 2; a + s + 1; p).
Note 1.
                                                     âˆž
                                                     X (a)n (b)n z n
                              2 F1 (a, b; c; z) =                      ,
                                                     n=0
                                                            (c)n n!

and (a)n = a(a + 1)(a + 2) Â· Â· Â· (a + n âˆ’ 1), are the hypergeometric series function
and the Pochhammerâ€™s symbol respectively, the series converges for a, b, c â‰¥ 0 and
|z| â‰¤ 1.


3. Parameter Estimation
3.1. Maximum Likelihood Method
     If Y1 , Y2 , . . . , Yn be a random sample drawn identically independently from
the two parameters discrete Lindley (TDL) distribution with observed values
x1 , x2 , . . . , xn then the joint probability function for TDL distribution can be ex-
pressed as
                                                                        n
                                                 (1 âˆ’ p)2n     Pn
                                                                i=1 xi
                                                                       Y
          f (x1 , x2 , . . . , xn ; p, Î²) =                   p            (1 + Î²xi ),
                                              (1 + p(Î² âˆ’ 1))n          i=1

                                                              n
                                                              X                 n
                                                                                X
 ln(L(p; Î²)) = 2n ln(1 âˆ’ p) âˆ’ n ln((1 + p(Î² âˆ’ 1))) +                xi ln p +         ln(1 + Î²xi ). (11)
                                                              i=1               i=1

By partially differentiating both sides of equation (11) with respect to p and Î²,
equating them to zero, we get M LE s of p and Î² respectively, which can be shown
as                                                      Pn
             âˆ‚ ln(L(p, Î²))       2n       n(Î² âˆ’ 1)           xi
                            =âˆ’        âˆ’              + i=1      = 0,
                   âˆ‚p           1 âˆ’ p 1 + p(Î² âˆ’ 1)         p
                                   2p     p(Î² âˆ’ 1)
                                       +             = xÌ„,                                         (12)
                                  1 âˆ’ p 1 + p(Î² âˆ’ 1)
                                                 n
                  âˆ‚ ln(L(p, Î²))         np       X     xi
                                =âˆ’             +            = 0,
                       âˆ‚Î²          1 + (Î² âˆ’ 1)p i=1 1 + Î²xi
this implies that
                                 n
                                 X      xi          np
                                             =              .                                      (13)
                                 i=1
                                     1 + Î²xi   1 + p(Î² âˆ’ 1)


                                                Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

A Two Parameter Discrete Lindley Distribution                                                55

The M LE s are computed using a computational package such as Mathematica
[7.0]. In view of the regularity conditions as stated by Rohatgi and Saleh on page
419, the M LE s i.e. (pÌ‚, Î²Ì‚) of TDL has a bivariate normal distribution with mean
(p,Î²) and a variance-covariance matrix (I(p,Î²))âˆ’1 . Thus (pÌ‚, Î²Ì‚) âˆ¼ BVN((p,Î²),
(I(p,Î²))âˆ’1 ) where I(p,Î²) denotes the information matrix and is given below
                                      ï£® âˆ’âˆ‚ 2 ln L(p,Î²)           2             ï£¹
                                       E(      âˆ‚p2       ) E( âˆ’âˆ‚ âˆ‚pâˆ‚Î²
                                                                   ln L(p,Î²)
                                                                             )
                                      ï£¯                                        ï£º
               I((p, Î²)|p=pÌ‚,Î²=Î²Ì‚ ) = ï£¯
                                      ï£°
                                                                               ï£º
                                                                               ï£»
                                          âˆ’âˆ‚ 2 ln L(p,Î²)      âˆ’âˆ‚ 2 ln L(p,Î²)
                                       E(     âˆ‚pâˆ‚Î²       ) E(      âˆ‚Î² 2      )

as entropy of a random variable is considered as the measure of the uncertainty
of the random variable. It is used to measure the amount of information required
to describe the random variable. In this regard, the entropy of the two parameter
discrete Lindley (TDL) distribution is defined as:

              1 + p(Î² âˆ’ 1)            (1 + Î² + p(Î² âˆ’ 1))p
H(Y ) = ln(                ) âˆ’ ln p(                       ) âˆ’ Î²E {x2 F1 (1, 1; 2; âˆ’Î²x)}
                (1 âˆ’ p)2             (1 âˆ’ p)(1 + p(Î² âˆ’ 1))
                                                                   Pâˆž       (a)n (b)n z n
where ln(1 + x) = x2 F1 (1, 1; 2; âˆ’x) and 2 F1 (a, b; c; z) =         n=0     (c)n n! .




4. Characterization
Theorem 7. Let Y be a nonnegative discrete random variable with probability
mass function P (Y = x) and x âˆˆ Z+ ; it then will follow the two parameter discrete
Lindley distribution with parameters p and Î² iff

                           phx                pÎ²(1 + p)
         M RL(Y ) =               +                               , âˆ€x âˆˆ Z+                 (14)
                         (1 âˆ’ p)2   ((1 âˆ’ p)(1 + Î²x) + pÎ²)(1 âˆ’ p)
                                x
where hx = P (YSx=x) , Sx = p ((1âˆ’p)(1+Î²x)+pÎ²)
                                 1+p(Î²âˆ’1)      ,0 < p < 1 and Î² â‰¥ 0.

Proof . Necessity:
           Pâˆž
                   According to Kemp (2004) the MRL function is defined as
             k=x+1 Sk
M RL(Y ) =      Sx    , this implies that
                                          Pâˆž           k
                                                                     Pâˆž            k
                         ((1 âˆ’ p) + Î²p)      k=x+1 p + Î²(1 âˆ’ p)        k=x+1 kp
          M RL(Y ) =                                                                   ,
                                            (1 + p(Î² âˆ’ 1))Sx

                               px p(1 âˆ’ p) {(1 âˆ’ p)(1 + Î²x) + (1 + p)Î²}
                M RL(Y ) =                                              ,
                                       (1 âˆ’ p)2 (1 + p(Î² âˆ’ 1))Sx
After simplification we get

                               phx                 pÎ²(1 + p)
               M RL(Y ) =             +                                ,
                             (1 âˆ’ p)2   {(1 âˆ’ p)(1 + Î²x) + pÎ²} (1 âˆ’ p)

                                           Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

56                                Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad


Sufficency: Suppose equation (14) holds then it can be written as
                        âˆž
                        X             pP (Y = x)   pÎ²(1 + p)px
                               Sk =              +              ,                        (15)
                                         1âˆ’p       1 + p(Î² âˆ’ 1)
                       k=x+1

Also
                       âˆž
                       X             P (Y = x + 1)      2p2 Î²px
                              Sk =                 +              ,                      (16)
                                         1âˆ’p         1 + p(Î² âˆ’ 1)
                      k=x+1

on comparing equation (15) with equation (16) we get

                                                      pÎ²px (1 âˆ’ p)2 (1 + Î²x)
               P (Y = x + 1) âˆ’ pP (Y = x) =                                  ,
                                                     (1 + p(Î² âˆ’ 1))(1 + Î²x)

               (1 + Î²x)P (Y = x + 1) = (1 + (x + 1)Î²)P (Y = x + 1)p,
                                         2
                              (1âˆ’p)
which gives P (Y = 0) = p0 = 1+p(Î²âˆ’1) and P (Y = x) = p0 px (1 + Î²x).

Theorem 8. The random variable Y âˆ¼ T DL(p, 1) iff it can be written as Y â‰¡
X1 + X2 where Xi âˆ¼ G0 (q) i.e. P (X = xi ) = pxi q, xi = 0, 1, . . . for i = 1, 2 are
independent random variables.

Proof . From equation (6) we get

                                      (1 âˆ’ p)2 (1 âˆ’ pet (1 âˆ’ Î²))
                          MY (t) =                               ,
                                      (1 âˆ’ pet )2 (1 âˆ’ p(1 âˆ’ Î²))

Î² â‰¥ 0, 0 < p < 1 for 0 < pet < 1.
     For Î² = 1 it simplifies as

                                                 (1 âˆ’ p)2
                                    MY (t) =                ,
                                                (1 âˆ’ pet )2

0 < p < 1 for 0 < pet < 1 therefore

                                  MY (t) = MX1 (t)MX2 (t),

0 < p < 1 for 0 < pet < 1 which implies the result.


5. Real Data Examples
    We used two data sets reported by Chakraborty & Chakravarty (2012), to in-
vestigate the competence of the proposed model. Suitsbility of the proposed model
is tested via the p-value and the Akaikes information criteria (AIC) proposed by
Hirotsugu Akaike in 1971. It was then compared with Poisson, Negative binomial,
Generalized Poisson and discrete gamma distributions; as stated in Chakraborty
& Chakravarty (2012).

                                             Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

A Two Parameter Discrete Lindley Distribution                                                        57

Data set 1: The first data set contains observations on a number of European red
mites on apple leaves and is presented in Table 3. Clearly this data set belongs to
on over dispersed structure that has ID = 1.9828. We present the MLE, observed
and expected frequencies, Log-Likelihood (LL), Chi-square values, p-values and
AIC values for two parameter discrete Lindley distribution: Î²Ì‚ = 0.146; pÌ‚ = 0.479;
LL = âˆ’222.3; d.f. = 5; Ï‡2 = 2.514; p-value = 0.774; AIC = 448.76.

                                 Table 3: Example 1.
   Red mites     0       1       2       3          4      5       6         7          8    Total
   Frequency    70      38      17      10          9      3       2         1          0     150
   TDL(p,Î²)    68.90   37.81   20.42   10.89      5.75   3.00     1.56     0.81       0.41    150


Data set 2: The second data set in table 4 is about the observations collected
from number of strikes in UK coal mining industries in four successive week periods
during 1948-1959. The clearly data mentioned in Table 4 is an under dispersed
data set with ID = 0.7467. The MLE, observed and expected frequencies, Log-
Likelihood (LL), Chi-square values, p-values and AIC values for the two parameter
discrete Lindley distribution are given below: Î²Ì‚ = 8.3855; pÌ‚ = 0.176; LL =
âˆ’187.44; d.f. = 3; Ï‡2 = 0.5108; p-value = 0.92; AIC = 378.

                                 Table 4: Example 2.
           Number of outbreaks      0        1         2         3         4      Total
              Frequency            46       76        24         9         1       156
               TDL(p,Î²)           45.95    76.08     25.39      6.59     1.53      156


   It can be observed that in these examples the proposed model not only gives
high p-values but also a minimum AIC compared to the distributions mentioned
by Chakraborty & Chakravarty (2012). It therefore depicts the situation that
the proposed model has the least loss of information in comparison with to the
standard distributions.


6. Discretized Bivariate Case
    Bivariate discrete random variables defined on integers or on non-negative val-
ues are used to model the paired count data that arise in a number of situations
such as: in the analysis of accidents, e.g. the number of accidents in a site be-
fore and after infrastructure changes; in epidemiological analysis, e.g. incidents of
different diseases in a series of districts; in medical research, e.g. the number of
seizures before and after treatment etc. In this regard, literature on bivariate dis-
crete distribution is sparse and worth mentioning particularly in terms of bivariate
discretized distributions. Here, we give a bivariate discretized Lindley distribution
by discretizing the bivariate continuous distribution, using the following equation:

                                                     âˆž          âˆž
                                                                                   !âˆ’1
                                                     X          X
          P (Y1 = x1 , Y2 = x2 ) = f (x1 , x2 )                        f (k1 , k2 )             (17)
                                                   k1 =âˆ’âˆž k2 =âˆ’âˆž



                                          Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

58                                 Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad


6.1. Derivation
    Suppose W 0 = (W1 , W2 ) and Z 0 = (Z1 , Z2 ) are two random vectors of indepen-
dent random variables, each of which is distributed Gamma(1, Î¸) and Gamma(2, Î¸)
                                    Î¸                Î²
respectively. Now, consider p1 = Î¸+Î²   and p2 = Î¸+Î²     are the respective weights of
W 0 and Z 0 such that p1 + p2 = 1, Î¸ > 0 and Î² â‰¥ 0. On mixing these densities, the
resulting distribution of the random vector X 0 = (X1 , X2 ) will be a bi variate two
parameter Lindley distribution i.e. X 0 âˆ¼ p1 W 0 + p2 Z 0 , and can be expressed as

                                       Î¸3
               fX1 ,X2 (x1 , x2 ) =       (1 + Î¸Î²x1 x2 )(exp(âˆ’Î¸(x1 + x2 ))),              (18)
                                      Î¸+Î²
x1 , x2 â‰¥ 0, Î² â‰¥ 0 and Î¸ > 0.
    On substituting equation (18) into equation (17) we get a discretized version
of bivariate Lindley distribution, expressed as:

                                      (1 âˆ’ eâˆ’Î¸ )4 (1 + Î¸Î²x1 x2 ) exp(âˆ’Î¸(x1 + x2 ))
       P (Y1 = x1 , Y2 = x2 ) =                                                    ,      (19)
                                                  (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’2Î¸

x1 , x2 âˆˆ Z+ , Î² â‰¥ 0 and Î¸ > 0.
     Its moment generating function is defined as:

                          (1 âˆ’ eâˆ’Î¸ )4 (1 âˆ’ eâˆ’(Î¸âˆ’t1 ) )(1 âˆ’ eâˆ’(Î¸âˆ’t2 ) ) + Î²Î¸eâˆ’2Î¸+t1 +t2
                                     
     MY1 ,Y2 (t1 , t2 ) =                                                               ,
                             ((1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’2Î¸ )(1 âˆ’ eâˆ’(Î¸âˆ’t1 ) )2 (1 âˆ’ eâˆ’(Î¸âˆ’t2 ) )2
|t1 , t2 | < 1, Î¸ â‰¥ (t1 , t2 ), Î² â‰¥ 0 and Î¸ > 0.
     Similarly, marginal probability mass functions of Yi for i = 1, 2 are given by:

                             (1 âˆ’ eâˆ’Î¸ )2
      gi (Yi = xi ) =                        (1 + (Î¸Î²xi âˆ’ 1)eâˆ’Î¸ ) exp(âˆ’Î¸(xi )),           (20)
                        (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’2Î¸

xi âˆˆ Z+ , Î² â‰¥ 0 and Î¸ > 0, and conditional probability mass functions of Yj | Yi =
xi , denoted by gj (Yj | Yi = xi ) for i 6= j = 1, 2, is expressed as:

                                      (1 âˆ’ eâˆ’Î¸ )2
           gj (Yj | Yi = xi ) =                      (1 + Î¸Î²xi xj ) exp(âˆ’Î¸(xj )),         (21)
                                  (1 + (Î²Î¸xi âˆ’ 1)eâˆ’Î¸

xi , xj âˆˆ Z+ , Î² â‰¥ 0 and Î¸ > 0.
     From equation (19) and (20) we get:

                               eâˆ’2Î¸ (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸(1 + eâˆ’Î¸ )2
                                   
                 E(Y1 , Y2 ) =                                   ,                        (22)
                                (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’2Î¸ (1 âˆ’ eâˆ’Î¸ )2

Yi , Yj âˆˆ Z+ , Î² â‰¥ 0 and Î¸ > 0.

                                  eâˆ’Î¸ (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’Î¸ (1 + eâˆ’Î¸ )
                                     
                     E(Yi ) =                                        ,                    (23)
                                    (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’2Î¸ (1 âˆ’ eâˆ’Î¸ )
Yi âˆˆ Z+ for i = 1, 2, Î² â‰¥ 0 and Î¸ > 0.


                                              Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

A Two Parameter Discrete Lindley Distribution                                        59

   This implies that
                  eâˆ’2Î¸ (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸(1 + eâˆ’Î¸ )2
                      
  Cov(Y1 , Y2 ) =
                   (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’2Î¸ (1 âˆ’ eâˆ’Î¸ )2
                                                                           2
                                      eâˆ’2Î¸ (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’Î¸ (1 + eâˆ’Î¸ )
                                           
                                   âˆ’                          2              , (24)
                                       {(1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’2Î¸ } (1 âˆ’ eâˆ’Î¸ )2
Yi âˆˆ Z+ for i = 1, 2,Î² â‰¥ 0 and Î¸ > 0. Its is obvious from equation (24) that for
Î² = 0 the Cov(Y1 , Y2 ) = 0.
Theorem 9. Let Y 0 = (Y1 , Y2 ) be a discrete random vector distributed according
to equation (19), then the probability mass functions of U = Y1 + Y2 are expressed
respectively as:
                             (1 âˆ’ eâˆ’Î¸ )4 (1 + u)eâˆ’Î¸u      Î²Î¸u(u âˆ’ 1)
              gU (U = u) =          âˆ’Î¸  2       âˆ’2Î¸
                                                     (1 +            ),            (25)
                              (1 âˆ’ e ) + Î²Î¸e                  6
u âˆˆ Z+ , Î² â‰¥ 0 and Î¸ > 0.

Proof . Suppose Y 0 = (Y1 , Y2 ) follows a two parameter discrete bivariate Lindley
distribution as defined in equation (19). Let us consider U = Y1 + Y2 and V = Y1 .
Now by using the change of variable technique we can write the joint probability
mass function of U and V as:
                               (1 âˆ’ eâˆ’Î¸ )4
     P (U = u, V = v) =                        (1 + Î¸Î²v(u âˆ’ v))(exp(âˆ’Î¸u)),     (26)
                          (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’2Î¸
0 â‰¤ v â‰¤ u âˆˆ Z+ , Î² â‰¥ 0 and Î¸ > 0.
    Now, on summing over v we get the probability mass function of U as expressed
in equation (25).
Theorem 10. If Y 0 = (Y1 , Y2 ) is a discrete random vector distributed according
to equation (19) then the probability mass functions of V = Y1 âˆ’ Y2 are expressed
respectively as:
                          (1 âˆ’ eâˆ’Î¸ )4 eâˆ’Î¸v
  gV (V = v) =
                 ((1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’2Î¸ )(1 âˆ’ eâˆ’2Î¸ )3
                             Ã— ((1 âˆ’ eâˆ’2Î¸ )3 + Î²Î¸eâˆ’2Î¸ (v âˆ’ 1 âˆ’ (v + 1)eâˆ’2Î¸ )), (27)
v âˆˆ Z,Î² â‰¥ 0 and Î¸ > 0.

Proof . Suppose Y 0 = (Y1 , Y2 ) is defined according to equation (19). Now consider
V = Y1 âˆ’ Y2 and M = Y1 . According to change of variable technique, the joint
probability mass function of V and M can be expressed as:
                           (1 âˆ’ eâˆ’Î¸ )4
P (V = v, M = m) =                         (1 + Î¸Î²m(v + m))(exp(âˆ’Î¸(v + 2m))),
                      (1 âˆ’ eâˆ’Î¸ )2 + Î²Î¸eâˆ’2Î¸
                                                                         (28)
v âˆˆ Z, m âˆˆ Z+ , Î² â‰¥ 0 and Î¸ > 0.
   Now, on summing over m we get the probability mass function of V , as ex-
pressed in equation (27).


                                       Revista Colombiana de EstadÃ­stica 39 (2016) 45â€“61

60                           Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad


7. Conclusion
    A two parameter discrete Lindley distribution has been proposed. Its various
distributional properties, reliability characteristics and characterization have been
studied. It was found that this distribution has a simple structure, is more math-
ematically amenable, more flexible and has a longer tail than the one parameter
discrete Lindley and other models in modeling actuarial and other count data
from various fields such as ecology, health, psychology, sociology and engineering.
It also has a less loss of information compared to the standard discrete distribu-
tions. Further issues such as characterization and mixtures are currently being
researched and may be discussed in the further papers.


Acknowledgements
   The authors are deeply thankful to the editor and the reviewer for their valuable
suggestions to improve the quality of the paper.
                                                             
               Received: September 2014 â€” Accepted: March 2015


References
Abouammoh A, Mashhour A. A note on the unimodality of discrete distributions.(1981). Communication in Statistics - Theory and Methods.
Al Huniti A, Al Dayian G. Discrete burr type-iii distribution.(2012). American Journal of Mathematics and Statistic.
Chakraborty S, Chakravarty D. Discrete gamma distributions: Properties and parameters estimations.(2012). Communication in Statistics Theory and Methods.
DeÌ†niz E, Ojeda E. The discrete lindley distribution: Properties and application.(2011). Journal of Statistical Computation and Simulation.
Hussain T, Ahmad M. Discrete inverse gamma distribution.(2012).International Conference on Statistical Sciences Islamic Countries Society of Statistical Sciences.
Hussain T, Ahmad M. Discrete inverse rayleigh distribution.(2014). Pakistan Journal of Statistics.
Inusah S, Kozubowski J. A discrete analogue of the laplace distribution.(2006). Journal of Statistical Planning and Inference.
Jazi M, Lai C, Alamatsaz M. A discrete inverse weibull distribution and estimation of its parameters.(2010). Statistical Methodology.
Johnson N, Kotz S, Kemp A. Univariate Discrete Distribution.(1992). John Wiley and Sons.
Kemp A. Statistical methodology.(1997). Journal of Statistical Planning and Inference.
Kemp A. Classes of discrete lifetime distributions.(2004). Communications in Statistics Theory and Methods.
Kemp A. The discrete half-normal distribution.(2006). Advances in mathematical and statistical modeling.
Kielson J, Gerber H. Some results for discrete unimodality.(1971). Journal of American Statistical Association.
Kozubowski J, Inusah S. A skew laplace distribution on integers.(2006). AISM.
Krishna H, Pundir P. Discrete maxwell distribution.(2007). http://interstat statjournals net/YEAR/2007/articles/0711003 pdf.
Krishna H, Pundir P. Discrete burr and discrete pareto distributions.(2009). Statistical Methodology.
Nakagawa T, Osaki S. The discrete weibull distribution.(1975). IEEE Transactions on Reliability.
Nekoukhou V, Alamatsaz M, Bidram H. A discrete analog of the generalized exponential distribution.(2012). Communication in Statistics Theory and Methods.
Rainville E. Special Functions.(1965). The Macmillan Company.
Roy D. Discrete normal distribution.(2003). Communication in Statistics Theory and Methods.
Roy D. Discrete rayleigh distribution.(2004). IEEE Transactions on Reliability.
Szablowski P. Discrete normal distribution and its relationship with jacobi theta functions.(2001). Statistics and Probability Letters.