A Two Parameter Discrete Lindley Distribution. Distribución Lindley de dos parámetros
Government Postgraduate College, Rawalakot, Pakistan. Department of Statistics, Faculty of Sciences, King Abdulaziz University, Jeddah, Saudi Arabia. National College of Business Administration and Economics, Lahore, Pakistan
Abstract
In this article we have proposed and discussed a two parameter discrete Lindley distribution. The derivation of this new model is based on a two step methodology i.e. mixing then discretizing, and can be viewed as a new generalization of geometric distribution. The proposed model has proved itself as the least loss of information model when applied to a number of data sets (in an over and under dispersed structure). The competing models such as Poisson, Negative binomial, Generalized Poisson and discrete gamma distributions are the well known standard discrete distributions. Its Lifetime classification, kurtosis, skewness, ascending and descending factorial moments as well as its recurrence relations, negative moments, parameters estimation via maximum likelihood method, characterization and discretized bi-variate case are presented.
Key words: Characterization, Discretized version, Estimation, Geometric distribution, Mean residual life, Mixture, Negative moments.
Resumen
En este artículo propusimos y discutimos la distribución Lindley de dos parámetros. La obtención de este Nuevo modelo está basada en una metodología en dos etapas: mezclar y luego discretizar, y puede ser vista como una generalización de una distribución geométrica. El modelo propuesto demostró tener la menor pérdida de información al ser aplicado a un cierto número de bases de datos (con estructuras de supra y sobredispersión). Los modelos estándar con los que se puede comparar son las distribuciones Poisson, Binomial Negativa, Poisson Generalizado y Gamma discrete.Su clasificación de tiempo de vida, kurtosis, sesgamiento, momentos factorials ascendientes y descendientes, al igual que sus relaciones de recurrencia, momentos negativos, estimación de parámetros via máxima verosimilitud, caracterización y discretización del caso bivariado son presentados.
Palabras clave: caracterización, estimación, distribución Geométrica, momentos negativos, mixtura, versión discretizada, vida media residual.


1. Introduction
    For the last few decades discretized distributions have been studied exten-
sively to model the discrete failure time data in statistical literature. Generally,
discretized versions are obtained from any continuous distribution defined on the
real line R with probability density function (pdf) f (x), and are based on the sup-
port; the set of integers Z = {0, ±1, ±2, ±3, . . .} have a probability mass function
that takes either of the two forms:

                           P (Y = x) = S(x) − S(x + 1),                              (1)

or                                                       !−1
                                              ∞
                                              X
                        P (Y = x) = f (x)           f (k)      .                     (2)
                                             k=−∞

The former in statistical literature is known as the discrete concentration approach
in which S(x) is the preserved survival function of continuous distribution at in-
tegers, and the latter is called the time discretization approach in which f (x) is
the preserved probability density function (pdf) of the continuous distribution at
integers.
    Following the approach as given in equation (1) Nakagawa & Osaki (1975),
Roy (2003, 2004), Krishna & Pundir (2009, 2007), Jazi, Lai & Alamatsaz (2010),
Dĕniz & Ojeda (2011), Chakraborty & Chakravarty (2012), Al-Huniti & Al-Dayian
(2012) and Hussain & Ahmad (2012, 2014) discretized continuous Weibull, Normal,
Rayleigh, Burr and Pareto, Maxwell, Inverse Weibull, Lindley, Gamma, Inverse
Gamma and Burr type -III, Inverse Gamma and Inverse Rayleigh distributions
respectively. Similarly Kemp (1997), Szablowski (2001), Inusah & Kozubowski
(2006), Kozubowski & Inusah (2006), Kemp (2006) and Nekoukhou, Alamatsaz
& Bidram (2012) adopted the latter approach as is presented in equation (2)
to discretize the Normal, Laplace, skew Laplace, half Normal and Generalized
Exponential distributions respectively. Such discretized versions are being applied
in the field of actuaries, engineering and biostatistics in which the lifetimes of
persons, organisms or products are measured in months, weeks or days.
    The discretization phenomenon generally arises when it becomes impossible or
inconvenient to measure the life length of a product or device on a continuous scale.
Such situations may arise, when the lifetimes need to be recorded on a discrete
scale rather than on a continuous analogue. For examples the number of to and


                                       Revista Colombiana de Estadística 39 (2016) 45–61

A Two Parameter Discrete Lindley Distribution                                       47

for motions of a pendulum or spring device before resting, the number of times
devices are switched on/off, the number of days a patient stays in an observation
ward, the length of successful stay of a pig (in terms of number of days/weeks, in
the laboratory) and the number of weeks/months/years a cancer patient survives
after treatment etc. Although there are a number of discrete distributions in the
literature to model the above mentioned situations there is still a lot of space left
to develop new discretized distribution that is suitable under different conditions.
    In this article, a two parameter discrete Lindley distribution is proposed. It
does not only have a simple structure, positively skewed and leptokurtic, but it
also has more flexibility than the Dĕniz & Ojeda (2011) single parameter discrete
Lindley distribution it also has less loss of information compared with standard
discrete distributions. Derivation of two parameter discrete Lindley distribution,
along with some properties, are given in section two, section three deals with esti-
mation of parameters. In section four characterization issue is addressed, section
five addresses the application of the proposed model and in the sixth section we
study a discretized bivariate version of the two parameter Lindley distribution.


2. Definition and Properties of a Two Parameter
   Discrete Lindley Distribution
2.1. Derivation
    The phenomenon of mixing and then discretizing the continuous distributions
with the help of proper weights and a set of parameters is so far a new one. In
this manuscript, after adopting the mixing and discretization technique, we have
proposed a two parameter discrete Lindley distribution, which can be viewed as
a new generalization of geometric distribution. Suppose W1 ∼ Gamma(1, θ) and
                                                                          θ
W2 ∼ Gamma(2, θ), on mixing these densities with probabilities p1 = θ+β      and
       β
p2 = θ+β  so that p1 + p2 = 1 and β ≥ 0, the resulting distribution of the random
variable X will be a two parameter Lindley distribution, i.e. X ∼ p1 W1 + p2 W2 .
This implies that
                     θ2
          f (x) =       (1 + βx) exp(−θx),      x ≥ 0, β ≥ 0 and θ > 0.            (3)
                    θ+β

    In order to model the discrete actuarial failure data Dĕniz & Ojeda (2011)
proposed asingle parameter discrete Lindley distribution which is not considered
a flexible model for analyzing different life time and actuarial data. It is used to
model the over dispersed data pattern (see Dĕniz & Ojeda 2011), which is math-
ematically a complicated one. Therefore, to increase the flexibility for modeling
purposes, we developed a two parameter discrete Lindley distribution by inserting
equation (3) into equation (2).
    Figure 1 depicts the curve behavior under different parameter combinations;
the curve changes to a reverse J shape as p → 0 and β → 0. Moreover, peakedness
of the curve decreases with a long right tail as p and β increases.


                                      Revista Colombiana de Estadística 39 (2016) 45–61

48                                         Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad



                                                                      Case 1
                                     0,8                              Case 2
                                                                      Case 3
                                                                      Case 4




                     Probabilities
                                     0,6

                                     0,4

                                     0,2

                                      0
                                           0       5             10      15
                                                       x-value
Figure 1: Probability graph for Two parameter Discrete Lindley Distribution Case 1.
        Figura  1: Probability
          β = 1.5;              graph
                    p = 0.45; Case  2. for  4.5; parameter
                                        β =Two                  3. βLindley
                                                           Discrete
                                                 p = 0.65; Case      = 6.25; p = 0.80;
          Case 4. β =Case
        Distribution   0.15;1.β
                              p=  1,5;p = 0,45;Case 2.β = 4,5;p = 0,65;Case
                                =0.10.
         3.β = 6,25;p = 0,80;Case 4.β = 0,15;p = 0,10.

Definition 1. A random variable Y has a two parameter discrete Lindley distri-
bution with parameters 0 < p < 1 and β ≥ 0, denoted by TDL (p, β), is defined
as
                           (1 − p)2 (1 + βx)px
 P (Y = x) = px =                              , x = 0, 1, 2, 3, . . . , 0 < p < 1 and β ≥ 0 (4)
                              (1 + p(β − 1))

where exp(−θ) = p. For β = 0 the distribution geometrically reduces, and for
β = 1 it becomes one a parameter discrete Lindley distribution. The recursive
relation between T DLs probabilities is given by

                 (1 + βx)P (Y = x + 1) = p(1 + β(x + 1))P (Y = x),                             (5)

for 0 < p < 1,β ≥ 0 and x = 0, 1, 2, 3, . . .


2.2. Reliability Characteristics of TDL
    Although, most of the statistical research is based on continuous lifetime proba-
bility distributions to model the real lifetime phenomena, reliability engineers/an-
thropologists are looking for solutions, for which time can be interpreted as a
discrete variable such as: the number of times a piece of equipment is operated;
the life of a switch being measured by the number of strokes; the life of equipment
being measured by the number of cycles it completes or the number of times it
is operated prior to failure; the life of a weapon is measured by the number of
rounds fired until failure; and the number of years of a married couple successfully
completed; or the number of miles that a plane is flown before failures etc. In
order to do this they started to discretize the continuous lifetime distributions.
In reliability theory, the survivor, the hazard, the cumulative hazard,the accumu-
lated hazard and mean residual life functions are important characteristics upon


                                                  Revista Colombiana de Estadística 39 (2016) 45–61

A Two Parameter Discrete Lindley Distribution                                              49

which the classification of discrete lifetime probability distribution is made. These
classifications, in turn, point out the nature of the product for the reliability an-
alyst, which could be for example, the increasing (decreasing) failure rate IFR
(DFR) class, increasing (decreasing) failure rate average IFRA (DFRA) class, the
new better (worse) than used NBU (NWU) class, new better (worse) than used in
expectation NBUE (NWUE) class and increasing (decreasing) mean residual life-
time IMRL (DMRL) class etc. (see Kemp 2004). These classes are generally based
on reliability/survival functions which give the probability that a component will
survive beyond a specified time. The basic definition and formulae of the above
mentioned characteristics for TDL are givenP    below. Reliability function of TDL is
                                                 ∞
defined and expressed as Sx = P (Y ≥ x) = k=x P (Y = k),
                                   px ((1 − p)(1 + βx) + pβ)
                            Sx =                             ,
                                          1 + p(β − 1)
0 < p < 1, β ≥ 0 and x = 0, 1, 2, 3, . . .
   Its failure rate function which gives the probability of failure given that it has
                                                        P (Y =x)
not occurred before a specific time, is defined as hx = P (Y ≥x)

                                       (1 − p)2 (1 + βx)
                             hx =                          ,
                                    ((1 − p)(1 + βx) + pβ)
0 < p < 1,β ≥ 0 and x = 0, 1, 2, 3, . . .
   Its Mean Residual Life (MRL) function is defined and expressed as M RL(Y ) =
E(Y − x|Y ≥ x),
                               phx                pβ(1 + p)
               M RL(Y ) =           2
                                      +                               ,
                             (1 − p)    ((1 − p)(1 + βx) + pβ)(1 − p)
0 < p < 1, β ≥ 0 and x = 0, 1, 2, 3, . . .
Theorem 1. If Y ∼ T DL(p, β) then the probability mass function (pmf )of the
random variable Y is log-concave for all choices of β and independent of p.

Proof . In order to show that the two parameter discrete Lindley distribution,
as defined in equation (4), is log-concave, it is sufficient to show that for β ≥ 0,
(px )2 ≥ px−1 px+1 ∀x = 1, 2, . . . This implies that (1 + βx)2 ≥ (1 + βx)2 − β 2 .
Generally, it is seen that the log-concave probability mass functions are strongly
unimodal (see Kielson & Gerber 1971, Nekoukhou et al. 2012) and have an in-
creasing failure rate (IFR) which suggest an intuitive concept caused by product
wearing out.

   Therefore, we have the following Corollary.
Corollary 1. If Y ∼ T DL(p, β) then the mode of the random variable Y is located
at m and m satisfies pβ−(1−p)
                       (1−p)β  ≤ m ≤ β−(1−p)
                                         (1−p)β .This implies that px ≥ px−1 for
x ≤ m and px+1 ≤ px for x ≥ m as stated by Kielson & Gerber (1971), Abouammoh
& Mashhour (1981) and Nekoukhou et al. (2012). From this, the following chain
of implication for a two parameter discrete Lindley (TDL) distribution (see Kemp
2004) is suggested IF R ⇒ IF RA ⇒ N BU ⇒ N BU E ⇒ DM RL.

                                             Revista Colombiana de Estadística 39 (2016) 45–61

50                              Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad


Theorem 2. If Y ∼ T DL(p, β), the probability generating function (pgf ) of Y is
given by
                              (1 − p)2 (1 − pt(1 − β))
                    GY (t) =                           ,
                              (1 − pt)2 (1 − p(1 − β))
β ≥ 0, 0 < p < 1 for 0 < pt < 1.

                                                                          P∞
Proof . By definition the pgf can be expressed as GY (t) = E(tY ) =          x=0 t
                                                                                     x
                                                                                         P (Y =
x), this implies that
                                                 ∞
                                     (1 − p)2 X
                       GY (t) =                    (pt)x (1 + βx),
                                   1 + p(β − 1) x=0

which on simplification yields

                                      (1 − p)2 (1 − pt(1 − β))
                           GY (t) =                            ,
                                      (1 − pt)2 (1 − p(1 − β))

β ≥ 0, 0 < p < 1 for 0 < pt < 1.
     On Replacing t by et we get a moment generating function (mgf) such as

                                      (1 − p)2 (1 − pet (1 − β))
                          MY (t) =                               ,                          (6)
                                      (1 − pet )2 (1 − p(1 − β))

β ≥ 0, 0 < p < 1 for 0 < pet < 1.

    The first four derivatives of equation (6), with respect to t at t = 0, yield the
                                               r
first four moments about origin i.e. µ0r = d M     Y (t)
                                                 dtr     |t=0 which after simplification
are:
                                    (1 − p + β(1 + p))p
                            µ01 =                           ,
                                   (1 + p(β − 1))(1 − p)

                                   (1 − p2 + β(1 + 4p + p2 ))p
                           µ02 =                               ,
                                     (1 + p(β − 1))(1 − p)2

                       (1 + 3p − 3p2 − p3 + β(1 + 11p + 11p2 + p3 ))p
               µ03 =                                                  ,
                                   (1 + p(β − 1))(1 − p)3

                  (1 + 10p − 10p3 − p4 + β(1 + 26p + 66p2 + 26p3 + p4 ))p
          µ04 =                                                           ,
                                  (1 + p(β − 1))(1 − p)4

                                (1 − p)2 + (1 − 3p2 + 2p)β + 2(pβ)2
                   V ar(Y ) =                                       ,
                                      (1 + p(β − 1))2 (1 − p)2

                                       (1 − p)2 + (1 − 3p2 + 2p)β + 2(pβ)2
          Indexof Dispersion =                                               .
                                     (1 + p(β − 1))(1 + p(β − 1) + β)(1 − p)


                                          Revista Colombiana de Estadística 39 (2016) 45–61

A Two Parameter Discrete Lindley Distribution                                                  51

2.3. Index of Dispersion
     Index of dispersion (ID) for discrete distributions is defined as variance to mean
ratio, it indicates whether a certain distribution is suitable for under or over dis-
persed data sets, and is used widely in ecology as a standard measure for measuring
clustering (over dispersion) or repulsion (under dispersion) (see Johnson, Kotz &
Kemp 1992). If ID≥ 1(≤ 1) the distribution is over dispersed (under dispersed).
It is observed that if either p → 1 or β → 0, the distribution will always follow over
dispersion and if p → 0, β → ∞ it will follow the under dispersion phenomenon.
Moreover, the distribution is positively skewed with a longer tail compared to a
one parameter discrete Lindley and leptokurtic in nature, which is evident from
the ratio of the square of the third mean moment to the cube of the second mean
moment and the ratio of the fourth mean moment to the square of variance. TDL
is positively skewed for β → 0 and p → 0. Also, it approaches 2 and zero (0)
as p → 1 and β → ∞ respectively, which is evident in Table 1. Moreover, it is
leptokurtic in nature, and has high peakedness as p → 0 and β →0 (see Table
2. Its peakedness approaches six as p → 1 and for smaller values of p and higher
values of β it becomes equal to 3.

                                  Table 1: Skewness.
     β ↓ p→     0.05    0.10    0.2     0.3     0.4     0.5     0.6     0.7     0.8     0.9
       0.05    21.09   11.61   6.95    5.45    4.75    4.34    4.08    3.86    3.59    3.11
       0.50    14.89    8.24   4.90    3.78    3.19    2.82    2.55    2.34    2.17    2.05
       3.50     4.31    2.34   1.68    1.68    1.78    1.87    1.93    1.97    1.99    1.99
       6.50     2.18    1.26   1.28    1.58    1.80    1.92    1.97    1.99    2.00    2.00
      10.50    1.12    0.77    1.22    1.67    1.90    1.99    2.02    2.02    2.01    2.00



                                  Table 2: Kurtosis.
    β↓p→       0.05     0.10     0.2     0.3     0.4     0.5     0.6     0.7     0.8     0.9
      0.05    26.08    16.59   11.93   10.42    9.69    9.26    8.95    8.65    8.26    7.50
      0.50    19.41    12.71    9.31    8.08    7.43    6.98    6.66    6.39    6.19    6.05
      3.50     7.28     5.63    5.40    5.59    5.76    5.87    5.94    5.97    5.99    6.00
      6.50     4.85     4.52    5.18    5.64    5.85    5.95    5.98    6.00    6.00    6.00
     10.50    3.74     4.23    5.37     5.83    5.99    6.02    6.03    6.02    6.01    6.00



Theorem 3. If Y∼ TDL(p,β) and rth , descending factorial moment of Y is given
by
                         r!pr (1 − p)−r (1 + βr + (β − 1)p)
                 µ0(r) =                                    ,             (7)
                                   (1 + p(β − 1))

where β ≥ 0, 0 < p < 1, r = 0, 1, . . . , (a)n = a(a + 1)(a + 2) · · · (a + n − 1) and
µ0(0) = 1.


Proof . The rth descending factorial moment for r.v. Y can be defined as µ0(r) =
           P∞
E(Y (r) ) = x=0 x(r) P (Y = x), which will from now an use the relation x(r) =

                                         Revista Colombiana de Estadística 39 (2016) 45–61

52                                   Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad

                               x!
x(x − 1) . . . (x − r + 1) = (x−r)! . Then, we have

                                                  ∞
                                     (1 − p)2    X      x!
                        µ0(r) =                               (1 + βx)px ,
                                  (1 + p(β − 1)) x=r (x − r)!
                                                     P∞       (a)n z n
by using the binomial series (1 − z)−a =              x=0       n! , (see Rainville 1965).   The
followings reached:

                (1 − p)2 r!pr
     µ0(r) =
               (1 + p(β − 1))
                                                                              p2
                                                                                   
                              −(r+1)
                   × (1 − p)         + βr + (r + 1)(r + 1)p + (r + 1)2 (r + 2) . . . ,
                                                                              2!

          (1 − p)−r r!pr n                                                        o
µ0(r) =                   (1 − p)−(r+1) + βr(1 − p)−(r+1) + βp(r + 1)(1 − p)−(r+2) ,
          (1 + p(β − 1))
After some algebraic manipulation, equation (7) is attained, which generates a
recursive relation between r and r − 1, descending factorial moments such as

       µ0(r) {(1 − p)(1 + β(r − 1) + (β − 1)p)} = {rp(1 + βr + (β − 1)p)} µ0(r−1)

β ≥ 0, 0 < p < 1, r = 1, 2, . . .

Theorem 4. If Y ∼ T DL(p, β), the rth ascending factorial moment of Y is given
by
                          r!p(1 − p)−r (1 + β − p + βpr)
                  µ0[r] =                                ,                 (8)
                                  (1 + p(β − 1))
                                                      p(1+β−p)
where β ≥ 0, 0 < p < 1, r = 0, 1, 2, . . . , µ0[0] = (1+p(β−1)) and (a)n = a(a + 1)(a +
2) . . . (a + n − 1).

Proof . The rth , absolute ascending
                              P∞        factorial moment can be defined and ex-
pressed as µ0[r] = E((Y )r ) = x=0 (x)r P (Y = x). This implies that
                                               (∞                ∞
                                                                                     )
                                 (1 − p)2       X                X
                    µ0[r] =                               x
                                                    (x)r p + β         x(x)r p   x
                                                                                         ,
                              (1 + p(β − 1))   x=0               x=0

                                 P∞ (a)n zn
by using the series P(1 − z)−a =    x=0    n!          P∞ 1965), we can get
                                               (see Rainville
                       ∞
equation (8), where x=0 (x)r px = r!p(1 − p)−r−1 and β x=0 x(x)r px = βr!p(1 −
p)−r−2 (1 + pr). Equation (8) yields a recursive relation between r and r − 1
ascending factorial moments such as

          µ0[r] {(1 − p)(1 + β − p + βp(r − 1))} = {r(1 + β − p + βpr)} µ0[r−1] ,

β ≥ 0, 0 < p < 1, r = 1, 2, . . .

      Thus the theorem.

                                               Revista Colombiana de Estadística 39 (2016) 45–61

A Two Parameter Discrete Lindley Distribution                                                                       53

Theorem 5. If Y ∼ T DL(p, β) the first order negative moment of Y is given by

                  (1 − p)2
  E(Y + a)−1 =
               (1 + p(β − 1))
          × a 2 F1 (a, 1; a + 1; p) + βp(a + 1)−1 2 F1 (a + 1, 2; a + 2; p) , (9)
              −1

                                                                          P∞        (a)n (b)n z n
where a > 0, β ≥ 0, 0 < p < 1 and 2 F1 (a, b; c; z) =                         n=0     (c)n n! .


                           1
                                              P∞                   −1
Proof . By definition E( Y +a )=                 x=0 (x + a)            P (Y = x), so we have

                                              ∞
                        1        (1 − p)2    X
                 E(        )=                   (x + a)−1 px (1 + βx).
                      Y +a    (1 + p(β − 1)) x=0
                                              P∞
After simplification
         P∞          we get equation (9) where x=0 (x+a)−1 px = a−1 2 F1 (a, 1; a+
1; p) and x=0 (x + a)−1 βxpx = βp(a + 1)−1 2 F1 (a + 1, 2; a + 2; p).

Corollary 2. The sth order negative moment of Y ∼ T DL(p, β) can be expressed
as

                     (1 − p)2
  E(Y + a)−s =                   a−s s+1 Fs (a, . . . , a, 1; a + 1, . . . , a + 1; p)
                  (1 + p(β − 1))
           (1 − p)2
      +                βp(a + 1)−s s+1 Fs (a + 1, · · · , a + 1, 2; a + 2, · · · , a + 2; p),
        (1 + p(β − 1))

where
                                                                 ∞
                                                                 X (a1 )n , . . . , (as )n z n
                s Fu (a1 , . . . , as ; b1 , . . . , bu ; z) =                                       ,
                                                                 n=0
                                                                        (b1 )n , . . . , (bu )n n!

the series converges for s = u + 1 and |z| < 1.

Theorem 6. If Y ∼ T DL(p, β), the sth order negative factorial moment of Y is
given by

              (1 − p)2
  µ0−[s] =
           (1 + p(β − 1))
    × ((a)s )−1 2 F1 (a, 1; a + s; p) + βp((a + 1)s )−1 2 F1 (a + 1, 2; a + s + 1; p) ,
       

                                                                                     (10)
                                                                                               P∞          (a)n (b)n z n
where a > 0, s = 0, 1, 2, . . . , β ≥ 0, 0 < p < 1 and 2 F1 (a, b; c; z) =                           n=0     (c)n n! .


Proof . The sth order negative factorial moment for Y is defined as
                                               ∞ s−1
                                  1           X   Y
               µ0−[s] = E((          )[s] ) =         (x + a + i)−1 P (Y = x),
                                Y +a          x=0 i=0


                                                   Revista Colombiana de Estadística 39 (2016) 45–61

54                                 Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad


on incorporating equation (4) we get
                                          ∞ s−1
                             (1 − p)2    X   Y
              µ0−[s] =                           (x + a + i)−1 px (1 + βx),
                          (1 + p(β − 1)) x=0 i=0

which after simplification yields equation (10).
           P∞ Qs−1                                                 P∞ Qs−1
   Where x=0 i=0 (x+a+i)−1 px = ((a)s )−1 2 F1 (a, 1; a + s; p) and x=0 i=0 (x+
a + i)−1 βxpx = βp((a + 1)s )−1 2 F1 (a + 1, 2; a + s + 1; p).
Note 1.
                                                     ∞
                                                     X (a)n (b)n z n
                              2 F1 (a, b; c; z) =                      ,
                                                     n=0
                                                            (c)n n!

and (a)n = a(a + 1)(a + 2) · · · (a + n − 1), are the hypergeometric series function
and the Pochhammer’s symbol respectively, the series converges for a, b, c ≥ 0 and
|z| ≤ 1.


3. Parameter Estimation
3.1. Maximum Likelihood Method
     If Y1 , Y2 , . . . , Yn be a random sample drawn identically independently from
the two parameters discrete Lindley (TDL) distribution with observed values
x1 , x2 , . . . , xn then the joint probability function for TDL distribution can be ex-
pressed as
                                                                        n
                                                 (1 − p)2n     Pn
                                                                i=1 xi
                                                                       Y
          f (x1 , x2 , . . . , xn ; p, β) =                   p            (1 + βxi ),
                                              (1 + p(β − 1))n          i=1

                                                              n
                                                              X                 n
                                                                                X
 ln(L(p; β)) = 2n ln(1 − p) − n ln((1 + p(β − 1))) +                xi ln p +         ln(1 + βxi ). (11)
                                                              i=1               i=1

By partially differentiating both sides of equation (11) with respect to p and β,
equating them to zero, we get M LE s of p and β respectively, which can be shown
as                                                      Pn
             ∂ ln(L(p, β))       2n       n(β − 1)           xi
                            =−        −              + i=1      = 0,
                   ∂p           1 − p 1 + p(β − 1)         p
                                   2p     p(β − 1)
                                       +             = x̄,                                         (12)
                                  1 − p 1 + p(β − 1)
                                                 n
                  ∂ ln(L(p, β))         np       X     xi
                                =−             +            = 0,
                       ∂β          1 + (β − 1)p i=1 1 + βxi
this implies that
                                 n
                                 X      xi          np
                                             =              .                                      (13)
                                 i=1
                                     1 + βxi   1 + p(β − 1)


                                                Revista Colombiana de Estadística 39 (2016) 45–61

A Two Parameter Discrete Lindley Distribution                                                55

The M LE s are computed using a computational package such as Mathematica
[7.0]. In view of the regularity conditions as stated by Rohatgi and Saleh on page
419, the M LE s i.e. (p̂, β̂) of TDL has a bivariate normal distribution with mean
(p,β) and a variance-covariance matrix (I(p,β))−1 . Thus (p̂, β̂) ∼ BVN((p,β),
(I(p,β))−1 ) where I(p,β) denotes the information matrix and is given below
                                       −∂ 2 ln L(p,β)           2             
                                       E(      ∂p2       ) E( −∂ ∂p∂β
                                                                   ln L(p,β)
                                                                             )
                                                                              
               I((p, β)|p=p̂,β=β̂ ) = 
                                      
                                                                               
                                                                               
                                          −∂ 2 ln L(p,β)      −∂ 2 ln L(p,β)
                                       E(     ∂p∂β       ) E(      ∂β 2      )

as entropy of a random variable is considered as the measure of the uncertainty
of the random variable. It is used to measure the amount of information required
to describe the random variable. In this regard, the entropy of the two parameter
discrete Lindley (TDL) distribution is defined as:

              1 + p(β − 1)            (1 + β + p(β − 1))p
H(Y ) = ln(                ) − ln p(                       ) − βE {x2 F1 (1, 1; 2; −βx)}
                (1 − p)2             (1 − p)(1 + p(β − 1))
                                                                   P∞       (a)n (b)n z n
where ln(1 + x) = x2 F1 (1, 1; 2; −x) and 2 F1 (a, b; c; z) =         n=0     (c)n n! .




4. Characterization
Theorem 7. Let Y be a nonnegative discrete random variable with probability
mass function P (Y = x) and x ∈ Z+ ; it then will follow the two parameter discrete
Lindley distribution with parameters p and β iff

                           phx                pβ(1 + p)
         M RL(Y ) =               +                               , ∀x ∈ Z+                 (14)
                         (1 − p)2   ((1 − p)(1 + βx) + pβ)(1 − p)
                                x
where hx = P (YSx=x) , Sx = p ((1−p)(1+βx)+pβ)
                                 1+p(β−1)      ,0 < p < 1 and β ≥ 0.

Proof . Necessity:
           P∞
                   According to Kemp (2004) the MRL function is defined as
             k=x+1 Sk
M RL(Y ) =      Sx    , this implies that
                                          P∞           k
                                                                     P∞            k
                         ((1 − p) + βp)      k=x+1 p + β(1 − p)        k=x+1 kp
          M RL(Y ) =                                                                   ,
                                            (1 + p(β − 1))Sx

                               px p(1 − p) {(1 − p)(1 + βx) + (1 + p)β}
                M RL(Y ) =                                              ,
                                       (1 − p)2 (1 + p(β − 1))Sx
After simplification we get

                               phx                 pβ(1 + p)
               M RL(Y ) =             +                                ,
                             (1 − p)2   {(1 − p)(1 + βx) + pβ} (1 − p)

                                           Revista Colombiana de Estadística 39 (2016) 45–61

56                                Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad


Sufficency: Suppose equation (14) holds then it can be written as
                        ∞
                        X             pP (Y = x)   pβ(1 + p)px
                               Sk =              +              ,                        (15)
                                         1−p       1 + p(β − 1)
                       k=x+1

Also
                       ∞
                       X             P (Y = x + 1)      2p2 βpx
                              Sk =                 +              ,                      (16)
                                         1−p         1 + p(β − 1)
                      k=x+1

on comparing equation (15) with equation (16) we get

                                                      pβpx (1 − p)2 (1 + βx)
               P (Y = x + 1) − pP (Y = x) =                                  ,
                                                     (1 + p(β − 1))(1 + βx)

               (1 + βx)P (Y = x + 1) = (1 + (x + 1)β)P (Y = x + 1)p,
                                         2
                              (1−p)
which gives P (Y = 0) = p0 = 1+p(β−1) and P (Y = x) = p0 px (1 + βx).

Theorem 8. The random variable Y ∼ T DL(p, 1) iff it can be written as Y ≡
X1 + X2 where Xi ∼ G0 (q) i.e. P (X = xi ) = pxi q, xi = 0, 1, . . . for i = 1, 2 are
independent random variables.

Proof . From equation (6) we get

                                      (1 − p)2 (1 − pet (1 − β))
                          MY (t) =                               ,
                                      (1 − pet )2 (1 − p(1 − β))

β ≥ 0, 0 < p < 1 for 0 < pet < 1.
     For β = 1 it simplifies as

                                                 (1 − p)2
                                    MY (t) =                ,
                                                (1 − pet )2

0 < p < 1 for 0 < pet < 1 therefore

                                  MY (t) = MX1 (t)MX2 (t),

0 < p < 1 for 0 < pet < 1 which implies the result.


5. Real Data Examples
    We used two data sets reported by Chakraborty & Chakravarty (2012), to in-
vestigate the competence of the proposed model. Suitsbility of the proposed model
is tested via the p-value and the Akaikes information criteria (AIC) proposed by
Hirotsugu Akaike in 1971. It was then compared with Poisson, Negative binomial,
Generalized Poisson and discrete gamma distributions; as stated in Chakraborty
& Chakravarty (2012).

                                             Revista Colombiana de Estadística 39 (2016) 45–61

A Two Parameter Discrete Lindley Distribution                                                        57

Data set 1: The first data set contains observations on a number of European red
mites on apple leaves and is presented in Table 3. Clearly this data set belongs to
on over dispersed structure that has ID = 1.9828. We present the MLE, observed
and expected frequencies, Log-Likelihood (LL), Chi-square values, p-values and
AIC values for two parameter discrete Lindley distribution: β̂ = 0.146; p̂ = 0.479;
LL = −222.3; d.f. = 5; χ2 = 2.514; p-value = 0.774; AIC = 448.76.

                                 Table 3: Example 1.
   Red mites     0       1       2       3          4      5       6         7          8    Total
   Frequency    70      38      17      10          9      3       2         1          0     150
   TDL(p,β)    68.90   37.81   20.42   10.89      5.75   3.00     1.56     0.81       0.41    150


Data set 2: The second data set in table 4 is about the observations collected
from number of strikes in UK coal mining industries in four successive week periods
during 1948-1959. The clearly data mentioned in Table 4 is an under dispersed
data set with ID = 0.7467. The MLE, observed and expected frequencies, Log-
Likelihood (LL), Chi-square values, p-values and AIC values for the two parameter
discrete Lindley distribution are given below: β̂ = 8.3855; p̂ = 0.176; LL =
−187.44; d.f. = 3; χ2 = 0.5108; p-value = 0.92; AIC = 378.

                                 Table 4: Example 2.
           Number of outbreaks      0        1         2         3         4      Total
              Frequency            46       76        24         9         1       156
               TDL(p,β)           45.95    76.08     25.39      6.59     1.53      156


   It can be observed that in these examples the proposed model not only gives
high p-values but also a minimum AIC compared to the distributions mentioned
by Chakraborty & Chakravarty (2012). It therefore depicts the situation that
the proposed model has the least loss of information in comparison with to the
standard distributions.


6. Discretized Bivariate Case
    Bivariate discrete random variables defined on integers or on non-negative val-
ues are used to model the paired count data that arise in a number of situations
such as: in the analysis of accidents, e.g. the number of accidents in a site be-
fore and after infrastructure changes; in epidemiological analysis, e.g. incidents of
different diseases in a series of districts; in medical research, e.g. the number of
seizures before and after treatment etc. In this regard, literature on bivariate dis-
crete distribution is sparse and worth mentioning particularly in terms of bivariate
discretized distributions. Here, we give a bivariate discretized Lindley distribution
by discretizing the bivariate continuous distribution, using the following equation:

                                                     ∞          ∞
                                                                                   !−1
                                                     X          X
          P (Y1 = x1 , Y2 = x2 ) = f (x1 , x2 )                        f (k1 , k2 )             (17)
                                                   k1 =−∞ k2 =−∞



                                          Revista Colombiana de Estadística 39 (2016) 45–61

58                                 Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad


6.1. Derivation
    Suppose W 0 = (W1 , W2 ) and Z 0 = (Z1 , Z2 ) are two random vectors of indepen-
dent random variables, each of which is distributed Gamma(1, θ) and Gamma(2, θ)
                                    θ                β
respectively. Now, consider p1 = θ+β   and p2 = θ+β     are the respective weights of
W 0 and Z 0 such that p1 + p2 = 1, θ > 0 and β ≥ 0. On mixing these densities, the
resulting distribution of the random vector X 0 = (X1 , X2 ) will be a bi variate two
parameter Lindley distribution i.e. X 0 ∼ p1 W 0 + p2 Z 0 , and can be expressed as

                                       θ3
               fX1 ,X2 (x1 , x2 ) =       (1 + θβx1 x2 )(exp(−θ(x1 + x2 ))),              (18)
                                      θ+β
x1 , x2 ≥ 0, β ≥ 0 and θ > 0.
    On substituting equation (18) into equation (17) we get a discretized version
of bivariate Lindley distribution, expressed as:

                                      (1 − e−θ )4 (1 + θβx1 x2 ) exp(−θ(x1 + x2 ))
       P (Y1 = x1 , Y2 = x2 ) =                                                    ,      (19)
                                                  (1 − e−θ )2 + βθe−2θ

x1 , x2 ∈ Z+ , β ≥ 0 and θ > 0.
     Its moment generating function is defined as:

                          (1 − e−θ )4 (1 − e−(θ−t1 ) )(1 − e−(θ−t2 ) ) + βθe−2θ+t1 +t2
                                     
     MY1 ,Y2 (t1 , t2 ) =                                                               ,
                             ((1 − e−θ )2 + βθe−2θ )(1 − e−(θ−t1 ) )2 (1 − e−(θ−t2 ) )2
|t1 , t2 | < 1, θ ≥ (t1 , t2 ), β ≥ 0 and θ > 0.
     Similarly, marginal probability mass functions of Yi for i = 1, 2 are given by:

                             (1 − e−θ )2
      gi (Yi = xi ) =                        (1 + (θβxi − 1)e−θ ) exp(−θ(xi )),           (20)
                        (1 − e−θ )2 + βθe−2θ

xi ∈ Z+ , β ≥ 0 and θ > 0, and conditional probability mass functions of Yj | Yi =
xi , denoted by gj (Yj | Yi = xi ) for i 6= j = 1, 2, is expressed as:

                                      (1 − e−θ )2
           gj (Yj | Yi = xi ) =                      (1 + θβxi xj ) exp(−θ(xj )),         (21)
                                  (1 + (βθxi − 1)e−θ

xi , xj ∈ Z+ , β ≥ 0 and θ > 0.
     From equation (19) and (20) we get:

                               e−2θ (1 − e−θ )2 + βθ(1 + e−θ )2
                                   
                 E(Y1 , Y2 ) =                                   ,                        (22)
                                (1 − e−θ )2 + βθe−2θ (1 − e−θ )2

Yi , Yj ∈ Z+ , β ≥ 0 and θ > 0.

                                  e−θ (1 − e−θ )2 + βθe−θ (1 + e−θ )
                                     
                     E(Yi ) =                                        ,                    (23)
                                    (1 − e−θ )2 + βθe−2θ (1 − e−θ )
Yi ∈ Z+ for i = 1, 2, β ≥ 0 and θ > 0.


                                              Revista Colombiana de Estadística 39 (2016) 45–61

A Two Parameter Discrete Lindley Distribution                                        59

   This implies that
                  e−2θ (1 − e−θ )2 + βθ(1 + e−θ )2
                      
  Cov(Y1 , Y2 ) =
                   (1 − e−θ )2 + βθe−2θ (1 − e−θ )2
                                                                           2
                                      e−2θ (1 − e−θ )2 + βθe−θ (1 + e−θ )
                                           
                                   −                          2              , (24)
                                       {(1 − e−θ )2 + βθe−2θ } (1 − e−θ )2
Yi ∈ Z+ for i = 1, 2,β ≥ 0 and θ > 0. Its is obvious from equation (24) that for
β = 0 the Cov(Y1 , Y2 ) = 0.
Theorem 9. Let Y 0 = (Y1 , Y2 ) be a discrete random vector distributed according
to equation (19), then the probability mass functions of U = Y1 + Y2 are expressed
respectively as:
                             (1 − e−θ )4 (1 + u)e−θu      βθu(u − 1)
              gU (U = u) =          −θ  2       −2θ
                                                     (1 +            ),            (25)
                              (1 − e ) + βθe                  6
u ∈ Z+ , β ≥ 0 and θ > 0.

Proof . Suppose Y 0 = (Y1 , Y2 ) follows a two parameter discrete bivariate Lindley
distribution as defined in equation (19). Let us consider U = Y1 + Y2 and V = Y1 .
Now by using the change of variable technique we can write the joint probability
mass function of U and V as:
                               (1 − e−θ )4
     P (U = u, V = v) =                        (1 + θβv(u − v))(exp(−θu)),     (26)
                          (1 − e−θ )2 + βθe−2θ
0 ≤ v ≤ u ∈ Z+ , β ≥ 0 and θ > 0.
    Now, on summing over v we get the probability mass function of U as expressed
in equation (25).
Theorem 10. If Y 0 = (Y1 , Y2 ) is a discrete random vector distributed according
to equation (19) then the probability mass functions of V = Y1 − Y2 are expressed
respectively as:
                          (1 − e−θ )4 e−θv
  gV (V = v) =
                 ((1 − e−θ )2 + βθe−2θ )(1 − e−2θ )3
                             × ((1 − e−2θ )3 + βθe−2θ (v − 1 − (v + 1)e−2θ )), (27)
v ∈ Z,β ≥ 0 and θ > 0.

Proof . Suppose Y 0 = (Y1 , Y2 ) is defined according to equation (19). Now consider
V = Y1 − Y2 and M = Y1 . According to change of variable technique, the joint
probability mass function of V and M can be expressed as:
                           (1 − e−θ )4
P (V = v, M = m) =                         (1 + θβm(v + m))(exp(−θ(v + 2m))),
                      (1 − e−θ )2 + βθe−2θ
                                                                         (28)
v ∈ Z, m ∈ Z+ , β ≥ 0 and θ > 0.
   Now, on summing over m we get the probability mass function of V , as ex-
pressed in equation (27).


                                       Revista Colombiana de Estadística 39 (2016) 45–61

60                           Tassaddaq Hussain, Muhammad Aslam & Munir Ahmad


7. Conclusion
    A two parameter discrete Lindley distribution has been proposed. Its various
distributional properties, reliability characteristics and characterization have been
studied. It was found that this distribution has a simple structure, is more math-
ematically amenable, more flexible and has a longer tail than the one parameter
discrete Lindley and other models in modeling actuarial and other count data
from various fields such as ecology, health, psychology, sociology and engineering.
It also has a less loss of information compared to the standard discrete distribu-
tions. Further issues such as characterization and mixtures are currently being
researched and may be discussed in the further papers.


Acknowledgements
   The authors are deeply thankful to the editor and the reviewer for their valuable
suggestions to improve the quality of the paper.
                                                             
               Received: September 2014 — Accepted: March 2015


References
Abouammoh A, Mashhour A. A note on the unimodality of discrete distributions.(1981). Communication in Statistics - Theory and Methods.
Al Huniti A, Al Dayian G. Discrete burr type-iii distribution.(2012). American Journal of Mathematics and Statistic.
Chakraborty S, Chakravarty D. Discrete gamma distributions: Properties and parameters estimations.(2012). Communication in Statistics Theory and Methods.
Dĕniz E, Ojeda E. The discrete lindley distribution: Properties and application.(2011). Journal of Statistical Computation and Simulation.
Hussain T, Ahmad M. Discrete inverse gamma distribution.(2012).International Conference on Statistical Sciences Islamic Countries Society of Statistical Sciences.
Hussain T, Ahmad M. Discrete inverse rayleigh distribution.(2014). Pakistan Journal of Statistics.
Inusah S, Kozubowski J. A discrete analogue of the laplace distribution.(2006). Journal of Statistical Planning and Inference.
Jazi M, Lai C, Alamatsaz M. A discrete inverse weibull distribution and estimation of its parameters.(2010). Statistical Methodology.
Johnson N, Kotz S, Kemp A. Univariate Discrete Distribution.(1992). John Wiley and Sons.
Kemp A. Statistical methodology.(1997). Journal of Statistical Planning and Inference.
Kemp A. Classes of discrete lifetime distributions.(2004). Communications in Statistics Theory and Methods.
Kemp A. The discrete half-normal distribution.(2006). Advances in mathematical and statistical modeling.
Kielson J, Gerber H. Some results for discrete unimodality.(1971). Journal of American Statistical Association.
Kozubowski J, Inusah S. A skew laplace distribution on integers.(2006). AISM.
Krishna H, Pundir P. Discrete maxwell distribution.(2007). http://interstat statjournals net/YEAR/2007/articles/0711003 pdf.
Krishna H, Pundir P. Discrete burr and discrete pareto distributions.(2009). Statistical Methodology.
Nakagawa T, Osaki S. The discrete weibull distribution.(1975). IEEE Transactions on Reliability.
Nekoukhou V, Alamatsaz M, Bidram H. A discrete analog of the generalized exponential distribution.(2012). Communication in Statistics Theory and Methods.
Rainville E. Special Functions.(1965). The Macmillan Company.
Roy D. Discrete normal distribution.(2003). Communication in Statistics Theory and Methods.
Roy D. Discrete rayleigh distribution.(2004). IEEE Transactions on Reliability.
Szablowski P. Discrete normal distribution and its relationship with jacobi theta functions.(2001). Statistics and Probability Letters.