The Family of Log-Skew-Normal Alpha-Power Distributions using Precipitation Data
Universidad de Córdoba;Univesidad Nacional de Colombia
Abstract
We present a new set of distributions for positive data based on a normal alpha-power (PSN) model including a new parameter which in turn makes the log-skew-normal alpha-power (LPSN) model more flexible than both the log-normal (LN) model and log-skew-normal (LSN) model. The LPSN model contains the LN model and LSN model as special cases. Furthermore, it models positive data with asymmetry and kurtosis larger than the one permitted by the LN distribution. Precipitation data illustrates the usefulness of the LPSN model being less influenced by outliers.
Key words: Asymmetry, Fisher information matrix, Kurtosis, Likelihood ratio test, Maximum likelihood estimator.
Resumen
Presentamos una nueva familia de distribuciones para datos positivos basada en el modelo skew-normal alpha-power (PSN), incluyendo un nuevo parámetro el cual hace el modelo log-skew-normal alpha-power (LPSN) más flexible que los modelos log-normal (LN) y log-skew-normal (LSN). El modelo LPSN contiene el modelo LN y el modelo LSN como casos particulares. Además, modela datos positivos con asimetría y curtosis más allá de lo permitido por la distribución LN. Datos de precipitación ilustran la utilidad del modelo LPSN siendo menos influenciado por outliers.
Palabras clave: asimetría, curtosis, estimador máxima verosimilitud, matriz de información de Fisher, test de razón de verosimilitud.

1. Introduction
    The log-normal (LN) distribution obtained as a transformation of the normal
distribution has been widely used to model different types of information including
income in economics and material lifetimes. In of different fields of knowledge,
asymmetry and kurtosis of the data are outside of the range allowed by the LN
distribution so it is necessary to use another distribution that can take into account
these issues. In the same way that Azzalini (1985), we introduce the skew-normal
(SN) distribution to conform data with a range of asymmetry and kurtosis outside
the range allowed by the normal distribution, Lin Stoyanov (2009) present the
log-skew-normal (LSN) distribution which is an extension for positive data of the
LN distribution in order to conform data with asymmetry and kurtosis outside
the range allowed by the LN distribution. The probability density function of this
model is given by
                                                                   
                                   2     log(y) − ξ         log(y) − ξ
            ϕLSN (y; ξ, η, λ) =      φ                 Φ λ
                                  ηy         η                   η
                                                                                   (1)
                                  1                            +
                              = φSN (log(y); ξ, η, λ) , y ∈ R
                                  y
where                                                        
                                       2         x−ξ         x−ξ
                  φSN (x; ξ, η, λ) =     φ               Φ λ
                                       η          η           η
denotes the density function of the SN distribution with parameters of location (ξ),
scale (η), and shape (λ). The LSN model [Y ∼ LSN (ξ, η, λ)] given by (1) contains
the parameters of location (ξ), scale (η), and shape (λ) that control the asymmetry
of the data. φ(.) and Φ(.) denote the density and cumulative distribution function
of standard normal distribution, N(0,1). Based on the SN of Azzalini (1985) and
generalized Gaussian (PN) of Durrans (1992), Martínez-Flórez (2011) introduce
and studies the main features of the asymmetric distribution called skew-normal
alpha-power (PSN) distribution with probability density function given by
                                                                 α−1
                    φP SN (z; λ, α) = αφSN (z; λ) {ΦSN (z; λ)}                        (2)

where z, λ ∈ R, α ∈ R+ , φSN (z; λ) = φSN (z; 0, 1, λ) as defined in (1) and ΦSN (z; λ)
in (3). The PSN model [X ∼ P SN (λ, α)] given by (2) considers parameters of
shape λ and α with
                                Z z
                 ΦSN (z; λ) =          φSN (t; λ)dt = Φ(z) − 2T (z, λ)                (3)
                                 −∞

being the cumulative distribution function of skew-normal distribution, Azzalini
(1985), and T (., λ) the Owen’s (1956) function.
   In (2), λ = 0 and α = 1 corresponds to the standard normal case, i.e.,
φSN (.; 0, 1, 0) = φP SN (z; 0, 1) = φSN (.; 0) = φ(.) and ΦSN (.; 0) = Φ(.). The
model is an extension of the PN model, Durrans (1992) and the Gupta Gupta
(2008) exponential model


                                         Revista Colombiana de Estadística 36 (2013) 43–57

Log-Skew-Normal Alpha-Power Distributions                                                                                          45


                                      ϕα (z; α) = αφ(z){Φ(z)}α−1 ,                     z∈R                                         (4)
replacing the normal density by the skew-normal density.
    Martínez-Flórez (2011) demonstrate that the expected information matrix of
the PSN model is nonsingular in the neighborhood of the skewness parameters
λ = 0 and α = 1 contrary to the case of Azzalini (1985) whose expected information
matrix is singular in the neighborhood of λ = 0. Table 1 shows the intervals
of asymmetry and kurtosis coefficients for the PSN, SN, and PN models. The
PSN model has greater asymmetry and the distribution is more platikurtic or
leptokurtic than the Azzalini (1985) and Durrans (1992) models. This shown an
advantage of the model (2) over the φSN (z; λ) and ϕα (z; α) models.
                                 √
Table 1: Intervals of asymmetry ( β1 ) and kurtosis (β2 ) coefficients, defined in (7), for
         the PSN, SN, and PN models given by Martínez-Flórez, G. (2011).
                                                                            √
          Model                                                               β1                            β2
          Skew-normal alpha-power (PSN) model                               [-1.4676 ; 0.9953)              [1.4672 ; 5.4386]
          Skew-normal (SN) model                                            (-0.9953 ; 0.9953)              [3 ; 3.8692)
          Generalized gaussian (PN) model                                   [-0.6115 ; 0.9007]              [1.7170 ; 4.3556]

   Figures 1(a) show corresponding and 1(b), the parameters λ and α of asym-
metry and kurtosis of the PSN distribution a more flexible model than Azzalini
(1985) and Durrans (1992) yielding.

                                  λ = −1                                                          α = 1.5
           0.7




                                                                           0.6




                                                   α = 0.75                                                           λ = − 0.75
           0.6




                                                   α=1                                                                λ=0
                                                                                                                      λ=1
                                                                           0.5




                                                   α=2
                                                   α = 3.5                                                            λ = 1.75
           0.5




                                                                           0.4
           0.4




                                                                 density
density




                                                                           0.3
           0.3




                                                                           0.2
           0.2




                                                                           0.1
           0.1




                                                                           0.0
           0.0




                                                                                 −6   −4   −2         0      2    4          6
                 −6   −4   −2         0    2   4         6
                                                                                                      z
                                      z

                                (a)                                                             (b)
      Figure 1: Probability density function of the skew-normal alpha-power distribution.


    Other work on this type of distribution was studied by Arnold Beaver (2002)
and Gupta Gupta (2004). We present a new set of distributions based on the
PSN distribution that corresponds to the log-skew-normal alpha-power (LPSN)
distribution.

                                                              Revista Colombiana de Estadística 36 (2013) 43–57

46           Guillermo Martínez-Flórez, Sandra Vergara-Cardozo Luz Mery González


    In Section 2, we describe the LPSN distribution, its observed information ma-
trix and the expected information matrix. We also perform an application of the
proposed model to data by IDEAM (2006) in which the coefficients of skewness
and kurtosis of the model justify the use of the LPSN model. We conclude with a
brief discussion in Section 3.


2. Log-Skew-Normal Alpha-Power (LPSN) Model
   The LPSN distribution is a new alternative for family distribution of positive
data with a range of asymmetry and/or kurtosis outside of the range permitted
by the LN and LSN distributions.
Definition 1. The positive random variable Y in the R+ has a univariate log-
skew-normal alpha-power distribution with parameters λ and α if the transformed
variable Z = log(Y ) has a PSN distribution with parameters λ and α. This
is denoted by Y ∼ LP SN (λ, α). The probability density function of a random
variable Y with distribution LP SN (λ, α) is given by
                      α                                   α−1
 ϕLP SN (y; λ, α) =     φSN (log(y); λ) {ΦSN (log(y); λ)}     , y, α ∈ R+ and λ ∈ R
                      y

     The cumulative distribution function of the LPSN model is given by
                      FY (y; λ, α) = {ΦSN (log(y); λ)}α , y ∈ R+                       (5)

   According to equation (5), the inversion method can be used to generate a
random variable with distribution LP SN (λ, α). Thus, if U is a uniform random
variable in (0,1) the random variable Y = exp{ΦISN (U 1/α ; λ)} has LPSN distri-
bution of the parameters λ and α where ΦISN represents the inverse function of
the SN distribution, ΦSN (.; λ), whose values can be obtained in many statistical
packages (R Development Core Team 2011).
    When α = 1, the LPSN distribution is identical to the LSN distribution
[ϕLP SN (y; λ, 1) = ϕLSN (y; 0, 1, λ)] and when λ = 0 and α = 1, the LPSN dis-
tribution is identical to the log-normal (LN) distribution. So LPSN distribution is
more flexible than LN and LSN distributions (see, for example, Figures 2(a) and
2(b)).


2.1. Moments of the Distribution
   The r-th moment of the random variable Y with LPSN distribution can be
written as,
                              Z 1
                        r
              µr = E(Y ) = α      {exp [rΦISN (y; λ)]} y α−1 dy       (6)
                                      0

     Let µ0r = E(Y − E(Y ))r , r = 2, 3, 4,
  µ02 = µ2 − µ21 , µ03 = µ3 − 3µ2 µ1 + 2µ31 and µ04 = µ4 − 4µ3 µ1 + 6µ2 µ21 − 3µ41


                                          Revista Colombiana de Estadística 36 (2013) 43–57

Log-Skew-Normal Alpha-Power Distributions                                                                                    47


                                      λ = 0.7                                                      α = 1.75



                                                       α = 0.75
                                                                                                                    λ = −1




                                                                                0.8
          0.5                                          α=1
                                                       α=2                                                          λ=0
                                                       α=5                                                          λ=1
                                                                                                                    λ=2
          0.4




                                                                                0.6
                                                                      density
          0.3
density




                                                                                0.4
          0.2




                                                                                0.2
          0.1




                                                                                0.0
          0.0




                                                                                      0   1   2    3        4   5      6     7
                 0      1    2    3         4     5        6      7
                                                                                                        Y
                                        Y

                                 (a)                                                              (b)
Figure 2: Probability density function of the log-skew-normal alpha-power distribution.



The variance, coefficient of variation, skewness and kurtosis are given by:
                                     p
                         0             σY2 p          µ0                 µ0
       2
     σY = V ar(Y ) = µ2 , CV =             ,  β1 = 0 33/2 and β2 = 04 2                                                      (7)
                                      µ1            [µ2 ]               [µ2 ]


2.2. Scale-Location
   Let P SN (ξ, η, λ, α) denotes a location-scale transformation of P SN (λ, α) where
ξ ∈ R, η ∈ R+ and Y = ξ + ηZ.

Definition 2. If X has a distribution of localization-scale parameters P SN (ξ, η,
λ, α) then the extension of scale-location to the LPSN distribution follows the
transformation X = log(Y ), where ξ ∈ R and η ∈ R+ . Then, the density of Y is
given by
                                                                                  α−1
                                                                       log(y) − ξ
                     ϕLP SN (y; ξ, η, λ, α) = αϕLSN (y; ξ, η, λ) ΦSN              ;λ                                         (8)
                                                                           η

                                                      y, α ∈ R+ , and λ ∈ R
where ϕLSN (y; ξ, η, λ) is defined in (1) and ΦSN (.; λ), in (3)

           We use the notation Y ∼ LP SN (ξ, η, λ, α). So LP SN (λ, α) = LP SN (0, 1, λ, α).
           A special case in the model (8) is when λ = 0, obtaining the density,
                                                                                            α−1
                                                α          log(y) − ξ                log(y) − ξ
                ϕLP SN (y; ξ, η, 0, α) =           φ                              Φ                   , y ∈ R+
                                                ηy             η                         η

                                                                  Revista Colombiana de Estadística 36 (2013) 43–57

48            Guillermo Martínez-Flórez, Sandra Vergara-Cardozo Luz Mery González


   This is denoted Y ∼ LP SNλ=0 (ξ, η, α). Like the model LSN model, this distri-
bution is also a generalization of the LN model which we will call the generalized
LN distribution.
     The following result is an extension of the LN and LSN distributions.
Theorem 1. For any λ ∈ R and α ∈ R+ , the random variable Y ∼ LP SN (ξ, η, λ, α)
does not have a moment generating function (MGF).

Proof . As λ = 0 and α = 1 in the LPSN model, we have the case of the LN
distribution, which does not have a moment generating function. Since MGF
satisfies the property,
                          MaY +b (t) = exp(bt)MY (at)
then it is sufficient to consider the standard case LP SN (λ, α).

     For fixed values α = α0 > 0 and λ = λ0 , the MGF of Y can be written as

            MY (t) = E(ety )
                     Z ∞
                   =     ety ϕLP SN (y; λ0 , α0 )dy
                      0
                     Z ∞
                          α0 ty                                     α −1
                   =         e φSN (log(y); λ0 ) {ΦSN (log(y); λ0 )} 0 dy
                      0    y
                     Z ∞
                   =     h(y, t, λ0 , α0 )g(y, λ0 , α0 )dy, y ∈ R+
                         0

with
                                        2α0 ty
                  h(y, t, λ0 , α0 ) =      e φ(log(y)){Φ(λ0 log(y))} > 0
                                         y
and
                                                                  α −1
                             g(y, λ0 , α0 ) = {ΦSN (log(y); λ0 )} 0
to all y > 0.
     When t > 0 is fixed, we prove that
                               Z ∞
                  J(λ0 ,α0 ) =     h(y, t, λ0 , α0 )g(y, λ0 , α0 )dy = ∞
                                    0

for all λ0 ∈ R and α0 ∈ R+ .
     If λ0 > 0 according to Lin Stoyanov (2009)
                                                              1
                                   lim inf {Φ(λ0 log(y))} ≥
                                   y→∞                        2
therefore h(y, t, λ0 , α0 ) → ∞ when y → ∞. Now, g(y, λ0 , α0 ) → 1 when y → ∞,
then we conclude that J(λ0 ,α0 ) → ∞ when y → ∞.
     According to Lin Stoyanov (2009), if λ0 < 0 then

                                          − log (Φ(−y))   1
                                    lim                 =
                                    y→∞         y2        2

                                             Revista Colombiana de Estadística 36 (2013) 43–57

Log-Skew-Normal Alpha-Power Distributions                                                            49

   Therefore, when y → ∞, we have the asymptotic approximation,
                                                        1             2
                            log (Φ(λ0 log(y))) ≈          (λ0 log(y))
                                                        2

    Then, we assume that log(α0 ) < ∞, where y → ∞ must be
                                        
                                  1     2                 1
log (h(y, t, λ0 , α0 ))−log(α0 ) ≈ log     − log(y) + ty − (λ20 + 1)(log(y))2 → ∞
                                  2     π                 2

Now, since g(y, λ0 , α0 ) → 1, when y → ∞, then we conclude that J(λ0 ,α0 ) → ∞
when y → ∞.


2.3. Inference
   The maximum likelihood estimation and observed and expected matrix infor-
mation for the parameters of the LP SN (ξ, η, λ, α) model are studied. For a ran-
dom sample of size n, Y1 , Y2 , . . . , Yn , with Yi ∼ LP SN (ξ, η, λ, α), the log-likelihood
function of θ = (ξ, η, λ, α)0 given Y , can be expressed by
                                          n                       n
                                          X                  1X 2
  `(θ, Y) = n (log(α) − log(η)) −               log(yi ) −        z
                                          i=1
                                                             2 i=1 i
                                          n
                                          X                               n
                                                                          X
                                     +          log {Φ(λzi )} + (α − 1)         log {ΦSN (zi ; λ)}
                                          i=1                             i=1


   where zi = log(yηi )−ξ . The elements of the score function are given by
                             n          n           n
                          1X         λX         α−1X
                U (ξ) =         zi −       wi −        w1i
                          η i=1      η i=1       η i=1
                                   n          n              n
                            n 1X 2 λX                    α−1X
                U (η) = −     +       zi −       zi wi −        w1i zi
                            η   η i=1      η i=1          η i=1
                          n               r               n
                          X                   2 (α − 1) X
               U (λ) =          zi wi −                    wi (λ)
                          i=1
                                              π 1 + λ2 i=1

and
                                             n
                                          n X
                            U (α) =        +    log {ΦSN (zi ; λ)}
                                          α i=1
                                                              √
            φ(λz)                              φ( 1+λ2 z )
where w = Φ(λz)             SN (z)
                  , w1 = ΦφSN (z;λ) and w(λ) = ΦSN (z;λ) . The score equations are
obtained by equating these partial derivatives to zero. The maximum likelihood
estimators (MLEs) are the solutions to the score equations. These solutions are
usually obtained by iterative numerical methods.

                                                Revista Colombiana de Estadística 36 (2013) 43–57

50              Guillermo Martínez-Flórez, Sandra Vergara-Cardozo Luz Mery González


2.3.1. Observed Information Matrix

     The elements of the observed information matrix are defined without the second
derivative of the log-likelihood function with respect to parameter denoted by
jξξ , jηξ , . . . , jαα which can be written as

                       n                 n
             n    λ2 X              λ2 X 2
     jξξ =      +         λz i wi +        w
             η2   η 2 i=1           η 2 i=1 i
                                               n                     r                n
                                        α−1X                             2 λ(α − 1) X
                                      +          w1i (zi + w1i ) −                      wi (λ)
                                         η 2 i=1                         π    η2    i=1


                  n            n               n                  n
             2 X          λ3 X 2          λ2 X          2   λ X
     jηξ =           zi +        z  w i +         z i w   −          wi
             η 2 i=1      η 2 i=1 i       η 2 i=1      i
                                                            η 2 i=1
                          r                n                         n
                              2 λ(α − 1) X                  α−1X
                        −                      z w
                                                i i (λ)   +             w1i (−1 + zi2 + zi w1i )
                              π    η2     i=1
                                                              η 2
                                                                    i=1


                n
             1 X
                   wi − λ2 zi2 wi − λzi wi2
                                            
     jλξ =
             η i=1
                           r             n                                              n
                               2 α−1X                        1                        1X
                        +                     wi (λ) zi +        w 1i ,       jαξ =         w1i
                               π η i=1                    1 + λ2                      η i=1


                   n            n               n               n
            n    3 X 2 2λ X                 λ3 X 3          λ2 X 2 2
     jηη = − 2 + 2    zi − 2       zi wi + 2       zi wi + 2       z w
            η   η i=1       η i=1           η i=1           η i=1 i i
                  r              n                      n
                    2 λ(α − 1) X 2              α−1X
                                                           zi w1i −2 + zi2 + zi w1i
                                                                                   
                −                   zi wi (λ) +
                    π    η2    i=1
                                                  η 2
                                                       i=1


                n             n             n
             1X            λ2 X 3        λX 2 2
     jλη =         zi wi −       zi wi −      z w
             η i=1         η i=1         η i=1 i i
                                             r      n                           
                                               2 α−1X                    1
                                          +            zi wi (λ) zi +        w1i
                                               π η i=1                1 + λ2


             n                             r           n
             X                           2 2λ(α − 1) X
     jλλ =         zi2 (λzi wi + wi2 ) −                  wi (λ)
             i=1
                                         π (1 + λ2 )2 i=1
                                        n
                                           " r                                         #
                                       X         1     λ     2        1     1      2
                            + 2(α − 1)      −              z wi (λ) +             w (λ)
                                       i=1
                                                2π 1 + λ2 i           π (1 + λ2 )2 i


                                               Revista Colombiana de Estadística 36 (2013) 43–57

Log-Skew-Normal Alpha-Power Distributions                                                   51

and
                   n                     r             n
               1X                            2 1 X                            n
         jαη =       zi w1i ,    jαλ =                    wi (λ),     jαα =
               η i=1                         π 1 + λ2 i=1                     α2


2.3.2. Expected Information Matrix

    The elements of the expected information matrix are the expected values of the
elements of the observed information matrix; let iξξ , iηξ , . . . , iαα be the elements
of the observed information matrix multiplied by n−1 , calling ajk = E(z j wk ),
a1jk = E(z j w1k ) and ajk (λ) = E(z j wk (λ)). The elements of the expected informa-
tion matrix can be written as
                                       r
             1      λ3       λ2           2 λ(α − 1)           α−1
      iξξ = 2 + 2 a11 + 2 a02 −                      a01 (λ) +         (a111 + a102 )
             η      η        η            π    η2               η2

                                                r
        2      λ3      λ2       λ                   2 λ(α − 1)
  iηξ = 2 a10 + 2 a21 + 2 a12 − 2 a10 −                        a11 (λ)
       η       η       η       η                    π    η2
                                                          α−1
                                                       +        (−a101 + a121 + a112 )
                                                            η2

                                    r
        1                              2 α − 1h
          a01 − λ2 a21 − λa12 +
                             
  iλξ =                                         a11 (λ)
        η                               π η
                                                    1              i               1
                                              +         E(w1 w(λ))  ,     iαξ =      a101
                                                 1 + λ2                            η

                                                        r
          1  3     2λ      λ3    λ2                      2 λ(α − 1)
  iηη = − 2 + a20 − 2 a11 + a31 + 2 a22 −                           a21 (λ)
         η   η     η       η     η                       π    η2
                                                        α−1
                                                      +      (−2a111 + a131 + a122 )
                                                         η2

                                    r
        1                              2 α − 1h
          a11 − λ2 a31 − λa22 +
                             
  iλη =                                         a21 (λ)+
        η                               π η
                                                  1               i                1
                                                      E(zw1 w(λ))   ,     iαη =      a111
                                               1 + λ2                              η




                                         Revista Colombiana de Estadística 36 (2013) 43–57

52            Guillermo Martínez-Flórez, Sandra Vergara-Cardozo Luz Mery González



                          r                            r
                              2 2λ(α − 1)                  2        h     λ
     iλλ = λa31 + a22 −                    a01 (λ) +         (α − 1) −        a21 (λ)
                              π (1 + λ2 )2                 π           1 + λ2
                                                                      r
                                                                        2     1             i
                                                                   +                 a02 (λ)
                                                                        π (1 + λ2 )2
                                  r
                                      2 1                                  1
                          iαλ =                a01 (λ),            iαα =
                                      π 1 + λ2                             α2
      For λ = 0 and α = 1 use the approximation
                                                       z2
                                                             
                  1    φ(z)             1
                                   ≈√         exp −
                                                    2(π 2 /4)
                    p
                  π Φ(z)[1 − Φ(z)]    2π(π/2)

given in Chaibub-Neto Branco (2003). The expected information matrix is
                                                      q                √          
                                    1                      2 1            π 1
                                   η2
                                               0           π η           2 η
                                                                      1 √ π2
                                              2
                                                                                   
                              0              η2
                                                           0         4η
                                                                                   
                                                                          8+π 2   
                   IF (θ) =  q
                                2 1                        2
                                                                        q
                                                                               1
                                                                                           (9)
                                               0
                                                                                  
                             √π η                         π                   2
                                                                                  
                                                          q                        
                                   π 1      1 √ π2             1
                                  2 η      4η                  2
                                                                           1
                                               8+π 2



whose determinant |IF (θ)| = 0.
    Therefore, we conclude that the expected information matrix of the model is
singular for the special case of a LN distribution. The upper 3 × 3 submatrix is
the expected information matrix from the log-skew-normal distribution.
                              q (respectively, row) is equal to first column (respec-
      As in (9) the third column
tively, row) multiply by η π2 , IF (θ) is singular. Using results from Rotnitzky,
Cox, Bottai Robins (2000) we find the asymptotic distribution of the maxi-
mum likelihood estimator of θ. DiCiccio Monti (2004) explains: “(Rotnitzky
et al. 2000) derived the asymptotic distribution of the MLE θb = (θb1 , θb2 , . . . , θbq )
under two conditions: a single component of the score function, say Sθ1 , vanishes
at some point θ = θ∗ , and some higher-order derivatives of Sθ1 taken with respect
to θ1 are possibly 0 at that point but the first nonzero derivative is not a linear
combination of the other score function components Sθ2 , . . . , Sθq ”.
     Using an iterative process suggested by Rotnitzky et al. (2000), we find a new
parameterization to PSN model that fulfill the two conditions in the same way
that Chiogna (1998) and DiCiccio Monti (2004) for the skew-normal distribution
and the skew exponential power distribution, respectively. Let θ∗ = (ξ∗, η∗, 0, 1)
denote the vector parameter of interest. For θ = θ∗, let Sθ (θ∗, Y ) = ∂`/∂θ∗ =
(Sξ∗ , Sη∗ , Sλ∗ , Sα∗ ) denote the score vector, so
                                                     r                      !
                                      Z ∗ Z ∗2 − 1     2 ∗              ∗
                       Sθ (θ∗, Y ) =     ,         ,     Z , 1 + log(Φ(Z ))
                                      η∗     η∗        π


                                             Revista Colombiana de Estadística 36 (2013) 43–57

Log-Skew-Normal Alpha-Power Distributions                                                           53
                 ∗
whit Z ∗ = Y η−ξ  ∗  . After some calculations we take the new parameterization
                                       q
              ˜ η̃, λ, α) with ξ˜ = ξ + 2 η ∗ λ and η̃ = η − η ∗ λ2 .
θ̃ = θ̃(θ) = (ξ,                         π                       π

    Making use of Theorem 3 in Rotnitzky et al. (2000) with the new parameteri-
zation we can conclude that:

  1. The MLE of θ is unique with probability tending to 1, and it is consistent.

  2. The likelihood ratio statistic for testing the simple null hypothesis
     H0 : θ = θ∗ converges in distribution to the χ2 distribution with four degrees
     of freedom.

  3. The random vector
                    q                              2
                                                                            
       n1/2 (ξ˜ − ξ + 2 η ∗ λ), n1/2 (η̃ − η − η ∗ λ ), n1/6 λ,
                         π
                                                             b n1/2 (b
                                                               π     α − 1)
                                    1/3
     converges to (Y1 , Y2 , Y3 , Y4 ), where (Y1 , Y2 , Y3 , Y4 ) is a normal random vec-
     tor with mean zero and covariance matrix equals to the inverse of the co-
     variance matrix
                                                                              √          −1
                              1                              2−π 1               π 1
                             η2
                                             0               √
                                                              2π 3 η            2 η
                                             2                              1 √ π2       
                         0                  η2
                                                                0           4η
                                                                                          
                                                                              q  8+π 2   
                                                           5π 2 −28π+44
                                                                                         
                      √2−π 1                0                                      1     
                      2π3 η                                     6π 3               2     
                      √                          2
                                                                q                         
                              π 1          1 √π                     1
                             2 η          4η                        2
                                                                                1
                                              8+π 2



2.4. Illustration
    Precipitation data (measured in inches) were collected from the Colombian
Institute of Hydrology, Meteorology and Environmental Studies in Córdoba, Colom-
                           q statistics for the variable under study are provided
bia (IDEAM 2006). Descriptive
                                   √
in Table 2. The quantities βb1 = b1 and βb2 = b2 , where β1 and β2 defined in
(7), indicate the asymmetry and kurtosis coefficients respectively.

             Table 2: Descriptive statistics of the precipitation variable
                                                                           √
             Variables         n          Mean           Variance             b1          b2
                Y             273         4.8360          9.7871           0.4632       2.6035
              log(Y )         273         1.2219          1.1155          -1.5608       5.5276


   The asymmetry and kurtosis coefficients are different from the corresponding
values expected for LN model and normal model. Precipitation data are fitted
using the LPSN model.
    The LPSN model is compared to the LN model as well as the LSN model to the
LP SNλ=0 model. The maximum likelihood method for estimating the parameters
is used and the Akaike information criterion (AIC), (Akaike 1974), is applied for

                                                      Revista Colombiana de Estadística 36 (2013) 43–57

54           Guillermo Martínez-Flórez, Sandra Vergara-Cardozo Luz Mery González


contrast. Firstly, the LN model is compared to the LPSN model by the hypothesis
tests
                   H0 : (λ, α) = (0, 1) versus H1 : (λ, α) 6= (0, 1)
Using the likelihood ratio statistic,

                                             `LN (θ)
                                                  b
                                    Λ=
                                            `LP SN (θ)
                                                    b

we obtain
                 −2 log(Λ) = −2(−735.4023 + 670.2293) = 130.346
which is greater than the value of the χ22,95% = 5.99. Then the LPSN model is
a good alternative for fitting the precipitation data. The LPSN model is also
compared to the LP SNλ=0 model and the LSN models by the hypothesis tests

     H01 : λ = 0 versus H11 : λ 6= 0,        and    H02 : α = 1 versus H12 : α 6= 1

respectively, using the likelihood ratio statistics
                           `LP SNλ=0 (θ)                      `LSN (θ)
                    Λ1 =                      and     Λ2 =
                            `LP SN (θ)                       `LP SN (θ)

After numerical evaluations, we obtain

               −2 log(Λ1 ) = 61.5960        and     − 2 log(Λ2 ) = 15.5056

which is greater than the value of the χ21,95% = 3.84. The best fit, with respect to
the other models, is shown by the LPSN model. Table 3 presents the MLEs and the
estimated standard errors (in parentheses) for LN, LSN, LPSN and models. Figure
3 shows the histogram of precipitacion data and fitted curves for the proposed
models in which the LPSN model presents the better fit of asymmetry and kurtosis
with respect to the other models.

Table 3: Parameters and estimated standard errors of the log-normal (LN), log-skew-
         normal (LSN), log-skew-normal alpha-power λ = 0 (LP SNλ=0 ), and the log-
         skew-normal alpha-power (LPSN) distributions.
 Parameter      Log-normal                LSN               LPSNλ=0                LPSN
   Loglik         -735.4023            -677.9821             -701.0273            -670.2292
    AIC          1474.8050              1361.964             1408.0550            1348.5490
     ξ         1.2219(0.0638)       2.4217(0.0392)        2.8280(0.0817)       2.2647(0.0529)
     η         1.0542(0.0451)       1.5971(0.0763)        0.1668(0.0507)       4.8760(0.3363)
     λ                –            -10.0515(2.2917)              –            -19.2702(2.4450)
     α                –                    –              0.0144(0.0008)       4.8579(0.5925)


  The Figure 4 shows the qqplots for LN, LSN and LPSN models. The LPSN
model shows better fit with respect to the LN and LSN models.




                                           Revista Colombiana de Estadística 36 (2013) 43–57

 Log-Skew-Normal Alpha-Power Distributions                                                                                                                                                                                               55




                                                              0.20
                                                                                                                                                                           LPSNλ=0
                                                                                                                                                                           LN
                                                                                                                                                                           LSN




                                                              0.15
                                                                                                                                                                           LPSN




                                                    density

                                                              0.10
                                                              0.05
                                                              0.00


                                                                                         0             2        4           6             8                           10             12            14

                                                                                                                        precipitation (inches)

 Figure 3: Histogram of the precipitation data. Densities are estimated by maximum
           likelihood.
                        80




                                                                                                                                                                       15
                        60
Theoretical quantiles




                                                                                                                                              Theoretical quantiles

                                                                                                                                                                       10
                        40




                                                                                                                                                                       5
                        20
                        0




                                                                                                                                                                       0




                             0   2   4    6         8          10                             12       14                                                                        0             2        4    6         8       10   12   14

                                         Sample quantiles                                                                                                                                                   Sample quantiles


                                         (a)                                                                                                                                                                (b)
                                                                                         15
                                                                 Theoretical quantiles

                                                                                         10
                                                                                         5
                                                                                         0




                                                                                                   0        2       4       6         8       10                            12            14

                                                                                                                           Sample quantiles


                                                                                                                          (c)
 Figure 4: Q-Qplot: (a) log-normal model, (b) log-skew-normal model, and (c) log-skew-
           normal alpha-power model.




                                                                                                                        Revista Colombiana de Estadística 36 (2013) 43–57

56         Guillermo Martínez-Flórez, Sandra Vergara-Cardozo Luz Mery González


3. Conclusion
    In this paper we propose a more flexible model than LN and LSN models
fit data with greater asymmetry and more platikurtic or leptokurtic than Azzalini
(1985) and Durrans (1992) models. General expressions for the moments are found,
maximum likelihood estimators are studied, observed and expected information
matrix are found, and also an asymptotic distribution of a MLEs vector is found.
Finally, an illustration is presented (see Figure 4). We contrast the LN, LSN,
and LPSN models through some precipitation data. According to AIC selection
criterion, the LPSN model makes the better fit with respect to the other models
considered.
                                                                      
                   Recibido: junio de 2012 — Aceptado: abril de 2013


References
Akaike H. A new look at statistical model identification.(1974). IEEE Transaction on Automatic Control.
Arnold B C, Beaver R. Skewed multivariate models related to hidden truncation and/or selective reporting.(2002).
Azzalini A. A class of distributions which includes the normal ones.(1985). Scandinavian Journal of Statistics.
Chaibub-Neto E, Branco M. Bayesian Reference Analysis for Binomial Calibration Problem.(2003). IME-USP.
Chiogna M. Some results on the scalar skew-normal distribution.(1998). Journal Italian Statistical Society.
DiCiccio T J, Monti A C. Inferential aspects of the skew exponential power distribution.(2004). Journal of the American Statistical Association.
Durrans S R. Distributions of fractional order statistics in hydrology.(1992). Water Resources Research.
Gupta D, Gupta R C. Analyzing skewed data by power normal model.(2008). Test 17.
Gupta R S, Gupta R D. Generalized skew normal model.(2004). Test 13.
IDEAM. Estudio Agroclimático del Departamento de Córdoba. (2006). Fondo Editorial Universidad de Córdoba.
Lin G D, Stoyanov J. The logarithmic skew-normal distributions are moment-indeterminate.(2009). Journal of Applied Probability.
Martínez-Flórez G. Extensões do modelo α-potêncial Tese de doutorado.(2011). Instituto de Matemática e Estatística Universidade de São Paulo.
R Development Core Team. R: A Language and Environment for Statistical Computing.(2011). R Foundation for Statistical Computing.
Rotnitzky A, Cox D R, Bottai M, Robins J. Likelihood-based inference with singular information matrix. (2000). Bernoulli.