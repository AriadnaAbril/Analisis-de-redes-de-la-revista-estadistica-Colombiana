Bivariate Generalization of the Kummer-Beta Distribution. Generalización Bivariada de la Distribución Kummer-Beta
Universidad del Valle, Cali, Colombia. Universidad de Antioquía, Medellín, Colombia
Abstract
In this article, we study several properties such as marginal and conditional distributions, joint moments, and mixture representation of the bivariate generalization of the Kummer-Beta distribution. To show the behavior of the density function, we give some graphs of the density for different values of the parameters. Finally, we derive the exact and approximate distribution of the product of two random variables which are distributed jointly as bivariate Kummer-Beta. The exact distribution of the product is derived as an infinite series involving Gauss hypergeometric function, whereas the beta distribution has been used as an approximate distribution. Further, to show the closeness of the approximation, we have compared the exact distribution and the approximate distribution by using several graphs. An application of the results derived in this article is provided to visibility data from Colombia. Key words: Beta distribution, Bivariate distribution, Dirichlet distribution, Hypergeometric function, Moments, Transformation.
Resumen
En este artículo, definimos la función de densidad de la generalización bivariada de la distribución Kummer-Beta. Estudiamos algunas de sus propiedades y casos particulares, así como las distribuciones marginales y condicionales. Para ilustrar el comportamiento de la función de densidad, mostramos algunos gráficos para diferentes valores de los parámetros. Finalmente, encontramos la distribución del producto de dos variables cuya distribución conjunta es Kummer-Beta bivariada y utilizamos la distribución beta como una aproximación. Además, con el fin de comparar la distribución exacta y la aproximada de este producto, mostramos algunos gráficos. Se presenta una aplicación a datos climáticos sobre niebla y neblina de Colombia.
Palabras clave: distribución Beta, distribución bivariada, distribución Dirichlet, función hipergeométrica, momentos, transformación.


1. Introduction
    The beta random variable is often used for representing processes with natural
lower and upper limits. For example, refer to Hahn & Shapiro (1967). Indeed,
due to a rich variety of its density shapes, the beta distribution plays a vital role
in statistical modeling. The beta distribution arises from a transformation of the
F distribution and is typically used to model the distribution of order statistics.
The beta distribution is useful for modeling random probabilities and proportions,
particularly in the context of Bayesian analysis. Varying within (0, 1) the standard
beta is usually taken as the prior distribution for the proportion p and forms
a conjugate family within the beta prior-Bernoulli sampling scheme. A natural
univariate extension of the beta distribution is the Kummer-Beta distribution
defined by the density function (Gupta, Cardeño & Nagar 2001, Nagar & Gupta
2002, Ng & Kotz 1995),

                         Γ(a + c) xa−1 (1 − x)c−1 exp (−λx)
                                                                                       (1)
                         Γ(a)Γ(c)     1 F1 (a; a + c; −λ)

where a > 0, c > 0, 0 < x < 1, −∞ < λ < ∞ and 1 F1 is the confluent hypergeo-
metric function defined by the integral (Luke 1969),
                                        Z 1
                                Γ(c)
           1 F1 (a; c; z) =                 ta−1 (1 − t)c−a−1 exp(zt) dt,
                            Γ(a)Γ(c − a) 0                                (2)
                                 Re(c) > Re(a) > 0

    The Kummer-Beta distribution can be seen as bimodal extension of the Beta
distribution (on a finite interval) and thus can help to describe real world phe-
nomena possessing bimodal characteristics and varying within two finite bounds.
The Kummer-Beta distribution is used in common value auctions where posterior
distribution of “value of a single good” is Kummer-Beta (Gordy 1998). Recently,
Nagar & Zarrazola (2005) derived distributions of product and ratio of two inde-
pendent random variables when at least one of them is Kummer-Beta.
    The random variables X and Y are said to have a bivariate Kummer-Beta
distribution, denoted by (X, Y ) ∼ KB(a, b; c; λ), if their joint density is given by

    f (x, y; a, b; c; λ) = C(a, b; c; λ)xa−1 y b−1 (1 − x − y)c−1 exp[−λ(x + y)]       (3)

where x > 0, y > 0, x + y < 1, a > 0, b > 0, c > 0, −∞ < λ < ∞ and
                            Γ(a + b + c)
          C(a, b; c; λ) =                {1 F1 (a + b; a + b + c; −λ)}−1               (4)
                            Γ(a)Γ(b)Γ(c)

                                       Revista Colombiana de Estadística 34 (2011) 497–512

Bivariate Kummer-Beta Distribution                                                       499

    For λ = 0, the density (3) slides to a Dirichlet density with parameters a, b and
c. In Bayesian analysis, the Dirichlet distribution is used as a conjugate prior dis-
tribution for the parameters of a multinomial distribution. However, the Dirichlet
family is not sufficiently rich in scope to represent many important distributional
assumptions, because the Dirichlet distribution has few number of parameters. We
provide a generalization of the Dirichlet distribution with added number of param-
eters. Several other bivariate generalizations of Beta distribution are available in
Mardia (1970), Barry, Castillo & Sarabia (1999), Kotz, Balakrishnan & Johnson
(2000), Balakrishnan & Lai (2009), Hutchinson & Lai (1991), Nadarajah & Kotz
(2005), and Gupta & Wong (1985).
    The matrix variate generalization of Beta and Dirichlet distributions have been
defined and studied extensively. For example, see Gupta & Nagar (2000).
    It can also be observed that bivariate generalization of the Kummer-Beta dis-
tribution defined by the density (3), belongs to the Liouville family of distributions
proposed by Marshall & Olkin (1979) and Sivazlian (1981), (also see Gupta & Song
(1996), Gupta & Richards (2001) and Song & Gupta (1997)).
    In this article we study several properties such as marginal and conditional dis-
tributions, joint moments, correlation, and mixture representation of the bivariate
Kummer-Beta distribution defined by the density (3). We also derive the exact
and approximate distribution of the product XY where (X, Y ) ∼ KB(a, b; c; λ).
Finally, an application of the results derived in this article is provided to visibility
data about fog and mist from Colombia.


2. Properties
    In this section we study several properties of the bivariate Kummer-Beta dis-
tribution defined in Section 1.
   Using the Kummers relation,

                        1 F1 (a; c; −z) = exp(−z)1 F1 (c − a; c; z)                      (5)

the density given in (3) can be rewritten as
                                                        c−1
        C(a, b; c; λ) exp(−λ)xa−1 y b−1 (1 − x − y)           exp[λ(1 − x − y)]          (6)

   Expanding exp[λ(1 − x − y)] in power series and rearranging certain factors,
the joint density of X and Y can also be expressed as
                             ∞                                               c+j−1
                             X Γ(a + b + c)Γ(c + j) λj xa−1 y b−1 (1 − x − y)
{1 F1 (c; a + b + c; λ)}−1
                             j=0
                                   Γ(a + b + c + j)Γ(c) j!         B(a, b, c + j)

where
                                             Γ(α)Γ(β)Γ(γ)
                              B(α, β, γ) =
                                             Γ(α + β + γ)

                                          Revista Colombiana de Estadística 34 (2011) 497–512

500Paula Andrea Bran-Cardona, Johanna Marcela Orozco-Castañeda & Daya Krishna Nagar

    Thus the bivariate Kummer-Beta distribution is an infinite mixture of Dirichlet
distributions.
    In Bayesian probability theory, if the posterior distributions are in the same
family as the prior probability distribution, the prior and posterior are then called
conjugate distributions, and the prior is called a conjugate prior. In case of multi-
nomial distribution, the usual conjugate prior is the Dirichlet distribution. If
                                             
                                     r+s+f r s
                P (r, s, f |x, y) =            x y (1 − x − y)f
                                      r, s, f
and
                                                              c−1
         p(x, y) = C(a, b; c; λ)xa−1 y b−1 (1 − x − y)              exp[−λ(x + y)]
where x > 0, y > 0, and x + y < 1, then

  p(x, y | r, s, f ) = C(a + r, b + s; c + f ; λ)
                                                                            c+f −1
                                    × xa+r−1 y b+s−1 (1 − x − y)                     exp[−λ(x + y)]

   Thus, the bivariate family of distributions considered in this article is the con-
jugate prior for the multinomial distribution.
    A distribution is said to be negatively likelihood ratio dependent if the density
f (x, y) satisfies
                      f (x1 , y1 )f (x2 , y2 ) ≤ f (x1 , y2 )f (x2 , y1 )
for all x1 > x2 and y1 > y2 (see Lehmann (1966)). In the case of bivariate
generalization of the Kummer-Beta distribution the above inequality reduces to
            (1 − x1 − y1 )(1 − x2 − y2 ) < (1 − x1 − y2 )(1 − x2 − y1 )
which clearly holds. Hence, the bivariate distribution defined by the density (3) is
negatively likelihood ratio dependent.
    If (X, Y ) ∼ KB(a, b; c; λ), then Ng & Kotz (1995) have shown that Y /(X +
Y ) and X + Y are mutually independent, Y /(X + Y ) ∼ B(b, a) and X + Y ∼
KB(a + b; c; λ). Here we give a different proof of this result based on angular
transformation.
Theorem 1. Let (X, Y ) ∼ KB(a, b; c; λ) and define X = R2 cos2 Θ and Y =
R2 sin2 Θ. Then, R2 and Θ are independent, R2 ∼ KB(a + b; c; λ) and sin2 Θ ∼
B(b, a).

Proof . Using the transformation X = R2 cos2 Θ and Y = R2 sin2 Θ with the
Jacobian J(x, y → r2 , θ) = 2r2 cos θ sin θ, in the joint density of X and Y , we
obtain the joint density of R and Θ as
        C(a, b; c; λ)(r2 )a+b (1 − r2 )c−1 exp(−λr2 )(cos θ)2a−1 (sin θ)2b−1 ,                    (7)
where 0 < r2 < 1 and 0 < θ < π/2. From (7), it is clear that R2 and Θ are
independent. Now, transforming S = R2 and U = sin2 Θ with the Jacobian
J(r2 , θ → s, u) = J(r2 → s)J(θ → u) = (4s)−1 [u(1 − u)]−1/2 , above we get the
desired result.

                                           Revista Colombiana de Estadística 34 (2011) 497–512

Bivariate Kummer-Beta Distribution                                                         501

   We derive marginal and conditional distributions as follows.

Theorem 2. If (X, Y ) ∼ KB(a, b; c; λ), then the marginal density of X is given
by

            C1 (a, b; c; λ) exp(−λx)xa−1 (1 − x)b+c−1 1 F1 (b; b + c; −λ(1 − x))           (8)

where 0 < x < 1 and

                              Γ(a + b + c)
          C1 (a, b; c; λ) =                {1 F1 (a + b; a + b + c; −λ)}−1
                              Γ(a)Γ(b + c)


Proof . To find the marginal pdf of X, we integrate (3) with respect to y to get
                                       Z 1−x
                                 a−1                                       c−1
      C(a, b; c; λ) exp(−λx)x                   exp(−λy)y b−1 (1 − x − y)        dy
                                        0


   Substituting z = y/(1 − x) with dy = (1 − x) dz above, one obtains
                                                Z 1
              a−1
 C(a, b; c; λ)x     exp(−λx)(1 − x)     b+c−1
                                                      exp[−λ(1 − x)z]z b−1 (1 − z)c−1 dz (9)
                                                 0

Now, the desired result is obtained by using (2).


   Using the above theorem, the conditional density function of X given Y = y,
0 < y < 1, is obtained as

       Γ(a + c)     exp(−λx)xa−1 (1 − x − y)c−1
                                                        ,           0<x<1−y
       Γ(a)Γ(c) (1 − y)a+c−1 1 F1 (a; a + c; −λ(1 − y))

   Graphs 1–6 of the density function for several values of a, b, c and λ correspond-
ing to six rows of Table 1, depicted in Figure 1, show a wide range of densities.
For example, large values of a, b, c give a density similar to a bivariate normal
density, whereas for small values of a, b, c the density is close to a uniform density.

           Table 1: Density functions for different values of a, b, c and λ.
                               Graph        a    b      c       λ
                                 1          2    1     1.5   −5.0
                                 2          2    2     5.0   −5.0
                                 3          5    3     2.0   −5.0
                                 4          2    1     2.0   −0.5
                                 5          5    3     9.0    0.5
                                 6          3    2     1.5    3.0



                                            Revista Colombiana de Estadística 34 (2011) 497–512

502Paula Andrea Bran-Cardona, Johanna Marcela Orozco-Castañeda & Daya Krishna Nagar




                  8
                                                                                                6
                  6                                             1.0                                                                1.0
           f Hx,yL 4                                                                 f Hx,yL 4
                    2                                                                        2
                    0                                                                         0
                   0.0                                 0.5 y                                 0.0                           0.5 y

                            x 0.5                                                                       x 0.5

  (1)                                       1.0 0.0                          (2)                                1.0 0.0




                                                                                            4                                            1.0
                  10                                                              f Hx,yL
                                                                 1.0
            f Hx,yL                                                                         2
                    5
                                                                                             0
                       0                                                                    0.0                               0.5 y
                      0.0                               0.5 y

                              x0.5                                                                  x 0.5


   (3)                                       1.0 0.0                        (4)                                  1.0 0.0




             15                                                                             4
                                                                      1.0                                                                1.0
        f Hx,yL10                                                                 f Hx,yL
                                                                                            2
                 5
                 0                                                                           0
                0.0                                       0.5     y                         0.0                                0.5 y


                            x 0.5                                                                   x    0.5


 (5)                                1.0 0.0         (6)                          1.0
                                                                                     0.0

                  Figure 1: Density functions for different values of the parameters.


   Further, using (3), the joint (r, s)-th moment is obtained as
                        Z 1 Z 1−x
    r s                                                                   c−1
E(X Y ) = C(a, b; c; λ)           exp[−λ(x + y)]xa+r−1 y b+s−1 (1 − x − y)    dy dx
                                        0      0
                           C(a, b; c; λ)
                     =
                       C(a + r, b + r; c; λ)
                       Γ(a + r)Γ(b + s)Γ(d) 1 F1 (a + b + r + s; d + r + s; −λ)
                     =
                       Γ(a)Γ(b)Γ(d + r + s)          1 F1 (a + b; d; −λ)

where d = a + b + c, a + r > 0 and b + s > 0. Now, substituting appropriately, we
obtain
                                                   a 1 F1 (a + b + 1; d + 1; −λ)
                                     E(X) =
                                                   d      1 F1 (a + b; d; −λ)


                                                   b 1 F1 (a + b + 1; d + 1; −λ)
                                     E(Y ) =
                                                   d      1 F1 (a + b; d; −λ)


                                                                Revista Colombiana de Estadística 34 (2011) 497–512

Bivariate Kummer-Beta Distribution                                                     503

                              a(a + 1) 1 F1 (a + b + 2; d + 2; −λ)
                  E(X 2 ) =
                              d(d + 1)      1 F1 (a + b; d; −λ)



                              b(b + 1) 1 F1 (a + b + 2; d + 2; −λ)
                  E(Y 2 ) =
                              d(d + 1)      1 F1 (a + b; d; −λ)



                                  ab    1 F1 (a + b + 2; d + 2; −λ)
                 E(XY ) =
                               d(d + 1)      1 F1 (a + b; d; −λ)



                            ab(a + 1)(b + 1)    1 F1 (a + b + 4; d + 4; −λ)
         E(X 2 Y 2 ) =
                         d(d + 1)(d + 2)(d + 3)      1 F1 (a + b; d; −λ)


                                                                      2 
           a a + 1 1 F1 (a + b + 2; d + 2; −λ) a 1 F1 (a+b+1; d+1; −λ)
Var(X) =                                      −
           d d+1        1 F1 (a + b; d; −λ)     d   1 F1 (a + b; d; −λ)


                                                                       2 
          b b + 1 1 F1 (a + b + 2; d + 2; −λ)   b 1 F1 (a+b+1; d+1; −λ)
Var(Y ) =                                     −
          d d+1        1 F1 (a + b; d; −λ)      d    1 F1 (a + b; d; −λ)

and
                                                                     2 
               ab 1 F1 (a + b + 2; d + 2; −λ) 1 1 F1 (a+b+1; d+1; −λ)
Cov(X, Y ) =                                 −
               d (d + 1)1 F1 (a + b; d; −λ)    d   1 F1 (a + b; d; −λ)


    Notice that E(XY ), E(X 2 ), E(Y 2 ), E(X) and E(Y ) involve 1 F1 (α; µ; −λ) which
can be computed using Mathematica by providing values of α, µ and λ. Table 2
provides correlations between X and Y for different values of a, b, c and λ. All the
tabulated values of correlation are negative because X and Y satisfy x + y < 1. As
can be seen, the choices of a, b small and c, λ large yield correlations close to zero,
whereas large values of a or b and small values of c or λ give small correlations.
Further, for fixed values of a, b and c, the correlation decreases as the value of λ
increases. Likewise, for fixed values of a, b and λ, the correlation decreases as c
increases.


3. Entropies
   In this section, exact forms of Renyi and Shannon entropies are determined for
the bivariate Kummer-Beta distribution defined in this article.
   Let (X , B, P) be a probability space. Consider a pdf f associated with P, dom-
inated by σ−finite measure µ on X . Denote by HSH (f ) the well-known Shannon
entropy introduced in Shannon (1948). It is define by
                                     Z
                       HSH (f ) = −     f (x) log f (x) dµ                     (10)
                                         X


                                        Revista Colombiana de Estadística 34 (2011) 497–512

504Paula Andrea Bran-Cardona, Johanna Marcela Orozco-Castañeda & Daya Krishna Nagar

                       Table 2: Correlation for values of a, b, c and λ.
 a      b     c λ = −5.000   −2.000   −1.000   −0.500     0.000    0.500    1.000    2.000    5.000
3.0    2.0   0.5    −0.936   −0.888   −0.862   −0.846    −0.828   −0.808   −0.785   −0.731   −0.494
1.0    2.0   1.0    −0.848   −0.717   −0.653   −0.616    −0.577   −0.536   −0.493   −0.406   −0.172
3.0    2.0   1.5    −0.819   −0.716   −0.670   −0.644    −0.617   −0.589   −0.559   −0.497   −0.304
5.0    3.0   2.0    −0.799   −0.723   −0.690   −0.673    −0.655   −0.635   −0.616   −0.573   −0.433
0.5    1.0   1.5    −0.736   −0.499   −0.406   −0.360    −0.316   −0.275   −0.237   −0.171   −0.055
1.0    2.0   2.0    −0.712   −0.543   −0.477   −0.442    −0.408   −0.374   −0.341   −0.279   −0.135
0.5    1.0   2.0    −0.654   −0.414   −0.332   −0.294    −0.258   −0.225   −0.195   −0.144   −0.054
1.0    2.0   3.0    −0.598   −0.429   −0.371   −0.343    −0.316   −0.290   −0.265   −0.219   −0.118
2.0    4.0   5.0    −0.535   −0.428   −0.391   −0.374    −0.356   −0.339   −0.322   −0.290   −0.204
2.0    2.0   5.0    −0.494   −0.365   −0.324   −0.305    −0.286   −0.267   −0.250   −0.218   −0.141
1.0    0.5   5.0    −0.322   −0.185   −0.151   −0.136    −0.123   −0.111   −0.100   −0.082   −0.046



   One of the main extensions of the Shannon entropy was defined by Rényi
(1961). This generalized entropy measure is given by

                                  log G(η)
                   HR (η, f ) =                    (for η > 0 and η 6= 1)                     (11)
                                    1−η

where
                                               Z
                                      G(η) =        f η dµ
                                               X


   The additional parameter η is used to describe complex behavior in probability
models and the associated process under study. Rényi entropy is monotonically
decreasing in η, while Shannon entropy (10) is obtained from (11) for η ↑ 1.
For details see Nadarajah & Zografos (2005), Zografos and Nadarajah (2005) and
Zografos (1999).
      First, we give the following lemma useful in deriving these entropies.

Lemma 1. Let g(a, b, c, λ) = limη→1 h(η), where

                       d
              h(η) =      1 F1 (η(a + b − 2) + 2; η(a + b + c − 3) + 3; −λη)                  (12)
                       dη

      Then,
                     ∞
                    X   Γ(a + b + j)Γ(a + b + c) (−λ)j h
  g(a, b, c, λ) =                                       j + (a + b − 2)ψ(a + b + j)
                    j=1
                        Γ(a + b)Γ(a + b + c + j) j!
                 + (a + b + c − 3)ψ(a + b + c) − (a + b − 2)ψ(a + b)
                                                  i
                 − (a + b + c − 3)ψ(a + b + c + j)
                                                                                              (13)

where ψ(α) = Γ′ (α)/Γ(α) is the digamma function.


                                          Revista Colombiana de Estadística 34 (2011) 497–512

Bivariate Kummer-Beta Distribution                                                       505

Proof . Expanding 1 F1 in series form, we write

                              ∞                  ∞ 
                                        (−λ)j                    (−λ)j
                                                              
                          d X                   X    d
                 h(η) =          ∆j (η)       =         ∆j (η) ,                        (14)
                          dη j=0          j!    j=0
                                                     dη            j!


where

                          Γ[η(a + b − 2) + 2 + j]Γ[η(a + b + c − 3) + 3] j
            ∆j (η) =                                                     η
                          Γ[η(a + b − 2) + 2]Γ[η(a + b + c − 3) + 3 + j]


   Now, differentiating the logarithm of ∆j (η) w.r.t. to η, one obtains

            d                         hj
               ∆j (η)       =   ∆j (η) + (a + b − 2)ψ(η(a + b − 2) + 2 + j)
            dη                         η
                                +(a + b + c − 3)ψ(η(a + b + c − 3) + 3)
                                −(a + b − 2)ψ(η(a + b − 2) + 2)
                                                                           i
                                −(a + b + c − 3)ψ(η(a + b + c − 3) + 3 + j)             (15)


   Finally, substituting (15) in (14) and taking η → 1, one obtains the desired
result.



Theorem 3. For the bivariate Kummer-Beta distribution defined by the pdf (3),
the Rényi and the Shannon entropies are given by
                                 
                             1
        HR (η, f ) =              η log C(a, b; c; λ) + log Γ[η(a − 1) + 1]
                           1−η
                           + log Γ[η(b − 1) + 1] + log Γ[η(c − 1) + 1]
                           − log Γ[η(a + b + c − 3) + 3]
                                                                                   
                           + log 1 F1 (η(a + b − 2) + 2; η(a + b + c − 3) + 3; −λη) (16)


and

      HSH (f )    = − log C(a, b; c; λ) − [(a − 1)ψ(a) + (b − 1)ψ(b) + (c − 1)ψ(c)
                                                               g(a, b, c, λ)
                    −(a + b + c − 3)ψ(a + b + c)] −                                , (17)
                                                       1 F1 (a + b; a + b + c; −λ)


respectively, where ψ(α) = Γ′ (α)/Γ(α) is the digamma function and g(a, b, c, λ) is
given by (13).


                                          Revista Colombiana de Estadística 34 (2011) 497–512

506Paula Andrea Bran-Cardona, Johanna Marcela Orozco-Castañeda & Daya Krishna Nagar

Proof . For η > 0 and η 6= 1, using the joint density of X and Y given by (3), we
have
                Z 1 Z 1−x
     G(η) =                f η (x, y; a, b; c; λ) dx dy
                   0   0
                                     Z 1 Z 1−x
              =   [C(a, b; c; λ)]η               xη(a−1) y η(b−1)
                                   0     0
                               η(c−1)
                  (1 − x − y)         exp[−ηλ(x + y)] dx dy
                                   [C(a, b; c; λ)]η
              =
                  C(η(a − 1) + 1, η(b − 1) + 1; η(c − 1) + 1; λ)
                  Γη (a + b + c)Γ[η(a − 1) + 1]Γ[η(b − 1) + 1]Γ[η(c − 1) + 1]
              =
                             Γη (a)Γη (b)Γη (c)Γ[η(a + b + c − 3) + 3]
                    1 F1 (η(a + b − 2) + 2; η(a + b + c − 3) + 3; −λη)
                  ×                                                    ,
                               {1 F1 (a + b; a + b + c; −λ)}η

where the last line has been obtained by using (4). Now, taking logarithm of G(η)
and using (11) we get (16). The Shannon entropy is obtained from (16) by taking
η ↑ 1 and using L’Hopital’s rule.


4. Exact and Approximate Distribution of the
   Product
     If (X, Y ) ∼ KB(a, b; c; λ), then Ng & Kotz (1995) have shown that X/(X + Y )
and X + Y are mutually independent, X/(X + Y ) ∼ B(a, b) and X + Y ∼ KB(a +
b; c; λ). In this section we derive the density of XY when (X, Y ) ∼ KB(a, b; c; λ).
The distribution of XY , where X and Y are independent random variables, X ∼
KB(a1 , b1 , λ1 ) and Y ∼ KB(a2 , b2 , λ2 ) has been derived in Nagar & Zarrazola
(2005). In order to derive the density of the product we essentially need the integral
representation of the Gauss hypergeometric function given by Luke (1969),
                                          Z 1
                                 Γ(c)
       2 F1 (a, b; c; z) =                    ta−1 (1 − t)c−a−1 (1 − zt)−b dt,
                             Γ(a)Γ(c − a) 0
                                      Re(c) > Re(a) > 0, | arg(1 − z)| < π.           (18)

Theorem 4. If (X, Y ) ∼ KB(a, b; c; λ), then the pdf of W = XY is given by
           √
            πC(a, b; c; λ) exp(−λ) wb−1 (1 − 4w)c−1/2
                  2a+c−b−1               √         b+c−a
                                     1 + 1 − 4w
                ∞                                     i
               X         Γ(c + i)           1 − 4w
             ×                               √
               i=0
                   Γ(c + 1/2 + i) 2i i! 1 + 1 − 4w
                                                    √       
                                                    2 1 − 4w            1
             ×2 F1 c + i, c + b − a + i; 2c + 2i;     √        , 0 < w < . (19)
                                                  1 + 1 − 4w            4


                                        Revista Colombiana de Estadística 34 (2011) 497–512

Bivariate Kummer-Beta Distribution                                                      507

Proof . Making the transformation W = XY with the Jacobian J(x, y → x, w) =
x−1 in (3), we obtain the joint density of X and W as

                                wb−1 (−x2 + x − w)c−1       λ(−x2 + x − w)
                                                                          
          C(a, b; c; λ) exp(−λ)                       exp
                                       xb+c−a                     x

where p < x < q with
                            √                           √
                       1−    1 − 4w                1+    1 − 4w
                  p=                ,         q=                ,
                             2                           2
and 0 < w < 1/4. Now, expanding exp λ(−x2 + x − w)/x in power series and
                                                          

integrating x in the above expression, we obtain the marginal density of W as
                                 Z q                    c−1                      
                               b−1     [(x − p)(q − x)]           λ(x − p)(q − x)
      C(a, b; c; λ) exp(−λ)w                                exp                     dx
                                     p        xb+c−a                     x
                                       ∞
                                           (q − p)2i+2c−1 λi 1 tc+i−1 (1 − t)c+i−1 dt
                                       X                    Z
      = C(a, b; c; λ) exp(−λ)wb−1                                                  b+c−a+i
                                       i=0
                                             q i+b+c−a i!    0   [1 − t (1−p/q)]

where we have used the substitution t = (q − x)/(q − p). Now, evaluating the
above integral using (18) and simplifying the resulting expression, we get the
desired result.

   In the rest of this section, we derive the approximate distribution of the product
XY . It is clear from Theorem 4, that the random variable 4W = 4XY has
support on (0, 1). We, therefore, are motivated to use the Beta distribution of two
parameters as an approximation to the exact distribution. Equating the first and
the second moments of 4W , with those of the Beta distribution with parameters
α and β, it is easy to see that

                                      E(W )[E(W ) − 4E(W 2 )]
                                α=                                                      (20)
                                        E(W 2 ) − (E(W ))2

and
                                 [E(W ) − 4E(W 2 )][1 − 4E(W )]
                          β=
                                     4[E(W 2 ) − (E(W ))2 ]

    The moments E(W ) and E(W 2 ) are available in Section 2, and can be computed
numerically for given values of a, b, c and λ. To demonstrate the closeness of the
approximation we, in Figure 2, graphically compare the exact and approximated
pdf of 4W . First, for different values of the parameters (a, b, c, λ) we compute the
corresponding estimates for (α, β), using (20) and (21). These estimates are given
in Table 3, and corresponding graphics are given in Figure 2, showing comparison
between exact and approximate densities. The exact pdf corresponds to the solid
curve and approximate pdf corresponds to the broken curve. It is evident that the
approximate density is quite close to the exact density.


                                        Revista Colombiana de Estadística 34 (2011) 497–512

508Paula Andrea Bran-Cardona, Johanna Marcela Orozco-Castañeda & Daya Krishna Nagar

                                                                  Table 3: Estimated values of α and β.
                                                            Figure           a     b       c      λ                                                     α                    β
                                                              1             3.0   1.0     0.5    0.5                                                 0.9567               1.0527
                                                              2             3.0   1.0     3.0    0.5                                                 0.9514               3.7098
                                                              3             3.0   3.0     1.0    0.5                                                 2.6239               1.5259
                                                              4             0.5   0.5     1.0    1.0                                                 0.2646               1.8184
                                                              5             3.0   3.0     1.0    1.0                                                 2.5250               1.5410
                                                              6             3.0   3.0     0.5    3.0                                                 2.2502               1.0365

                                                2.5                                                                                                         8
                                                                                                                                                            7
                   Exact and approximated pdf




                                                                                                                               Exact and approximated pdf
                                                  2
                                                                                                                                                            6
                                                1.5                                                                                                         5
                                                                                                                                                            4
                                                  1                                                                                                         3
                                                                                                                                                            2
                                                0.5
                                                                                                                                                            1
                                                      0    0.2   0.4        0.6   0.8     1                                                                     0       0.2    0.4        0.6    0.8   1
 (1)                                                                   4W                       (2)                                                                                  4W
                                                   2                                                                                                        10
                                                1.75
       Exact and approximated pdf




                                                                                                                   Exact and approximated pdf
                                                                                                                                                             8
                                                 1.5
                                                1.25                                                                                                         6
                                                   1
                                                0.75                                                                                                        4
                                                 0.5
                                                                                                                                                             2
                                                0.25
                                                       0   0.2   0.4        0.6   0.8     1                                                                      0      0.2    0.4        0.6    0.8   1
 (3)                                                                   4W                       (4)                                                                                  4W
                                                   2                                                                                               2.5
                                                1.75
       Exact and approximated pdf




                                                                                                       Exact and approximated pdf




                                                                                                                                                             2
                                                 1.5
                                                1.25                                                                                               1.5
                                                   1
                                                0.75                                                                                                         1
                                                 0.5
                                                                                                                                                   0.5
                                                0.25
                                                       0   0.2   0.4        0.6   0.8     1                                                                         0    0.2    0.4        0.6   0.8       1
 (5)                    4W                (6)                     4W

Figure 2: Graphics of the exact density function (solid curve) and the approximate
          (broken curve).



5. Application
    In this section, we consider the data of fog and mist collect from five Colombian
airports and present an application of the model given by (3).
    Fog or mist is a collection of water droplets or ice crystals suspended in the
air at or near the Earth’s surface. The only difference between mist and fog is
visibility. The phenomenon is called fog if the visibility is one kilometer or less;
otherwise it is known as mist.

                                                                                        Revista Colombiana de Estadística 34 (2011) 497–512

Bivariate Kummer-Beta Distribution                                                  509

   We consider data available at the website of IDEAM (Institute Hydrology,
Meteorology and Environmental Studies, Colombia) collected from the following
5 major Colombian airports regarding the fog and mist:

   • Ernesto Cortissoz Airport (Barranquilla)
   • El Dorado Airport (Bogota)
   • Alfonso Bonilla Aragón Airport (Cali)
   • Rafael Núñez Airport (Cartagena)
   • José María Córdova Airport (Medellin)

   The data comprises average number of days each month in which mist or fog
appeared during the period from 1975 to 1991. We consider the following variables:
    X: the proportion of days with mist (the phenomenon weather provides a
visibility of more than 1 km)
    Y : proportion of days with fog (the phenomenon weather provides a visibility
of 1 km or less)
    In addition the following variables are of interest:
    X + Y : proportion of days with the weather phenomenon (mist or fog)
    X/(X + Y ): proportion of days with visibility greater than 1 km with respect
to the total proportion of days exhibiting the phenomenon (mist or fog)
   Y /(X + Y ): proportion of days with visibility less than 1 km with respect to
the total proportion of days exhibiting the phenomenon (mist or fog)
    Table 4, gives the estimates of a, b, c and λ, which were obtained using the
maximum likelihood method, and by implementing Fisher scoring method (Kotz
et al. (2000), p. 504). Table 5, gives estimated values of the moments E[X/(X +
Y )], E[Y /(X + Y )] and E(X + Y ) for five airports.

                     Table 4: Estimated values of a, b, c and λ.
                 Airport              a        b        c          λ
                 Barranquilla     0.620    0.266   153.00     −176.0
                 Bogota           8.290    3.370     3.82       12.3
                 Cali             0.303    0.088    70.80      −94.4
                 Cartagena        0.206    0.091   396.00     −407.0
                 Medellin        12.300    6.580     3.41       18.5



6. Conclusions of the Application
    As conclusions, we can say that the proportion of days with visibility less than 1
km with respect to the total number of days presenting the phenomenon is similar
for Barranquilla, Bogota and Cartagena airports. This ratio is a little lower for

                                     Revista Colombiana de Estadística 34 (2011) 497–512

510Paula Andrea Bran-Cardona, Johanna Marcela Orozco-Castañeda & Daya Krishna Nagar

                    Table 5: Estimated values of the moments.
           Airport        E[X/(X + Y )]     E[Y /(X + Y )]    E(X + Y )
           Barranquilla          0.700              0.300         0.129
           Bogotá                0.711              0.289         0.572
           Cali                  0.775              0.225         0.221
           Cartagena             0.695              0.305         0.023
           Medellín              0.651              0.349         0.675


the Cali and Medellin airports, the value of this ratio is higher. For example, we
can say that the airport at Barranquilla has 30% of total days (with phenomenon)
with fog. For Medellin, this percentage corresponds to 34.9% and for Cali to
22.5%. The proportion of days with phenomenon (mist or fog) is higher for the
Medellin airport followed by the Bogota airport. Cartagena airport presents the
lower proportion.
                                                                 
              Recibido: agosto de 2010 — Aceptado: agosto de 2011


References
Balakrishnan, N. & Lai, C. D. (2009), Continuous Bivariate Distributions, second edn, Springer.
Barry, C. A., Castillo, E. & Sarabia, J. M. (1999), Conditional Specification of Statistical Models, Springer Series in Statistics, Springer-Verlag, New York.
Gordy, M. (1998), ‘Computationally convenient distributional assumptions for common-value auctions’, Computational Economics 12, 61–78.
Gupta, A. K., Cardeño, L. & Nagar, D. K. (2001), ‘Matrix variate Kummer-Dirichlet distributions’, Journal of Applied Mathematics 1(3), 117–139.
Gupta, A. K. & Nagar, D. K. (2000), Matrix Variate Distributions, Vol. 104 of Chapman & Hall/CRC Monographs and Surveys in Pure and Applied Mathematics, Chapman & Hall/CRC, Boca Raton, FL.
Gupta, A. K. & Song, D. (1996), ‘Generalized Liouville distribution’, Computers & Mathematics with Applications 32(2), 103–109.
Gupta, A. K. & Wong, C. F. (1985), ‘On three and five parameter bivariate Beta distributions’, International Journal for Theoretical and Applied Statistics 32(2), 85–91.
Gupta, R. D. & Richards, D. S. P. (2001), ‘The history of the Dirichlet and Liouville distributions’, International Statistical Review 69(3), 433–446.
Hahn, G. J. & Shapiro, S. S. (1967), Statistical Models in Engineering, John Wiley and Sons, New York.
Hutchinson, T. P. & Lai, C. D. (1991), The Engineering Statistician’s Guide To Continuous Bivariate Distributions, Rumsby Scientific Publishing, Adelaide.
Kotz, S., Balakrishnan, N. & Johnson, N. L. (2000), Continuous Multivariate Distributions. Vol. 1. Models and applications, Wiley Series in Probability and Statistics: Applied Probability and Statistics, second edn, Wiley-Interscience, New York.
Lehmann, E. L. (1966), ‘Some concepts of dependence’, Annals of Mathematical Statistics 37, 1137–1153.
Luke, Y. L. (1969), The Special Functions and their Approximations, Vol. 53 of Mathematics in Science and Engineering, Academic Press, New York.
Mardia, K. V. (1970), Families of Bivariate Distributions, Hafner Publishing Co., Darien, Conn. Griffin’s Statistical Monographs and Courses, No. 27.
Marshall, A. W. & Olkin, I. (1979), Inequalities: Theory of Majorization and its Applications, Vol. 143 of Mathematics in Science and Engineering, Academic Press Inc., New York.
Nadarajah, S. & Kotz, S. (2005), ‘Some bivariate Beta distributions’, A Journal of Theoretical and Applied Statistics 39(5), 457–466.
Nadarajah, S. & Zografos, K. (2005), ‘Expressions for Rényi and Shannon for bivariate distributions’, Information Sciences 170(2-4), 173–189. *http://dx.doi.org/10.1016/j.ins.2004.02.020
Nagar, D. K. & Gupta, A. K. (2002), ‘Matrix-variate Kummer-Beta distribution’, Journal of the Australian Mathematical Society 73(1), 11–25.
Nagar, D. K. & Zarrazola, E. (2005), ‘Distributions of the product and the quotient of independent Kummer-Beta variables’, Scientiae Mathematicae Japonicae 61(1), 109–117.
Ng, K. W. & Kotz, S. (1995), Kummer-Gamma and Kummer-Beta univariate and multivariate distributions, Technical Report 84, Department of Statistics, The University of Hong Kong, Hong Kong.
Rényi, A. (1961), On measures of entropy and information, in ‘Procedings 4th Berkeley Symposium Mathematical Statistics and Probability’, University of California Press, Berkeley, California, pp. 547–561.
Shannon, C. E. (1948), ‘A mathematical theory of communication’, The Bell System Technical Journal 27, 379–423, 623–656.
Sivazlian, B. D. (1981), ‘On a multivariate extension of the Gamma and Beta distributions’, SIAM Journal on Applied Mathematics 41(2), 205–209. 
Song, D. & Gupta, A. K. (1997), ‘Properties of generalized Liouville distributions’, Random Operators and Stochastic Equations 5(4), 337–348.
Zografos, K. (1999), ‘On maximum entropy characterization of Pearson’s type II and VII multivariate distributions’, Journal of Multivariate Analysis 71(1), 67–75. *http://dx.doi.org/10.1006/jmva.1999.1824
Zografos, K. & Nadarajah, S. (2005), ‘Expressions for Rényi and Shannon entropies for multivariate distributions’, Statistics & Probability Letters 71(1), 71–84. *http://dx.doi.org/10.1016/j.spl.2004.10.023
