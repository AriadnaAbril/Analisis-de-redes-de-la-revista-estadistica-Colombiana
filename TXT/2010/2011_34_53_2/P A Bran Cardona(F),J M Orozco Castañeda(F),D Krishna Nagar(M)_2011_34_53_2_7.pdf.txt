Bivariate Generalization of the Kummer-Beta Distribution. GeneralizaciÃ³n Bivariada de la DistribuciÃ³n Kummer-Beta
Universidad del Valle, Cali, Colombia. Universidad de AntioquÃ­a, MedellÃ­n, Colombia
Abstract
In this article, we study several properties such as marginal and conditional distributions, joint moments, and mixture representation of the bivariate generalization of the Kummer-Beta distribution. To show the behavior of the density function, we give some graphs of the density for different values of the parameters. Finally, we derive the exact and approximate distribution of the product of two random variables which are distributed jointly as bivariate Kummer-Beta. The exact distribution of the product is derived as an infinite series involving Gauss hypergeometric function, whereas the beta distribution has been used as an approximate distribution. Further, to show the closeness of the approximation, we have compared the exact distribution and the approximate distribution by using several graphs. An application of the results derived in this article is provided to visibility data from Colombia. Key words: Beta distribution, Bivariate distribution, Dirichlet distribution, Hypergeometric function, Moments, Transformation.
Resumen
En este artÃ­culo, definimos la funciÃ³n de densidad de la generalizaciÃ³n bivariada de la distribuciÃ³n Kummer-Beta. Estudiamos algunas de sus propiedades y casos particulares, asÃ­ como las distribuciones marginales y condicionales. Para ilustrar el comportamiento de la funciÃ³n de densidad, mostramos algunos grÃ¡ficos para diferentes valores de los parÃ¡metros. Finalmente, encontramos la distribuciÃ³n del producto de dos variables cuya distribuciÃ³n conjunta es Kummer-Beta bivariada y utilizamos la distribuciÃ³n beta como una aproximaciÃ³n. AdemÃ¡s, con el fin de comparar la distribuciÃ³n exacta y la aproximada de este producto, mostramos algunos grÃ¡ficos. Se presenta una aplicaciÃ³n a datos climÃ¡ticos sobre niebla y neblina de Colombia.
Palabras clave: distribuciÃ³n Beta, distribuciÃ³n bivariada, distribuciÃ³n Dirichlet, funciÃ³n hipergeomÃ©trica, momentos, transformaciÃ³n.


1. Introduction
    The beta random variable is often used for representing processes with natural
lower and upper limits. For example, refer to Hahn & Shapiro (1967). Indeed,
due to a rich variety of its density shapes, the beta distribution plays a vital role
in statistical modeling. The beta distribution arises from a transformation of the
F distribution and is typically used to model the distribution of order statistics.
The beta distribution is useful for modeling random probabilities and proportions,
particularly in the context of Bayesian analysis. Varying within (0, 1) the standard
beta is usually taken as the prior distribution for the proportion p and forms
a conjugate family within the beta prior-Bernoulli sampling scheme. A natural
univariate extension of the beta distribution is the Kummer-Beta distribution
defined by the density function (Gupta, CardeÃ±o & Nagar 2001, Nagar & Gupta
2002, Ng & Kotz 1995),

                         Î“(a + c) xaâˆ’1 (1 âˆ’ x)câˆ’1 exp (âˆ’Î»x)
                                                                                       (1)
                         Î“(a)Î“(c)     1 F1 (a; a + c; âˆ’Î»)

where a > 0, c > 0, 0 < x < 1, âˆ’âˆž < Î» < âˆž and 1 F1 is the confluent hypergeo-
metric function defined by the integral (Luke 1969),
                                        Z 1
                                Î“(c)
           1 F1 (a; c; z) =                 taâˆ’1 (1 âˆ’ t)câˆ’aâˆ’1 exp(zt) dt,
                            Î“(a)Î“(c âˆ’ a) 0                                (2)
                                 Re(c) > Re(a) > 0

    The Kummer-Beta distribution can be seen as bimodal extension of the Beta
distribution (on a finite interval) and thus can help to describe real world phe-
nomena possessing bimodal characteristics and varying within two finite bounds.
The Kummer-Beta distribution is used in common value auctions where posterior
distribution of â€œvalue of a single goodâ€ is Kummer-Beta (Gordy 1998). Recently,
Nagar & Zarrazola (2005) derived distributions of product and ratio of two inde-
pendent random variables when at least one of them is Kummer-Beta.
    The random variables X and Y are said to have a bivariate Kummer-Beta
distribution, denoted by (X, Y ) âˆ¼ KB(a, b; c; Î»), if their joint density is given by

    f (x, y; a, b; c; Î») = C(a, b; c; Î»)xaâˆ’1 y bâˆ’1 (1 âˆ’ x âˆ’ y)câˆ’1 exp[âˆ’Î»(x + y)]       (3)

where x > 0, y > 0, x + y < 1, a > 0, b > 0, c > 0, âˆ’âˆž < Î» < âˆž and
                            Î“(a + b + c)
          C(a, b; c; Î») =                {1 F1 (a + b; a + b + c; âˆ’Î»)}âˆ’1               (4)
                            Î“(a)Î“(b)Î“(c)

                                       Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

Bivariate Kummer-Beta Distribution                                                       499

    For Î» = 0, the density (3) slides to a Dirichlet density with parameters a, b and
c. In Bayesian analysis, the Dirichlet distribution is used as a conjugate prior dis-
tribution for the parameters of a multinomial distribution. However, the Dirichlet
family is not sufficiently rich in scope to represent many important distributional
assumptions, because the Dirichlet distribution has few number of parameters. We
provide a generalization of the Dirichlet distribution with added number of param-
eters. Several other bivariate generalizations of Beta distribution are available in
Mardia (1970), Barry, Castillo & Sarabia (1999), Kotz, Balakrishnan & Johnson
(2000), Balakrishnan & Lai (2009), Hutchinson & Lai (1991), Nadarajah & Kotz
(2005), and Gupta & Wong (1985).
    The matrix variate generalization of Beta and Dirichlet distributions have been
defined and studied extensively. For example, see Gupta & Nagar (2000).
    It can also be observed that bivariate generalization of the Kummer-Beta dis-
tribution defined by the density (3), belongs to the Liouville family of distributions
proposed by Marshall & Olkin (1979) and Sivazlian (1981), (also see Gupta & Song
(1996), Gupta & Richards (2001) and Song & Gupta (1997)).
    In this article we study several properties such as marginal and conditional dis-
tributions, joint moments, correlation, and mixture representation of the bivariate
Kummer-Beta distribution defined by the density (3). We also derive the exact
and approximate distribution of the product XY where (X, Y ) âˆ¼ KB(a, b; c; Î»).
Finally, an application of the results derived in this article is provided to visibility
data about fog and mist from Colombia.


2. Properties
    In this section we study several properties of the bivariate Kummer-Beta dis-
tribution defined in Section 1.
   Using the Kummers relation,

                        1 F1 (a; c; âˆ’z) = exp(âˆ’z)1 F1 (c âˆ’ a; c; z)                      (5)

the density given in (3) can be rewritten as
                                                        câˆ’1
        C(a, b; c; Î») exp(âˆ’Î»)xaâˆ’1 y bâˆ’1 (1 âˆ’ x âˆ’ y)           exp[Î»(1 âˆ’ x âˆ’ y)]          (6)

   Expanding exp[Î»(1 âˆ’ x âˆ’ y)] in power series and rearranging certain factors,
the joint density of X and Y can also be expressed as
                             âˆž                                               c+jâˆ’1
                             X Î“(a + b + c)Î“(c + j) Î»j xaâˆ’1 y bâˆ’1 (1 âˆ’ x âˆ’ y)
{1 F1 (c; a + b + c; Î»)}âˆ’1
                             j=0
                                   Î“(a + b + c + j)Î“(c) j!         B(a, b, c + j)

where
                                             Î“(Î±)Î“(Î²)Î“(Î³)
                              B(Î±, Î², Î³) =
                                             Î“(Î± + Î² + Î³)

                                          Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

500Paula Andrea Bran-Cardona, Johanna Marcela Orozco-CastaÃ±eda & Daya Krishna Nagar

    Thus the bivariate Kummer-Beta distribution is an infinite mixture of Dirichlet
distributions.
    In Bayesian probability theory, if the posterior distributions are in the same
family as the prior probability distribution, the prior and posterior are then called
conjugate distributions, and the prior is called a conjugate prior. In case of multi-
nomial distribution, the usual conjugate prior is the Dirichlet distribution. If
                                             
                                     r+s+f r s
                P (r, s, f |x, y) =            x y (1 âˆ’ x âˆ’ y)f
                                      r, s, f
and
                                                              câˆ’1
         p(x, y) = C(a, b; c; Î»)xaâˆ’1 y bâˆ’1 (1 âˆ’ x âˆ’ y)              exp[âˆ’Î»(x + y)]
where x > 0, y > 0, and x + y < 1, then

  p(x, y | r, s, f ) = C(a + r, b + s; c + f ; Î»)
                                                                            c+f âˆ’1
                                    Ã— xa+râˆ’1 y b+sâˆ’1 (1 âˆ’ x âˆ’ y)                     exp[âˆ’Î»(x + y)]

   Thus, the bivariate family of distributions considered in this article is the con-
jugate prior for the multinomial distribution.
    A distribution is said to be negatively likelihood ratio dependent if the density
f (x, y) satisfies
                      f (x1 , y1 )f (x2 , y2 ) â‰¤ f (x1 , y2 )f (x2 , y1 )
for all x1 > x2 and y1 > y2 (see Lehmann (1966)). In the case of bivariate
generalization of the Kummer-Beta distribution the above inequality reduces to
            (1 âˆ’ x1 âˆ’ y1 )(1 âˆ’ x2 âˆ’ y2 ) < (1 âˆ’ x1 âˆ’ y2 )(1 âˆ’ x2 âˆ’ y1 )
which clearly holds. Hence, the bivariate distribution defined by the density (3) is
negatively likelihood ratio dependent.
    If (X, Y ) âˆ¼ KB(a, b; c; Î»), then Ng & Kotz (1995) have shown that Y /(X +
Y ) and X + Y are mutually independent, Y /(X + Y ) âˆ¼ B(b, a) and X + Y âˆ¼
KB(a + b; c; Î»). Here we give a different proof of this result based on angular
transformation.
Theorem 1. Let (X, Y ) âˆ¼ KB(a, b; c; Î») and define X = R2 cos2 Î˜ and Y =
R2 sin2 Î˜. Then, R2 and Î˜ are independent, R2 âˆ¼ KB(a + b; c; Î») and sin2 Î˜ âˆ¼
B(b, a).

Proof . Using the transformation X = R2 cos2 Î˜ and Y = R2 sin2 Î˜ with the
Jacobian J(x, y â†’ r2 , Î¸) = 2r2 cos Î¸ sin Î¸, in the joint density of X and Y , we
obtain the joint density of R and Î˜ as
        C(a, b; c; Î»)(r2 )a+b (1 âˆ’ r2 )câˆ’1 exp(âˆ’Î»r2 )(cos Î¸)2aâˆ’1 (sin Î¸)2bâˆ’1 ,                    (7)
where 0 < r2 < 1 and 0 < Î¸ < Ï€/2. From (7), it is clear that R2 and Î˜ are
independent. Now, transforming S = R2 and U = sin2 Î˜ with the Jacobian
J(r2 , Î¸ â†’ s, u) = J(r2 â†’ s)J(Î¸ â†’ u) = (4s)âˆ’1 [u(1 âˆ’ u)]âˆ’1/2 , above we get the
desired result.

                                           Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

Bivariate Kummer-Beta Distribution                                                         501

   We derive marginal and conditional distributions as follows.

Theorem 2. If (X, Y ) âˆ¼ KB(a, b; c; Î»), then the marginal density of X is given
by

            C1 (a, b; c; Î») exp(âˆ’Î»x)xaâˆ’1 (1 âˆ’ x)b+câˆ’1 1 F1 (b; b + c; âˆ’Î»(1 âˆ’ x))           (8)

where 0 < x < 1 and

                              Î“(a + b + c)
          C1 (a, b; c; Î») =                {1 F1 (a + b; a + b + c; âˆ’Î»)}âˆ’1
                              Î“(a)Î“(b + c)


Proof . To find the marginal pdf of X, we integrate (3) with respect to y to get
                                       Z 1âˆ’x
                                 aâˆ’1                                       câˆ’1
      C(a, b; c; Î») exp(âˆ’Î»x)x                   exp(âˆ’Î»y)y bâˆ’1 (1 âˆ’ x âˆ’ y)        dy
                                        0


   Substituting z = y/(1 âˆ’ x) with dy = (1 âˆ’ x) dz above, one obtains
                                                Z 1
              aâˆ’1
 C(a, b; c; Î»)x     exp(âˆ’Î»x)(1 âˆ’ x)     b+câˆ’1
                                                      exp[âˆ’Î»(1 âˆ’ x)z]z bâˆ’1 (1 âˆ’ z)câˆ’1 dz (9)
                                                 0

Now, the desired result is obtained by using (2).


   Using the above theorem, the conditional density function of X given Y = y,
0 < y < 1, is obtained as

       Î“(a + c)     exp(âˆ’Î»x)xaâˆ’1 (1 âˆ’ x âˆ’ y)câˆ’1
                                                        ,           0<x<1âˆ’y
       Î“(a)Î“(c) (1 âˆ’ y)a+câˆ’1 1 F1 (a; a + c; âˆ’Î»(1 âˆ’ y))

   Graphs 1â€“6 of the density function for several values of a, b, c and Î» correspond-
ing to six rows of Table 1, depicted in Figure 1, show a wide range of densities.
For example, large values of a, b, c give a density similar to a bivariate normal
density, whereas for small values of a, b, c the density is close to a uniform density.

           Table 1: Density functions for different values of a, b, c and Î».
                               Graph        a    b      c       Î»
                                 1          2    1     1.5   âˆ’5.0
                                 2          2    2     5.0   âˆ’5.0
                                 3          5    3     2.0   âˆ’5.0
                                 4          2    1     2.0   âˆ’0.5
                                 5          5    3     9.0    0.5
                                 6          3    2     1.5    3.0



                                            Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

502Paula Andrea Bran-Cardona, Johanna Marcela Orozco-CastaÃ±eda & Daya Krishna Nagar




                  8
                                                                                                6
                  6                                             1.0                                                                1.0
           f Hx,yL 4                                                                 f Hx,yL 4
                    2                                                                        2
                    0                                                                         0
                   0.0                                 0.5 y                                 0.0                           0.5 y

                            x 0.5                                                                       x 0.5

  (1)                                       1.0 0.0                          (2)                                1.0 0.0




                                                                                            4                                            1.0
                  10                                                              f Hx,yL
                                                                 1.0
            f Hx,yL                                                                         2
                    5
                                                                                             0
                       0                                                                    0.0                               0.5 y
                      0.0                               0.5 y

                              x0.5                                                                  x 0.5


   (3)                                       1.0 0.0                        (4)                                  1.0 0.0




             15                                                                             4
                                                                      1.0                                                                1.0
        f Hx,yL10                                                                 f Hx,yL
                                                                                            2
                 5
                 0                                                                           0
                0.0                                       0.5     y                         0.0                                0.5 y


                            x 0.5                                                                   x    0.5


 (5)                                1.0 0.0         (6)                          1.0
                                                                                     0.0

                  Figure 1: Density functions for different values of the parameters.


   Further, using (3), the joint (r, s)-th moment is obtained as
                        Z 1 Z 1âˆ’x
    r s                                                                   câˆ’1
E(X Y ) = C(a, b; c; Î»)           exp[âˆ’Î»(x + y)]xa+râˆ’1 y b+sâˆ’1 (1 âˆ’ x âˆ’ y)    dy dx
                                        0      0
                           C(a, b; c; Î»)
                     =
                       C(a + r, b + r; c; Î»)
                       Î“(a + r)Î“(b + s)Î“(d) 1 F1 (a + b + r + s; d + r + s; âˆ’Î»)
                     =
                       Î“(a)Î“(b)Î“(d + r + s)          1 F1 (a + b; d; âˆ’Î»)

where d = a + b + c, a + r > 0 and b + s > 0. Now, substituting appropriately, we
obtain
                                                   a 1 F1 (a + b + 1; d + 1; âˆ’Î»)
                                     E(X) =
                                                   d      1 F1 (a + b; d; âˆ’Î»)


                                                   b 1 F1 (a + b + 1; d + 1; âˆ’Î»)
                                     E(Y ) =
                                                   d      1 F1 (a + b; d; âˆ’Î»)


                                                                Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

Bivariate Kummer-Beta Distribution                                                     503

                              a(a + 1) 1 F1 (a + b + 2; d + 2; âˆ’Î»)
                  E(X 2 ) =
                              d(d + 1)      1 F1 (a + b; d; âˆ’Î»)



                              b(b + 1) 1 F1 (a + b + 2; d + 2; âˆ’Î»)
                  E(Y 2 ) =
                              d(d + 1)      1 F1 (a + b; d; âˆ’Î»)



                                  ab    1 F1 (a + b + 2; d + 2; âˆ’Î»)
                 E(XY ) =
                               d(d + 1)      1 F1 (a + b; d; âˆ’Î»)



                            ab(a + 1)(b + 1)    1 F1 (a + b + 4; d + 4; âˆ’Î»)
         E(X 2 Y 2 ) =
                         d(d + 1)(d + 2)(d + 3)      1 F1 (a + b; d; âˆ’Î»)


                                                                      2 
           a a + 1 1 F1 (a + b + 2; d + 2; âˆ’Î») a 1 F1 (a+b+1; d+1; âˆ’Î»)
Var(X) =                                      âˆ’
           d d+1        1 F1 (a + b; d; âˆ’Î»)     d   1 F1 (a + b; d; âˆ’Î»)


                                                                       2 
          b b + 1 1 F1 (a + b + 2; d + 2; âˆ’Î»)   b 1 F1 (a+b+1; d+1; âˆ’Î»)
Var(Y ) =                                     âˆ’
          d d+1        1 F1 (a + b; d; âˆ’Î»)      d    1 F1 (a + b; d; âˆ’Î»)

and
                                                                     2 
               ab 1 F1 (a + b + 2; d + 2; âˆ’Î») 1 1 F1 (a+b+1; d+1; âˆ’Î»)
Cov(X, Y ) =                                 âˆ’
               d (d + 1)1 F1 (a + b; d; âˆ’Î»)    d   1 F1 (a + b; d; âˆ’Î»)


    Notice that E(XY ), E(X 2 ), E(Y 2 ), E(X) and E(Y ) involve 1 F1 (Î±; Âµ; âˆ’Î») which
can be computed using Mathematica by providing values of Î±, Âµ and Î». Table 2
provides correlations between X and Y for different values of a, b, c and Î». All the
tabulated values of correlation are negative because X and Y satisfy x + y < 1. As
can be seen, the choices of a, b small and c, Î» large yield correlations close to zero,
whereas large values of a or b and small values of c or Î» give small correlations.
Further, for fixed values of a, b and c, the correlation decreases as the value of Î»
increases. Likewise, for fixed values of a, b and Î», the correlation decreases as c
increases.


3. Entropies
   In this section, exact forms of Renyi and Shannon entropies are determined for
the bivariate Kummer-Beta distribution defined in this article.
   Let (X , B, P) be a probability space. Consider a pdf f associated with P, dom-
inated by Ïƒâˆ’finite measure Âµ on X . Denote by HSH (f ) the well-known Shannon
entropy introduced in Shannon (1948). It is define by
                                     Z
                       HSH (f ) = âˆ’     f (x) log f (x) dÂµ                     (10)
                                         X


                                        Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

504Paula Andrea Bran-Cardona, Johanna Marcela Orozco-CastaÃ±eda & Daya Krishna Nagar

                       Table 2: Correlation for values of a, b, c and Î».
 a      b     c Î» = âˆ’5.000   âˆ’2.000   âˆ’1.000   âˆ’0.500     0.000    0.500    1.000    2.000    5.000
3.0    2.0   0.5    âˆ’0.936   âˆ’0.888   âˆ’0.862   âˆ’0.846    âˆ’0.828   âˆ’0.808   âˆ’0.785   âˆ’0.731   âˆ’0.494
1.0    2.0   1.0    âˆ’0.848   âˆ’0.717   âˆ’0.653   âˆ’0.616    âˆ’0.577   âˆ’0.536   âˆ’0.493   âˆ’0.406   âˆ’0.172
3.0    2.0   1.5    âˆ’0.819   âˆ’0.716   âˆ’0.670   âˆ’0.644    âˆ’0.617   âˆ’0.589   âˆ’0.559   âˆ’0.497   âˆ’0.304
5.0    3.0   2.0    âˆ’0.799   âˆ’0.723   âˆ’0.690   âˆ’0.673    âˆ’0.655   âˆ’0.635   âˆ’0.616   âˆ’0.573   âˆ’0.433
0.5    1.0   1.5    âˆ’0.736   âˆ’0.499   âˆ’0.406   âˆ’0.360    âˆ’0.316   âˆ’0.275   âˆ’0.237   âˆ’0.171   âˆ’0.055
1.0    2.0   2.0    âˆ’0.712   âˆ’0.543   âˆ’0.477   âˆ’0.442    âˆ’0.408   âˆ’0.374   âˆ’0.341   âˆ’0.279   âˆ’0.135
0.5    1.0   2.0    âˆ’0.654   âˆ’0.414   âˆ’0.332   âˆ’0.294    âˆ’0.258   âˆ’0.225   âˆ’0.195   âˆ’0.144   âˆ’0.054
1.0    2.0   3.0    âˆ’0.598   âˆ’0.429   âˆ’0.371   âˆ’0.343    âˆ’0.316   âˆ’0.290   âˆ’0.265   âˆ’0.219   âˆ’0.118
2.0    4.0   5.0    âˆ’0.535   âˆ’0.428   âˆ’0.391   âˆ’0.374    âˆ’0.356   âˆ’0.339   âˆ’0.322   âˆ’0.290   âˆ’0.204
2.0    2.0   5.0    âˆ’0.494   âˆ’0.365   âˆ’0.324   âˆ’0.305    âˆ’0.286   âˆ’0.267   âˆ’0.250   âˆ’0.218   âˆ’0.141
1.0    0.5   5.0    âˆ’0.322   âˆ’0.185   âˆ’0.151   âˆ’0.136    âˆ’0.123   âˆ’0.111   âˆ’0.100   âˆ’0.082   âˆ’0.046



   One of the main extensions of the Shannon entropy was defined by RÃ©nyi
(1961). This generalized entropy measure is given by

                                  log G(Î·)
                   HR (Î·, f ) =                    (for Î· > 0 and Î· 6= 1)                     (11)
                                    1âˆ’Î·

where
                                               Z
                                      G(Î·) =        f Î· dÂµ
                                               X


   The additional parameter Î· is used to describe complex behavior in probability
models and the associated process under study. RÃ©nyi entropy is monotonically
decreasing in Î·, while Shannon entropy (10) is obtained from (11) for Î· â†‘ 1.
For details see Nadarajah & Zografos (2005), Zografos and Nadarajah (2005) and
Zografos (1999).
      First, we give the following lemma useful in deriving these entropies.

Lemma 1. Let g(a, b, c, Î») = limÎ·â†’1 h(Î·), where

                       d
              h(Î·) =      1 F1 (Î·(a + b âˆ’ 2) + 2; Î·(a + b + c âˆ’ 3) + 3; âˆ’Î»Î·)                  (12)
                       dÎ·

      Then,
                     âˆž
                    X   Î“(a + b + j)Î“(a + b + c) (âˆ’Î»)j h
  g(a, b, c, Î») =                                       j + (a + b âˆ’ 2)Ïˆ(a + b + j)
                    j=1
                        Î“(a + b)Î“(a + b + c + j) j!
                 + (a + b + c âˆ’ 3)Ïˆ(a + b + c) âˆ’ (a + b âˆ’ 2)Ïˆ(a + b)
                                                  i
                 âˆ’ (a + b + c âˆ’ 3)Ïˆ(a + b + c + j)
                                                                                              (13)

where Ïˆ(Î±) = Î“â€² (Î±)/Î“(Î±) is the digamma function.


                                          Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

Bivariate Kummer-Beta Distribution                                                       505

Proof . Expanding 1 F1 in series form, we write

                              âˆž                  âˆž 
                                        (âˆ’Î»)j                    (âˆ’Î»)j
                                                              
                          d X                   X    d
                 h(Î·) =          âˆ†j (Î·)       =         âˆ†j (Î·) ,                        (14)
                          dÎ· j=0          j!    j=0
                                                     dÎ·            j!


where

                          Î“[Î·(a + b âˆ’ 2) + 2 + j]Î“[Î·(a + b + c âˆ’ 3) + 3] j
            âˆ†j (Î·) =                                                     Î·
                          Î“[Î·(a + b âˆ’ 2) + 2]Î“[Î·(a + b + c âˆ’ 3) + 3 + j]


   Now, differentiating the logarithm of âˆ†j (Î·) w.r.t. to Î·, one obtains

            d                         hj
               âˆ†j (Î·)       =   âˆ†j (Î·) + (a + b âˆ’ 2)Ïˆ(Î·(a + b âˆ’ 2) + 2 + j)
            dÎ·                         Î·
                                +(a + b + c âˆ’ 3)Ïˆ(Î·(a + b + c âˆ’ 3) + 3)
                                âˆ’(a + b âˆ’ 2)Ïˆ(Î·(a + b âˆ’ 2) + 2)
                                                                           i
                                âˆ’(a + b + c âˆ’ 3)Ïˆ(Î·(a + b + c âˆ’ 3) + 3 + j)             (15)


   Finally, substituting (15) in (14) and taking Î· â†’ 1, one obtains the desired
result.



Theorem 3. For the bivariate Kummer-Beta distribution defined by the pdf (3),
the RÃ©nyi and the Shannon entropies are given by
                                 
                             1
        HR (Î·, f ) =              Î· log C(a, b; c; Î») + log Î“[Î·(a âˆ’ 1) + 1]
                           1âˆ’Î·
                           + log Î“[Î·(b âˆ’ 1) + 1] + log Î“[Î·(c âˆ’ 1) + 1]
                           âˆ’ log Î“[Î·(a + b + c âˆ’ 3) + 3]
                                                                                   
                           + log 1 F1 (Î·(a + b âˆ’ 2) + 2; Î·(a + b + c âˆ’ 3) + 3; âˆ’Î»Î·) (16)


and

      HSH (f )    = âˆ’ log C(a, b; c; Î») âˆ’ [(a âˆ’ 1)Ïˆ(a) + (b âˆ’ 1)Ïˆ(b) + (c âˆ’ 1)Ïˆ(c)
                                                               g(a, b, c, Î»)
                    âˆ’(a + b + c âˆ’ 3)Ïˆ(a + b + c)] âˆ’                                , (17)
                                                       1 F1 (a + b; a + b + c; âˆ’Î»)


respectively, where Ïˆ(Î±) = Î“â€² (Î±)/Î“(Î±) is the digamma function and g(a, b, c, Î») is
given by (13).


                                          Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

506Paula Andrea Bran-Cardona, Johanna Marcela Orozco-CastaÃ±eda & Daya Krishna Nagar

Proof . For Î· > 0 and Î· 6= 1, using the joint density of X and Y given by (3), we
have
                Z 1 Z 1âˆ’x
     G(Î·) =                f Î· (x, y; a, b; c; Î») dx dy
                   0   0
                                     Z 1 Z 1âˆ’x
              =   [C(a, b; c; Î»)]Î·               xÎ·(aâˆ’1) y Î·(bâˆ’1)
                                   0     0
                               Î·(câˆ’1)
                  (1 âˆ’ x âˆ’ y)         exp[âˆ’Î·Î»(x + y)] dx dy
                                   [C(a, b; c; Î»)]Î·
              =
                  C(Î·(a âˆ’ 1) + 1, Î·(b âˆ’ 1) + 1; Î·(c âˆ’ 1) + 1; Î»)
                  Î“Î· (a + b + c)Î“[Î·(a âˆ’ 1) + 1]Î“[Î·(b âˆ’ 1) + 1]Î“[Î·(c âˆ’ 1) + 1]
              =
                             Î“Î· (a)Î“Î· (b)Î“Î· (c)Î“[Î·(a + b + c âˆ’ 3) + 3]
                    1 F1 (Î·(a + b âˆ’ 2) + 2; Î·(a + b + c âˆ’ 3) + 3; âˆ’Î»Î·)
                  Ã—                                                    ,
                               {1 F1 (a + b; a + b + c; âˆ’Î»)}Î·

where the last line has been obtained by using (4). Now, taking logarithm of G(Î·)
and using (11) we get (16). The Shannon entropy is obtained from (16) by taking
Î· â†‘ 1 and using Lâ€™Hopitalâ€™s rule.


4. Exact and Approximate Distribution of the
   Product
     If (X, Y ) âˆ¼ KB(a, b; c; Î»), then Ng & Kotz (1995) have shown that X/(X + Y )
and X + Y are mutually independent, X/(X + Y ) âˆ¼ B(a, b) and X + Y âˆ¼ KB(a +
b; c; Î»). In this section we derive the density of XY when (X, Y ) âˆ¼ KB(a, b; c; Î»).
The distribution of XY , where X and Y are independent random variables, X âˆ¼
KB(a1 , b1 , Î»1 ) and Y âˆ¼ KB(a2 , b2 , Î»2 ) has been derived in Nagar & Zarrazola
(2005). In order to derive the density of the product we essentially need the integral
representation of the Gauss hypergeometric function given by Luke (1969),
                                          Z 1
                                 Î“(c)
       2 F1 (a, b; c; z) =                    taâˆ’1 (1 âˆ’ t)câˆ’aâˆ’1 (1 âˆ’ zt)âˆ’b dt,
                             Î“(a)Î“(c âˆ’ a) 0
                                      Re(c) > Re(a) > 0, | arg(1 âˆ’ z)| < Ï€.           (18)

Theorem 4. If (X, Y ) âˆ¼ KB(a, b; c; Î»), then the pdf of W = XY is given by
           âˆš
            Ï€C(a, b; c; Î») exp(âˆ’Î») wbâˆ’1 (1 âˆ’ 4w)câˆ’1/2
                  2a+câˆ’bâˆ’1               âˆš         b+câˆ’a
                                     1 + 1 âˆ’ 4w
                âˆž                                     i
               X         Î“(c + i)           1 âˆ’ 4w
             Ã—                               âˆš
               i=0
                   Î“(c + 1/2 + i) 2i i! 1 + 1 âˆ’ 4w
                                                    âˆš       
                                                    2 1 âˆ’ 4w            1
             Ã—2 F1 c + i, c + b âˆ’ a + i; 2c + 2i;     âˆš        , 0 < w < . (19)
                                                  1 + 1 âˆ’ 4w            4


                                        Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

Bivariate Kummer-Beta Distribution                                                      507

Proof . Making the transformation W = XY with the Jacobian J(x, y â†’ x, w) =
xâˆ’1 in (3), we obtain the joint density of X and W as

                                wbâˆ’1 (âˆ’x2 + x âˆ’ w)câˆ’1       Î»(âˆ’x2 + x âˆ’ w)
                                                                          
          C(a, b; c; Î») exp(âˆ’Î»)                       exp
                                       xb+câˆ’a                     x

where p < x < q with
                            âˆš                           âˆš
                       1âˆ’    1 âˆ’ 4w                1+    1 âˆ’ 4w
                  p=                ,         q=                ,
                             2                           2
and 0 < w < 1/4. Now, expanding exp Î»(âˆ’x2 + x âˆ’ w)/x in power series and
                                                          

integrating x in the above expression, we obtain the marginal density of W as
                                 Z q                    câˆ’1                      
                               bâˆ’1     [(x âˆ’ p)(q âˆ’ x)]           Î»(x âˆ’ p)(q âˆ’ x)
      C(a, b; c; Î») exp(âˆ’Î»)w                                exp                     dx
                                     p        xb+câˆ’a                     x
                                       âˆž
                                           (q âˆ’ p)2i+2câˆ’1 Î»i 1 tc+iâˆ’1 (1 âˆ’ t)c+iâˆ’1 dt
                                       X                    Z
      = C(a, b; c; Î») exp(âˆ’Î»)wbâˆ’1                                                  b+câˆ’a+i
                                       i=0
                                             q i+b+câˆ’a i!    0   [1 âˆ’ t (1âˆ’p/q)]

where we have used the substitution t = (q âˆ’ x)/(q âˆ’ p). Now, evaluating the
above integral using (18) and simplifying the resulting expression, we get the
desired result.

   In the rest of this section, we derive the approximate distribution of the product
XY . It is clear from Theorem 4, that the random variable 4W = 4XY has
support on (0, 1). We, therefore, are motivated to use the Beta distribution of two
parameters as an approximation to the exact distribution. Equating the first and
the second moments of 4W , with those of the Beta distribution with parameters
Î± and Î², it is easy to see that

                                      E(W )[E(W ) âˆ’ 4E(W 2 )]
                                Î±=                                                      (20)
                                        E(W 2 ) âˆ’ (E(W ))2

and
                                 [E(W ) âˆ’ 4E(W 2 )][1 âˆ’ 4E(W )]
                          Î²=
                                     4[E(W 2 ) âˆ’ (E(W ))2 ]

    The moments E(W ) and E(W 2 ) are available in Section 2, and can be computed
numerically for given values of a, b, c and Î». To demonstrate the closeness of the
approximation we, in Figure 2, graphically compare the exact and approximated
pdf of 4W . First, for different values of the parameters (a, b, c, Î») we compute the
corresponding estimates for (Î±, Î²), using (20) and (21). These estimates are given
in Table 3, and corresponding graphics are given in Figure 2, showing comparison
between exact and approximate densities. The exact pdf corresponds to the solid
curve and approximate pdf corresponds to the broken curve. It is evident that the
approximate density is quite close to the exact density.


                                        Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

508Paula Andrea Bran-Cardona, Johanna Marcela Orozco-CastaÃ±eda & Daya Krishna Nagar

                                                                  Table 3: Estimated values of Î± and Î².
                                                            Figure           a     b       c      Î»                                                     Î±                    Î²
                                                              1             3.0   1.0     0.5    0.5                                                 0.9567               1.0527
                                                              2             3.0   1.0     3.0    0.5                                                 0.9514               3.7098
                                                              3             3.0   3.0     1.0    0.5                                                 2.6239               1.5259
                                                              4             0.5   0.5     1.0    1.0                                                 0.2646               1.8184
                                                              5             3.0   3.0     1.0    1.0                                                 2.5250               1.5410
                                                              6             3.0   3.0     0.5    3.0                                                 2.2502               1.0365

                                                2.5                                                                                                         8
                                                                                                                                                            7
                   Exact and approximated pdf




                                                                                                                               Exact and approximated pdf
                                                  2
                                                                                                                                                            6
                                                1.5                                                                                                         5
                                                                                                                                                            4
                                                  1                                                                                                         3
                                                                                                                                                            2
                                                0.5
                                                                                                                                                            1
                                                      0    0.2   0.4        0.6   0.8     1                                                                     0       0.2    0.4        0.6    0.8   1
 (1)                                                                   4W                       (2)                                                                                  4W
                                                   2                                                                                                        10
                                                1.75
       Exact and approximated pdf




                                                                                                                   Exact and approximated pdf
                                                                                                                                                             8
                                                 1.5
                                                1.25                                                                                                         6
                                                   1
                                                0.75                                                                                                        4
                                                 0.5
                                                                                                                                                             2
                                                0.25
                                                       0   0.2   0.4        0.6   0.8     1                                                                      0      0.2    0.4        0.6    0.8   1
 (3)                                                                   4W                       (4)                                                                                  4W
                                                   2                                                                                               2.5
                                                1.75
       Exact and approximated pdf




                                                                                                       Exact and approximated pdf




                                                                                                                                                             2
                                                 1.5
                                                1.25                                                                                               1.5
                                                   1
                                                0.75                                                                                                         1
                                                 0.5
                                                                                                                                                   0.5
                                                0.25
                                                       0   0.2   0.4        0.6   0.8     1                                                                         0    0.2    0.4        0.6   0.8       1
 (5)                    4W                (6)                     4W

Figure 2: Graphics of the exact density function (solid curve) and the approximate
          (broken curve).



5. Application
    In this section, we consider the data of fog and mist collect from five Colombian
airports and present an application of the model given by (3).
    Fog or mist is a collection of water droplets or ice crystals suspended in the
air at or near the Earthâ€™s surface. The only difference between mist and fog is
visibility. The phenomenon is called fog if the visibility is one kilometer or less;
otherwise it is known as mist.

                                                                                        Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

Bivariate Kummer-Beta Distribution                                                  509

   We consider data available at the website of IDEAM (Institute Hydrology,
Meteorology and Environmental Studies, Colombia) collected from the following
5 major Colombian airports regarding the fog and mist:

   â€¢ Ernesto Cortissoz Airport (Barranquilla)
   â€¢ El Dorado Airport (Bogota)
   â€¢ Alfonso Bonilla AragÃ³n Airport (Cali)
   â€¢ Rafael NÃºÃ±ez Airport (Cartagena)
   â€¢ JosÃ© MarÃ­a CÃ³rdova Airport (Medellin)

   The data comprises average number of days each month in which mist or fog
appeared during the period from 1975 to 1991. We consider the following variables:
    X: the proportion of days with mist (the phenomenon weather provides a
visibility of more than 1 km)
    Y : proportion of days with fog (the phenomenon weather provides a visibility
of 1 km or less)
    In addition the following variables are of interest:
    X + Y : proportion of days with the weather phenomenon (mist or fog)
    X/(X + Y ): proportion of days with visibility greater than 1 km with respect
to the total proportion of days exhibiting the phenomenon (mist or fog)
   Y /(X + Y ): proportion of days with visibility less than 1 km with respect to
the total proportion of days exhibiting the phenomenon (mist or fog)
    Table 4, gives the estimates of a, b, c and Î», which were obtained using the
maximum likelihood method, and by implementing Fisher scoring method (Kotz
et al. (2000), p. 504). Table 5, gives estimated values of the moments E[X/(X +
Y )], E[Y /(X + Y )] and E(X + Y ) for five airports.

                     Table 4: Estimated values of a, b, c and Î».
                 Airport              a        b        c          Î»
                 Barranquilla     0.620    0.266   153.00     âˆ’176.0
                 Bogota           8.290    3.370     3.82       12.3
                 Cali             0.303    0.088    70.80      âˆ’94.4
                 Cartagena        0.206    0.091   396.00     âˆ’407.0
                 Medellin        12.300    6.580     3.41       18.5



6. Conclusions of the Application
    As conclusions, we can say that the proportion of days with visibility less than 1
km with respect to the total number of days presenting the phenomenon is similar
for Barranquilla, Bogota and Cartagena airports. This ratio is a little lower for

                                     Revista Colombiana de EstadÃ­stica 34 (2011) 497â€“512

510Paula Andrea Bran-Cardona, Johanna Marcela Orozco-CastaÃ±eda & Daya Krishna Nagar

                    Table 5: Estimated values of the moments.
           Airport        E[X/(X + Y )]     E[Y /(X + Y )]    E(X + Y )
           Barranquilla          0.700              0.300         0.129
           BogotÃ¡                0.711              0.289         0.572
           Cali                  0.775              0.225         0.221
           Cartagena             0.695              0.305         0.023
           MedellÃ­n              0.651              0.349         0.675


the Cali and Medellin airports, the value of this ratio is higher. For example, we
can say that the airport at Barranquilla has 30% of total days (with phenomenon)
with fog. For Medellin, this percentage corresponds to 34.9% and for Cali to
22.5%. The proportion of days with phenomenon (mist or fog) is higher for the
Medellin airport followed by the Bogota airport. Cartagena airport presents the
lower proportion.
                                                                 
              Recibido: agosto de 2010 â€” Aceptado: agosto de 2011


References
Balakrishnan, N. & Lai, C. D. (2009), Continuous Bivariate Distributions, second edn, Springer.
Barry, C. A., Castillo, E. & Sarabia, J. M. (1999), Conditional Specification of Statistical Models, Springer Series in Statistics, Springer-Verlag, New York.
Gordy, M. (1998), â€˜Computationally convenient distributional assumptions for common-value auctionsâ€™, Computational Economics 12, 61â€“78.
Gupta, A. K., CardeÃ±o, L. & Nagar, D. K. (2001), â€˜Matrix variate Kummer-Dirichlet distributionsâ€™, Journal of Applied Mathematics 1(3), 117â€“139.
Gupta, A. K. & Nagar, D. K. (2000), Matrix Variate Distributions, Vol. 104 of Chapman & Hall/CRC Monographs and Surveys in Pure and Applied Mathematics, Chapman & Hall/CRC, Boca Raton, FL.
Gupta, A. K. & Song, D. (1996), â€˜Generalized Liouville distributionâ€™, Computers & Mathematics with Applications 32(2), 103â€“109.
Gupta, A. K. & Wong, C. F. (1985), â€˜On three and five parameter bivariate Beta distributionsâ€™, International Journal for Theoretical and Applied Statistics 32(2), 85â€“91.
Gupta, R. D. & Richards, D. S. P. (2001), â€˜The history of the Dirichlet and Liouville distributionsâ€™, International Statistical Review 69(3), 433â€“446.
Hahn, G. J. & Shapiro, S. S. (1967), Statistical Models in Engineering, John Wiley and Sons, New York.
Hutchinson, T. P. & Lai, C. D. (1991), The Engineering Statisticianâ€™s Guide To Continuous Bivariate Distributions, Rumsby Scientific Publishing, Adelaide.
Kotz, S., Balakrishnan, N. & Johnson, N. L. (2000), Continuous Multivariate Distributions. Vol. 1. Models and applications, Wiley Series in Probability and Statistics: Applied Probability and Statistics, second edn, Wiley-Interscience, New York.
Lehmann, E. L. (1966), â€˜Some concepts of dependenceâ€™, Annals of Mathematical Statistics 37, 1137â€“1153.
Luke, Y. L. (1969), The Special Functions and their Approximations, Vol. 53 of Mathematics in Science and Engineering, Academic Press, New York.
Mardia, K. V. (1970), Families of Bivariate Distributions, Hafner Publishing Co., Darien, Conn. Griffinâ€™s Statistical Monographs and Courses, No. 27.
Marshall, A. W. & Olkin, I. (1979), Inequalities: Theory of Majorization and its Applications, Vol. 143 of Mathematics in Science and Engineering, Academic Press Inc., New York.
Nadarajah, S. & Kotz, S. (2005), â€˜Some bivariate Beta distributionsâ€™, A Journal of Theoretical and Applied Statistics 39(5), 457â€“466.
Nadarajah, S. & Zografos, K. (2005), â€˜Expressions for RÃ©nyi and Shannon for bivariate distributionsâ€™, Information Sciences 170(2-4), 173â€“189. *http://dx.doi.org/10.1016/j.ins.2004.02.020
Nagar, D. K. & Gupta, A. K. (2002), â€˜Matrix-variate Kummer-Beta distributionâ€™, Journal of the Australian Mathematical Society 73(1), 11â€“25.
Nagar, D. K. & Zarrazola, E. (2005), â€˜Distributions of the product and the quotient of independent Kummer-Beta variablesâ€™, Scientiae Mathematicae Japonicae 61(1), 109â€“117.
Ng, K. W. & Kotz, S. (1995), Kummer-Gamma and Kummer-Beta univariate and multivariate distributions, Technical Report 84, Department of Statistics, The University of Hong Kong, Hong Kong.
RÃ©nyi, A. (1961), On measures of entropy and information, in â€˜Procedings 4th Berkeley Symposium Mathematical Statistics and Probabilityâ€™, University of California Press, Berkeley, California, pp. 547â€“561.
Shannon, C. E. (1948), â€˜A mathematical theory of communicationâ€™, The Bell System Technical Journal 27, 379â€“423, 623â€“656.
Sivazlian, B. D. (1981), â€˜On a multivariate extension of the Gamma and Beta distributionsâ€™, SIAM Journal on Applied Mathematics 41(2), 205â€“209. 
Song, D. & Gupta, A. K. (1997), â€˜Properties of generalized Liouville distributionsâ€™, Random Operators and Stochastic Equations 5(4), 337â€“348.
Zografos, K. (1999), â€˜On maximum entropy characterization of Pearsonâ€™s type II and VII multivariate distributionsâ€™, Journal of Multivariate Analysis 71(1), 67â€“75. *http://dx.doi.org/10.1006/jmva.1999.1824
Zografos, K. & Nadarajah, S. (2005), â€˜Expressions for RÃ©nyi and Shannon entropies for multivariate distributionsâ€™, Statistics & Probability Letters 71(1), 71â€“84. *http://dx.doi.org/10.1016/j.spl.2004.10.023
