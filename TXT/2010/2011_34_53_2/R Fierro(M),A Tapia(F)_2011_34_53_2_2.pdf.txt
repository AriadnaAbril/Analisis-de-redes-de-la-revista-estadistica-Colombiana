Testing Homogeneity for Poisson Processes. Prueba de homogeneidad para procesos de Poisson .
Universidad Católica de Valparaíso, Valparaíso, Chile. Universidade de São Paulo, São Paulo, Brasil
Abstract
We developed an asymptotically optimal hypothesis test concerning the homogeneity of a Poisson process over various subintervals. Under the null hypothesis, maximum likelihood estimators for the values of the intensity function on the subintervals are determined, and are used in the test for homogeneity.
Key words: Poisson process, hypothesis testing, local alternatives, asymptotic distribution, asymptotically optimal, likelihood ratio test.
Resumen
Una prueba de hipótesis asintótica para verificar homogeneidad de un proceso de Poisson sobre ciertos subintervalos es desarrollada. Bajo la hipótesis nula, estimadores máximo verosímiles para los valores de la función intensidad sobre los subintervalos mencionados son determinados y usados en el test de homogeneidad.
Palabras clave: proceso de Poisson, prueba de hipótesis, alternativas locales, distribución asintótica, asintóticamente óptimo, prueba de razón de verosimilitud.

1. Introduction
    Poisson processes have been used to model random phenomena in areas such
as communications, hydrology, meteorology, insurance, reliability, and seismology,
among others. These processes are often appropriate for modeling a series of events
over time.
    Poisson processes are governed by an intensity function λ(t), which determines
the instantaneous rate of event occurrence at time t. Equivalently, Ra Poisson
                                                                          t
process is also governed by the cumulative intensity function Λ(t) = 0 λ(τ ) dτ .
When the intensity function is a constant, the Poisson process is known as a
homogeneous Poisson process. When the intensity function varies with time, the
Poisson process is known as a nonhomogeneous Poisson process (NHPP). A special
case of an NHPP which arises in this paper has an intensity function that is
piecewise constant over various time subintervals. The main aim of this paper is
to develop a hypothesis test to determine whether an observed point process is
drawn from a homogeneous Poisson process or a nonhomogeneous Poisson process
with a piecewise constant intensity function.
   A number of authors have carried out statistical analysis on the intensity of
an NHPP. For instance, Leemis (1991), Leemis (2004), Kuhl, Wilson   Johnson
(1997), Arkin   Leemis (2000), Kuhl   Wilson (2000), Henderson (2003), and
others have considered the nonparametric estimation of the cumulative intensity
function for a NHPP, and some of these authors have devoted their attention to
modeling the periodic behavior of the process.
    By following ideas from Fierro (2008), and considering, as in Leemis (2004), a
finite time horizon that has been partitioned into subintervals, we state a result for
testing whether a Poisson process is homogeneous or not over certain time intervals.
Although a nonhomogeneous Poisson process is oftentimes a more accurate model
of a phenomenon occurring in a non-stationary fashion, from a statistical point
of view, the modeling based on a homogeneous Poisson process is simpler due to
the fact that its intensity function depends only upon a single real parameter.
Even though the process could be nonhomogeneous, it is important to investigate
whether the process is homogeneous at certain time intervals.
    For this reason, the main aim of this paper is to develop an asymptotic like-
lihood test for homogeneity. It is proved that this test is asymptotically optimal.
As in Neyman (1949), we study the asymptotic behavior of the log likelihood of
the test, but additionally, we consider the noncentral scenario to obtain an approx-
imation to the power of the test. A sequence of local alternative hypotheses are
stated, similar to those considered in some tests, which can be found in Serfling
(1980), Karr (1991) and Lehmann (1999). Under the null hypothesis, the inten-
sity function of the process is piecewise constant and, in order to obtain sufficient
information to estimate these constants, observations from each of these intervals
should be considered. A maximum likelihood estimator should take this informa-
tion into account, for example, when estimating the cumulative intensity function.
The methods introduced here are parametric because the inference on the inten-
sity function of a NHPP involves a finite number of parameters. This technique
has been argued against by some authors because it requires the introduction of
parameters by the modeler (Leemis 1991, Arkin   Leemis 2000); this technique,
however, has been used by Henderson (2003) and Leemis (2004) and we believe it
is appropriate in many settings. Even though, in this work, the intensity of the

                                     Revista Colombiana de Estadística 34 (2011) 421–432

Homogeneity for Poisson Processes                                                             423

nonhomogeneous Poisson process is not sequentially estimated, it is worth men-
tioning there are other estimation methods. One of them is the Shiryayev-Roberts
test which was introduced by Shiryaev (1963) and Roberts (1966). This procedure
is concerned with the sequential detection of changes in distributions occurring at
unknown points in time.
    The article is organized as follows. In Section 2 we introduce the null hypothesis
and derive maximum likelihood estimators under the null hypothesis and without
restrictions on the parameters. In Section 3, the asymptotic normality of the
estimators is stated with the main results introduced in Section 4. In Section 5,
an example is presented. Finally a method for simulations of NHPP variables
under the null hypothesis, is proposed in Section 5.


2. Preliminaries
    Let T be a fixed strictly positive real number and let us partition the interval
[0, T ] into m subintervals [t0 , t1 ], (t1 , t2 ], . . . , (tm−1 , tm ], where t0 = 0 and tm = T .
The subintervals do not necessarily have equal widths. Let us denote by C the
class of all functions λ which are piecewise constant on each subinterval defined
above. From now on, the constant value of λ on (ti−1 , ti ] will be denoted by λi .
Consequently,
                                                         X m
                        λ(t) = λ1 I[t0 ,t1 ] (t) +            λi I(ti−1 ,ti ] (t)
                                                    i=2
where IC stands for the indicator function on a set C.
    This work refers to the hypothesis test that the intensity λ is constant in
certain groups of the above subintervals. To do this, we need to partition the set
J = {1, . . . , m} into r subsets J(1), . . . , J(r), (r groups), that is, J = J(1) ∪ · · · ∪
J(r), and for u 6= v, J(u) ∩ J(v) = ∅. Let us denote by m(u) the cardinality of
J(u). Hence m(1) + · · · + m(r) = m. With these notations,          S we are interested
in finding out whether or not λ(t) is constant on the sets i∈J(u) (ti−1 , ti ], (u ∈
{1, . . . , r}). Consequently, the null hypothesis should be stated in mathematical
terms as follows:

                        H0 : ∀u ∈ {1, . . . , r}, ∀i, j ∈ J(u), λi = λj                        (1)

    This hypothesis can be stated in the following simpler equivalent form:

                         H0 : ∀u ∈ {1, . . . , r}, ∀i ∈ J(u), λi = λu
              P
where λu =       i∈J(u) λi /m(u).
   Considering r = 1, H0 is the hypothesis corresponding to λ is the intensity of
an homogeneous Poisson process.
    Assume there are N1 , . . . , Nk independent realizations of a nonhomogeneous
Poisson process with intensity λ ∈ C and as before, λi denotes the constant value
of λ on (ti−1 , ti ]. Put N k = N1 + · · · + Nk . An estimation of λi can be obtained
by counting the jumps of Nk into the interval (ti−1 , ti ].

                                          Revista Colombiana de Estadística 34 (2011) 421–432

424                                                            Raúl Fierro   Alejandra Tapia

   From Theorem 2.31, in Karr (1991), a likelihood function for λ1 , . . . , λm is
given on [0, T ] by
                             "Z                        Z          #
                                          T                                T
          L(λi ; 1 ≤ i ≤ m) = exp             log(λ(t)) dN k (t) − k           λ(t) dt
                                      0                                0


   Hence,
                                          "m                                      #
                                           X
              L(λi ; 1 ≤ i ≤ m) = exp               {log(λi )△Nik − kλi △ti }
                                              i=1

where △Nik = N k (ti ) − N k (ti−1 ) and △ti = ti − ti−1 .
   Under H0 , this likelihood function on [0, T ] becomes
                                                                     
                                  Xr            X               X
      L0 (λu ; 1 ≤ u ≤ r) = exp      log(λu )       △Nik − kλu   △ti 
                                    u=1               i∈J(u)                   i∈J(u)


                                                                      cu , 1 ≤ u ≤ r,
   It is easy to see that the maxima of L0 and L are attained at λu = λ
and λi = λbi , 1 ≤ i ≤ m, respectively, where
                           P           k
                     c       i∈J(u) △Ni                      △Nik
                     λ = P
                      u                       and      λbi =
                           k i∈J(u) △ti                      k△ti

    For the sake of simplicity, the reference to k in these maximum likelihood
estimators has been omitted.
    Notice that, under H0 , λbi is not sufficient for λi and thus there exists infor-
mation from the data which is not                                      b
                                   P containedk in the statistic λi . This lack of
information is contained in T = i∈J(u) △Ni , for instance. Consequently, it is
prominent the convenience of using, under H0 , λ  cu instead of λbi , in any estimation
of a function of λi , (i ∈ J(u)). This fact is relevant in Section 5, where an esti-
mation of the cumulative intensity function of the process is considered in variate
generation by inversion and by thinning for a NHPP from event count data.


3. Asymptotic Normality of Estimators
    For making inference about the parameters λi , (i = 1, . . . , r), for instance, in
order to obtain asymptotic confidence intervals for these parameters, we need the
corresponding estimators to be consistent and asymptotically normal. This fact is
stated in Proposition 1 below. Moreover, Corollary 1, provides us the asymptotical
distribution for the parameters under the null hypothesis.

Proposition 1. For each i = 1, . . . , m, λbi is consistent and asymptotically normal
N (0, λi ), which means that the following two conditions hold:

                                     Revista Colombiana de Estadística 34 (2011) 421–432

Homogeneity for Poisson Processes                                                      425

(C1) For each i = 1, . . . , m, λbi converges to λi , with probability 1, as k → ∞.
     √
(C2) k(λ c1 − λ1 , . . . , λc
                            m − λm ) converges in distribution to an m-variate normal
    random vector having mean zero and covariance matrix Σ given by
                                                              
                                    λ1               ···    0
                                   ..               ..     .. 
                                Σ= .                   .    . 
                                              0      ···    λm

Proof . Conditions (C1) and (C2) directly follow from Kolmogorov’s Law of Large
Numbers, the independent increments property of Poisson processes and the clas-
sical Central Limit Theorem.

Corollary 1. Under H0 , for each u = 1, . . . , r, λcu converges to λu as k ↑ ∞ and
√
    c1    1         cr   r
  k(λ − λ , . . . , λ − λ ) converges in distribution to an r-variate normal random
vector having mean zero and covariance matrix Σ given by
                                                            
                                  λ1              ···    0
                                 ..              ..      .. 
                              Σ= .                  .     . 
                                  0               ···    λr

    The above corollary enables us to obtain the usual confidence-interval estimate
for λu , and hence for λi where i ∈ J(u). Indeed, an asymptotically 100(1 − α)%
confidence interval for λu is
                              q                         q
                    λcu − zα/2 λcu /k < λu < λcu + zα/2 λ cu /k

where zα/2 is the 1 − α/2 percentile of the standard normal distribution.


4. Main Result
   The main result of this paper is stated in Theorem 1 below. For testing H0
against H0 fails to be true, we denote by Rk the likelihood ratio, that is

                                           cu ; 1 ≤ u ≤ r)
                                       L0 (λ
                             Rk =
                                       L(λbi ; 1 ≤ i ≤ m)

and hence
                                                                          
                           r
                           X X
             Rk = exp                                       cu − λbi )△ti ]
                                           cu /λbi )△N k − k(λ
                                      [log(λ                                           (2)
                                                      i
                         u=1 i∈J(u)


     Even though Rk depends on N k , it is worth noting Rk does not depend on k,
i.e., Rk depends on k only through N k .

                                        Revista Colombiana de Estadística 34 (2011) 421–432

426                                                                  Raúl Fierro   Alejandra Tapia

    In order to state the main result, for each u ∈ {1, . . . , r}, we consider the
following sequence of local alternatives to the null hypothesis:
                                                                        √
                   H(k) : ∀u ∈ {1, . . . , r}, ∀i ∈ J(u), λi = λu + δi / k                        (3)
                                                                          P
where δ = (δ1 , . . . , δm ) is a fixed vector in Rm satisfying                i∈J(u) δi = 0, for each
u ∈ {1, . . . , r}.

Theorem 1. Under H(k) as k → ∞, −2 log(Rk ) has noncentral asymptotically
χ2 distribution with m − r degrees of freedom and noncentrality parameter

                            r
                                                    "        P                   #2
                            X 1         X                        j∈J(u) δj △tj
                   2
               Φ        =                       △ti δi − P
                            u=1
                                  λu                              j∈J(u) △tj
                                       i∈J(u)
                                                            P                        !2 
                            r
                            X           X
                              1                                          δj △tj
                        =                       △ti δi2 −       Pj∈J(u)                 
                            u=1
                                λu                                 j∈J(u) △tj
                                       i∈J(u)




Proof . By taking into account that log(x) = (x − 1) − (x − 1)2 /2 + O((x − 1)3 ),
from (2) it is obtained

                            r
                            X X                                                   
      −2 log(Rk )       =                cu )/λbi ]2 △N k + O([(λbi − λ
                                 [(λbi − λ                i
                                                                      cu )/λbi ]3 )
                            u=1 i∈I(u)
                            Xm                         q      
                        =        (Uik )2 + OP ((Uik )3 / △Nik )
                            i=1

                          q
where Uik = (λbi − λcu ) k△ti /λbi whenever i ∈ J(u), and in general, An = OP (Bn )
means that given any η > 0, there is a constant M = M (η) and a positive integer
n0 = n0 (η) such that Pr{|An | ≤ M |Bn |} ≥ 1 − η for every n > n0 .
                                                            √                         k
    For each i = 1, . . . , m, let △Mik = (△Nik −kλi △ti )/ k. Since △M1k , . . . , △Mm
                                                                     k            k
are independent, by the classical Central Limit Theorem, {(△M1 , . . . , △Mm )}k∈N
converges in distribution to a normal random vector having mean zero and co-
variance matrix Σ given by the diagonal matrix Σ = diag(λ1 △t1 , . . . , λ√m △tm ).
Under
√      H(k) , for each u = 1, . . . , r and each i ∈ J(u), △Nik = λu k△ti + δi k△ti +
  k△Mik . Hence,
                                              δi  △M k
                                   λbi = λu + √ + √ i                                             (4)
                                               k   k△ti

and
                                   P                      k
                                                                 P
                       cu = λ + √ P
                             u                   j∈J(u) △Mj
                                        j∈J(u) δj △tj
                       λ                      +√ P                                                (5)
                                 k j∈J(u) △tj   k j∈J(u) △tj

                                            Revista Colombiana de Estadística 34 (2011) 421–432

Homogeneity for Poisson Processes                                                       427

   From (4) and (5), for each i ∈ J(u) one obtains
                   s                      P              k
                                                             P               !
                       △ti       △Mik       j∈J(u) △Mj         j∈J(u) δj △tj
         Uik   =           δi +        − P                  − P
                       λbi        △ti        j∈J(u) △tj         j∈J(u) △tj

                                        p          q
                         √      P                   c
                          △t  i  j∈J(u)   △t j Vj
                                                 k
                                                    λj /λbi
               =   Vik −           P
                                     j∈J(u) △tj

                       q           q
where Vik = △Mik /       b
                        λi △ti + δi △ti /λbi .
                                                     √
    Under H(k) , for eachqi ∈ J(u), λi = λu + δi / k and by Proposition 1 in Section
3, for each i, j ∈ J(u), c    λj /λbi → 1, with probability 1, as k → ∞. Consequently,
from a slight modification of Proposition 1 in Section 3 and Slutzky’s theorem,
                 k
{(U1k , . . . , Um )}k∈N converges in distribution to U = (U1 , . . . , Um ), where for each
i ∈ J(u), (u = 1, . . . , r),
                                       √   P        p
                                        △ti j∈J(u) △tj Vj
                             Ui = Vi −     P
                                             j∈J(u) △tj


and V = (V1 , . . . , Vm )t is a vector of m independent normal random variables
                 p and such that for each u ∈ {1, . . . , r} and each j ∈ J(u),
with variance one,
Vj has mean
        Pm   δ j    △tj /λu . Hence, {−2 log(Rk ))}k∈N converges in distribution to
    2            2
kUk = i=1 Ui , where k · k stands for the Euclidean norm in Rm .
   Let
                                                    
                                     P(1) · · ·  0
                                                .. 
                               P =  ...  ..
                                              .   . 
                                      0   · · · P(r)

where forp     each u = 1,P. . . , r, P(u) = (pij (u); i, j ∈ J(u)) is the matrix defined by
pij (u) = △ti △tj / j∈J(u) △tj . Hence, U = (I − P)V, and since for each u =
1, . . . , r, P(u) is an idempotent matrix having rank 1, the matrix P is idempotent
as well and has rank r. Consequently, I − P is idempotent and has rank m − r. It
follows from Theorem 3.5.1 in Serfling (1980) that kUk2 has χ2 distribution with
m − r degrees of freedom and non-centrality parameter µ(I − P)µt , where
                              q                       q
                       µ = (δ1 △t1 /λu(1) , . . . , δm △tm /λu(m) )

and for each i ∈ {1, . . . , m}, u(i) is the unique integer in {1, . . . , r} such that
i ∈ J(u(i)). Since µt (I − P)µ = k(I − P)µk2 = kµk2 − kPµk2 , the proof is
complete.


    The corollary below is useful to test the hypothesis whether a Poisson process
is homogeneous or not.

                                       Revista Colombiana de Estadística 34 (2011) 421–432

428                                                        Raúl Fierro   Alejandra Tapia

Corollary 2. Let λ   e = Pm λj /m, (δ1 , . . . , δm ) ∈ Rm such that Pm δi = 0 and
                            j=1                                       j=1
H(k) be the statistical hypothesis defined as
                                                                 √
                                                         e + δi / k
                        H(k) : ∀i ∈ {1, . . . , m}, λi = λ

   Then, under H(k) , −2 log(Rk ) has noncentral asymptotically χ2 distribution
with m − 1 degrees of freedom and noncentrality parameter
                               m
                                     "     Pm            #2
                        2   1X                j=1 δj △tj
                      Φ =        △ti δi − Pm
                            e
                            λ                  j=1 △tj
                                 i=1

Note 1. A natural application of the foregoing theorem is to calculate the ap-
proximate power of the test relative to
                       H0 : ∀u ∈ {1, . . . , r}, ∀i ∈ J(u), λi = λu
against the simple alternative
                       H1 : ∀u ∈ {1, . . . , r}, ∀i ∈ J(u), λi = λ∗i

    Suppose that the critical region is {−2 log(Rk ) > t0 }, where t0 has been cal-
culated for a level of significance α based upon the null hypothesis asymptotic
χ2 −distribution of −2 log(Rk ).
                               √
    We interpret δi in H(k) as k(λ∗i − λu ) and approximate the power of the test
by means of the probability of {χ2 > t0 }, where χ2 is a random variable having
χ2 −distribution with m − r degrees of freedom and noncentrality parameter
                          r
                                          "     P                #
                                                               ∗ 2
                        X     1 X                  j∈J(u) △tj λj
                  2
                Φ =k                  △ti λi − P
                                             ∗

                        u=1
                             λu                     j∈J(u) △tj
                                  i∈J(u)

Note 2. By the standard Central Limit Theorem, for m − r and k large enough,
−2 log(Rk ) has approximate normal distribution with mean m − r and variance
2(m − r).
    Based on Theorem 1, an asymptotically maximum likelihood test, for testing
H0 , according to (1), against local alternatives, can be stated. An important
property of a test is its power optimality. The following proposition allows to
conclude the above-mentioned test is asymptotically uniformly most powerful.
Proposition 2. Let B(R) be the Borel σ-algebra of subsets of R and for each ν ≥ 0,
Pν be the probability distribution on (R, B(R)) corresponding to the χ2 −distribution
with g degrees of freedom and noncentrality parameter ν. For testing H : ν = 0
against K : ν > 0, the test defined by the critical region [tα , ∞), where P0 ([tα , ∞)) =
α, is uniformly most powerful.

Proof . The probability density function corresponding to the χ2 −distribution
with g degrees of freedom and noncentrality parameter ν is given by
                                                              
                      xg/2−1 e−(x+ν)/2     X∞
                                                (νx/4)j Γ(g/2) 
        f (x, g, ν) =                    1+                      I]0,∞[ (x)
                         2g/2 Γ(g/2)        j=1
                                                 j!Γ(j + g/2)


                                       Revista Colombiana de Estadística 34 (2011) 421–432

Homogeneity for Poisson Processes                                                          429

   Hence, for each x ≥ 0, we have f (x, g, ν) = f (x, g, 0)G(x, g, ν), where
                                                               
                                            X∞          j
                                                (νx/4) Γ(g/2) 
                  G(x, g, ν) = e−ν/2 1 +
                                            j=1
                                                 j!Γ(j + g/2)

   Let A = [tα , ∞[ and B be a Borelian subset of R such that P0 (B) = α. We
need to prove, for each ν ≥ 0, Pν (A) ≥ Pν (B).
   We have
                     Z                                     Z
 Pν (A) − Pν (B) =            f (x, g, 0)G(x, g, ν) dx −            f (x, g, 0)G(x, g, ν) dx
                      A∩B c                                A c ∩B

and since G is increasing at the first variable, we derive
                                    Z                        Z                             
  Pν (A) − Pν (B) ≥ G(tα , g, ν)             f (x, g, 0) dx −                 f (x, g, 0) dx
                                         A∩B c                       A c ∩B

                     =   G(tα , g, ν)(P0 (A) − P0 (B))
                     =   0

   Therefore, the proof is complete.
Corollary 3. Let H0 and H(k) be the statistical hypotheses defined by (1) and (3),
respectively. For testing H0 against H(k) with a significance level α, (0 < α < 1),
the test defined by the critical region {−2 log(Rk ) > tα } is asymptotically uniformly
most powerful, where tα > 0 is determined by

                           lim Pr(−2 log(Rk ) > tα ) = α.
                           k→∞



5. An Example
    Let us suppose in a call center there are k employees in charge of state con-
nections. The call number is recorded from 10.00 am to 1.00 pm every day during
a seven-day period. It is possible to assume the number of phone connections
made for each server follows a Poisson process and that these k Poisson processes
are independent. For this purpose, it is assume the end of a working day agrees
with the beginning of the next day. Even though people usually go for a walk on
Saturday and Sunday, it is suspected that on weekends this number decreases due
to people are not working. To find out this circumstance, the null hypothesis is
defined as “H01 : the call rates are every day the same”. From Corollary 4.1, in this
case, −2 log(Rk ) has asymptotically χ2 -distribution with six degrees of freedom.
Another test could be stated by defining the null hypothesis as “H02 : the call rates
from Monday to Friday are the same, and the Saturday call rate equals the Sun-
day one”. In this last case, there are two groups J(1) and J(2) and consequently,
−2 log(Rk ) has asymptotically χ2 -distribution with five degrees of freedom.
    In order to compare both tests, we simulate k = 10 copies of Poisson process
and test H01 and H02 with the same data set. The call rate corresponding to the

                                       Revista Colombiana de Estadística 34 (2011) 421–432

430                                                                Raúl Fierro   Alejandra Tapia

working days was assumed to be 50 calls/hour, and the call rate on Saturday and
Sunday was assumed to be 45 calls/hour. Both hypothesis tests were performed
105 times with a level of significance α = 0.05, and as result of this simulation,
H01 and H02 were rejected 96.6% and 4.95%, respectively, which illustrates the
test and gives an insight of its power.


6. Variate Generation
    The cumulative intensity function for a NHPP is often estimated for simulating
the NHPP. A number of methods for carrying out this simulation are described
in Lewis   Shedler (1979), where the simulation method for a NHPP by thinning
is stated. In this section, our purpose is not to give detailed variate generation
algorithms, but to give an estimation of the cumulative intensity function based on
cu (u = 1, . . . , r), which are, under H0 , estimators containing sufficient informa-
λ
tion for the parameters λ1 , . . . , λm . To this end, an estimator for the cumulative
intensity function is defined and the basis of variate generation by inversion is
recalled.
   For each t ≥ 0, let i(t) denote the unique i ∈ {1, . . . , m} satisfying t ∈ Qi(t) ,
where Q1 = [t0 , t1 ] and Qi = (ti−1 , ti ] for j ∈ {2, . . . , m}. By writing U (t) = {u :
∃i ≤ i(t), i ∈ J(u)} and V (u, t) = {j ∈ J(u) : j < i(t)}, the cumulative intensity
                                               Rt
function Λ : [0, T ] → R defined as Λ(t) = 0 λ(u) du satisfies
                             X        X
                   Λ(t) =                      λj △tj + λi(t) (t − ti(t)−1 )
                            u∈U(t) j∈V (u,t)


    Let ui denote the unique u ∈ {1, . . . , r} such that i ∈ J(u) and define u(t) =
ui(t) . Under H0 , we have
                              X              X
                    Λ(t) =            λu               △ti + λu(t) (t − ti(t) )
                             u∈U(t)        i∈V (u,t)


                                       b where for t ≥ 0,
   Consequently, Λ can be estimated by Λ,
                              X              X
                    b =
                    Λ(t)              cu
                                      λ                      [
                                                       △ti + λu(t) (t − t
                                                                          i(t) )
                             u∈U(t)        i∈V (u,t)


    Following Leemis (2004), a realization of a Poisson process for modeling in a
discrete-event simulation can be generated, under H0 , by inversion. Let
                         (
                                        b ≥ u} if u ≤ Λ(T
                            inf{t > 0 : Λ(t)               b )
                 b
                 Ψ(u)  =
                                    +∞                     b )
                                                  if u > Λ(T

    Note that for each u ≥ 0, Λ(       b
                                    b Ψ(u)) = u, almost everywhere, and consequently,
if S1 , S2 , . . . are the points in a homogeneous Poisson process of rate one (which

                                           Revista Colombiana de Estadística 34 (2011) 421–432

Homogeneity for Poisson Processes                                                        431

                                           b 1 ), Ψ(S
                                  b then Ψ(S
have been chosen independently of Λ),              b 2 ), . . . are the points in a
nonhomogeneous Poisson process with cumulative intensity function Λ.   b This fact
enables us to generate NHPP event times starting from standard Poisson random
variate generation.
    According to Henderson (2003), at the beginning of Section 3, pages 379-380,
for a general rate function, a faster generation procedure of NHPP event times is
obtained by thinning. This method for simulating the NHPP was introduced by
Lewis   Shedler (1979) and it is based on an estimator of the rate function λ.
Under H0 , a maximum likelihood estimator for λ is given by λ,   b which is defined
for t ≥ 0 as
                                  X r     X
                          b
                          λ(t) =      cu
                                      λ        I(ti−1 ,ti ] (t).
                                     u=1    i∈J(u)

Recall that thinning first generates a candidate event time T ∗ , and then accepts
                                 b ∗ )/λ∗ , where λ∗ is an upper bound of λ. The
the event time with probability λ(T
novelty here is that in this case, thinning is based on the estimators λ    c1 , . . . , λ
                                                                                         cr ,
                                                             1           r
which, as pointed out before, are sufficient statistics for λ , . . . , λ .


7. Conclusions and Recommendations
    In this paper we carry out a hypothesis test that allows us to find out whether
or not a NHPP could be considered homogeneous in certain time intervals. Such
an inquiry becomes very important when it is assumed that the rate function is a
piecewise constant on subintervals of the time. Indeed, when there exists a great
non-homogeneity and an approximated piecewise constant rate function has to be
defined, it is necessary to partition the time interval in many subintervals. How-
ever, if homogeneity is observed in a large subset (which need not be connected) of
the time horizon, a lesser number of subintervals will be necessary and an economy
of computational time and/or memory to store the information could be obtained.
On the other hand, under the null hypothesis, the estimators of the constant val-
ues of the intensity function are expressed in terms of sufficient statistics, which
enables us to make use of the whole information provided by the data. This fact
is particularly important for generating Poisson variates by inversion or thinning
procedure.


Acknowledgements
   This work was partially supported by Dirección de Investigación e Innovación
de la Pontificia Universidad Católica de Valparaíso under projects 124.722/2010
and 037.335/2011. The authors also thank the editor and referees for their helpful
suggestions and corrections.
                                                                   
                Recibido: octubre de 2010 — Aceptado: abril de 2011


                                        Revista Colombiana de Estadística 34 (2011) 421–432

432                                                   Raúl Fierro   Alejandra Tapia

References
Arkin B L, Leemis L M. Nonparametric estimation of the cumulative intensity function for a nonhomogeneous Poisson process from overlapping realizations.(2000). Management Science.
Fierro R. Test of homogeneity for some population models based on counting processes.(2008).Communications in Statistics - Theory and Methods.
Henderson S G.Estimation for nonhomogeneous Poisson processes from aggregated data.(2003). Operation Research Letters.
Karr A F. Point Processes and their Statistical Inference.(1991). Marcel Dekker.
Kuhl M E, Wilson J R. Least square estimation of nonhomogeneous Poisson processes.(2000). Journal of Statistical Computation and Simulation.
Kuhl M E, Wilson J R, Johnson M A. Estimating and simulating Poisson processes having trends or multiple periodicities.(1997).IIE Transactions.
Leemis L M. Nonparametric estimation of the cumulative intensity function for a nonhomogeneous Poisson process. (1991). Management Science.
Leemis L M. Nonparametric estimation and variate generation for a nonhomogeneous Poisson process from event count data. (2004). IIE Transactions.
Lehmann E L. Elements of Large-Sample Theory.(1999). Springer-Verlag.
Lewis P A W, Shedler G S. Simulation of nonhomogeneous Poisson process by thinning.(1979). Naval Research Logistics.
Neyman J. Contribution to the theory of the χ2 test.(1949).Berkeley Symposium on Mathematical Statistics and Probability.
Roberts S W. A comparison of some control chart procedures.(1966). Technometrics.
Serfling R J. Approximation Theorems of Mathematical Statistics.(1980). Wiley and Sons.
Shiryaev A N. On optimum methods in quickest detection problems.(1963). Theory Probability and Its Applications.