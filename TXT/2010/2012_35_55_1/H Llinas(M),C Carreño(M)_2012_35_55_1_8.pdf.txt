The Multinomial Logistic Model for the Case in which the Response Variable Can Assume One of Three Levels and Related Models.  El modelo logístico multinomial para el caso en que la variable de respuesta puede asumir uno de tres niveles y modelos relacionados
Universidad del Norte, Barranquilla, Colombia.  Corporación Universitaria Americana, Barranquilla, Colombia
Abstract
The aim of this work is to examine multinomial logistic models when the response variable can assume three levels, generalizing a previous work of logistic models with binary response variables. We also describe some related models: The null, complete, and saturated models. For each model, we present and prove some theorems concerning to the estimation of the corresponding parameters with details that we could not find in the current literature.
Key words: Binomial distribution, Logistic model, Multinomial logit.
Resumen
El objetivo de este trabajo es examinar los modelos de regresión logística multinomial cuando la variable de respuesta puede asumir tres niveles, generalizando un trabajo anterior con variables respuesta binarias. También describimos algunos modelos relacionados: los modelos nulo, completo y saturado. Para cada modelo, presentamos y demostramos teoremas relacionados con la estimación de los parámetros correspondientes con detalles que no fueron posibles encontrar en la literatura.
Palabras clave: distribución binomial, logit multinomial, modelo logístico.

1. Introduction

    Llinás (2006) studied logistic models with a dichotomous response variable.
A theorem was proved on the existence and uniqueness of maximum likelihood
(ML) estimations for the logistic model and also about its calculations. Addition-
ally, based on asymptotic theory for these ML-estimations and the score vector,
approximations were found for different deviations −2 log L, where L is the likeli-
hood function. Based on these approximations, statistics were obtained for several
hypothesis tests, each with an asymptotic chi-squared distribution. The asymp-
totic theory was developed for the case of independent, non-identically distributed
variables; thus, modifications are required to apply this theory to the case of iden-
tically distributed variables. In this article, a distinction is always made between
grouped data and ungrouped data.
    Applications of the multinomial logistic model in various fields of engineering
and health sciences have made this technique as a fundamental tool for data anal-
ysis and subsequent decision making. For this reason firstly, it is important to
clarify the theoretical foundations of these models so that they can be applied to
specific situations within the data analysis process, which requires more than the
use of a statistical program.
    We will present to the reader the theoretical background of this model in an
effort to describe the continuity of its construction and the elements that are used
to perform different analyses with respect to hypothesis tests, relative risks, odds,
odds ratios, etc.
    For this reason, and following the methodology proposed by Llinás (2006), this
article studies multinomial logistic models only for the case in which the variable
of interest can assume one of three levels. We describe related models, such as the
null, full, and saturated models. For each model, the estimation theorems for the
corresponding parameters are presented, providing details that are not found in
the current literature (e.g., Agresti 1990, Hosmer & Lemeshow 2000, Kleinbaum
& Klein 2002).
    The article is organized into six sections. The first section consists of a intro-
duction motivating this reason. The second section explains the basic Bernoulli
model. The third section explains the full model. The fourth section explains the
null model. The fifth section studies the saturated model and the basic assump-
tions, and the sixth section develops the theory corresponding to the multinomial
logistic model.



2. The Bernoulli Model

    Let us suppose that the variable of interest Y can assume one of three values or
levels: 0, 1 or 2. For each r = 0, 1, 2, we let pr := P (Y = r) denote the probability
that Y assumes the value r.


                                     Revista Colombiana de Estadística 35 (2012) 131–138

The Multinomial Logistic Model                                                                           133

   With n independent observations of Y , a sample Y = (Y1 , . . . , Yn )T is obtained
with data yi ∈ {0, 1, 2} for i = 1, . . . , n, in which yi is a possible value of Yi , which
are independent of one another.
   In order to construct the likelihood function, we create three independent bi-
nary variables with values of 0 and 1 as follows:
                                    
                                      1, if Yi = r
                             Uri =
                                      0, otherwise

where r = 0, 1, 2 and i = 1, . . . , n.                 Observe that Uri ∼ B(1, pri ), where
pri = P (Yi = r).
   In terms of the Uri variables, the sample variables are Yi = (U0i , U1i , U2i ), with
                                            2
                                            P
values of yi = (u0i , u1i , u2i ), in which   uri = 1, for a fixed i. A statistical model
                                               r=0
is obtained in which
                                               2
                                               Y
                              P (Yi = yi ) =         puriri ,   i = 1, . . . , n
                                               r=0


    Setting y = (y1 , . . . , yn )T , we obtain the logarithm of the likelihood function
for the 2n-dimensional parameter p = (p01 , p11 , . . . , p0n , p1n )T :
                 n
                 X
        L(p) =         [u0i ln p0i + u1i ln p1i + (1 − u0i − u1i ) ln(1 − p0i − p1i )]                   (1)
                 i=1



3. The Complete Model
   The complete model is characterized by the assumption that all pri (with
r = 0, 1, 2 and i = 1, . . . , n) are considered parameters.

Theorem 1. In the complete model, the ML-estimations of pri are Pbri = Uri with
values pbri = uri for r = 0, 1, 2 and i = 1, . . . , n. Additionally, Lc := L(y) = 0.

Proof . Consider equation (1), in which
               X                  X                                    X
    L(p) =           ln p0i +           ln p1i +                                   ln(1 − p0i − p1i ).
                    i                        i                           i
              u0i =1,u1i =0            u0i =0,u1i =1               u0i =0,u1i =0



                                !
    Consider that L(p) = 0 if and only if p0i = u0i and p1i = u1i for each
i = 1, . . . , n. This condition proves the existence of the ML-estimations. If for
some i it is true that pri 6= uri , r = 0, 1, then L(p) < 0. This condition demon-
strates that the ML-estimations are unique because if p    e is a vector that has at
least one pri component that is different from uri , then L(p) < Lc (given that
upon replacing pri = uri in L(p), Lc = 0).


                                            Revista Colombiana de Estadística 35 (2012) 131–138

134                                                      Humberto Llinás & Carlos Carreño


4. The Null Model
   The null model is characterized by the assumption that for each r = 0, 1, 2, all
the pri values (i = 1, . . . , n) are considered equal; that is, there are two parameters,
p0 and p1 . In this case, equation (1) becomes
            L(p)     =     n[u0 ln p0 + u1 ln p1 + (1 − u0 − u1 ) ln(1 − p0 − p1 )]      (2)
                   n
                   P uri
in which ur =            n .
                   i=1

Theorem 2. In the null model, the ML-estimation of pr is Pbr = U r with value
pbr = ur . Additionally, Lo := L(b
                                 p) < 0 if and only if 0 < u0 + u1 < 1.

Proof . It is clear that from equation (2) that

   • If u0 + u1 = 0, then u0 = u1 = 0. Therefore, L(p) = 0 if and only if
     pr = 0 = ur .
   • If u0 + u1 = 1, then u0 = 0 or u1 = 0. Therefore, for u0 = 0, L(p) = 0 if and
     only if p1 = 1 = u1 and u1 = 1, L(p) = 0 if and only if p0 = 1 = u0 .
   • Now let us assume that 0 < u0 + u1 < 1. From equation (2) and for a given
     r, it can be proven that
                                 ∂L(p)   ur   1 − u0 − u1
                                       =    −             = 0
                                  ∂pr    pr   1 − p0 − p1
        if and only if pbr = ur . Given that
                           ∂ 2 L(b
                                                                   
                                 p)        ur      1 − u0 − u1
                                    =  −        −                     < 0
                             ∂p2r          pb2r   (1 − pb0 − pb1 )2
        this solution is unique. Additionally, ln ur and ln(1 − u0 − u1 ) are both
        negative. Therefore, Lo < 0.


5. The Saturated Model and Assumptions
      The saturated model is characterized by the following assumptions:
Assumption 1. It is assumed that:

   1. There are K explanatory variables X1 , . . . , XK (some may be numerical and
      other may be categorical) with values x1i , . . . , xKi for i = 1, . . . , n (which
      are set or observed by the statistician depending on whether the variables
      are deterministic or random);
   2. Among the n individual vectors (x1i , . . . , xKi ) of the values of the explana-
      tory variables Xs, there are J different possible combinations, defining J
      populations. Therefore, J ≤ n. J is often referred to as the number of
      covariate patterns in the applied literature.

                                          Revista Colombiana de Estadística 35 (2012) 131–138

The Multinomial Logistic Model                                                                135

Notation. The notation for each population j = 1, . . . , J is denoted as follows:

   • The number of Yij observations (or of Urij observations in the r category)
     in each jth population is nj , with n1 + · · · + nJ = n;

   • For a fixed r = 0, 1, 2; the random variable corresponding to the sum of the
                                               nj
                                               P                        nj
                                                                        P
     nj observations of Urij , given by Zrj :=    Urij with value zrj =    urij , in
                                                        i=1                             i=1
              J
              P             n
                            P
      which         zrj =         uri .
              j=1           i=1


   For simplicity, the jth population (x1j , . . . , xKj ) will be abbreviated with the
symbol ?.
Assumption 2. For each fixed r = 0, 1, 2, each population j = 1, . . . , J and each
observation i = 1, . . . , n in population j, it is assumed that

   • (Urij | ?) ∼ B(1, prj )

   • The (Urij | ?) variables are independent of one another.

   Below, the ? symbol will be omitted. Assumption 2 implies the following:

  1. For each r = 0, 1, 2 and each fixed j = 1, . . . , J, all the prij , i = 1, . . . , n, in
     each jth population are equal.                  In other words, the 2J-dimensional
     p = (p01 , p11 , . . . , p0J , p1J )T vector is the parameter.

  2. For each r = 0, 1, 2 and each population j = 1, . . . , J:

         • Zrj ∼ B(nj , prj )
         • The Zrj variables are independent among populations.

In the saturated model, the logarithm of the maximum likelihood function will be

              J
              X
    L(p) =          [z0j ln p0j + z1j ln p1j + (nj − z0j − z1j ) ln(1 − p0j − p1j )]          (3)
              j=1

                                                                        Z
Theorem 3. In the saturated model, the ML-estimations of prj are Perj = nrjj ,
                       z
with the values perj = nrjj , j = 1, . . . , J. Furthermore,

            J
            X
   L(e
     p) =             p0j ln pe0j + pe1j ln pe1j + (1 − pe0j − pe1j ) ln(1 − pe0j − pe1j )]
                  nj [e                                                                       (4)
            j=1


   It also holds that Ls := L(e
                              p) < 0 for 0 < perj < 1.


                                           Revista Colombiana de Estadística 35 (2012) 131–138

136                                                             Humberto Llinás & Carlos Carreño


Proof . Let us hold r and j. If 0 < perj < 1, then we have

                                ∂L    zrj   nj − z0j − z1j
                                    =     −                =0
                               ∂prj   prj   1 − p0j − p1j
                       z
if and only if perj = nrjj . Therefore, if 0 < zrj < nj , for each r and j, then we have
                                                 "                           #
                      ∂2L                    n2j         n2j
                                          =−     +                               <0
                      ∂p2rj                  zrj   nj − z0j − z1j
                                   prj
                              prj =e

      Two extreme cases must be analyzed:
                         ∂L                  n
    • If zrj = 0, then ∂p  rj
                              = − 1−p0jj−p1j decreases in pj . In this case, L decreases
      in prj ; that is, L(p) is maximized for prj = 0.
                          ∂L           n
    • If zrj = nj , then, ∂p j
                               = pjj increases in prj . In this case, L increases in prj ;
      that is, L(p) is maximized for prj = 1.

    In the saturated model, the value of L can be obtained by replacing in equation
(3), each prj with perj , j = 1, . . . , J. Thus, we obtain equation (4). Under the
condition that 0 < perj < 1 it can be shown that ln perj y ln(1 − perj ) are both
negative. Therefore, the sum of the right side of equation (4) is also negative.


6. The Multinomial Logistic Model
6.1. Assumptions
    Assumptions 1 and 2 from section 5 are preserved, with the additional assump-
tion that a matrix                                   
                                 1 x11 · · · xK1
                         C =  ...    ..          .. 
                              
                                       .           . 
                                 1 x1J · · · xKJ
has a complete range Rg(C) = 1 + K ≤ J. To obtain a logistic model, one of
the categories of the dependent variable Y , such as 0, is used as a reference. The
following additional assumption is also made:
Assumption 3.
                                     
                                 p1j
                 g1 (xj ) = ln         = δ1 + β11 xj1 + · · · + β1K xjK                      (5)
                                 p0j
                                    
                                 p2j
                 g2 (xj ) = ln         = δ2 + β21 xj1 + · · · + β2K xjK                      (6)
                                 p0j

in which xj := (1, xj1 , . . . , xjK )T . Let

                           α = (δ1 , β11 , . . . , β1K , δ2 , β21 . . . , β2K )T


                                              Revista Colombiana de Estadística 35 (2012) 131–138

The Multinomial Logistic Model                                                       137

denote the vector of the 2(1 + K) parameters in the model. Note that the assump-
tion that Rg(C) = 1 + K allows the α parameter to be identified.
    For a given observation xj in population j and for the so-called risk is calculated
as follows:
                                      exp{gr (xj )}
                             prj =   2
                                                                                     (7)
                                     P
                                        exp{gs (xj )}
                                     s=0

for each r = 0, 1, 2 and with g0 (xj ) = 0. The logarithm of the likelihood function
can be written as a function of α, as follows:
           J
             "                                                 2
                                                                              !#
          X                                                    X
 L(α) =        z1 g1 (xj ) + (nj − z0j − z1j )g2 (xj ) − nj ln   exp{gr (xj )}   (8)
          j=1                                                 r=0



6.2. Relation between the Multinomial Logistic Model and
     the Saturated Model
   The equations of assumption 3 in Section 6.1 can be written in a vector form,
where g r = Cβ r , r = 1, 2, in which g r is a J-dimensional vector with elements
g(xj ), j = 1, 2, . . . , J.
   Given the above, the following cases can be highlighted:

Case 1. J = 1 + K
    In this case, C is an invertible matrix. Therefore,
                                  βr = C −1 gr ,   r = 1, 2

      That is, there is a one-to-one relationship between the parameters of the
      saturated model and those of the logistic model. In other words, the two
      models express the same thing.
      Particularly, the ML-estimations of the probabilities prj are equal in both
      models: pbrj = perj for each j = 1, 2, . . . , 1 + K.
Case 2. J > 1 + K
                  b must first be calculated, and based on these values, the prj
    In this case, α
    values can be calculated. In general, we observe that pbrj 6= perj .


7. Likelihood Equations
   The likelihood equations are found by calculating the first derivatives of L(α)
with respect to each one of the 2(1 + K) unknown parameters, as follows. For
every k = 0, 1, . . . , K, we have
                    J                                            J
                                      nj xjk eg1 (xj )
                                                             
    ∂L(α)        X                                               X
             =           z1j xjk −                             =     xjk (z1j − nj p1j )
     ∂β1k         j=1
                                   1 + eg1 (xj ) + eg2 (xj )     j=1


                                      Revista Colombiana de Estadística 35 (2012) 131–138

138                                                      Humberto Llinás & Carlos Carreño


and
                   J 
                                                  nj xjk eg2 (xj )
                                                                         
          ∂L(α) X
                =      (nj − z0j − nz1j )xjk −
           ∂β2k   j=1
                                               1 + eg1 (xj ) + eg2 (xj )
                      J
                      X
                  =         xjk [(nj − z0j − z1j ) − nj p2j ]
                      j=1
                      J
                      X
                  =         xjk (z2j − nj p2j )
                      j=1


    Therefore, for every k = 0, 1, . . . , K and every r = 0, 1, 2, the likelihood equa-
tions are given by
                                           J
                           ∂L(α) X
                                    =        xjk (zrj − nj prj )
                            ∂βrk         j=1

   The estimator of maximum likelihood is obtained by setting these equations
equal to zero and solving for the logistic parameters. The solution requires the
same type of iterations that were used to obtain the estimations in the binary case,
as demonstrated in Llinás (2006).


8. Conclusions
    We have studied the multinomial logistic models when the response variable
can assume one of three values and also described some related models such as the
null, complete, and saturated models. We have presented and proved the theorems
1, 2 and 3, which give us the estimation of the corresponding parameters.
                                                                  
               Recibido: junio de 2011 — Aceptado: febrero de 2012


References
Agresti, A. (1990), Categorical Data Analysis, 2 edn, John Wiley and Sons, Inc., New York.
Hosmer, D. & Lemeshow, S. (2000), Applied Logistic Regresssion, 2 edn, John Wiley and Sons, Inc., New York.
Kleinbaum, D. & Klein, M. (2002), Logistic Regression: A Self-Learning Text, 2 edn, Springer, New York.
Llinás, H. (2006), ‘Precisiones en la teoría de los modelos logísticos’, Revista Colombiana de Estadística 29(2), 239–265.
