Entropy Estimation From Ranked Set Samples With Application to Test of Fit. EstimaciÃ³n de entropÃ­a de muestras de rango ordenado con aplicaciÃ³n a pruebas de ajuste
University of Isfahan, Isfahan, Iran. Hakim Sabzevari University, Sabzevar, Iran
Abstract
This article deals with entropy estimation using ranked set sampling (RSS). Some estimators are developed based on the empirical distribution function and its nonparametric maximum likelihood competitor. The suggested entropy estimators have smaller root mean squared errors than the other entropy estimators in the literature. The proposed estimators are then used to construct goodness of t tests for inverse Gaussian distribution.
Key words Judgment ranking, Goodness of t test, Entropy estimation.
Resumen
Este artÃ­culo trata sobre la estimaciÃ³n de entropÃ­a usando muestras de rango ordenado (RSS). Algunos estimadores se desarrollan con base en distribuciones empÃ­ricas y si estimaciÃ³n no paramÃ©trica de mÃ¡xima verosimilitud. Los estimadores de entropÃ­a sugeridos tienen menor raÃ­z del error de cuadrados medios que otros reportados en literatura. Los estimadores propuestos son usados para construir pruebas de bondad de ajuste para distribuciones inversas Gaussianas.
Palabras clave Bondad de ajuste, EstimaciÃ³n de entropÃ­a, Ranking de juicios.
 
1. Introduction

   In situations where exact measurements of sample units are expensive or dif-
cult to obtain, but ranking them (in small sets) is cheap or easy, ranked set
sampling (RSS) scheme is an appropriate alternative to simple random sampling
(SRS). It often leads to improved statistical inference as compared with SRS. This
sampling strategy was proposed by McIntyre (1952) for estimating the mean of
pasture yield. He noticed that while obtaining exact value of yield of a plot is
dicult and time-consuming, one can simply rank adjacent plots in terms of their
pasture yield by eye inspection. The RSS scheme can be described as follows:

   1. Draw a simple random sample of size k 2 from the population of interest, and
      then partition them into k samples of size k .

   2. Rank each sample of size k in an increasing magnitude of the variable of
      interest without obtaining precise values of the sample units. The Ranking
      process in this step can be done based on personal judgement, eye inspection
      or using a concomitant variable, and need not to be accurate.

   3. Actually obtain the exact measurement of the unit with rank r in the rth
      sample (for r = 1, . . . , k ).

   4. Repeat steps (1)-(3), n times (cycles) to draw a ranked set sample of size
      N = nk .

Let X[r]s : r = 1, . . . , k; s = 1, . . . , n be a ranked set sample of size N = nk ,
     

where X[r]s is the rth judgement ordered unit from the sth cycle. The term judge-
ment order implies that the ranking process in step 2 in the above is done without
referring to precise values of the sample units, and therefore it may be inaccurate
(imperfect). Thus, the rthe judgement ordered unit and the true rth ordered unit
may be dierent. Note that all sample units in the RSS scheme are independent,
but not identically distributed. For r = 1, . . . , k , X[r]1 , . . . , X[r]n are independent
and identically distributed sample units, and they follow the distribution of the
rth judgement order statistic in a sample of size k . In the sequel, the subscript [Â·]
in X[r]s is used to indicate that ranking process that may not be perfect. In the
case of perfect ranking (i.e. the ranking process in step 2 in the above is accurate),
we replace [Â·] by (Â·) in the subscript of X[r]s .
    It should be noted that the application of RSS scheme is not limited to agri-
cultural problems. It can be applied in any situations where ranking observa-
tions are much easier than measuring them. Some other potential applications
of RSS scheme are in forestry (Halls and Dell, 1966), medicine (Chen, Stasny &
Wolfe 2005), environmental monitoring (Nussbaum & Sinha 1997, Kvam 2003, Oz-
turk, Bilgin & Wolfe 2005) and entomology (Howard, Jones, Mauldin & Beal 1982).
      The RSS estimator of the population mean is given by
                                               k   n
                                           1 XX
                               X RSS =               X[r]s .
                                          nk r=1 s=1


                                        Revista Colombiana de EstadÃ­stica 40 (2017) 223241

Entropy Estimation From Ranked Set Samples With Application to Test of Fit              225

   There has been a lot of research in RSS scheme since its introduction. Takahasi
& Wakimoto (1968) proved the X RSS is an unbiased estimator of the population
mean and has less variance than X SRS , the sample mean in SRS scheme. The
problem of variance estimation in RSS scheme has been considered by Stokes
(1980), MacEachern, Ozturk, Wolfe & Stark (2002), Perron & Sinha (2004) and
Zamanzade & Vock (2015). The empirical distribution function (EDF) in RSS
scheme is given by
                                       k  n
                                   1 XX
                                                                               (1)
                                                        
                       FÌ‚em (t) =            I X[r]s â‰¤ t .
                                  nk r=1 s=1

    Stokes & Sager (1988) proved that this estimator is unbiased and has smaller
variance than the EDF in SRS scheme for a xed total sample size (N ), regardless
of ranking errors. It can bee seen that as n â†’ âˆž,
                       âˆš                   
                                              d       2
                                                         
                         nk FÌ‚em (t) âˆ’ F (t) â†’ N 0, Ïƒem    ,

       d
where â†’ indicates convergence in distribution,
                                      k
                            2      1X                         
                           Ïƒem =         F[r] (t) 1 âˆ’ F[r] (t) ,
                                   k r=1

and F[r] is cumulative distribution function (CDF) of the rth judgement order
statistic in a sample of size k .
    Let X(r)s : r = 1, . . . , k; s = 1, . . . , n be a ranked set sample of size N = nk
         

collected under the perfect ranking assumption. Accordingly, X(r)s follows the
distribution
      Pn      of rth true order statistic in a sample of size k . For r = 1, . . . , k ,
Yr = s=1 I X(r)s â‰¤ t has a binomial distribution with mass parameter n, and
success probability Br,k+1âˆ’r (F (t)), where
                                        Z F (t)  
                                                 k râˆ’1         kâˆ’r
                 Br,k+1âˆ’r (F (t)) =            r    y  (1 âˆ’ y)     dy
                                         0       r

is CDF of beta distribution with parameters r and k + 1 âˆ’ r computed at the point
F (t). Thus, the log-likelihood function of (Y1 , . . . , Yn ) can be written as
                                n
                                X
               L (F (t))   =          Yr log {Br,k+1âˆ’r (F (t))}
                                r=1
                                Xn
                           +          (n âˆ’ Yr ) log {1 âˆ’ Br,k+1âˆ’r (F (t))} .
                                r=1


  It can be shown that L (F (t)) is strictly concave in F (t). Therefore, the
maximum likelihood estimator of CDF is dened as

                               FÌ‚L (t) =     max         L (F (t)) .                    (2)
                                           F (t)âˆˆ[0,1]


                                         Revista Colombiana de EstadÃ­stica 40 (2017) 223241

226                                                     Ehsan Zamanzade & M. Mahdizadeh

This estimator was introduced by Kvam & Samaniego (1994), and its asymptotic
behavior was studied by Huang (1997), and Duembgen & Zamanzade (2013). As
n â†’ âˆž, we have
                       âˆš                 
                                            d      2
                                                     
                        nk FÌ‚L (t) âˆ’ F (t) â†’ N 0, ÏƒL   ,

where
                               k                 2
                                                              !âˆ’1
                        2
                               X                f(r) (t)
                       ÏƒL =k                                       ,
                               r=1
                                     F(r) (t) 1 âˆ’ F(r) (t)

and f(r) (t) is the probability density function (pdf) of rth order statistic in a
sample of size k .
   It can be shown that ÏƒL 2      2
                              â‰¤ Ïƒem , and therefore FÌ‚L is asymptotically more
ecient than FÌ‚em under perfect ranking assumption.
    Several variations of the RSS design have been developed to facilitate ecient
estimation of the population parameters. For example, Samawi, Abu-Daayeh &
Ahmed (1996) proposed extreme ranked set sampling to decrease the ranking error.
He showed that the sample mean in extreme ranked set sampling is unbiased, and
outperforms its counterpart in SRS of the same size. Muttlak (1996) proposed
pair ranked set sampling to reduce the number required observations for ranking
in RSS scheme by half. Median ranked set sampling has been proposed by Muttlak
(1997), and it was shown that the corresponding mean estimator is more ecient
that X RSS for symmetric distributions. Haq, Brown, Moltchanova & Al-Omari
(2014) proposed mixed ranked set sampling design to mix both SRS and RSS
designs.
    In Section 2, we propose some nonparametric estimators for entropy in RSS
scheme. We then compare dierent entropy estimators via Monte Carlo simulation.
In Section 3, we employ the proposed entropy estimators in developing entropy
based tests of t for inverse Gaussian distribution. We then compare the powers
of the proposed tests with their rivals in the literature. A real data example is
presented in Section 4. We end with a conclusion in Section 5.


2. Estimation of Entropy in SRS and RSS Schemes

      The entropy of a continuous random variable X is dened by Shannon (1948)
as                                  Z âˆž
                         H (f ) = âˆ’     log (f (x)) f (x) dx.               (3)
                                         âˆ’âˆž

Since the notion of entropy has wide applications in statistics, engineering and
information sciences, the problem of estimation of H (f ) has been frequently ad-
dressed by many researchers. Vasicek (1976) was the rst who proposed to estimate
H (f ) based on spacings. He noted that equation (3) can be rewritten as

                                                    d âˆ’1
                                    Z 1                    
                         H (f ) =         log          F (p) dp.                        (4)
                                     0              dp

                                         Revista Colombiana de EstadÃ­stica 40 (2017) 223241

Entropy Estimation From Ranked Set Samples With Application to Test of Fit           227

Vasicek (1976) suggested to estimate equation (4) by using the EDF and applying
dierence operator instead of dierential operator.
    Let X1 , . . . , XN be a simple random sample of size N from a population of the
interest. The Vasicek's (1976) entropy estimator is given by
                              N                              
                          1 X             N
                                                                                     (5)
                                                            
                   HV =         log          X(i+m) âˆ’ X(iâˆ’m) ,
                          N i=1           2m

where X(1) , . . . , X(N ) are ordered values of the simple random sample, m â‰¤ N2 is
an integer which is called window size, X(i) = X(1) for i < 1, and X(i) = X(N ) for
i > N.
    Ebrahimi, Habibullah & Soo (1994) modied Vasicek's (1976) entropy esti-
mator by assigning less weights to the observations at the boundaries in equation
(5) which are replaced by X(1) and X(N ) . Their proposed estimator has the form

                              N                                
                          1 X              N
                                                                                     (6)
                                                              
                   HE =         log            X(i+m) âˆ’ X(iâˆ’m) ,
                          N i=1           ci m

where                      ï£±
                                 iâˆ’1
                           ï£²1 + m
                           ï£´               1â‰¤iâ‰¤m
                       ci = 2              m+1â‰¤iâ‰¤nâˆ’m.
                             1 + nâˆ’i
                           ï£´
                                           nâˆ’m+1â‰¤iâ‰¤n
                           ï£³
                                  m

Simulation results of Ebrahimi et al. (1994) showed that HE has smaller bias and
mean square error (MSE) than Vasicek's (1976) entropy estimator.
   Another modication of Vasicek's (1976) entropy estimator has been proposed
by Correa (1995). He noted that equation (5) can be rewritten as
                                  N
                                          (                     )
                           1 X                X(i+m) âˆ’ X(iâˆ’m)
                      HV =       log             i+m   iâˆ’m
                                                                    .
                           N i=1                  N âˆ’ N

The inside of the brackets in the above    equation is the slope of the straight line
which joins the points X(i+m) , i+m     and  X(iâˆ’m) , iâˆ’m  . Correa (1995) suggested
                                      
                                   N                   N
to estimate this slope by local linear regression and using all 2m + 1 points instead
of only two points. His suggested entropy estimator has the form
                           N
                                  ( Pi+m                          )
                        1 X            j=iâˆ’m X(j) âˆ’ X (i) (j âˆ’ i)
                HC =          log        Pi+m                  2    ,             (7)
                       N i=1          N j=iâˆ’m X(j) âˆ’ X (i)
                     Pi+m
where X (i) = 2m+1
                1
                       j=iâˆ’m X(j) .
  Correa's (1995) simulation results indicate that HC generally produces less
MSE than HV .
  The problem of entropy estimation in RSS scheme has been considered by
Mahdizadeh & Arghami (2009). Let X[r]s : r = 1, . . . , k; s = 1, . . . , n be a ranked
                                


                                      Revista Colombiana de EstadÃ­stica 40 (2017) 223241

228                                                        Ehsan Zamanzade & M. Mahdizadeh

set sample of size N = nk with ordered values Z1 , . . . , ZN . Mahdizadeh and
Arghami (2009)'s entropy estimator is is given by

                                     N                              
                                1 X                 N
                      HM =            log              (Zi+m âˆ’ Ziâˆ’m ) ,                   (8)
                                N i=1               2m

where Zi = Z1 for i < 1, and Zi = ZN for i > N .
    Mahdizadeh & Arghami's (2009) simulation results indicate that HM is supe-
rior to its counterpart in SRS, HV . They then develop an entropy based goodness
of t test for inverse Gaussian distribution in RSS scheme. Mahdizadeh (2012)
used this entropy estimator for developing test of t for the Laplace distribution
based on a ranked set sample.
   The rst and the second estimators we propose in this paper, are motivated
by Ebrahimi et al.'s (1994) entropy estimator in SRS. Their estimator can be
rewritten as
                         N
                                (                          )
                      1 X             X(i+m) âˆ’ X(iâˆ’m)
              HE =          log                           ,
                      N i=1       Fn X(i+m) âˆ’ Fn X(iâˆ’m)
                     PN
where Fn (t) = N1     i=1 I (Xi â‰¤ t) is EDF in SRS scheme.
      Thus, an analogous entropy estimators in RSS scheme can be developed as
                                 N                                     
                              1 X                  Zi+m âˆ’ Ziâˆ’m
                      w
                     HE =           log                                     ,             (9)
                              N i=1           Fw (Zi+m ) âˆ’ Fw (Ziâˆ’m )

where w âˆˆ {em, L}, with FÌ‚em and FÌ‚L dened in (1) and (2), respectively.
   We can also modify Correa's (1995) entropy estimator to be applied in RSS
scheme. Correa's type RSS estimators of entropy have the form
                          N
                                 ( Pi2                                       )
                     1 X                 j=i1   Zj âˆ’ Z i    Fw (Zj ) âˆ’ F w (i)
             HCw =         log                   Pi2                2           ,       (10)
                     N i=1
                                                      j=i1 Zj âˆ’ Z i

                                                                  Pi2
where i1 = max{1, i âˆ’ m}, i2 = min{N, i + m}, Z i = i2âˆ’i1+1   1
                                                                     j=i1 Zj , and
                 Pi2
F w (i) = i2âˆ’i1+1 j=i1 Fw (Zj ) for w âˆˆ {em, L}. It is worth noting that HCw also
             1

modies HC at the boundaries.
    In the following of this section, we compare dierent entropy estimators by
using Monte Carlo simulation. We have generated 50,000 random samples of size
10, 20, 30 and 50 in RSS. The set size value is taken to be 2 and 5. So, we can
assess the eect of increasing total sample size (N ) for a xed set size, and also
the eect of increasing set size (k ) for a xed sample size, on the performance of
the estimators in the RSS setting. The ranking process is done by using fraction
of random ranking due to Frey, Ozturk & Deshpande (2007). In this imperfect
ranking scenario, it is assumed that the rth judgement order statistic is the true


                                           Revista Colombiana de EstadÃ­stica 40 (2017) 223241

Entropy Estimation From Ranked Set Samples With Application to Test of Fit                 229

rth order statistic with probability Î», and it is selected randomly with probability
1 âˆ’ Î». Therefore, the distribution of rth judgement order statistic is given by

                                 F[r] = Î»F(r) + (1 âˆ’ Î») F.

In this simulation study, the values of Î» are taken to be Î» = 1 (perfect ranking),
Î» = 0.8 (nearly perfect ranking), Î» = 0.5 (moderate ranking) and Î» = 0.2 (almost
random ranking). The selection of window size (m), which minimizes MSE of the
entropy estimator, is still an open problem in the entropy estimation context. We
have used the Grzegorzewski & Wieczorkowski's (1999) heuristic formula to select
m subject to N in the entropy estimators as follows
                                      hâˆš         i
                                 m=      N + 0.5 ,

where [x] is integer part of x.
    In order to compare dierent entropy estimators, we have reported the root of
mean squared error (RMSE) of dierent entropy estimators for standard uniform
(U (0, 1)), standard exponential (Exp(1)) and standard normal (N (0, 1)) distribu-
tions in Tables 1-3, respectively.


          Table 1: Power estimates of dierent entropy based tests for inverse Gaussian
          distribution for N = 20 in RSS.

 N    k     HM       em
                    HE       em
                            HC         L
                                      HE       L
                                              HC         HM       em
                                                                 HE       HCem      L
                                                                                   HE       L
                                                                                           HC
                            Î»=1                                          Î» = 0.8
 10   2     0.428   0.210    0.166    0.208   0.163      0.438   0.219    0.173    0.213   0.168
      5     0.382   0.165    0.134    0.163   0.130      0.406   0.188    0.147    0.177   0.146

 20   2     0.264   0.124    0.089    0.122   0.088      0.268   0.127    0.090    0.123   0.089
      5     0.243   0.104    0.079    0.102   0.077      0.255   0.114    0.083    0.106   0.087

 30   2     0.204   0.090    0.062    0.088   0.062      0.206   0.092    0.063    0.088   0.063
      5     0.191   0.077    0.058    0.075   0.056      0.197   0.083    0.059    0.076   0.067

 40   2     0.171   0.071    0.049    0.070   0.049      0.173   0.072    0.050    0.069   0.051
      5     0.162   0.062    0.047    0.060   0.046      0.167   0.067    0.048    0.059   0.056

 50   2     0.152   0.059    0.042    0.058   0.041      0.153   0.060    0.042    0.058   0.043
      5     0.144   0.052    0.040    0.050   0.039      0.148   0.055    0.040    0.048   0.049

 N    k     HM       em
                    HE       HCem      L
                                      HE       L
                                              HC         HM       em
                                                                 HE       HCem      L
                                                                                   HE       L
                                                                                           HC
                            Î» = 0.5                                      Î» = 0.2
 10   2     0.444   0.226    0.178    0.213   0.172      0.448   0.230    0.181    0.212   0.175
      5     0.436   0.218    0.170    0.193   0.169      0.449   0.230    0.181    0.192   0.185

 20   2     0.272   0.131    0.092    0.122   0.092      0.273   0.132    0.093    0.118   0.094
      5     0.266   0.125    0.088    0.105   0.102      0.274   0.134    0.094    0.102   0.119

 30   2     0.209   0.095    0.065    0.087   0.066      0.210   0.096    0.067    0.085 0.070
      5     0.205   0.090    0.062    0.072   0.082      0.209   0.095    0.064    0.068 0.100
                                                                                      Continued

                                           Revista Colombiana de EstadÃ­stica 40 (2017) 223241

230                                                   Ehsan Zamanzade & M. Mahdizadeh

                                       Table 1. Continued

 40   2    0.175   0.075    0.051    0.068   0.053      0.176   0.075    0.050    0.064   0.055
      5    0.173   0.072    0.049    0.055   0.072      0.176   0.075    0.051    0.053   0.092

 50   2    0.154   0.061    0.042    0.055   0.045      0.155   0.062    0.042    0.052   0.048
      5    0.152   0.059    0.042    0.044   0.066      0.155   0.062    0.042    0.044   0.086




          Table 2: Monte Carlo estimates of RMSE of dierent entropy estimators for
          Exp(1) distribution, H (f ) = 1.

 N    k    HM        em
                    HE      em
                           HC         L
                                     HE       L
                                             HC         HM       em
                                                                HE       HCem      L
                                                                                  HE       L
                                                                                          HC
                           Î»=1                                          Î» = 0.8
 10   2    0.526   0.361    0.336    0.359   0.334      0.540   0.376    0.349    0.371   0.345
      5    0.460   0.294    0.280    0.293   0.277      0.496   0.332    0.310    0.323   0.305

 20   2    0.330   0.235    0.222    0.234   0.221      0.337   0.243    0.229    0.241   0.228
      5    0.292   0.194    0.186    0.192   0.185      0.315   0.220    0.209    0.214   0.209

 30   2    0.253   0.184    0.177    0.183   0.177      0.260   0.192    0.185    0.190   0.185
      5    0.223   0.150    0.149    0.149   0.148      0.242   0.172    0.168    0.168   0.169

 40   2    0.211   0.155    0.153    0.155   0.154      0.216   0.161    0.159    0.160   0.159
      5    0.186   0.126    0.129    0.126   0.129      0.201   0.144    0.144    0.142   0.147

 50   2    0.182   0.135    0.136    0.134   0.136      0.187   0.141    0.142    0.140   0.142
      5    0.160   0.110    0.115    0.110   0.115      0.175   0.127    0.130    0.126   0.133

 N    k    HM        em
                    HE      HCem      L
                                     HE       L
                                             HC         HM       em
                                                                HE       HCem      L
                                                                                  HE       L
                                                                                          HC
                           Î» = 0.5                                      Î» = 0.2
 10   2    0.557   0.394    0.364    0.385   0.359      0.564   0.399    0.368    0.387   0.363
      5    0.539   0.375    0.348    0.358   0.342      0.558   0.394    0.363    0.370   0.359

 20   2    0.347   0.255    0.240    0.250   0.239      0.352   0.261    0.246    0.255   0.246
      5    0.337   0.246    0.233    0.236   0.237      0.354   0.262    0.245    0.247   0.252

 30   2    0.265   0.197    0.190    0.194   0.191      0.270   0.203    0.196    0.199   0.198
      5    0.260   0.192    0.185    0.185   0.192      0.270   0.202    0.194    0.194   0.209

 40   2    0.222   0.167    0.165    0.165   0.166      0.229   0.173    0.169    0.170   0.171
      5    0.217   0.162    0.160    0.158   0.168      0.226   0.171    0.167    0.167   0.185

 50   2    0.193   0.149    0.150    0.148   0.151      0.195   0.150    0.150    0.148   0.153
      5    0.188   0.141    0.142    0.140   0.152      0.195   0.149    0.149    0.151   0.170




                                          Revista Colombiana de EstadÃ­stica 40 (2017) 223241

Entropy Estimation From Ranked Set Samples With Application to Test of Fit                231

          Table 3: Monte Carlo estimates of RMSE of dierent entropy estimators for
          N (0, 1) distribution, H (f ) = 1.419.

 N    k    HM        em
                    HE      em
                           HC         L
                                     HE       L
                                             HC         HM       em
                                                                HE       HCem      L
                                                                                  HE       L
                                                                                          HC
                           Î»=1                                          Î» = 0.8
 10   2    0.603   0.389    0.331    0.386   0.328      0.608   0.394    0.336    0.386   0.329
      5    0.555   0.340    0.285    0.338   0.283      0.577   0.362    0.306    0.348   0.294

 20   2    0.368   0.242    0.202    0.240   0.201      0.372   0.245    0.205    0.241   0.201
      5    0.343   0.217    0.180    0.214   0.177      0.355   0.228    0.189    0.218   0.183

 30   2    0.278   0.182    0.154    0.181   0.154      0.280   0.184    0.156    0.181   0.154
      5    0.261   0.164    0.138    0.162   0.136      0.268   0.171    0.144    0.164   0.141

 40   2    0.228   0.147    0.128    0.146   0.128      0.229   0.149    0.129    0.146   0.128
      5    0.215   0.134    0.116    0.133   0.115      0.220   0.139    0.120    0.133   0.118

 50   2    0.195   0.125    0.112    0.125   0.112      0.197   0.127    0.113    0.125   0.112
      5    0.184   0.114    0.101    0.113   0.100      0.190   0.119    0.106    0.114   0.104

 N    k    HM        em
                    HE      HCem      L
                                     HE       L
                                             HC         HM       em
                                                                HE       HCem      L
                                                                                  HE       L
                                                                                          HC
                           Î» = 0.5                                      Î» = 0.2
 10   2    0.610   0.394    0.336    0.380   0.323      0.621   0.405    0.346    0.383   0.326
      5    0.600   0.384    0.327    0.351   0.299      0.618   0.402    0.343    0.352   0.302

 20   2    0.372   0.245    0.205    0.236   0.198      0.375   0.247    0.206    0.234   0.196
      5    0.368   0.241    0.200    0.218   0.186      0.374   0.246    0.205    0.210   0.186

 30   2    0.280   0.182    0.153    0.175   0.149      0.282   0.185    0.156    0.175   0.150
      5    0.278   0.181    0.153    0.162   0.144      0.281   0.183    0.155    0.155   0.145

 40   2    0.231   0.149    0.129    0.144   0.126      0.230   0.148    0.128    0.140   0.124
      5    0.226   0.145    0.125    0.131   0.121      0.230   0.148    0.129    0.128   0.126

 50   2    0.196   0.126    0.112    0.122   0.110      0.196   0.125    0.111    0.119   0.109
      5    0.195   0.124    0.110    0.113   0.109      0.197   0.126    0.113    0.111   0.114




    Table 1 gives the simulation results when the parent distribution is standard
uniform. We observe from this table that HE    em
                                                  has less RMSE than HM for all
considered values of N , k and Î». We also observe that the performances of all
estimators improve as the sample size (N ) or set size (k ) increases while the other
parameters are xed. It is also interesting to note that HCem and HCL are the best
entropy estimators in terms of RMSE, and the dierences in their performances
are negligible.
    The simulation results for standard exponential and standard normal distribu-
tions are given in Tables 2-3. The observed patterns are similar to those in Table
1. In particular, HEem
                       always has the better performance than HM , and HCem and
HC are the best entropy estimators.
  L




                                          Revista Colombiana de EstadÃ­stica 40 (2017) 223241

232                                                       Ehsan Zamanzade & M. Mahdizadeh

3. Entropy Based Tests of Fit for Inverse Gaussian

      Distribution

    We develop some entropy based goodness of t tests for inverse Gaussian dis-
tribution using RSS. The pdf of a continuous random variable X with inverse
Gaussian distribution is given by
                                       21                 
                                 Î»                  Î»
               fÂµ,Î» (x) =                     exp âˆ’ 2 (x âˆ’ Âµ) ,           x â‰¥ 0,            (11)
                                2Ï€x3               2Âµ x
where Âµ > 0 and Î» > 0. The CDF of a random variable X with inverse Gaussian
distribution is given by
               ï£± q                   q            
                       Î»  t             2Î»        Î»  t
                          Âµ âˆ’1   + exp Âµ Î¦ âˆ’ t Âµ + 1
               ï£²Î¦                                              t > 0,
       F (t) =          t

                                      0                        tâ‰¤0
               ï£³

where Î¦ (.) is CDF of the standard normal distribution. We refer the interested
reader to Sanhueza, Leiva & LÃ³pez-Kleine (2011) for more information about the
properties of this distribution.
    Vasicek (1976) was the rst who developed an entropy based goodness of t
test for normal distribution by using a characterization of normal distribution
based on entropy. Since then, many researchers developed entropy based tests of
t for many well known distributions by characterizing them in terms of entropy.
Mudholkar & Tian (2002) presented the following characterization of the inverse
Gaussian distribution, and used it to develop a test of t.
Theorem 1. (Mudholkar & Tian 2002). The random variable X with inverse
                                                              âˆš
Gaussian distribution is characterized by the property that 1/ X attains the max-
imum entropy among all non-negative,   and continuous random variables Y with a
given value at E Y 2 âˆ’ 1/E Y âˆ’2 .
                                   


    Let x(1) , . . . , x(N ) be observed ordered values of a simple random sample of
                                                                       âˆš
size N from a continuous population with pdf f (x). Let yi = 1/ x(N +1âˆ’i) , for
i = 1, . . . , N . Mudholkar & Tian (2002) suggested to reject the composite null
hypothesis H0 : f (x) = fÂµ,Î» (x) if

                          TV = exp {HV (y)} / (w/2) â‰¤ TV,Î± ,                                (12)

where fÂµ,Î» (x) is the pdf in (11), HV (y) is Vasicek's (1976) entropy estimator
                           PN
based on yi values, w2 = i=1 1/x(i) âˆ’ 1/x , and TV,Î± is the 100Î± percentile of
                                            

the null distribution of TV .
    One can also substitute Vasicek's (1976) entropy estimator in (12) with Cor-
rea's (1995) entropy estimator, and construct a test of t for inverse Gaussian
distribution.
    Let x[r]s : r = 1, . . . , k; s = 1, . . . , n be an observed ranked set sample of size
        

N = nk from a continuous population with pdf f (x). Let z1 , . . . , zN be the

                                              Revista Colombiana de EstadÃ­stica 40 (2017) 223241

Entropy Estimation From Ranked Set Samples With Application to Test of Fit          233

                                                     âˆš
ordered values of the ranked set sample, and yiâˆ— = 1/ zN +1âˆ’i , for i = 1, . . . , N .
By following lines of Mudholkar & Tian (2002), we propose to reject the null
composite hypothesis H0 : f (x) = fÂµ,Î» (x) if

                                                                                   (13)
                                 B âˆ—
                       TAB = exp HA                   B
                                    (y ) / (wz /2) â‰¤ TA,Î± ,
A âˆˆ {V, E, C} and B âˆˆ {em, L}. Also, HA     B
                                              (y âˆ— ) is the entropy estimator based
                    PN
on yi values, wz = i=1 (1/zi âˆ’ 1/z), and TA,Î± is the 100Î± percentile of the null
     âˆ—          2                             B

distribution of TAB which is obtained under assumption of perfect ranking. It is
worth noting that the critical values of the all above entropy based tests cannot
be obtained analytically because of complicated form of the corresponding test
statistics. Thus, the critical values of the entropy based tests of t should be
obtained via Monte Carlo simulation.
Remark 1. In line with Ebrahimi et al. (1994), one can simply show that HM =
         n                        o
                            (mâˆ’1)!
HEem
     + N2 m log (2m) + log (2mâˆ’1)!    , and therefore the goodness of t tests
based on HM and HE are equivalent.
                   em

    In the sequel, we compare dierent entropy based tests of size 0.05 for inverse
Gaussian distribution in RSS. For N = 10, 20 and 50, we have generated 50,000
random samples in RSS scheme, so we can observe the performance of the tests
when sample size is small (N = 10), moderate (N = 20), and large (N = 50). The
value of the set size (k ) in the RSS setting is taken to be 2 and 5, therefore we can
assess the eect of increasing set size on the goodness of t tests. The scenario of
imperfect ranking is fraction of random ranking as described in previous section,
and the value of Î» (the fraction of perfect ranking) is taken to be 1, 0.8, 0.5 and
0.2. The alternative distributions which have been used in this simulation study
are standard exponential distribution (Exp(1)), Weibull distribution with shape
parameter 2 and scale âˆš  parameter 1 (W (2, 1)), lognormal distribution with mean e2
and standard error e e4 âˆ’ 1 (LN (0, 2)), beta distribution with parameters 2, 2
                       2

(Beta(2, 2)) and beta distribution with parameters 5 and 2 (Beta(5, 2)). We also
considered standard inverse Gaussian distribution (IG(1, 1)) to assess dierent
tests in terms of type I error rate control. This is important because the critical
values of the entropy based tests are obtained under assumption of perfect ranking.
Figure 1 shows the pdf of the alternative distributions. It is clear from this gure
that a variety of functional forms of pdfs are considered in the simulation study.
The value of window size (m) plays a signicant role in entropy based goodness of
t tests. Given a sample size, the optimum value of the window size which produces
maximum power of each test depends on the alternative distribution. Since the
alternative distribution is unknown in practice, it is not possible to determine a
single optimum value for m. In Table 4, we present the suggested value of m
subject to N which gives relatively good powers for all alternatives considered in
this simulation study. In the simulation study, the value of m is selected according
to the Table 4. The simulation results are presented in Tables 5-7.




                                     Revista Colombiana de EstadÃ­stica 40 (2017) 223241

234                                                                            Ehsan Zamanzade & M. Mahdizadeh




                 2.5
                                                                                                  IG(1, 1)
                                                                                                  Exp(1)
                                                                                                  W(2, 1)
                                                                                                  LN(0, 2)




                 2.0
                                                                                                  B(2, 2)
                                                                                                  B(5, 2)
                                                                                                  U(0, 1)
                 1.5
          f(x)

                 1.0
                 0.5
                 0.0




                        0.0             0.5           1.0          1.5             2.0          2.5           3.0

                                                                    x

                       Figure 1: The pdf of dierent alternative distributions.


Table 4: Suggested values of m subject to N in entropy based tests for inverse Gaussian
         distribution.
        N        â‰¤ 15         [16,25]     [26, 35]      [36, 45]        [46, 55]     [56, 75]     [76, 100]         â‰¥ 101
        m          3             4             5             6             7             8              9            10



         Table 5: Power estimates of dierent entropy based tests for inverse Gaussian
         distribution for N = 10 in RSS.

                                TM             em
                                              TC   TEL              L
                                                                   TC                TM        TCem           L
                                                                                                             TE        L
                                                                                                                      TC
      Alt               k                        Î»=1                                         Î» = 0.8
      IG(1, 1)          2       0.051         0.051    0.052       0.052            0.051       0.049       0.048     0.044
                        5       0.048         0.050    0.049       0.050            0.058       0.056       0.049     0.046

      Exp(1)            2       0.203         0.165    0.207       0.170            0.201       0.159       0.198     0.156
                        5       0.223         0.176    0.233       0.185            0.223       0.174       0.214     0.170

      U (0, 1)          2       0.494         0.441    0.500       0.447            0.487       0.428       0.478     0.418
                        5       0.543         0.477    0.555       0.492            0.535       0.469       0.512     0.450

      W (2, 1)          2       0.132         0.115    0.137       0.121            0.131       0.109       0.128     0.105
                        5       0.142         0.118    0.151       0.127            0.147       0.124       0.140     0.116

      LN (0, 2)         2       0.127         0.094    0.131       0.097            0.122       0.087       0.121     0.086
                        5       0.132         0.094    0.141       0.101            0.133       0.094       0.130     0.093

      Beta(2, 2)        2       0.244         0.219    0.252       0.226            0.240       0.207       0.237 0.202
                        5       0.266         0.229    0.281       0.246            0.266       0.228       0.253 0.218
                                                                                                               Continued


                                                            Revista Colombiana de EstadÃ­stica 40 (2017) 223241

Entropy Estimation From Ranked Set Samples With Application to Test of Fit                235

                                     Table 5. Continued

    Beta(5, 2)   2   0.246   0.244    0.255   0.252       0.247   0.237   0.242   0.229
                 5   0.266   0.256    0.283   0.278       0.277   0.264   0.262   0.251
                     TM       em
                             TC      TEL        L
                                               TC         TM       em
                                                                  TC       TEL     L
                                                                                  TC
    Alt          k              Î» = 0.5                              Î» = 0.2
    IG(1, 1)     2   0.052   0.052    0.045   0.041       0.051   0.052   0.038   0.035
                 5   0.200   0.159    0.186   0.148       0.199   0.160   0.175   0.140

    Exp(1)       2   0.489   0.432    0.461   0.401       0.486   0.433   0.436   0.379
                 5   0.132   0.113    0.120   0.098       0.127   0.111   0.105   0.086

    U (0, 1)     2   0.124   0.091    0.115   0.084       0.121   0.089   0.103   0.076
                 5   0.240   0.210    0.218   0.185       0.236   0.210   0.198   0.168

    W (2, 1)     2   0.251   0.241    0.225   0.210       0.242   0.237   0.198   0.183
                 5   0.059   0.059    0.039   0.034       0.061   0.061   0.030   0.024

    LN (0, 2)    2   0.217   0.175    0.182   0.147       0.219   0.175   0.158   0.127
                 5   0.516   0.457    0.443   0.383       0.517   0.458   0.394   0.332

    Beta(2, 2)   2   0.148   0.126    0.113   0.092       0.149   0.129   0.092   0.071
                 5   0.134   0.096    0.110   0.081       0.134   0.097   0.093   0.068

    Beta(5, 2)   2   0.271   0.238    0.215   0.180       0.264   0.232   0.170   0.137
                 5   0.276   0.268    0.215   0.198       0.273   0.264   0.169   0.146




    Table 5 presents the simulation results for N = 10. We observe from this table
that the power of all goodness of t tests increase with the set size (k ) while the
other parameters are xed. It is also evident that the powers of all tests decrease
when the value of Î» goes from one to zero (from perfect ranking case to imperfect
ranking case). While in perfect ranking setup (Î» = 1), the tests based on HM and
HCL are most powerful ones, TM beats the others in imperfect ranking setup. It
is of interest to note that TCL is the least powerful test for the case of imperfect
ranking (Î» < 1).
   The estimated powers of goodness of t tests for sample size N = 20 and
50 are reported in Tables 6-7. As one expects, the powers of all tests increase
with the sample size (N ). The test based on HM is the most powerful test in
most considered cases and HCL is the least powerful test in the case of imperfect
ranking.


       Table 6: Power estimates of dierent entropy based tests for inverse Gaussian
       distribution for N = 20 in RSS.

                     TM       em
                             TC   TEL           L
                                               TC         TM       em
                                                                  TC       TEL     L
                                                                                  TC
    Alt          k              Î»=1                                  Î» = 0.8
    IG(1, 1)     2   0.050   0.050    0.050   0.050       0.050   0.049   0.046 0.046
                                                                             Continued


                                        Revista Colombiana de EstadÃ­stica 40 (2017) 223241

236                                                     Ehsan Zamanzade & M. Mahdizadeh

                                       Table 6. Continued
                   5   0.049   0.050    0.050 0.050         0.053   0.054   0.044   0.043

      Exp(1)       2   0.448   0.404    0.450   0.407       0.445   0.401   0.439   0.397
                   5   0.471   0.427    0.480   0.437       0.468   0.421   0.448   0.404

      U (0, 1)     2   0.883   0.850    0.882   0.849       0.881   0.848   0.871   0.837
                   5   0.922   0.890    0.920   0.888       0.910   0.878   0.885   0.850

      W (2, 1)     2   0.255   0.222    0.258   0.226       0.245   0.215   0.239   0.212
                   5   0.269   0.235    0.280   0.247       0.265   0.233   0.246   0.217

      LN (0, 2)    2   0.323   0.278    0.326   0.280       0.312   0.268   0.306   0.265
                   5   0.335   0.287    0.345   0.298       0.330   0.284   0.316   0.273

      Beta(2, 2)   2   0.540   0.500    0.543   0.505       0.526   0.488   0.515   0.478
                   5   0.572   0.530    0.584   0.545       0.563   0.523   0.530   0.490

      Beta(5, 2)   2   0.512   0.487    0.516   0.492       0.503   0.479   0.491   0.469
                   5   0.545   0.516    0.560   0.535       0.542   0.516   0.504   0.477
                       TM       em
                               TC      TEL        L
                                                 TC         TM       em
                                                                    TC       TEL     L
                                                                                    TC
      Alt          k              Î» = 0.5                              Î» = 0.2
      IG(1, 1)     2   0.052   0.052    0.043   0.043       0.050   0.050   0.038   0.034
                   5   0.442   0.401    0.421   0.383       0.442   0.401   0.404   0.366

      Exp(1)       2   0.878   0.848    0.858   0.824       0.875   0.842   0.841   0.802
                   5   0.251   0.221    0.228   0.201       0.248   0.217   0.210   0.182

      U (0, 1)     2   0.313   0.270    0.295   0.255       0.311   0.267   0.278   0.236
                   5   0.529   0.491    0.496   0.459       0.527   0.486   0.465   0.425

      W (2, 1)     2   0.504   0.481    0.465   0.443       0.502   0.476   0.437   0.407
                   5   0.057   0.057    0.034   0.030       0.062   0.062   0.026   0.020

      LN (0, 2)    2   0.459   0.416    0.395   0.355       0.457   0.414   0.346   0.309
                   5   0.894   0.863    0.830   0.786       0.887   0.856   0.779   0.727

      Beta(2, 2)   2   0.266   0.233    0.204   0.178       0.267   0.235   0.160   0.135
                   5   0.331   0.285    0.276   0.237       0.329   0.283   0.234   0.197

      Beta(5, 2)   2   0.557   0.519    0.453   0.412       0.554   0.515   0.378   0.331
                   5   0.534   0.510    0.422   0.392       0.531   0.506   0.339   0.305




         Table 7: Power estimates of dierent entropy based tests for inverse Gaussian
         distribution for N = 50 in RSS.

                       TM       em
                               TC   TEL           L
                                                 TC         TM       em
                                                                    TC       TEL     L
                                                                                    TC
      Alt          k              Î»=1                                  Î» = 0.8
      IG(1, 1)     2   0.051   0.051    0.050   0.052       0.051   0.050   0.047 0.046
                   5   0.050   0.049    0.051   0.050       0.055   0.055   0.041 0.041
                                                                               Continued


                                          Revista Colombiana de EstadÃ­stica 40 (2017) 223241

Entropy Estimation From Ranked Set Samples With Application to Test of Fit                 237

                                     Table 7. Continued

    Exp(1)       2   0.833   0.817    0.832     0.819      0.831   0.815   0.824   0.810
                 5   0.851   0.837    0.852     0.837      0.843   0.830   0.815   0.800

    U (0, 1)     2   1       0.999    1         0.999      0.999   0.999   0.999   0.999
                 5   1         1      1           1          1     1       0.999   0.999

    W (2, 1)     2   0.535   0.513    0.536     0.518      0.538   0.515   0.525   0.506
                 5   0.560   0.539    0.568     0.546      0.563   0.541   0.512   0.497

    LN (0, 2)    2   0.709   0.681    0.709     0.684      0.711   0.682   0.701   0.672
                 5   0.732   0.704    0.736     0.707      0.732   0.705   0.694   0.667

    Beta(2, 2)   2   0.933   0.919    0.932     0.920      0.931   0.917   0.924   0.910
                 5   0.954   0.941    0.953     0.940      0.947   0.936   0.918   0.901

    Beta(5, 2)   2   0.917   0.907    0.917     0.908      0.916   0.905   0.907   0.896
                 5   0.944   0.934    0.944     0.934      0.935   0.927   0.897   0.884
                     TM       em
                             TC      TEL          L
                                                 TC         TM      em
                                                                   TC       TEL     L
                                                                                   TC
    Alt          k              Î» = 0.5                               Î» = 0.2
    IG(1, 1)     2   0.051   0.052    0.038     0.037      0.047   0.045   0.029   0.027
                 5   0.829   0.816    0.810     0.798      0.821   0.807   0.783   0.772

    Exp(1)       2   1       0.998    0.999     0.998      0.999   0.998   0.999   0.997
                 5   0.531   0.510    0.498     0.482      0.515   0.492   0.450   0.432

    U (0, 1)     2   0.709   0.679    0.681     0.654      0.690   0.666   0.647   0.617
                 5   0.931   0.920    0.909     0.899      0.922   0.905   0.884   0.866

    W (2, 1)     2   0.913   0.905    0.889     0.878      0.907   0.897   0.858   0.846
                 5   0.057   0.056    0.019     0.018      0.056   0.059   0.009   0.008

    LN (0, 2)    2   0.845   0.832    0.762     0.747      0.838   0.824   0.694   0.672
                 5   1       0.999    0.998     0.995        1     0.999   0.996   0.993

    Beta(2, 2)   2   0.546   0.527    0.405     0.387      0.557   0.547   0.319   0.298
                 5   0.711   0.684    0.603     0.570      0.717   0.691   0.531   0.498

    Beta(5, 2)   2   0.938   0.927    0.849     0.825      0.934   0.924   0.758   0.725
                 5   0.929   0.921    0.809     0.783      0.921   0.912   0.696   0.660




   Finally, we would like to mention that all simulation studies in this work are
                     R
programmed using statistical software, and the corresponding code is available
on request from the rst author.




                                          Revista Colombiana de EstadÃ­stica 40 (2017) 223241

238                                               Ehsan Zamanzade & M. Mahdizadeh

4. A real data example

    The data set used in this section is obtained by Murray, Ridout & Cross (2000)
and is known as apple tree data set. This data set is a result of a research study in
which apple trees are sprayed with chemical containing uorescent tracer, Tinopal
CBS-X, at 2% concentration level in water, and is given in Table 5 of Mahdizadeh
& Zamanzade (2016). The variable of interest is the percentage of each leaf's
upper surface area which is covered with spray deposit. It is important to note
that the exact measurement of variable of interest requires chemical analysis of
the solution collected from the surface of the leaves which is expensive and time-
consuming. On the other hand, an expert can use the visual appearance of the
spray deposits on the leaf surfaces under ultraviolet light for ranking them within
each set. Therefore, RSS can be regarded as oering the potential for improving
statistical inference over SRS. Murray et al. (2000) collected data by using RSS
with set size 5 and cycle size 10 in two dierent groups (low and high volumes of
spray). Suppose that we are interested in tting a statistical model on two groups
of apple tree data set. The entropy-based goodness of t test statistic value (TSV)
along with its critical value (CV) at signicance level Î± = 0.05 for inverse Gaussian
distribution are given in Table 8.

Table 8: Entropy-based goodness of t test of inverse Gaussian distribution for apple
         tree data set.
                                          HM       em
                                                  HC       L
                                                          HE       L
                                                                  HC
                CV                        3.302   3.789   3.653   3.800
                TSV (low volume group)    2.689   3.137   2.889   3.168
                TSV (high volume group)   2.943   3.489   3.161   3.517


   By comparing each test statistic with the corresponding critical value, we con-
clude that the two data sets do not follow inverse Gaussian distribution.


5. Conclusion

    In this paper, we employed empirical and maximum likelihood estimators of
CDF for developing some entropy based tests for inverse Gaussian distribution in
RSS scheme. We observe that although the entropy estimators based on maxi-
mum likelihood estimation of CDF have good performance in terms of RMSE, the
corresponding tests are not successful when the ranking is not perfect. Since the
quality of ranking in RSS is often unknown in practice, we recommend to use test
of t for inverse Gaussian based on empirical distribution function.


Acknowledgements

  The authors are thankful to anonymous referees for their constructive com-
ments and suggestions on the paper.


                                    Revista Colombiana de EstadÃ­stica 40 (2017) 223241

Entropy Estimation From Ranked Set Samples With Application to Test of Fit          239

                
                    Received: October 2016  Accepted: April 2017
References
Chen H, Stasny E A, Wolfe D A. Ranked set sampling for ecient estimation of a population proportion.(2005). Statistics in Medicine.
Correa J C. A new estimator of entropy.(1995). Communications in StatisticsTheory Methods.
Duembgen L, Zamanzade E. Inference on a distribution function from ranked set samples.(2013). arXiv:1304.6950v3 [stat.ME].
Ebrahimi N, Habibullah M, Soo E. Two measures of sample entropy.(1994). Statistics and Probability Letters.
Frey J, Ozturk O, Deshpande J. Nonparametric tests for perfect judgment rankings.(2007). Journal of the American Statistical Association.
Grzegorzewski P, Wieczorkowski R. Entropy-based goodness-of-t test for exponentiality.(1999). Communications in Statistics-Theory Methods.
Haq A, Brown J, Moltchanova E, Al-Omari A. Mixed ranked set sampling design.(2014). Journal of Applied Statistics.
Howard R W, Jones S C, Mauldin J K, Beal R H. Abundance distribution and colony size estimates for reticulitermes spp (isopter: Rhinotermitidae) in southern mississippi.(1982). Environmental Entomology.
Huang J. Asymptotic properties of the npmle of a distribution function based on ranked set samples.(1997). The Annals of Statistics.
Kvam P H. Ranked set sampling based on binary water quality data with covariates.(2003). Journal of Agricultural - Biological and Environmental Statistics.
Kvam P, Samaniego F. Nonparametric maximum likelihood estimation based on ranked set samples.(1994). Journal of the American Statistical Association.
MacEachern S, Ozturk O, Wolfe D, Stark G. A new ranked set sample estimator of variance.(2002). Journal of the Royal Statistical Society.
Mahdizadeh M. On the use of ranked set samples in entropy based test of fit for the laplace distribution.(2012). Revista Colombiana de EstadÃ­stica.
Mahdizadeh M, Arghami N. Eficiency of ranked set sampling in entropy estimation and goodness-of-fit testing for the inverse gaussian law.(2009). Journal of Statistical Computation and Simulation.
Mahdizadeh M, Zamanzade E. Kernel-based estimation of P (X > Y ) in ranked set sampling.(2016). Statistics and Operations Research Transactions.
McIntyre G A. A method for unbiased selective sampling using ranked set sampling.(1952). Australian Journal of Agricultural Research.
Mudholkar G S, Tian L. An entropy characterization of the inverse gaussian distribution and related goodness-of-t test.(2002). Journal of Statistical Planning and Inference.
Murray R A, Ridout M S, Cross J V. The use of ranked set sampling in spray deposit assessment.(2000). Aspects of Applied Biology.
Muttlak H. Pair rank set sampling.(1996). Biometrical Journal.
Muttlak H. Median ranked set sampling.(1997). Journal of Applied Statistical Sciences.
Nussbaum B D, Sinha B K. Cost efective gasoline sampling using ranked set sampling in Proceedings of the Section on Statistics and the Environment.(1997). American Statistical Association.
Ozturk O, Bilgin O, Wolfe D A. Estimation of population mean and variance in block management: a ranked set sampling approach in a finite population setting.(2005). Journal of Statistical Computation and Simulation.
Perron F, Sinha B. Estimation of variance based on a ranked set sample.(2004). Journal of Statistical Planning and Inference.
Samawi H, Abu-Daayeh H, Ahmed S. Estimating the population mean using extreme ranked set sampling.(1996). Biometrical Journal.
Sanhueza A, Leiva V, LÃ³pez Kleine L. On the student-t mixture inverse gaussian model with an application to protein production.(2011). Revista Colombiana de EstadÃ­stica.
Shannon C E. A mathematical theory of communications.(1948). Bell System Technical Journal.
Stokes S L. Estimation of variance using judgment ordered ranked set samples.(1980). Biometrics.
Stokes S L, Sager T W. Characterization of a ranked-set sample with application to estimating distribution functions.(1988). Journal of the American Statistical Association.
Takahasi K, Wakimoto K. On unbiased estimates of the population mean based on the sample stratified by means of ordering.(1968). Annals of the Institute of Statistical Mathematics.
Vasicek O. A test for normality based on sample entropy.(1976). Journal of Royal Statistical Society.
Zamanzade E, Vock M. Variance estimation in ranked set sampling using a concomitant variable.(2015). Statistics and Probability Letters.
