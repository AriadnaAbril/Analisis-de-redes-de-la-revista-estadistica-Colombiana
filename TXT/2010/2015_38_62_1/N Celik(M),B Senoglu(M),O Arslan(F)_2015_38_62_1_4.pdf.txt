Estimation and Testing in One-Way ANOVA when the Errors are Skew-Normal. EstimaciÃ³n y pruebas de hipÃ³tesis en ANOVA a una vÃ­a cuando los errores se distribuyen como normal sesgados
Bartin University, Bartin, Turkey.  Ankara University, Ankara, Turkey
Abstract
We consider one-way analysis of variance (ANOVA) model when the error terms have skew- normal distribution. We obtain the estimators of the model parameters by using the maximum likelihood (ML) and the modified maximum likelihood (MML) methodologies (see, Tiku 1967). In the ML method, iteratively reweighting algorithm (IRA) is used to solve the likelihood equations. The MML approach is a non-iterative method used to obtain the explicit estimators of model parameters. We also propose new test statistics based on these estimators for testing the equality of treatment effects. Simulation results show that the proposed estimators and the tests based on them are more efficient and robust than the corresponding normal theory solutions. Also, real data is analysed to show the performance of the proposed estimators and the tests.
Key words: ANOVA, Modified Likelihood, Iteratively Reweighting Algorithm, Skew-Normal, Monte Carlo Simulation, Robustness.
Resumen
Se considera el modelo de anÃ¡lisis de varianza a una vÃ­a (ANOVA) cuando los tÃ©rminos de error siguen una distribuciÃ³n normal sesgada. Se obtienen estimadores de los parÃ¡metros desconocidos mediante el uso de la metodologÃ­a de mÃ¡xima verosimilitud (ML). Se proponen nuevos estadÃ­sticos de prueba basados en estos estimadores. Los resultados de la simulaciÃ³n muestran que los estimadores propuestos y los tests basados en ellos son mÃ¡s eficientes y robustos que los correspondientes a las soluciones de la teorÃ­a normal. Un conjunto de datos real es analizado con el fin de mostrar el desempeÃ±o de los estimadores propuestos y sus tests relacionados.
Palabras clave: ANOVA, estimaciÃ³n, normal sesgada, pruebas de hipÃ³tesis, robustez.


1. Introduction
     Consider the following one-way ANOVA model,

                yij = Âµ + Î±i + ij , i = 1, 2, . . . , a; j = 1, 2, . . . , n            (1)

where, yij are the responses corresponding to jth observation in the ith treatment,
Âµ is the overall mean, Î±i is the effect of ith treatment and ij are the independent
and identically distributed (iid) random error terms.
    In general, normality assumption is made for the random error terms and the
well known least squares (LS) method is used for estimating model parameters.
However, in the literature, there are numerous studies pointing out that non-
normal distributions are more prevalent than normal distribution , in practice,
see for example, (Pearson 1932, Geary 1947, Huber 1981, Tan & Tiku 1999). It
is known that LS estimators of the parameters and the test statistics based on
them lose their efficiency when the normality assumption is not satisfied, (see,
Tukey 1960). That is why there is great interest in studying the effect of non-
normality on the F statistics used for testing the main effects and the interaction
in the framework of experimental design; see, for example, (Geary 1947, Srivastava
1959, Donaldson 1968, Spjotvoll & Aastveit 1980, Tan & Tiku 1999, Senoglu &
Tiku 2001). The following conclusions have been drawn from these studies. For
numerous non-normal distributions:

 i. Type I error of the F statistic is not much different than that for a normal
    distribution. This is essentially due to the central limit theorem.
 ii. Power of the F test is considerably lower than that for a normal distribution.
     This is essentially due to the inefficiency of the sample mean.

    See Senoglu & Tiku (2001) and the references therein. These conclusions are
particularly true for non normal distributions having skewness in different direc-
tions (Senoglu & Tiku 2002).
    Therefore, it is necessary to obtain new F statistics whose distribution provides
satisfactory approximations to the percentage points of the null distribution when
the distribution of the error terms is non-normal (see condition i). The proposed
test should also maintain higher power than the classical F test based on LS
estimators (see condition ii).
    There are various ways of analyzing non-normal data, such as Box-Cox nor-
malizing transformation and nonparametric methods. However, in this study, we
adopt the parametric ML and MML methods where original data are used rather
than transformed data. In the ML method, the likelihood equations are solved
iteratively by using the iteratively reweighting algorithm (IRA). However, in the
MML method, the explicit estimators of model parameters are obtained by ap-
proximating the likelihood equations.
   In this study, we assume that the distribution of the error terms in one-way
ANOVA model in (1) is Azzaliniâ€™s skew-normal (Azzalini 1985, 1986) and obtain
the ML and the MML estimators of the model parameters. We then propose new


                                            Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

Estimation and Testing in One-Way ANOVA when the Errors are Skew-Normal               77

test statistics based on these estimators. To the best of our knowledge, there is no
previous work assuming SN (Î») as an error distribution in the context of ANOVA.
The reason for choosing the SN (Î») as an error distribution is that it includes the
normal distribution as well as plausible alternatives thereof with different levels
of skewness and kurtosis. Therefore, SN (Î») distribution is considered to be an
extension of normal distribution. This provides us flexibility for modeling the data
with normal âˆ’ like shape but with skewness and heavy tails. It is also useful for
modeling the data having normal distribution with outliers and contamination.
Its mathematical tractability is another reason for using SN (Î») in this study.
    The rest of the paper is organized as follows. In Section 2, SN (Î») distribution is
introduced. The ML and the MML estimators are derived in Section 3 and Section
4, respectively. Efficiencies of the ML and the MML estimators are compared via
Monte Carlo simulation study in Section 5. New test statistics for testing the
equality of treatment effects are proposed in Section 6. Power comparisons and
robustness properties of these tests are also given in this section. A real life example
is analyzed in Section 7 to present the application of the proposed estimators and
the tests based on them. Our conclusions are presented.


2. Skew-Normal Distribution
   The probability density function (pdf) of the SN (Î») distribution is given by
                               h(z) = 2Ï†(z)Î¦(Î»z)                                     (2)
where Ï†(z) and Î¦(z) are the pdf and the cumulative distribution function (cdf) of
the standard normal distribution, respectively. Î» is the skewness parameter, it is
also known as the shape parameter since it regulates the shape of the distribution.
If a random variable Z has a skew-normal distribution with parameter Î» then
it is denoted by Z âˆ¼ SN (Î»). Some extensions of this distribution con found
in MartÃ­nez-FlÃ³rez, Vergara-Cardozo & GonzÃ¡lez (2013) and Pereira, Marques &
da Costa (2012).
    It may be noted that for Î»=0, SN (Î») reduces to the well known standard
normal distribution N (0, 1). When Î» â†’ âˆž, SN (Î») converges to the half-normal
distribution, h(z) is strongly unimodal for fixed Î». It is right skewed for Î» > 0
and left skewed for Î» < 0. SN (Î») distribution has also the following properties:
   i. If Z âˆ¼ SN (Î») then âˆ’Z âˆ¼ SN (âˆ’Î»)
   ii. If Z âˆ¼ SN (Î») then Z 2 âˆ¼ Ï‡21 (see, Azzalini 2005).
    To better understand the shape of the SN (Î») distribution, see the coefficients
of skewness (Î³1 ) and the kurtosis (Î³2 ) for some representative values of Î» given in
Table 1.
   It is clear from Table 1 that the skewness of the distribution increases as the
skewness parameter Î» increases (in absolute value). Skewness of the SN (Î») distri-
bution takes values in the interval (âˆ’0.995, 0.995) and the maximum value of its
kurtosis is 3.869. Here, it should be noted that the skewness values correspond-
ing to the positive Î» values are exactly the same, but with opposite sign, with


                                        Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

78                                              Nuri Celik, Birdal Senoglu & Olcay Arslan

      Table 1: The skewness and the kurtosis values of the SN (Î») distribution.
          Î»      0.0     1.0    2.0       3.0    4.0   5.0      10     20      âˆž
          Î³1    0.00    0.14    0.45     0.67   0.78   0.85    0.96   0.99   0.995
          Î³2    3.00    3.06    3.31     3.51   3.63   3.71    3.82   3.86   3.869



the skewness values corresponding to the negative Î» values. Therefore, in Table
1, we just reproduce the skewness values corresponding to the positive Î» values
for brevity. It can also be seen that the SN (Î») and the normal distribution are
indistinguishable for Î» < 3.
   Here and in many other studies, we consider a more general form of the distri-
bution given in (2) by performing a change of location and scale:

                                       Y = Âµ + ÏƒZ                                       (3)

    Based on this linear transformation, pdf of the random variable Y is obtained
as shown below,
                                   2 yâˆ’Âµ       yâˆ’Âµ
                          h(y) =     Ï†(   )Î¦(Î»     )                                    (4)
                                   Ïƒ    Ïƒ       Ïƒ
where, Âµ âˆˆ R is the location parameter and Ïƒ âˆˆ R+ is the scale parameter. If
the random variable Y has SN (Î») distribution with the parameters Âµ, Ïƒ and Î»,
then it is denoted by Y âˆ¼ SN (Âµ, Ïƒ, Î»). The expected value and the variance of
SN (Âµ, Ïƒ, Î») distribution are given by,
                         s
                               2Î»2                        2Î»2
            E(Y ) = Âµ +             2
                                      Ïƒ, V (Y ) = (1 âˆ’            )Ïƒ 2     (5)
                            Ï€(1 + Î» )                  Ï€(1 + Î»2 )

respectively.


3. Maximum Likelihood Estimator
    Consider the model (1) and assume the distribution of ij , (i = 1, 2, . . . , a; j =
1, 2, . . . , n) is skew-normal SN (0, Ïƒ, Î»).
                                2      
                       h() =    Ï†( )Î¦(Î» ), âˆ’âˆž <  < âˆž                                  (6)
                                Ïƒ Ïƒ     Ïƒ

    Here, it should be noted that the skewness parameter is assumed to be known
throughout the study. Since the ML method gives doubtful estimates when we
estimate the location, the scale and the shape parameters simultaneously unless
large samples ( n > 250 or so) are available, (see, Bowman & Shenton 2001, Kantar
& Senoglu 2008). See also, the Introduction of Acitas, Kasap, Senoglu & Arslan
(2013). However, the sample size is much smaller than 250 in the context of ex-
perimental design. Therefore, in this study, we only estimate the location and the
scale parameters for a better fitting. In spite of the fact that the shape parameter


                                           Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

Estimation and Testing in One-Way ANOVA when the Errors are Skew-Normal                                   79

is assumed to be known, in practice, we must identify its value. Shape parameters
can be identified by using various techniques, such as Q-Q plots, goodness-of fit
tests etc. The algorithm given in Acitas et al. (2013, p. 417) can also be used
for the identification of the shape parameter, see also Islam & Tiku (2004). Sup-
pose that the value of the shape parameter in skew-normal distribution might be
somewhat misspecified by using these techniques. Then the question arises what
effect will it have on the efficiencies of the location and the scale estimators. The
answer is that this does not adversely affect the efficiencies of the estimators since
the estimators obtained in this study are robust to plausible deviations of the true
model.
    To obtain the ML estimators of the unknown parameters in model (1), the log-
likelihood function
                                                    a   n           a   n
                                       N         1 XX 2          1 XX
    ln L = N ln 2 âˆ’ N ln Ïƒ âˆ’             ln 2Ï€ âˆ’           zij +           ln Î¦(Î»zij )                   (7)
                                       2         2 i=1 j=1       2 i=1 j=1

is maximized with respect to the unknown parameters Âµ, Î±i and Ïƒ. Here zij =
ij  yij âˆ’Âµâˆ’Î±i
 Ïƒ =      Ïƒ    .
   By differentiating the log-likelihood function with respect to the unknown pa-
rameters and equating them to zero we obtain the following likelihood equations
                            a   n           a X n
                   âˆ‚ ln L X X              X       Ï†(Î»zij )
                         =         zij âˆ’ Î»                   =0
                    âˆ‚Âµ     i=1 j=1         i=1 j=1
                                                   Î¦(Î»z ij )
                            n           n
                   âˆ‚ ln L X            X   Ï†(Î»zij )
                         =     zij âˆ’ Î»               =0                                                  (8)
                    âˆ‚Î±i    j=1         j=1
                                           Î¦(Î»z ij )
                                  a X n          a X n
                   âˆ‚ ln L        X
                                          2
                                                X           Ï†(Î»zij )
                          = âˆ’N +         zij âˆ’Î»         zij          =0
                    âˆ‚Ïƒ           i=1 j=1        i=1 j=1
                                                            Î¦(Î»zij )

   Solutions of these equations are the ML estimators. These equations have no
explicit solutions; therefore we resort to iterative methods.
   If we appropriately reorganize the likelihood equations in (8) and define the
weight function wij as below
                                        Ï†(Î»zij )
                                 wij =
                                        Î¦(Î»zij )
    the likelihood equations can be written as follows:
                                                                         Pa        Pn               2
                                                                     2       i=1   j=1 (yij âˆ’ yÌ„i. )
ÂµÌ‚ = yÌ„.. âˆ’ Î»wÌ„.. ÏƒÌ‚, Î±Ì‚i = yÌ„i. âˆ’ yÌ„.. âˆ’ Î»(wÌ„i. âˆ’ wÌ„.. )ÏƒÌ‚, ÏƒÌ‚ =                                        (9)
                                                                                N (1 âˆ’ Î»2 t2 )
where
          Pn                    Pa     Pn                       Pn                                 Pn
                                                                                          i = 1a
                                                                                      P
           j=1 yij               i=1       j=1 yij               j=1 wij                            j=1 wij
 yÌ„i. =              , yÌ„.. =                        , wÌ„i. =              , wÌ„.. =
               n                       N                             n                         N
          Pa    2
           i=1 wi.
and t=         a


                                                     Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

80                                                       Nuri Celik, Birdal Senoglu & Olcay Arslan


   We use IRA which is very popular in robustness studies to compute the ML esti-
mates of the parameters. It can be shown that IRA is an expectation-maximization
(EM) type algorithm so that its convergence is guaranteed (see, Arslan & Genc
2009). Also Arrellano-Valle, Bolfarine & Lachos (2005),Lachos, Bolfarine, Arellano-
Valle & Montenegro (2007), Xie, Wei & Lin (2009), Lachos, Ghosh & Arellano-
Valle (2010), Lachos, Bandyopadhyay & Garay (2011), Garay, Lachos & Abanto-
Valle (2011), Garay, Lachos, Labra & Ortega (2013). In the above mentioned
papers, skew normal is used as an error distribution in the context of regression
and linear mixed models. Steps of the IRA are given below.
     Iteratively reweighting algorithm (IRA):

                                               (0)
  i. Identify the initial estimates Âµi (i = 1, 2, . . . , a) and Ïƒ (0) for Âµi and Ïƒ, re-
     spectively.

                                                  (m)                                             Pa      (m) 2
                                    (m)       Ï†(Î»zij )                      (m)                    i=1 (wÌ„i. )
 ii. Compute the weights wij              =       (m)    , the averages wÌ„i.      and t(m) =           a
                                              Î¦(Î»zij )
                              (m)
                (m)    yij âˆ’Âµi
     where zij =            (i = 1, 2, . . . , a; j = 1, 2, . . . , n). Here, m is the number
                          Ïƒ (m)
     of iterations and takes the values 1, 2, 3, . . .

                                                       following updating equa-
iii. Find new estimates of the parameters by usingPthe P
                                                                      a       n               2
            (m+1)                   (m)                                       j=1 (yij âˆ’yÌ„i. )
     tions Âµi         = yÌ„.. âˆ’ Î»wÌ„i. Ïƒ (m) and (Ïƒ 2 )(m) =            i=1
                                                                      N (1âˆ’Î»2 (t(m) )2 )


                                                (m+1)        (m)
iv. Continue the iterations until |Âµi    âˆ’ Âµi | < d and |Ïƒ (m+1) âˆ’ Ïƒ (m) | < d
    where d is a predetermined small constant.

    It should be noted that LS estimates are used as initial estimates for this algo-
rithm. However, some other robust estimates can also be used as initial estimates.



4. Modified Maximum Likelihood Estimator
    In this section, we use the MML methodology originated by Tiku (1967) to
obtain the explicit estimators of the model parameters by approximating the like-
lihood equations appropriately. This methodology is used to alleviate the com-
putational difficulties encountered in solving the likelihood equations given above.
MML methodology proceeds as follows: Let

                        yi(1) < yi(2) < Â· Â· Â· < yi(n) , i = 1, 2, . . . , a                            (10)

be the order statistics obtained by arranging yij (i = 1, 2, . . . , a; j = 1, 2, . . . , n)
in ascending order. The likelihood equations in (8) can be written in terms of
    order statistics
the P          Pn as shown below, since complete sums are invariant to ordering
      n
(i.e i=1 yi = i=1 y(i) ).

                                                 Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

Estimation and Testing in One-Way ANOVA when the Errors are Skew-Normal                                  81



                         a   n             a X n
                âˆ‚ ln L X X                X
                      =         zi(j) âˆ’ Î»         g(zi(j) ) = 0
                 âˆ‚Âµ     i=1 j=1           i=1 j=1
                         n             n
                âˆ‚ ln L X              X
                      =     zi(j) âˆ’ Î»     g(zi(j) ) = 0                                                 (11)
                 âˆ‚Î±i    j=1           j=1
                               a X n             a X n
                âˆ‚ ln L        X
                                       2
                                                X
                       = âˆ’N +         zi(j) âˆ’ Î»         zi(j) g(zi(j) ) = 0
                 âˆ‚Ïƒ           i=1 j=1           i=1 j=1


                   Ï†(Î»z)                       yi     âˆ’Âµâˆ’Î±i
    Here, g(z) = Î¦(Î»z)     and zi(j) = (j) Ïƒ         . It should be noted that the last two
          âˆ‚ ln L
terms of âˆ‚Ïƒ are obtained by simply multiplying the terms of âˆ‚ âˆ‚Âµ             ln L
                                                                                  by zi(j) . zi(j)
is the loading factor and instrumental in yielding an estimator which is always real
and positive. Then, we linearize the intractable terms in (11) by using the first two
terms of Taylor series expansion around the expected values of the standardized
order statistics, i.e., t(j) = E(zi(j) ), j = 1, 2, . . . , n. This linearization yields

                g(zi(j) ) = Î±j âˆ’ Î³j zi(j) , i = 1, 2, . . . , a; j = 1, 2 . . . , n                     (12)

where
                                                   Î»2 t(j) Î¦(Î»t(j) + Î»Ï†(Î»t(j) )
                                                                                 
                            Ï†(Î»t(j) )
                       Î³j =
                            Î¦(Î»t(j) )                        Î¦(Î»t(j) )
and
                                                   Ï†(Î»t(j) )
                                      Î±(j) =                 + t(j) Î³(j)
                                                   Î¦(Î»t(j) )

   The exact values of t(j) are not available, however, we use their approximate
values obtained from the equation,
                                 Z t(j)
                                                          j
                  F (t(j) ) =             h(z)dz =           , (j = 1, 2 . . . , n)                     (13)
                                  âˆ’âˆž                     n+1

(see, Tiku & Akkaya 2004). Here, we use the property: If F (zj ) âˆ¼ U (0, 1) then
                                                        j
F (z(j) ) âˆ¼ Beta(j, n âˆ’ j + 1) with the expected value n+1 , (j = 1, 2 . . . , n).
   Incorporating equation (12) into the likelihood equations in (11), we obtain
                                         Lâˆ— âˆ‚ ln Lâˆ—       âˆ‚ ln Lâˆ—
the modified likelihood equations âˆ‚ ln âˆ‚Âµ , âˆ‚Î±i and         âˆ‚Ïƒ . The solutions of these
modified likelihood equations are the following MML estimators
                                                          âˆš
                         âˆ†                             B + B 2 âˆ’ 4N C
            ÂµÌ‚ = ÂµÌ‚.. âˆ’ Î» ÏƒÌ‚, Î±Ì‚i = ÂµÌ‚i. âˆ’ ÂµÌ‚.. , ÏƒÌ‚ =   p                         (14)
                         m                              2 N (N âˆ’ a)

where
         Pn                           Pa                      n                                   n
          j=1 Î²(j) yi(j)               i=1 ÂµÌ‚i.
                                                              X                                   X
ÂµÌ‚i. =                     , ÂµÌ‚.. =                 ,âˆ†=Î»            Î±(j) , Î²(j) = 1+Î»Î³(j) , m =         Î²(j)
              m                            a                  j=1                                 j=1


                                                     Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

82                                             Nuri Celik, Birdal Senoglu & Olcay Arslan

                 a X
                 X n                                   a X
                                                       X n
            B=             Î±(j) (yi(j) âˆ’ ÂµÌ‚i. ), C =             Î²(j) (yi(j) âˆ’ ÂµÌ‚i. )2
                 i=1 j=1                               i=1 j=1
                                                                         p
   The divisor N in the expression for ÏƒÌ‚ was replaced by                 N (N âˆ’ a) as a bias
correction. MML estimators have the following properties:

 i. They are the functions of sample observations and are easy to compute.
 ii. They are asymptotically equivalent to the ML estimators. Therefore, under
     regularity conditions, they are asymptotically fully efficient, i.e., they are un-
     biased and minimum variance bound (MVB) estimators.
iii. Even for small sample sizes, they are highly efficient.
iv. They are robust.

    It should be noted that weights Î²(j) in (12) have half-umbrella ordering, i.e.,
they are a decreasing sequence of positive numbers in the direction of the long
tail. Therefore, weights Î²(j) given to the extreme residuals deplete the dominant
effect of long tail and outliers. This is a very important property for achieving
robustness, see for example Tiku & Akkaya (2004). On the other hand, in LS
method, all e(j) receive the same weight. This exposes the LS estimators to the
dominant effect of long tail and outliers making them nonrobust.


5. Comparison of Estimators
    In this section, we compare the ML, MML and LS estimators of the model
parameters in terms of means, variances and mean square errors (MSE) for some
representative values of the skewness parameter Î». All the simulations are based
on [100, 000/n] Monte Carlo runs. In the simulation study, we use a = 3, 5, n =
5, 10, 15, 20 and Î± = 0.05, however, we just reproduce the results for a = 3 for the
sake of brevity. Without loss of generality, we choose the following setting in our
simulation: Âµi (Âµ + Î±i ) = 0(i = 1, 2, . . . , 1) and Ïƒ = 1.
    Here, it should be noted that we are interested in Î» values satisfying the prop-
erty 0.4 < [P (X > E(X))] < 0.6 in the context of experimental design. We,
therefore use Î» values satisfying the mentioned condition, i.e. we take âˆ’1 < Î» < 1
from now on. Simulation results are given in Table 2.
     From Table 2, it is seen that both the ML and the MML estimators are more
efficient than the LS estimators of Âµi and Ïƒ when the skewness parameter Î» is close
to 1. When the skewness parameter Î» is close to 0 all the three estimators have
similar efficiencies as expected. Because, SN (Î») distribution reduces to normal
distribution when Î» is equal to 0; in that case, algebraic forms of the ML and the
MML estimators are exactly the same with the corresponding LS estimators of the
unknown parameters.
    It is interesting to note that relative efficiencies (REs) of the ML and the MML
estimators decrease as the sample size n increases.


                                          Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

Estimation and Testing in One-Way ANOVA when the Errors are Skew-Normal                                                 83

Table 2: Means, variances and MSEs for the LS, ML and MML estimators of Âµi and Ïƒ.
                    Mean                           Variance                         MSE                     RE
  n       ÂµÌ‚i,LS   ÂµÌ‚i,M L   ÂµÌ‚i,M M L   ÂµÌ‚i,LS   ÂµÌ‚i,M L   ÂµÌ‚i,M M L   ÂµÌ‚i,LS     ÂµÌ‚i,M L    ÂµÌ‚i,M M L   ÂµÌ‚i,M L   ÂµÌ‚i,M M L
 Î» = 0
   5      âˆ’0.002   âˆ’0.002     âˆ’0.002     0.201    0.201       0.201     0.201       0.201       0.201      100        100
  10      âˆ’0.005   âˆ’0.005     âˆ’0.005     0.097    0.097       0.097     0.097       0.097       0.097      100        100
  15      âˆ’0.003   âˆ’0.003     âˆ’0.003     0.067    0.067       0.067     0.067       0.067       0.067      100        100
  20      âˆ’0.001   âˆ’0.001     âˆ’0.001     0.048    0.048       0.048     0.048       0.048       0.048      100        100
Î» = 0.4
   5      0.021    0.008       0.009     0.186    0.186       0.186     0.186       0.186       0.186      100        100
  10      0.017    0.005       0.006     0.091    0.089       0.090     0.091       0.089       0.090      98          99
  15      0.011    âˆ’0.001      0.001     0.063    0.060       0.061     0.063       0.060       0.061      96          97
  20      0.015    0.002       0.002     0.048    0.046       0.046     0.048       0.046       0.046      96          96
Î» = 0.7
   5      0.055    0.012       0.013     0.165    0.166       0.166     0.168       0.166       0.166       99         99
  10      0.053    0.006       0.008     0.082    0.082       0.082     0.085       0.082       0.082       97         97
  15      0.051    0.003       0.004     0.053    0.054       0.054     0.056       0.054       0.054       96         96
  20      0.055    0.006       0.008     0.041    0.042       0.042     0.044       0.026       0.042       96         96
Î» = 1.0
   5       0.104    0.023      0.024      0.139    0.139      0.139      0.149      0.142       0.142       95         95
  10       0.107    0.015      0.018      0.072    0.072      0.072      0.083      0.073       0.073       88         88
  15       0.104    0.011      0.012      0.045    0.045      0.045      0.056      0.046       0.046       82         82
  20       0.101    0.004      0.007      0.034    0.034      0.034      0.044      0.034       0.034       77         77
   n      ÏƒÌ‚i,LS   ÏƒÌ‚i,M L   ÏƒÌ‚i,M M L   ÏƒÌ‚i,LS   ÏƒÌ‚i,M L   ÏƒÌ‚i,M M L   ÏƒÌ‚i,M L   ÏƒÌ‚i,M M L    ÏƒÌ‚i,LS     ÏƒÌ‚i,M L   ÏƒÌ‚i,M M L
 Î» = 0
   5      0.981    0.981       0.981     0.040    0.040       0.040     1.003       1.003       1.003      100        100
  10      0.992    0.992       0.992     0.019    0.019       0.019     1.002       1.002       1.002      100        100
  15      0.994    0.994       0.994     0.012    0.012       0.012     1.000       1.000       1.000      100        100
  20      0.996    0.996       0.996     0.009    0.009       0.009     1.002       1.002       1.002      100        100
Î» = 0.4
   5      0.997    0.987       0.987     0.038    0.038       0.038     1.033       1.013       1.013       98         98
  10      0.991    0.981       0.981     0.018    0.018       0.018     1.001       0.981       0.981       98         98
  15      1.007    0.997       0.997     0.012    0.012       0.012     1.026       1.006       1.006       98         98
  20      0.997    0.988       0.989     0.010    0.009       0.010     1.006       0.986       0.986       98         98
Î» = 0.7
   5      1.008    0.981       0.982     0.042    0.039       0.039     1.060       1.001       1.005       95         95
  10      1.019    0.991       0.991     0.020    0.019       0.019     1.059       1.005       1.005       95         95
  15      1.022    0.994       0.994     0.012    0.012       0.012     1.059       1.001       1.001       95         95
  20      1.059    0.997       0.997     0.008    0.008       0.008     1.061       1.003       1.003       95         95
Î» = 1.0
   5      1.024    0.988       0.989     0.049    0.043       0.044     1.097       0.988       1.002       90         91
  10      1.044    0.990       0.996     0.020    0.018       0.018     1.111       0.999       1.012       90         91
  15      1.045    0.992       0.996     0.013    0.012       0.012     1.106       0.998       1.005       90         91
  20      1.048    0.996       0.998     0.010    0.009       0.009     1.109       1.003       1.006       90         91




    Robustness: In this study, we use the following definition of robustness. An
estimator is called robust if it is fully efficient under the assumed model and
maintains high efficiency under the plausible alternatives of the assumed model,
(see, Tiku & Akkaya 2004). Assume, for illustration, that the true model in the
simulation study is taken to be SN (0, 1, 1). We use the following sample models
to represent a large number of plausible alternatives.
   Sample Models:
   Model (1): Dixonâ€™s outlier model: (n âˆ’ 1) observations come from SN (0, 1, 1)
but one observation (we do not know which one) comes from SN (0, 2, 1)
   Model (2): Dixonâ€™s outlier model: (n âˆ’ 1) observations come from SN (0, 1, 1)
but one observation (we do not know which one) comes from SN (0, 4, 1)
   Model (3): Mixture model: 0.90SN (0, 1, 1) + 0.10SN (0, 1, 0.4)
   Model (4): Contamination model: 0.90SN (0, 1, 1) + 0.10N (0, 1).
    Given in Table 3 are the simulated values of the means, variances and MSEs
for the ML, the MML and the LS estimators of the model parameters Âµi (i =
1, 2, . . . , a) and Ïƒ under the alternative models. We simply reproduce the results
for Âµ1 since they are all similar. We also give the REs of the ML and the MML
estimators with respect to the LS estimators.


                                                       Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

84                                                             Nuri Celik, Birdal Senoglu & Olcay Arslan

Table 3: Means, variances and MSEs for the LS, ML and the MML estimators of Âµi
         and Ïƒ for the alternative models.
                    Mean                           Variance                         MSE                     RE
     n    ÂµÌ‚i,LS   ÂµÌ‚i,M L   ÂµÌ‚i,M M L   ÂµÌ‚i,LS   ÂµÌ‚i,M L   ÂµÌ‚i,M M L   ÂµÌ‚i,LS     ÂµÌ‚i,M L    ÂµÌ‚i,M M L   ÂµÌ‚i,M L   ÂµÌ‚i,M M L
Model 1
  5       0.096    âˆ’0.011      0.004     0.206    0.203       0.203     0.216       0.203       0.203       94         94
  10      0.101    âˆ’0.011      0.007     0.092    0.092       0.092     0.102       0.092       0.092       90         90
  15      0.081    âˆ’0.022     âˆ’0.016     0.059    0.059       0.059     0.066       0.059       0.059       90         90
  20      0.089    âˆ’0.010     âˆ’0.006     0.040    0.040       0.040     0.049       0.041       0.041       84         84
Model 2
  5       0.280    0.102       0.199     0.507    0.540       0.489     0.585       0.550       0.528       94         91
  10      0.167    0.023       0.119     0.160    0.166       0.154     0.187       0.167       0.169       89         89
  15      0.143    0.017       0.112     0.092    0.095       0.090     0.112       0.095       0.097       84         89
  20      0.110    0.010       0.084     0.057    0.057       0.056     0.070       0.058       0.060       82         89
Model 3
  5       0.057    âˆ’0.024     âˆ’0.024     0.160    0.163       0.163     0.164       0.164       0.164      100        100
  10      0.064    âˆ’0.029     âˆ’0.026     0.079    0.081       0.081     0.084       0.082       0.082      97          97
  15      0.065    âˆ’0.029     âˆ’0.029     0.048    0.049       0.049     0.052       0.050       0.050      96          96
  20      0.068    âˆ’0.026     âˆ’0.026     0.038    0.038       0.038     0.043       0.039       0.039      91          91
Model 4
  5        0.052   âˆ’0.034      âˆ’0.033     0.148    0.147      0.148      0.147      0.147       0.147       99         99
  10       0.055   âˆ’0.036      âˆ’0.036     0.081    0.080      0.080      0.082      0.080       0.080       98         98
  15       0.059   âˆ’0.037      âˆ’0.037     0.056    0.055      0.055      0.059      0.057       0.057       97         97
  20       0.051   âˆ’0.031      âˆ’0.032     0.039    0.039      0.039      0.041      0.039       0.039       95         95
  n       ÏƒÌ‚i,LS   ÏƒÌ‚i,M L   ÏƒÌ‚i,M M L   ÏƒÌ‚i,LS   ÏƒÌ‚i,M L   ÏƒÌ‚i,M M L   ÏƒÌ‚i,M L   ÏƒÌ‚i,M M L    ÏƒÌ‚i,LS     ÏƒÌ‚i,M L   ÏƒÌ‚i,M M L
Model 1
  5       1.313    1.242       1.243     0.107    0.096       0.095     1.830       1.639       1.639       90         90
  10      1.201    1.138       1.136     0.043    0.038       0.038     1.485       1.334       1.331       90         90
  15      1.153    1.094       1.092     0.023    0.021       0.021     1.352       1.219       1.217       90         90
  20      1.129    1.072       1.071     0.016    0.015       0.015     1.292       1.164       1.163       90         90
Model 2
  5       2.178    2.051       2.020     0.547    0.435       0.426     5.292       4.702       4.521       88         86
  10      1.738    1.622       1.599     0.228    0.212       0.238     3.251       2.843       2.721       87         84
  15      1.565    1.467       1.441     0.145    0.114       0.134     2.595       2.266       2.179       87         84
  20      1.455    1.348       1.340     0.096    0.079       0.087     2.214       1.897       1.861       85         84
Model 3
  5       1.046    0.994       1.001     0.045    0.041       0.042     1.141       1.030       1.043       90         91
  10      1.063    1.009       1.016     0.023    0.020       0.020     1.154       1.040       1.053       90         91
  15      1.071    1.016       1.021     0.015    0.013       0.013     1.161       1.046       1.057       90         91
  20      1.067    1.013       1.018     0.011    0.009       0.009     1.149       1.037       1.046       90         91
Model 4
  5       1.074    1.015       1.030     0.056    0.050       0.052     1.212       1.085       1.113       90         92
  10      1.081    1.025       1.034     0.027    0.024       0.025     1.196       1.077       1.095       90         92
  15      1.088    1.034       1.040     0.016    0.015       0.015     1.201       1.084       1.097       90         91
  20      1.087    1.032       1.039     0.012    0.010       0.011     1.194       1.077       1.091       90         91




   It can be seen that the ML and the MML estimators are robust owing to the
reason mentioned at the end of the Section 4.


6. Hypothesis Testing
    In one-way ANOVA, our aim is to compare the equality of treatment effects,
in other words, to test the following null hypothesis
                                       H0 : Î±i = 0, i = 1, 2, . . . , a                                               (15)
against the alternative hypothesis
                                           H1 : at least one Î±i 6= 0.
Traditionally, for testing the null hypothesis given in (15) the following test statis-
tics based on the LS estimators are used

                                                       Pn
                                                     n i=1 Î±Ì‚i,LS
                                          FLS =                2                                                      (16)
                                                      (a âˆ’ 1)ÏƒÌ‚LS

                                                       Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

Estimation and Testing in One-Way ANOVA when the Errors are Skew-Normal              85

    As mentioned earlier, power of FLS is very sensitive to non-normality and to
data anomalies. Therefore, in this paper, we propose the following test statistics
based on the ML and the MML estimators as an alternative to the test statistic
given in (16),
                       Pn                              Pn
                     n i=1 Î±Ì‚i,M L                   m i=1 Î±Ì‚i,M M L
          FM L =                      2   , FM M L =           2             (17)
                 (a âˆ’ 1)(1 âˆ’ Î»2 t2 )ÏƒÌ‚M L             (a âˆ’ 1)ÏƒÌ‚M ML

   Large values of FM L and FM M L lead to the rejection of H0 . For large n
values, distribution of both FM L and FM M L are central F with degrees of freedom
(aâˆ’1, N âˆ’a). On the other hand, for small n values, we use Monte Carlo simulation
study to verify how close their null distribution is to central F . We simulate the
Type I errors of FM L and FM M L by computing the following probabilities
 P (FM L â‰¥ FÎ± (a âˆ’ 1, N âˆ’ a)|H0 ) and P (FM M L â‰¥ FÎ± (a âˆ’ 1, N âˆ’ a)|H0 ), (18)
respectively. Table 4 shows that central F distribution with a âˆ’ 1 and N âˆ’ a
degrees of freedom provides accurate approximations to the distributions of FM L
and FM M L even for small n values.
  Table 4: Simulated Type I Errors of FLS , FM L and FM M L tests a = 3; Î± = 0.050.
                      Î»       n        5       10     15       20
                             FLS     0.050   0.049   0.048   0.050
                      0      FM L    0.054   0.050   0.053   0.052
                            FM M L   0.053   0.051   0.056   0.054
                             FLS     0.046   0.055   0.055   0.045
                     0.4     FM L    0.049   0.054   0.056   0.049
                            FM M L   0.048   0.055   0.054   0.047
                             FLS     0.049   0.054   0.049   0.053
                     0.7     FM L    0.050   0.052   0.049   0.049
                            FM M L   0.051   0.054   0.047   0.048
                             FLS     0.054   0.048   0.051   0.049
                     1.0     FM L    0.055   0.049   0.052   0.054
                            FM M L   0.055   0.049   0.053   0.053


   We now compare the power of the FM L and FM M L tests with the traditional
FLS test by simulating the probabilities
 P (FM L â‰¥ FÎ± (a âˆ’ 1, N âˆ’ a)|H1 ) and P (FM M L â‰¥ FÎ± (a âˆ’ 1, N âˆ’ a)|H1 ), (19)
for some representative values of Î». It should be noted that all the observations are
divided by their standard errors. A constant d is added to the observations in the
first and third treatments and a constant 2d is subtracted from the observations
in the second treatment. Simulation results showing the power comparisons of the
proposed tests with the LS based test are given in Table 5.
    From Table 5 it is clear that power of FLS , FM L and FM M L are very similar
when Î» is close to 0. When Î» approaches 1, FM L and FM M L seem more powerful
than the FLS , but the differences are not very attractive. This is not surprising due
to the fact that the quadratic form of a skew-normal distributed random variable
has the chi-square distribution (Azzalini 1985, Gupta & Huang 2002).


                                       Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

86                                         Nuri Celik, Birdal Senoglu & Olcay Arslan

 Table 5: Power values of the FLS , FM L and FM M L tests: a = 3,n = 10; Î± = 0.050.
  Î»         0                0.4               0.7               1.0
  d FLS FM L FM M L FLS FM L FM M L FLS FM L FM M L FLS FM L FM M L
  0 0.050 0.050 0.050 0.049 0.049 0.049 0.055 0.056 0.054 0.051 0.052 0.053
 0.1 0.09 0.09  0.09  0.09 0.09   0.09  0.08 0.09   0.08  0.08 0.09   0.09
 0.2 0.24 0.24  0.24  0.22 0.22   0.22  0.20 0.21   0.20  0.17 0.19   0.19
 0.3 0.48 0.48  0.48  0.46 0.46   0.46  0.40 0.41   0.40  0.35 0.38   0.37
 0.4 0.72 0.72  0.72  0.71 0.71   0.71  0.65 0.66   0.66  0.58 0.61   0.59
 0.5 0.90 0.90  0.90  0.89 0.89   0.89  0.84 0.85   0.84  0.78 0.80   0.79
 0.6 0.98 0.98  0.98  0.97 0.97   0.97  0.95 0.96   0.96  0.91 0.92   0.92
 0.7 0.99 0.99  0.99  0.99 0.99   0.99  0.99 0.99   0.99  0.97 0.98   0.97


   Robustness: We use the following definitions of robustness formulated by Box
(1953). See also Box & Tiao (1964), Tiku, Tan & Balakrishnan (1986).
    Criterion robustness: If the Type I error of a test is not substantially higher
under plausible alternatives than that attained under an assumed model, the test
is said to have criterion robustness.
    Efficiency robustness: If the power of a test is the highest possible (or nearly
so) under an assumed model but stays high for all plausible models, the test is
said to have efficiency robustness.
    In this section, our aim is to identify the affect of deviations from an assumed
model on the Type I error and the power of the proposed tests. For this purpose,
we use the sample models given in Section 5. These simulated values of the power
of the proposed tests and the FLS test are given in Table 6.

Table 6: Values of the power for the alternatives to SN (0, 1, 1): a = 3, n = 10; Î± =
         0.050.
            (1)               (2)               (3)               (4)
  d FLS FM L FM M L FLS FM L FM M L FLS FM L FM M L FLS FM L FM M L
  0 0.050 0.053 0.054 0.031 0.055 0.053 0.050 0.052 0.051 0.048 0.054 0.053
 0.1 0.06 0.08  0.08  0.06 0.09   0.08  0.08 0.09   0.10  0.09 0.10   0.10
 0.2 0.15 0.19  0.19  0.18 0.26   0.27  0.18 0.21   0.22  0.18 0.21   0.21
 0.3 0.28 0.33  0.33  0.35 0.44   0.45  0.35 0.38   0.39  0.35 0.38   0.38
 0.4 0.47 0.52  0.52  0.44 0.54   0.55  0.57 0.61   0.61  0.57 0.62   0.63
 0.5 0.65 0.70  0.69  0.57 0.67   0.68  0.75 0.78   0.79  0.78 0.81   0.82
 0.6 0.81 0.85  0.84  0.70 0.79   0.80  0.90 0.92   0.93  0.91 0.94   0.94
 0.7 0.92 0.94  0.95  0.89 0.96   0.96  0.98 0.99   0.99  0.96 0.98   0.98


   It is clear from Table 6 that the power of the FM L and FM M L tests are much
higher than the corresponding FLS test for all the sample models, i.e., Model (1)
through Model (4). For d = 0, the values represent Type I errors. Then it is said
that proposed tests have criterion robustness as well as the efficiency robustness.


7. Application
   Consider the data given in Montgomery (2005); pertaining to the relationship
between the radio frequency power setting and the etch rate for plasma. This is

                                      Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

Estimation and Testing in One-Way ANOVA when the Errors are Skew-Normal              87

an example of a one-way ANOVA with 4 levels of the factor and 5 replicates. The
data is given in Table 7.

                         Table 7: Radio Frequency Data.
                160 W          180 W           200 W           220 W
                  575           565             600             725
                  542           593             651             700
                  530           590             610             715
                  539           579             637             685
                  570           610             629             710


    To identify the distribution of the error terms, we use the Q-Q plot technique,
one of the well-known and widely used graphical techniques. The Q-Q plot of
normal distribution is shown in Figure 1. On the other hand, among the Q-Q plots
of the residuals obtained for various different values of the skewness parameter Î»,
SN (Âµ, Ïƒ, Î» = 1) adequately models the residuals, since the observations do not
deviate very much from the straight line, see Figure 2.




            Figure 1: Q-Q plot of the residuals for normal distribution.


    When we take the skewness parameter Î» as 1, parameter estimates and calcu-
lated F values are obtained as shown in Table 8).
    The ML and the MML estimates of Âµi are very close to the LS estimate of Âµi
with smaller standard errors. All the three tests are consistent in rejecting the
null hypothesis, H0 : there is no difference between the radio frequency powers.




                                       Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

88                                         Nuri Celik, Birdal Senoglu & Olcay Arslan




                Figure 2: Q-Q plot of the residuals for SN (Î» = 1).

           Table 8: The parameter estimates and the calculated F values.
                      Âµ       Î±1       Î±2       Î±3     Î±4       Ïƒ         F
       LS           617.75   âˆ’66.55   âˆ’30.35   7.65   89.25   22.125   66.797âˆ—
       ML           616.28   âˆ’64.22   âˆ’34.12   8.28   90.08   19.818   84.041âˆ—
       MML          616.34   âˆ’64.05   âˆ’34.68   8.08   90.65   21.108   71.125âˆ—
       *Reject H0



    However, the p values for FM L and FM M L are much smaller than the p value
of the FLS . This is due to the smaller standard errors of the ML and the MML
estimators. Therefore, their results are more reliable than normal theory results.


8. Conclusion
    Traditionally, LS estimators and the tests based on them are used in the context
of experimental design. However, efficiencies of the LS estimators are low when the
usual normality assumption is not satisfied. They are also not robust to departures
from normality.
    In this paper, we derived estimators of the model parameters in one-way
ANOVA by using the ML and the MML methodologies. New test statistics based
on these estimators were proposed for testing the equality of the treatment effects
when the distribution of the error terms is skew-normal. SN (Î») distribution cov-
ers the normal and normal-like distributions with different skewness and kurtosis
values. Therefore, it provides very flexible and simple alternative model for the
normal distribution in most practical problems.


                                      Revista Colombiana de EstadÃ­stica 38 (2015) 75â€“91

Estimation and Testing in One-Way ANOVA when the Errors are Skew-Normal             89

   Simulation studies show that the ML and the MML estimators and the tests
based on them are more efficient and robust than the corresponding LS versions
thereof.
   It can also be seen that there is no significant difference between the method-
ologies based on ML and MML even for small sample sizes. The methodology
based on ML is somewhat preferable than the methodology based on MML in
terms of efficiency and power. On the other hand, the methodology based on
MML is computationally feasible and less time consuming.


Acknowledgements
   The authors would like to thank the referees for their many helpful comments
and suggestions.
                                                             
                Received: November 2013 â€” Accepted: June 2014


References
Acitas S, Kasap S, Senoglu B, Arslan O. Robust estimation with the skew t2 distribution.(2013). Pakistan Journal of Statistics.
Arrellano Valle R, Bolfarine H, Lachos V. Skew-normal linear mixed models.(2005). Journal of Data Science.
Arslan O, Genc A. The skew generalized t (sgt) distribution as the scale mixture of a skew exponential distribution and its application in robust estimation.(2009). Statistics.
Azzalini A. A class of distributions which includes the normal ones.(1985). Scandinavian Journal of Statistics.
Azzalini A. Further results on a class of distributions which includes the normal ones.(1986). Statistica.
Azzalini A. The skew-normal distribution and related multivariate families (with discussion).(2005). Scandinavian Journal of Statistics.
Bowman K, Shenton L. Weibull distributions when the shape parameter is defined.(2001). Computational Statistics and Data Analysis.
Box G. Non-normality and test of variances.(1953). Biometrika.
Box G, Tiao G. A Bayesian approach to the importance of assumptions applied to the comparison of variances.(1964). Biometrika.
Donaldson T. Robustness of the f-test to errors of both kinds and the correlation between the numerator and denominator of the F ratio.(1968). Journal of American Statistical Association.
Garay A, Lachos V, Abanto Valle C. Nonlinear regression models based on scale mixtures of skew-normal distributions.(2011). Journal of Korean Statistical Society.
Garay A, Lachos V, Labra F, Ortega E. Statistical diagnostics for nonlinear regression models based on scale mixtures of skew normal distributions.(2013). Journal of Statistical Computation and Simulation.
Geary R. Testing for normality.(1947). Biometrika.
Gupta A, Huang W. Quadratic forms in skew normal variates.(2002). Journal of Mathematical Analysis and Applications.
Huber P. Robust Statistics.(1981). Jonh Wiley.
Islam M, Tiku M. Multiple linear regression model under nonnormality.(2004). Communication Statistics -Theory Methods.
Kantar Y, Senoglu B. A comparative study for the location and scale parameters of the weibull distribution with given shape parameter.(2008). Computers and Geosciences.
Lachos V, Bandyopadhyay D, Garay A. Heteroscedastic non linear regression models based on scale mixtures of skew-normal distributions.(2011). Statistics and Probability Letters.
Lachos V, Bolfarine H, Arellano Valle R B, Montenegro L. Likelihood based inference for multivariate skew normal regression models.(2007). Communications in Statistics.
Lachos V, Ghosh P, Arellano Valle R. Likelihood based inference for skew-normal independent linear mixed models.(2010). Statistica Sinica.
MartÃ­nez FlÃ³rez G, Vergara Cardozo S, GonzÃ¡lez L M. The family of Log-Skew-Normal Alpha-power distributions using precipitation data.(2013). Revista Colombiana de EstadÃ­stica.
Montgomery D. Design and Analysis of Experiments.(2005). John Wiley and Sons.
Pearson E.  The analysis of variance in cases of nonnormal variation.(1932). Biometrika.
Pereira J R, Marques L A, da Costa J M. An empirical comparison of EM initialization methods and model choice criteria for mixtures of SkewNormal distributions.(2012). Revista Colombiana de EstadÃ­stica.
Senoglu B, Tiku M. Analysis of variance in experimental design with nonnormal error distributions.(2001). Communication Statistical Theory Methods.
Senoglu B, Tiku M. Linear contrasts in experimental design with non-identical error distributions.(2002). Biometrical Journal.
Spjotvoll E, Aastveit H. Comparison of robust estimators on some data from field experiments.(1980). Scandinavian Journal of Statistics.
Srivastava A. Effect of nonnormality on the power of the analysis of variance test.(1959). Biometrika.
Tan W, Tiku M. Sampling Distributions in Terms of Laguerre Polynomials with Applications.(1999). Wiley Eastern.
Tiku M. Estimating the mean and standard deviation from censored normal samples.(1967). Biometrika.
Tiku M, Akkaya A. Robust Estimation and Hypothesis Testing.(2004). New Age International.
Tiku M, Tan W, Balakrishnan N. Robust Inference.(1986). Marcel Dekker.
Tukey J. A survey of sampling from contaminated distributions in I Olkin - Contributions to Probability and Statistics.(1960). Stanford University Press.
Xie F, Wei B, Lin J. Homogeneity diagnostics for skew-normal nonlinear regression models.(2009). Statistics and Probability Letters.