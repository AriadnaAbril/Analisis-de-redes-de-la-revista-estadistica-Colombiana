COMPARACIÓN POR SIMULACIÓN DE TRES MÉTODOS DE ESTIMACIÓN DE PARÁMETROS PARA LA DISTRIBUCIÓN DE GUMBELL CON MUESTRAS ALEATORIAS Y AUTOCORRELACIONADAS
Universidad Nacional de Colombia
Resumen: En este trabajo se muestra una comparación del comportamiento de los estimadores de momentos, máximo verosímiles y de momentos de probabilidad ponderados para los parámetros y percentalis de la distribución de Gumbell, por medio de la simulación estadístia bajo dos supuestos.
1. Muestras a l e a t o r i a s .
2. Muestras autocorrelacionadas de primer orden que se asimien
   aleatorias.



        Para realizar las simulaciones a gran escala se imple-
mento un programa en lenguas SAS en el computador del cen-
tro de cálculo de la Udversidad Nacional. De los resultados

                                                                111


obtenidos con dicho programa se concluye que el mejor método
para la estimación de parámetros y percentiles es el de mo-
mentos de probabilidad ponderados, ya que para todo tamaño de
muestra es prácticamente insesgado y la varianza es conq>ara-
ble con la de los otros métodos para la mayoría de los tama-
ños de muestra.



1. Diseño experimental.

1.1. Generalidades.

      El proceso en términos generales consiste en generar
muestras aleatorias de diferentes tamaños de la distribudón
de Gumbell y, para los mismos tamaños de muestra, generar ya
lores de un proceso autocorrelacionado de orden uno con dis-
tribución marginal Gumbell.

      La implementación de este procedimiento requiere enton
ees de un mecadsmo para generar valores que se distribuyan
Gumbell, y es aquí donde se puede aprovechar que la función
de distribución es inversible. Más formalmente: Una variable
aleatoria X se dice que tiene distribución de Gumbell si

          F(x) - Exp{-Exp[-((x-y)/a)] }

donde F(x) - P[X 4 x].

      La inversa de la distribución de Gumbell es:

             X - y -a m [-ln(F)]

y de la teoría estadística se conoce que F(x) tiene distribu
ción uniforme en el intervalo udtario. Por lo tanto, basta

112


generar un valor U(0,1) y aplicar la función inversa de F p£
ra generar un valor Gumbell.

        Se consideró adecuado generar muestras de tamaño n - 5,
10, 20, 30, 50, 80, 100 y 1000, ya que este rango cubre    la
gran mayoría de los tamaños de muestra posibles en estudios
aplicadoa y también los tres tipos de tamaño muestral (grande,
mediano y pequeño), de acuerdo con los teoremas límites.

        Una vez generadas las muestras, se calculan las estima
ciones de los parámetros de la distribución (a y y ) , y a par
tir de estos los percentiles x(F) donde F e fi:

      fi = {0.001, 0.010, 0.020, 0.050, 0.100, 0.250, 0.500,
           0.750, 0.900, 0.950, 0.980, 0.990, 0.999}.


        Con este procedimiento se determinan para cada muestra
las estimaciones de los parámetros y percentiles utilizando

1 Método de momentos convencionales.

2 Método de máxima verosimilitud.

3 Método de momentos de probabilidad ponderados.

        Ahora, si § denota un estimador de 6 e: [a y   X(F)], t£
mando como base, N muestras de tamaño n: la media y la varian
za de los 6 se obtiene como:


                í le] - ( I o.]/N
                          l-l
         a[o] - {1/W I e 2 - ( i / W I § )2 }
                    l-l ^           I"! ^
respectivamente, donde N - 50000 si n < 100 y N ' 2000, si

                                                                 113


n > 100.

         Para cada uno de los tres métodos y para cada muestra
de tamaño n, el sesgo de los estimadores de 6 se calcula así:


                   y [e -e ] = e -{[[e]

y el errorcuadrático medio como:


          ECM(6/n, método) = y'^[8-e] + a^ [O]


La eficacia relativa de dos métodos en la estimación de 6 da^
do un tamaño de muestra n se define como:


  EF[e. Método 1, Método 2, ni = ECM (6, Método 1, n)
                                 ECM (6, Método 2, n)


Si EF < 1, el Método 1 es más eficiente en la estimación de
6 que el Método 2. Si EF > 1 el Método 2 es más eficiente en
la estimación de 6 que el Método 1. Si EF = 1 no se puede e£
tablecer una preferenda con base en la eficiencia del Méto-
do 1 relativo al Método 2.

      Para cada uno de los tres métodos se consideraron dos
casos:

1. Una muestra de tamaño n que proviene de un proceso pura-
  mente aleatorio.

2. Una muestra de tamaño n que procede de un proceso serial-
  mente correlacionado visto como puramente aleatorio.

114


1.2. Generación de números aleatorios Gumbell.

Generación de muestras aleatorias.

           Para el caso de un proceso aleatorio las N muestras de
tamaño n fueron generadas usando la forma inversa de la di£
tribución de Gumbell. Se realizó un programa diseñado en el
paquete SAS tomando un valor nixmérico como semilla, usando
la función RANUNI que genera números aleatorios U(0,1) de
un generador multiplicativo para un módulo primo iguala
    31
2        -1. La semilla debe ser una constante numérica que es me
                31
ñor que 2 -1 que se tomó como la fecha de ejecución del
programa.

Generación de un Proceso             autocorrelacionado.

           Para e l proceso serialmente correlacionado los datos
fueron generado usando e l método sugerido por H.A. THOMAS,
(1976) a s í :


                     h = ^ h - 1 -^ ^' •" ^z ^'^ «1

que representa un proceso de Markov, donde la correlación
de primer orden de los Z.. y 6 . es una variable aleatoria
normalmente distribdda con media cero y varianza uno, inde
pendiente de Zj._- Í6.. son generados         mediante la función
RANNOR). De la misma manera Z. esta normalmente distribdda
con media cero y varianza uno.

            Dando los valores de Z., los correspondientes valores
de F(Z.) ' P[Z 4 z.] están dados por:

                     Hz^) ' j \^i2)dz ,

                                                                           115


donde i ¡ , es la función de densidad para la distribución nor-
mal. Los valores de X^ serialmente correlacionados para               la
dstribución de Gumbell fueron obteddos así:

                X^ = y - aln {- ln (F(z^)) }

Los valores de 6. - 1,2,...,n fueron generados aplicando la
técdca de BOX y MULLER (1958) de la función RANOR de SAS.
El valor de P    se tomó como 0.5, lo suficientemente grande
para asegurar el efecto de la correlación serial.




2. Narco teórico.

Momentos de probabilidad ponderados.

      Greenwood y otros (1979) defideron momentos de proba-
bilidad ponderados así:




donde^,/,kcc R. Si l , j , k son enteros no negativos, M. .- i, es
                                                         A . , j ,R
proporcionalal momento .¿-ésimo respecto al origen de la es-
tadística de orden (y+l)-ésima, de una muestra de tamaño
ik + j + 1 ) , En especial:

     w^y,fe-»[i+^' «^+^J ^[\j+i),ik+j+i)''^

donde 6[ ,] corresponde a la función Beta.

      Para / - O y 1 - fe, se escribirá:

116


          M(fe)-"i,o,fe-<^/'^+^>^[\fe+il                   (^)

se probó que ^fu\ es un estimador insesgado de M,i v para una
muestra aleatoria de tamaño n, donde k es un entero no nega-
tivo. ^ f h \ se obtiene como sigue: Supongamos que las n obser^
vaciones están ordenadas en forma ascendente desde X.     hasta

V
      El número total de posibles formas de      obtener un con-
junto de submuestras de tamaño ík+1) es:



                       -CJ
el número de estas N submuestras que contienen X., la obser-
vación más pequeña es:


                      «1


similarmente, para las N submuestras que contienen x. pero
no X., es decir, el número de submuestras posibles en los
cuales x^ es la observación más    pequeña es:


                      "2


En general el número de submuestras de tamaño (fe+l) que con
tienen X- pero dnguna de las anteriores (X,,... ,X . j) , es




Nótese que a i I ^ n - fe+1, N . - 0.

                                                               117


      Dado que existe un total de N posibles submuestras, de
N . , en los cuales X. puede ser la observación más pequeña,
en un estimador de probabilidad de que X^ sea la observacióa
más pequeña en una submuestra de tamaño (fe+1) tomada de una
muestra de tamaño n es:

                       ^l
                       ir           , " : ' ) / ( : , )


Note que




es un estimador no paramétrico y cuya distribución no depen-
de de la densidad de la variable involucrada. Por lo tanto,
un estimador del mídmo de una submuestra de tamaño (fe+1) ex
traída de una nuestra de tamaño n es:



     EK,fcfi/«i-j/-¿

pero de la relación establecida en (1) se obtiene


     M          l/(fe+l)     I     Xj
         (fe)
                            l'l



                     A.-1         \ k

                 ,    %^          fn-l

118


El valor esperado de X^ viene dado por:


         E[X] ' i h ^     ¡ \ p ^ - ^ (l-F)'^-^ciF


donde O = 0(F) y F = F(0),     sí el valor esperado M... puede
ser expresado como:




                      • (l-F)*^ dF .


Donde j ' l - l . Esto denota que:
             n_i_fe
              -1-"^ fn-l.k\
              j l [ j I F^a-F)^-^-^-^
           - [F + d-Ff-'^-l-l ,

donde

         E[M(fe)] - j O (l-F)'^(ÍF-M(j^j .
                      o

De donde se concluye que este estimador de ^/L-V es insesgado.

        A partir de este resultado, se pueden obtener estimad£
res de los parámetros de la distribución de Gumbella partir
de MfiLx como sigue:

                                                                          119


                      a = [M^^j - 2M(jj] / l n ( 2 )


                      ^ = **(o) - ^ "fe •




3. A n á l i s i s de r e s u l t a d o s .

3>1> Parámetro de localización para muestras a l e a t o r i a s .
      3.1.1. Sesgo.

        Como podemos observar en forma clara en la figura (2),
Tabla (1) se presentó una jerarquía. El método de momentos
es el más sesgado, seguido por el método de máxima verosimi-
litud. El método de momentos de probabilidad ponderados pre-
senta un insesgamiento muy notorio para todos los tamaños de
muestra examinados, por supuesto es el mejor de los tres.


        En los tres métodos podemos ver claramente la tenden-
cia a sobreestimar e l parámetro.

       Los tres métodos pueden ser comparados en tamaños             de
muestra grandes.


      3.1.2. Varianza.

       Como podemos observar en la figura (4) Tabla (1), la
varianza disminuye cuando n aimenta.

       El método de momentos de probabilidad ponderados pre-
senta varianza mínima para todo n, segdda del método dem^L

120


ma verosimilitud y momentos convencional.

         Para todos los tamaños de muestras se observa que mo-
mentos de probabilidad ponderados presenta varianza mínima,
aunque cuando n es mayor de 20 las varianzas son practica-
mente iguales.


      3.1.3. Error cuadrático medio.

         En la figura (6) Tabla (1), se puede observar que el
mejor método es momentos de probabilidad ponderados seguido
por máxima verosimilitud y momentos convencionales.



3.2. Parámetro de dispersión para muestras aleatorias.


      3.2.1. Sesgo.

      Como se observa en la figura (1) Tabla (1), los tres
métodos presentan una subestimación a 4 1 .

      Al igual que en los casos anteriores en la figura (1)
Tabla (1) se observa que él sesgo decrece exponencialmente
para todos los tamaños de muestra analizados en los tres mé
todos.

      Podemos ver a lo largo de todos los tamaños de muestra
analizados una jerarquía muy notoria, momentos de probabili-
dad ponderados es el más insesgado, segddo por máxima vero-
similitud y momentos convencionales.

       El método de momentos de probabilidad ponderado es muy
bueno para muestras pequeñas y prácticamente insesgado para
tamaño de muestra superior a 10.

                                                                 121


     3.2.2. Varianza.

      El estimador máximo verosímil es el que presenta varian
za mídma para todos los tamaños de muestra como lo podemos
ver en la figura (3) Tabla (1).

      Para los métodos de momento y momentos de probabilidad
ponderados la varianza está en función de n.

      Para un n pequeño (n - 5, 10), momentos convencionales
es mayor o igual que momentos de probabilidad.

      Para un n > 20 momentos de probabilidad ponderados es
mayor que momentos convencionales.

      Se observa que a medida que aumenta el tamaño de mues-
tra, la diferencia que se presenta entre las varianzas    del
método de máxima verosimilitud y el método de momentos     de
probabilidad ponderados es cada vez más pequeño, hasta    ser
aproximadamente nula a partir de un n mayor que 50. La va-
rianza de momentos es muy grande en comparación con las ante-
riores .


     3.2.3. Error cuadrático m e d o .

      En la figura (5) Tabla (1), podemos ver que el método
de máxima verosimilitud es el mejor para todo n.

      Para los métodos de momentos y momentos de probabili-
dad ponderados el error cuadrático m e d o esta en función de
n.

      Para muestras pequefias (n - 5 ) , momentos convenciona-
les es mayor o igual que momentos de probabilidad ponderados.

122


       Para muestras en las cuales (n > 10), momentos de pro-
babilidad ponderados es mayor que momentos convencionales.

       El error cuadrático medio de máxima verosimilitud     es
aproximadamente 0.75 del de momentos de probabilidad ponde-
rados .

       Para alfa el cambio entre error sistemático (sesgo) y
error aleatorio (varianza) resulta desfavorable en términos
del error cuadrático medo. Sin embargo es mejor en general
d   método de momentos de probabilidad ponderado por insesga-
miento mientras que el método de máxima verosimilitud      por
varianza.

       Por la utilización de computadores es más fácil traba-
jar con momentos de probabilidad ponderados, pero con la pro^
fusión de computadores y programas, los dos métodos son igual
mente utilizables.



3.3. Percentiles para muestras aleatorias.


      3.3.1. Sesgo.

       Como se puede observar en la Tabla (2) existe    una je-
rarquía muy clara. El método de momentos de probabilidad pon
derados es el mejor de los tres métodos para todo n, el mé-
todo de máxima verosimilitud se encuentra en el medio y      el
peor de todos es el método de momentos convencionales.

       Para los métodos de momentos de probabilidad pondera-
dos y m^xíTf"* verosimilitud el sesgo es muy similar en mues-
tras de tamaño mayores o iguales a 100.

                                                                 123


        Dentro del rango medio (0.25 - 0.75) los percentiles
se estiman mucho mejor que para los demás.


       3.3.2. Varianza.

        Como se observa en la Tabla (5) en los percentiles dcd
rango medio, la varianza de momentos de probabilidad ponde-
rados es menor que la de máxima verosimilitud y la de momen
tos convencionales.

        En los extremos de la Tabla (4) se observa que la va-
rianza de máxima verosimilitud es la menor, pero para mues-
tras grandes, los métodos de momentos de probabilidad ponde^
rados y máxima verosimilitud son comprables.

       Para todos los tamaños de muestra analizados, el meto
todo de momentos posee la varianza máa grande.


       3.3.3. Error cuadrático medo.

       En la Tabla (5) podemos darnos cuenta que para el ran
go medio (0.25 - 0.75) es d mátodo de momentos de probabi-
lidad ponderados es el mejor, seguido por máxima verosimili
tud.



4. Conclusiones.

       La coaparación de \m nuevo método de estimación, d n^
todo de momentos de probabilidad ponderados con otros    dos
métodos más antiguos, TO^XÍIM verosimilitud y momentos conven
dónales fue explorado mediante un programa en el paquete

124


SAS. Los experimentos aportaron la estimación de los parame
tros y cuantiles de un proceso puramente aleatorio y un pr£
ceso autocorrelationado tratado como puramente aleatorio.
Las conclusiones derivadas de estos experimentos son:


k . t . Para un proceso puramente aleatorio.

      El sesgo de momentos de probabilidad ponderados es sim
pre el más pequeño para todos los tamaños de muestra estudia
dos. Se nota que desde muestras de tamaño pequeño es      casi
despreciable y a medida que n aumenta. Las estimaciones    de
máxima verosimilitud se acercan a las de momentos de proba-
bilidad ponderada.

      El método de momentos de probabilidad ponderados cam-
bia una gran cantidad de error aistemático por error aleato-
rio para tamaños de muestra muy pequeños (n - 5, 10, 20) y,
en general; para los percentiles que están fuera de la banda
central (0,25 - 0,75). En otros casos este cambio no afecta
prácticamente en nada y resulta mucho mejor momentos de pro-
babilidad ponderado que máxima verosimilitud. Es decir: si
el sesgo es la principal preocupación el mejor en todos los
casos es el método de momentos de probabilidad ponderados.
En el supuesto que el sesgo sea secundario será mejor usar
el método de máxima verosimilitud, cuando se estima con tama
ños de muestra pequeña (n - 5, 10, 20) o para percentiles
que se encuentran en la franja extema (0,25 - 0,75).

      En ningún caso se recomienda el uso del   método de n»
mentos convencionales.

                                                               125


4.2. Para un proceso autocorrelacionado.

      Para el proceso autocorrelacionado visto como puramen
te aleatorio se conservan los mismos resultados obtenidos
en el caso anterior, con la diferencia de que presenta ma-
yor sesgo y mayor varianza. Sin embargo, se puede notar que
los estimadores son asintóticamente insesgados pero con ve-
locidad de convergencia menor a la de una muestra aleatoria.
Por último, si se sabe que las observaciones provienen de un
proceso autocorrelacionado, basta con tener una muestra   de
tamaño moderado para garantizar buenos resultados. En el ca^
so de muestras pequeñas se recomienda tener mucho cuidado,
porque los errores (sesgo y varianza) pueden ser demasiado
grandes dependiendo del   área de aplicación.

126




BIBLIOGRAFÍA
Ahrens, J.H., U. Dieter (1970), Pseuso-randon Numbers: A new proposal for choice of Multipliers. Computing 12, 223-246.
Allard, J.L., A.R. Dobell and T.E. Hull (1963). Mixed, Comgruential Randon Number Generators for Decimal Machine. JACM 10, 131-141.
Arvillias, A . C , and D.G. Maritsas (1978). Particioning the period of a Class m-sequences and Aplications to pseudorandom Number Generation, JACM 25, 675-686.
Barnett, V.D. (1962), The Behavior of pseudo-dandom sequence Generated on Computers by the Multiplicative Congruential Method. Math. 16, 63-69,
Bedall, F.K. and H. Zimmermann (1976). On the Generation of N(y,a)-Distributed Random Vectors by M(0,l)-distributed Random Numbers. Biometrische Zeitschrift 18, 467-472.
Bell J.R. (1968). Normal Random Deviates, CACM 11, 498.
Butler, E.L. (1970). Algorithm 270: General Random Number Generator, CACM 13, 49-52.
Clay, S.C.R.D. Fardo and M. Manzumdar (1975). On using the Box-Muller Transformation with Multiplicative Congruential Pseudo-Random Number Generators, Appl. Stat. 24, 132-135.
Claustriaux, J.J. (1976). Generation and validity Control of Pseudo-Random Number on a Computer with 16 Bit Words, Revue de Statistique Appliques 24, 75-88.
Coldwell, R.L. (1974). Correlational Defects in the Standart IBM 360 Random Number Generator and Clasical Ideal Gas Correlational Function. J. Computational phydsics 14, 223-226.
Dieter, U. (1972). Statistical Interdependiente of Pseudo Ramdom Number Generated by the linear Congruential Method, in Applications of Number Theory to Numerical Analysis. edited by S.K. Zeremba. Academic Press. New York. 287-318.
Downham, D.Y. and F.D.K. Robers (1967). Multiplicative Congruential Pseudo-Random Number Generators. Comp. J. 10, 74-77.
Fuller A.T. (1976). The Period of Pseudo-Random Numbers Generated by Lehmer's Congruential Method. Comp. J. 19. 173-177.
Greenberger, M. (1961a). Notes on a New Pseudo-Random Number generator, JACM 8, 163-167.
Greenwood, J.A. Landwehr, J.M. Mátalas, N.C., and Wallis, J.R. (1979). Probability Weighted Moments: Definition and Relation to parameters of several Distributions Expresable in Inverse form.
Galembos, J. (1978). The Asymptotic theory of extreme Order Statistics. Weley, New York.
Hemmerle, W.J. (1969). Generating Pseudo-Random Numbers on a Two's Complement Machine such as the IBM 360, CACM 12, 382-383.
Hosting, J.R.M. (1984). Testing Whether the shape parameter is Zero in the generalized extreme - value distribution. Biometrika 71, in press.
Johnson, M.E. and J.S. Ramberg (1977). Elliptically Symmetric Distributions: Characterizations and Random Variate Generation. Proceedings of the Statistical Computing Section. American Statistical Association, Washington, D.C, 262-265.
Jenkinson, A.TF. (1969). Statistics of extremes WMO Tecnical NOTE 98. Genera: World Meteorological office.
Lewis, P.A.W., C.S. Goodman, and J.W. Miller (1969). A Pseudorandom Number Generator for the System 360, IBM. Systems J. 8, 136-146.
Liniger, W. (1961). On a Method by D.H. Lehmer for the generation of Pseudo-Random Numbers. Numer. Math. 3. 265-270.
Landwehr J.M., Mátalas, N.C and Wallis. J.R., Serve Comparisons of flood statistics in realand log Space, Water Resour. res., 14 (5) 902-920, 1978.
Londwehr, J.M.: Matacas, N.C and Wallis, J.R. (1979). Probability Weighted moments compared with some tradicional Thechniques in estimating Gumbell parameter and quantiles. Water Resour. rec: 15.
Mars, P. and A.J. Miller (1977). Theory and Desing of a Digital Stochastic Computer Random Number Generador, Mathematics and Computers is Simulation 19, 193-216.
Smith W.B., and R.R. Hocking (1972). Wishart Variate Generator,Appl. Stat. 21. 341-345.

